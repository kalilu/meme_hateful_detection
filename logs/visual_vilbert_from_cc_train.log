2020-06-10T20:39:54 INFO: Loading datasets
2020-06-10T20:40:02 INFO: CUDA Device 0 is: Tesla T4
2020-06-10T20:40:06 INFO: Torch version is: 1.5.0+cu101
2020-06-10T20:40:06 INFO: Loading checkpoint
2020-06-10T20:40:20 INFO: Copying model.bert.embeddings.word_embeddings.weight from model.bert.embeddings.word_embeddings.weight
2020-06-10T20:40:20 INFO: Copying model.bert.embeddings.position_embeddings.weight from model.bert.embeddings.position_embeddings.weight
2020-06-10T20:40:20 INFO: Copying model.bert.embeddings.token_type_embeddings.weight from model.bert.embeddings.token_type_embeddings.weight
2020-06-10T20:40:20 INFO: Copying model.bert.embeddings.LayerNorm.weight from model.bert.embeddings.LayerNorm.weight
2020-06-10T20:40:20 INFO: Copying model.bert.embeddings.LayerNorm.bias from model.bert.embeddings.LayerNorm.bias
2020-06-10T20:40:20 INFO: Copying model.bert.embeddings.token_type_embeddings_visual.weight from model.bert.embeddings.token_type_embeddings_visual.weight
2020-06-10T20:40:20 INFO: Copying model.bert.embeddings.position_embeddings_visual.weight from model.bert.embeddings.position_embeddings_visual.weight
2020-06-10T20:40:20 INFO: Copying model.bert.embeddings.projection.weight from model.bert.embeddings.projection.weight
2020-06-10T20:40:20 INFO: Copying model.bert.embeddings.projection.bias from model.bert.embeddings.projection.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.0.attention.self.query.weight from model.bert.encoder.layer.0.attention.self.query.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.0.attention.self.query.bias from model.bert.encoder.layer.0.attention.self.query.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.0.attention.self.key.weight from model.bert.encoder.layer.0.attention.self.key.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.0.attention.self.key.bias from model.bert.encoder.layer.0.attention.self.key.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.0.attention.self.value.weight from model.bert.encoder.layer.0.attention.self.value.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.0.attention.self.value.bias from model.bert.encoder.layer.0.attention.self.value.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.0.attention.output.dense.weight from model.bert.encoder.layer.0.attention.output.dense.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.0.attention.output.dense.bias from model.bert.encoder.layer.0.attention.output.dense.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.0.attention.output.LayerNorm.weight from model.bert.encoder.layer.0.attention.output.LayerNorm.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.0.attention.output.LayerNorm.bias from model.bert.encoder.layer.0.attention.output.LayerNorm.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.0.intermediate.dense.weight from model.bert.encoder.layer.0.intermediate.dense.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.0.intermediate.dense.bias from model.bert.encoder.layer.0.intermediate.dense.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.0.output.dense.weight from model.bert.encoder.layer.0.output.dense.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.0.output.dense.bias from model.bert.encoder.layer.0.output.dense.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.0.output.LayerNorm.weight from model.bert.encoder.layer.0.output.LayerNorm.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.0.output.LayerNorm.bias from model.bert.encoder.layer.0.output.LayerNorm.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.1.attention.self.query.weight from model.bert.encoder.layer.1.attention.self.query.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.1.attention.self.query.bias from model.bert.encoder.layer.1.attention.self.query.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.1.attention.self.key.weight from model.bert.encoder.layer.1.attention.self.key.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.1.attention.self.key.bias from model.bert.encoder.layer.1.attention.self.key.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.1.attention.self.value.weight from model.bert.encoder.layer.1.attention.self.value.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.1.attention.self.value.bias from model.bert.encoder.layer.1.attention.self.value.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.1.attention.output.dense.weight from model.bert.encoder.layer.1.attention.output.dense.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.1.attention.output.dense.bias from model.bert.encoder.layer.1.attention.output.dense.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.1.attention.output.LayerNorm.weight from model.bert.encoder.layer.1.attention.output.LayerNorm.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.1.attention.output.LayerNorm.bias from model.bert.encoder.layer.1.attention.output.LayerNorm.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.1.intermediate.dense.weight from model.bert.encoder.layer.1.intermediate.dense.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.1.intermediate.dense.bias from model.bert.encoder.layer.1.intermediate.dense.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.1.output.dense.weight from model.bert.encoder.layer.1.output.dense.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.1.output.dense.bias from model.bert.encoder.layer.1.output.dense.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.1.output.LayerNorm.weight from model.bert.encoder.layer.1.output.LayerNorm.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.1.output.LayerNorm.bias from model.bert.encoder.layer.1.output.LayerNorm.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.2.attention.self.query.weight from model.bert.encoder.layer.2.attention.self.query.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.2.attention.self.query.bias from model.bert.encoder.layer.2.attention.self.query.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.2.attention.self.key.weight from model.bert.encoder.layer.2.attention.self.key.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.2.attention.self.key.bias from model.bert.encoder.layer.2.attention.self.key.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.2.attention.self.value.weight from model.bert.encoder.layer.2.attention.self.value.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.2.attention.self.value.bias from model.bert.encoder.layer.2.attention.self.value.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.2.attention.output.dense.weight from model.bert.encoder.layer.2.attention.output.dense.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.2.attention.output.dense.bias from model.bert.encoder.layer.2.attention.output.dense.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.2.attention.output.LayerNorm.weight from model.bert.encoder.layer.2.attention.output.LayerNorm.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.2.attention.output.LayerNorm.bias from model.bert.encoder.layer.2.attention.output.LayerNorm.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.2.intermediate.dense.weight from model.bert.encoder.layer.2.intermediate.dense.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.2.intermediate.dense.bias from model.bert.encoder.layer.2.intermediate.dense.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.2.output.dense.weight from model.bert.encoder.layer.2.output.dense.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.2.output.dense.bias from model.bert.encoder.layer.2.output.dense.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.2.output.LayerNorm.weight from model.bert.encoder.layer.2.output.LayerNorm.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.2.output.LayerNorm.bias from model.bert.encoder.layer.2.output.LayerNorm.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.3.attention.self.query.weight from model.bert.encoder.layer.3.attention.self.query.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.3.attention.self.query.bias from model.bert.encoder.layer.3.attention.self.query.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.3.attention.self.key.weight from model.bert.encoder.layer.3.attention.self.key.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.3.attention.self.key.bias from model.bert.encoder.layer.3.attention.self.key.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.3.attention.self.value.weight from model.bert.encoder.layer.3.attention.self.value.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.3.attention.self.value.bias from model.bert.encoder.layer.3.attention.self.value.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.3.attention.output.dense.weight from model.bert.encoder.layer.3.attention.output.dense.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.3.attention.output.dense.bias from model.bert.encoder.layer.3.attention.output.dense.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.3.attention.output.LayerNorm.weight from model.bert.encoder.layer.3.attention.output.LayerNorm.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.3.attention.output.LayerNorm.bias from model.bert.encoder.layer.3.attention.output.LayerNorm.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.3.intermediate.dense.weight from model.bert.encoder.layer.3.intermediate.dense.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.3.intermediate.dense.bias from model.bert.encoder.layer.3.intermediate.dense.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.3.output.dense.weight from model.bert.encoder.layer.3.output.dense.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.3.output.dense.bias from model.bert.encoder.layer.3.output.dense.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.3.output.LayerNorm.weight from model.bert.encoder.layer.3.output.LayerNorm.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.3.output.LayerNorm.bias from model.bert.encoder.layer.3.output.LayerNorm.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.4.attention.self.query.weight from model.bert.encoder.layer.4.attention.self.query.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.4.attention.self.query.bias from model.bert.encoder.layer.4.attention.self.query.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.4.attention.self.key.weight from model.bert.encoder.layer.4.attention.self.key.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.4.attention.self.key.bias from model.bert.encoder.layer.4.attention.self.key.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.4.attention.self.value.weight from model.bert.encoder.layer.4.attention.self.value.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.4.attention.self.value.bias from model.bert.encoder.layer.4.attention.self.value.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.4.attention.output.dense.weight from model.bert.encoder.layer.4.attention.output.dense.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.4.attention.output.dense.bias from model.bert.encoder.layer.4.attention.output.dense.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.4.attention.output.LayerNorm.weight from model.bert.encoder.layer.4.attention.output.LayerNorm.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.4.attention.output.LayerNorm.bias from model.bert.encoder.layer.4.attention.output.LayerNorm.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.4.intermediate.dense.weight from model.bert.encoder.layer.4.intermediate.dense.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.4.intermediate.dense.bias from model.bert.encoder.layer.4.intermediate.dense.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.4.output.dense.weight from model.bert.encoder.layer.4.output.dense.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.4.output.dense.bias from model.bert.encoder.layer.4.output.dense.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.4.output.LayerNorm.weight from model.bert.encoder.layer.4.output.LayerNorm.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.4.output.LayerNorm.bias from model.bert.encoder.layer.4.output.LayerNorm.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.5.attention.self.query.weight from model.bert.encoder.layer.5.attention.self.query.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.5.attention.self.query.bias from model.bert.encoder.layer.5.attention.self.query.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.5.attention.self.key.weight from model.bert.encoder.layer.5.attention.self.key.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.5.attention.self.key.bias from model.bert.encoder.layer.5.attention.self.key.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.5.attention.self.value.weight from model.bert.encoder.layer.5.attention.self.value.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.5.attention.self.value.bias from model.bert.encoder.layer.5.attention.self.value.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.5.attention.output.dense.weight from model.bert.encoder.layer.5.attention.output.dense.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.5.attention.output.dense.bias from model.bert.encoder.layer.5.attention.output.dense.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.5.attention.output.LayerNorm.weight from model.bert.encoder.layer.5.attention.output.LayerNorm.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.5.attention.output.LayerNorm.bias from model.bert.encoder.layer.5.attention.output.LayerNorm.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.5.intermediate.dense.weight from model.bert.encoder.layer.5.intermediate.dense.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.5.intermediate.dense.bias from model.bert.encoder.layer.5.intermediate.dense.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.5.output.dense.weight from model.bert.encoder.layer.5.output.dense.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.5.output.dense.bias from model.bert.encoder.layer.5.output.dense.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.5.output.LayerNorm.weight from model.bert.encoder.layer.5.output.LayerNorm.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.5.output.LayerNorm.bias from model.bert.encoder.layer.5.output.LayerNorm.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.6.attention.self.query.weight from model.bert.encoder.layer.6.attention.self.query.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.6.attention.self.query.bias from model.bert.encoder.layer.6.attention.self.query.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.6.attention.self.key.weight from model.bert.encoder.layer.6.attention.self.key.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.6.attention.self.key.bias from model.bert.encoder.layer.6.attention.self.key.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.6.attention.self.value.weight from model.bert.encoder.layer.6.attention.self.value.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.6.attention.self.value.bias from model.bert.encoder.layer.6.attention.self.value.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.6.attention.output.dense.weight from model.bert.encoder.layer.6.attention.output.dense.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.6.attention.output.dense.bias from model.bert.encoder.layer.6.attention.output.dense.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.6.attention.output.LayerNorm.weight from model.bert.encoder.layer.6.attention.output.LayerNorm.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.6.attention.output.LayerNorm.bias from model.bert.encoder.layer.6.attention.output.LayerNorm.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.6.intermediate.dense.weight from model.bert.encoder.layer.6.intermediate.dense.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.6.intermediate.dense.bias from model.bert.encoder.layer.6.intermediate.dense.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.6.output.dense.weight from model.bert.encoder.layer.6.output.dense.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.6.output.dense.bias from model.bert.encoder.layer.6.output.dense.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.6.output.LayerNorm.weight from model.bert.encoder.layer.6.output.LayerNorm.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.6.output.LayerNorm.bias from model.bert.encoder.layer.6.output.LayerNorm.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.7.attention.self.query.weight from model.bert.encoder.layer.7.attention.self.query.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.7.attention.self.query.bias from model.bert.encoder.layer.7.attention.self.query.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.7.attention.self.key.weight from model.bert.encoder.layer.7.attention.self.key.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.7.attention.self.key.bias from model.bert.encoder.layer.7.attention.self.key.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.7.attention.self.value.weight from model.bert.encoder.layer.7.attention.self.value.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.7.attention.self.value.bias from model.bert.encoder.layer.7.attention.self.value.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.7.attention.output.dense.weight from model.bert.encoder.layer.7.attention.output.dense.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.7.attention.output.dense.bias from model.bert.encoder.layer.7.attention.output.dense.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.7.attention.output.LayerNorm.weight from model.bert.encoder.layer.7.attention.output.LayerNorm.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.7.attention.output.LayerNorm.bias from model.bert.encoder.layer.7.attention.output.LayerNorm.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.7.intermediate.dense.weight from model.bert.encoder.layer.7.intermediate.dense.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.7.intermediate.dense.bias from model.bert.encoder.layer.7.intermediate.dense.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.7.output.dense.weight from model.bert.encoder.layer.7.output.dense.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.7.output.dense.bias from model.bert.encoder.layer.7.output.dense.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.7.output.LayerNorm.weight from model.bert.encoder.layer.7.output.LayerNorm.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.7.output.LayerNorm.bias from model.bert.encoder.layer.7.output.LayerNorm.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.8.attention.self.query.weight from model.bert.encoder.layer.8.attention.self.query.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.8.attention.self.query.bias from model.bert.encoder.layer.8.attention.self.query.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.8.attention.self.key.weight from model.bert.encoder.layer.8.attention.self.key.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.8.attention.self.key.bias from model.bert.encoder.layer.8.attention.self.key.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.8.attention.self.value.weight from model.bert.encoder.layer.8.attention.self.value.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.8.attention.self.value.bias from model.bert.encoder.layer.8.attention.self.value.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.8.attention.output.dense.weight from model.bert.encoder.layer.8.attention.output.dense.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.8.attention.output.dense.bias from model.bert.encoder.layer.8.attention.output.dense.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.8.attention.output.LayerNorm.weight from model.bert.encoder.layer.8.attention.output.LayerNorm.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.8.attention.output.LayerNorm.bias from model.bert.encoder.layer.8.attention.output.LayerNorm.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.8.intermediate.dense.weight from model.bert.encoder.layer.8.intermediate.dense.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.8.intermediate.dense.bias from model.bert.encoder.layer.8.intermediate.dense.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.8.output.dense.weight from model.bert.encoder.layer.8.output.dense.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.8.output.dense.bias from model.bert.encoder.layer.8.output.dense.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.8.output.LayerNorm.weight from model.bert.encoder.layer.8.output.LayerNorm.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.8.output.LayerNorm.bias from model.bert.encoder.layer.8.output.LayerNorm.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.9.attention.self.query.weight from model.bert.encoder.layer.9.attention.self.query.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.9.attention.self.query.bias from model.bert.encoder.layer.9.attention.self.query.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.9.attention.self.key.weight from model.bert.encoder.layer.9.attention.self.key.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.9.attention.self.key.bias from model.bert.encoder.layer.9.attention.self.key.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.9.attention.self.value.weight from model.bert.encoder.layer.9.attention.self.value.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.9.attention.self.value.bias from model.bert.encoder.layer.9.attention.self.value.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.9.attention.output.dense.weight from model.bert.encoder.layer.9.attention.output.dense.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.9.attention.output.dense.bias from model.bert.encoder.layer.9.attention.output.dense.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.9.attention.output.LayerNorm.weight from model.bert.encoder.layer.9.attention.output.LayerNorm.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.9.attention.output.LayerNorm.bias from model.bert.encoder.layer.9.attention.output.LayerNorm.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.9.intermediate.dense.weight from model.bert.encoder.layer.9.intermediate.dense.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.9.intermediate.dense.bias from model.bert.encoder.layer.9.intermediate.dense.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.9.output.dense.weight from model.bert.encoder.layer.9.output.dense.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.9.output.dense.bias from model.bert.encoder.layer.9.output.dense.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.9.output.LayerNorm.weight from model.bert.encoder.layer.9.output.LayerNorm.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.9.output.LayerNorm.bias from model.bert.encoder.layer.9.output.LayerNorm.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.10.attention.self.query.weight from model.bert.encoder.layer.10.attention.self.query.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.10.attention.self.query.bias from model.bert.encoder.layer.10.attention.self.query.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.10.attention.self.key.weight from model.bert.encoder.layer.10.attention.self.key.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.10.attention.self.key.bias from model.bert.encoder.layer.10.attention.self.key.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.10.attention.self.value.weight from model.bert.encoder.layer.10.attention.self.value.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.10.attention.self.value.bias from model.bert.encoder.layer.10.attention.self.value.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.10.attention.output.dense.weight from model.bert.encoder.layer.10.attention.output.dense.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.10.attention.output.dense.bias from model.bert.encoder.layer.10.attention.output.dense.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.10.attention.output.LayerNorm.weight from model.bert.encoder.layer.10.attention.output.LayerNorm.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.10.attention.output.LayerNorm.bias from model.bert.encoder.layer.10.attention.output.LayerNorm.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.10.intermediate.dense.weight from model.bert.encoder.layer.10.intermediate.dense.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.10.intermediate.dense.bias from model.bert.encoder.layer.10.intermediate.dense.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.10.output.dense.weight from model.bert.encoder.layer.10.output.dense.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.10.output.dense.bias from model.bert.encoder.layer.10.output.dense.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.10.output.LayerNorm.weight from model.bert.encoder.layer.10.output.LayerNorm.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.10.output.LayerNorm.bias from model.bert.encoder.layer.10.output.LayerNorm.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.11.attention.self.query.weight from model.bert.encoder.layer.11.attention.self.query.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.11.attention.self.query.bias from model.bert.encoder.layer.11.attention.self.query.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.11.attention.self.key.weight from model.bert.encoder.layer.11.attention.self.key.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.11.attention.self.key.bias from model.bert.encoder.layer.11.attention.self.key.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.11.attention.self.value.weight from model.bert.encoder.layer.11.attention.self.value.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.11.attention.self.value.bias from model.bert.encoder.layer.11.attention.self.value.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.11.attention.output.dense.weight from model.bert.encoder.layer.11.attention.output.dense.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.11.attention.output.dense.bias from model.bert.encoder.layer.11.attention.output.dense.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.11.attention.output.LayerNorm.weight from model.bert.encoder.layer.11.attention.output.LayerNorm.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.11.attention.output.LayerNorm.bias from model.bert.encoder.layer.11.attention.output.LayerNorm.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.11.intermediate.dense.weight from model.bert.encoder.layer.11.intermediate.dense.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.11.intermediate.dense.bias from model.bert.encoder.layer.11.intermediate.dense.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.11.output.dense.weight from model.bert.encoder.layer.11.output.dense.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.11.output.dense.bias from model.bert.encoder.layer.11.output.dense.bias
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.11.output.LayerNorm.weight from model.bert.encoder.layer.11.output.LayerNorm.weight
2020-06-10T20:40:20 INFO: Copying model.bert.encoder.layer.11.output.LayerNorm.bias from model.bert.encoder.layer.11.output.LayerNorm.bias
2020-06-10T20:40:20 INFO: Copying model.bert.pooler.dense.weight from model.bert.pooler.dense.weight
2020-06-10T20:40:20 INFO: Copying model.bert.pooler.dense.bias from model.bert.pooler.dense.bias
2020-06-10T20:40:20 INFO: Pretrained model loaded
2020-06-10T20:40:21 INFO: ===== Model =====
2020-06-10T20:40:21 INFO: VisualBERT(
  (model): VisualBERTForClassification(
    (bert): VisualBERTBase(
      (embeddings): BertVisioLinguisticEmbeddings(
        (word_embeddings): Embedding(30522, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (token_type_embeddings_visual): Embedding(2, 768)
        (position_embeddings_visual): Embedding(512, 768)
        (projection): Linear(in_features=2048, out_features=768, bias=True)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (classifier): Sequential(
      (0): BertPredictionHeadTransform(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      )
      (1): Linear(in_features=768, out_features=2, bias=True)
    )
  )
  (losses): Losses()
)
2020-06-10T20:40:21 INFO: Total Parameters: 112044290. Trained Parameters: 112044290
2020-06-10T20:40:21 INFO: Starting training...
2020-06-10T20:40:23 WARNING: /pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha)

2020-06-10T20:40:23 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-10T20:43:05 INFO: progress: 100/22000, train/total_loss: 0.6647, train/total_loss/avg: 0.6647, train/hateful_memes/cross_entropy: 0.6647, train/hateful_memes/cross_entropy/avg: 0.6647, max mem: 11406.0, experiment: run, epoch: 1, num_updates: 100, iterations: 100, max_updates: 22000, lr: 0., ups: 0.61, time: 02m 43s 912ms, time_since_start: 03m 10s 225ms, eta: 09h 58m 16s 757ms
2020-06-10T20:45:52 INFO: progress: 200/22000, train/total_loss: 0.6647, train/total_loss/avg: 0.6704, train/hateful_memes/cross_entropy: 0.6647, train/hateful_memes/cross_entropy/avg: 0.6704, max mem: 11406.0, experiment: run, epoch: 1, num_updates: 200, iterations: 200, max_updates: 22000, lr: 0., ups: 0.60, time: 02m 47s 310ms, time_since_start: 05m 57s 535ms, eta: 10h 07m 53s 591ms
2020-06-10T20:48:39 INFO: progress: 300/22000, train/total_loss: 0.6647, train/total_loss/avg: 0.6630, train/hateful_memes/cross_entropy: 0.6647, train/hateful_memes/cross_entropy/avg: 0.6630, max mem: 11406.0, experiment: run, epoch: 2, num_updates: 300, iterations: 300, max_updates: 22000, lr: 0.00001, ups: 0.60, time: 02m 47s 099ms, time_since_start: 08m 44s 635ms, eta: 10h 04m 20s 675ms
2020-06-10T20:51:26 INFO: progress: 400/22000, train/total_loss: 0.6482, train/total_loss/avg: 0.6573, train/hateful_memes/cross_entropy: 0.6482, train/hateful_memes/cross_entropy/avg: 0.6573, max mem: 11406.0, experiment: run, epoch: 2, num_updates: 400, iterations: 400, max_updates: 22000, lr: 0.00001, ups: 0.60, time: 02m 46s 971ms, time_since_start: 11m 31s 607ms, eta: 10h 01m 05s 842ms
2020-06-10T20:54:13 INFO: progress: 500/22000, train/total_loss: 0.6482, train/total_loss/avg: 0.6165, train/hateful_memes/cross_entropy: 0.6482, train/hateful_memes/cross_entropy/avg: 0.6165, max mem: 11406.0, experiment: run, epoch: 2, num_updates: 500, iterations: 500, max_updates: 22000, lr: 0.00001, ups: 0.60, time: 02m 47s 070ms, time_since_start: 14m 18s 677ms, eta: 09h 58m 40s 111ms
2020-06-10T20:57:00 INFO: progress: 600/22000, train/total_loss: 0.6404, train/total_loss/avg: 0.5785, train/hateful_memes/cross_entropy: 0.6404, train/hateful_memes/cross_entropy/avg: 0.5785, max mem: 11406.0, experiment: run, epoch: 3, num_updates: 600, iterations: 600, max_updates: 22000, lr: 0.00001, ups: 0.60, time: 02m 46s 978ms, time_since_start: 17m 05s 656ms, eta: 09h 55m 33s 457ms
2020-06-10T20:59:47 INFO: progress: 700/22000, train/total_loss: 0.6404, train/total_loss/avg: 0.5449, train/hateful_memes/cross_entropy: 0.6404, train/hateful_memes/cross_entropy/avg: 0.5449, max mem: 11406.0, experiment: run, epoch: 3, num_updates: 700, iterations: 700, max_updates: 22000, lr: 0.00002, ups: 0.60, time: 02m 47s 381ms, time_since_start: 19m 53s 038ms, eta: 09h 54m 12s 342ms
2020-06-10T21:02:35 INFO: progress: 800/22000, train/total_loss: 0.4533, train/total_loss/avg: 0.5150, train/hateful_memes/cross_entropy: 0.4533, train/hateful_memes/cross_entropy/avg: 0.5150, max mem: 11406.0, experiment: run, epoch: 4, num_updates: 800, iterations: 800, max_updates: 22000, lr: 0.00002, ups: 0.60, time: 02m 47s 170ms, time_since_start: 22m 40s 208ms, eta: 09h 50m 40s 096ms
2020-06-10T21:05:22 INFO: progress: 900/22000, train/total_loss: 0.4533, train/total_loss/avg: 0.4926, train/hateful_memes/cross_entropy: 0.4533, train/hateful_memes/cross_entropy/avg: 0.4926, max mem: 11406.0, experiment: run, epoch: 4, num_updates: 900, iterations: 900, max_updates: 22000, lr: 0.00002, ups: 0.60, time: 02m 47s 042ms, time_since_start: 25m 27s 250ms, eta: 09h 47m 25s 880ms
2020-06-10T21:08:09 INFO: progress: 1000/22000, train/total_loss: 0.3885, train/total_loss/avg: 0.4776, train/hateful_memes/cross_entropy: 0.3885, train/hateful_memes/cross_entropy/avg: 0.4776, max mem: 11406.0, experiment: run, epoch: 4, num_updates: 1000, iterations: 1000, max_updates: 22000, lr: 0.00002, ups: 0.60, time: 02m 47s 101ms, time_since_start: 28m 14s 352ms, eta: 09h 44m 51s 384ms
2020-06-10T21:08:09 INFO: Checkpoint time. Saving a checkpoint.
2020-06-10T21:08:12 INFO: Evaluation time. Running on full validation set...
2020-06-10T21:08:52 INFO: progress: 1000/22000, val/total_loss: 0.7778, val/hateful_memes/cross_entropy: 0.7778, val/hateful_memes/accuracy: 0.6320, val/hateful_memes/binary_f1: 0.5377, val/hateful_memes/roc_auc: 0.7184, num_updates: 1000, epoch: 4, iterations: 1000, max_updates: 22000, val_time: 08s 865ms, best_update: 1000, best_iteration: 1000, best_val/hateful_memes/roc_auc: 0.718400
2020-06-10T21:08:54 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-10T21:11:40 INFO: progress: 1100/22000, train/total_loss: 0.3885, train/total_loss/avg: 0.4551, train/hateful_memes/cross_entropy: 0.3885, train/hateful_memes/cross_entropy/avg: 0.4551, max mem: 11430.0, experiment: run, epoch: 5, num_updates: 1100, iterations: 1100, max_updates: 22000, lr: 0.00003, ups: 0.60, time: 02m 47s 837ms, time_since_start: 31m 45s 683ms, eta: 09h 44m 38s 135ms
2020-06-10T21:14:28 INFO: progress: 1200/22000, train/total_loss: 0.3885, train/total_loss/avg: 0.4518, train/hateful_memes/cross_entropy: 0.3885, train/hateful_memes/cross_entropy/avg: 0.4518, max mem: 11430.0, experiment: run, epoch: 5, num_updates: 1200, iterations: 1200, max_updates: 22000, lr: 0.00003, ups: 0.60, time: 02m 47s 520ms, time_since_start: 34m 33s 203ms, eta: 09h 40m 44s 254ms
2020-06-10T21:17:15 INFO: progress: 1300/22000, train/total_loss: 0.3971, train/total_loss/avg: 0.4475, train/hateful_memes/cross_entropy: 0.3971, train/hateful_memes/cross_entropy/avg: 0.4475, max mem: 11430.0, experiment: run, epoch: 5, num_updates: 1300, iterations: 1300, max_updates: 22000, lr: 0.00003, ups: 0.60, time: 02m 47s 449ms, time_since_start: 37m 20s 652ms, eta: 09h 37m 42s 025ms
2020-06-10T21:20:02 INFO: progress: 1400/22000, train/total_loss: 0.3885, train/total_loss/avg: 0.4322, train/hateful_memes/cross_entropy: 0.3885, train/hateful_memes/cross_entropy/avg: 0.4322, max mem: 11430.0, experiment: run, epoch: 6, num_updates: 1400, iterations: 1400, max_updates: 22000, lr: 0.00003, ups: 0.60, time: 02m 46s 898ms, time_since_start: 40m 07s 551ms, eta: 09h 33m 01s 064ms
2020-06-10T21:22:49 INFO: progress: 1500/22000, train/total_loss: 0.3885, train/total_loss/avg: 0.4120, train/hateful_memes/cross_entropy: 0.3885, train/hateful_memes/cross_entropy/avg: 0.4120, max mem: 11430.0, experiment: run, epoch: 6, num_updates: 1500, iterations: 1500, max_updates: 22000, lr: 0.00004, ups: 0.60, time: 02m 46s 707ms, time_since_start: 42m 54s 259ms, eta: 09h 29m 35s 132ms
2020-06-10T21:25:35 INFO: progress: 1600/22000, train/total_loss: 0.3432, train/total_loss/avg: 0.3938, train/hateful_memes/cross_entropy: 0.3432, train/hateful_memes/cross_entropy/avg: 0.3938, max mem: 11430.0, experiment: run, epoch: 7, num_updates: 1600, iterations: 1600, max_updates: 22000, lr: 0.00004, ups: 0.60, time: 02m 46s 495ms, time_since_start: 45m 40s 754ms, eta: 09h 26m 05s 091ms
2020-06-10T21:28:22 INFO: progress: 1700/22000, train/total_loss: 0.3432, train/total_loss/avg: 0.3729, train/hateful_memes/cross_entropy: 0.3432, train/hateful_memes/cross_entropy/avg: 0.3729, max mem: 11430.0, experiment: run, epoch: 7, num_updates: 1700, iterations: 1700, max_updates: 22000, lr: 0.00004, ups: 0.60, time: 02m 47s 017ms, time_since_start: 48m 27s 772ms, eta: 09h 25m 04s 576ms
2020-06-10T21:31:09 INFO: progress: 1800/22000, train/total_loss: 0.3432, train/total_loss/avg: 0.3577, train/hateful_memes/cross_entropy: 0.3432, train/hateful_memes/cross_entropy/avg: 0.3577, max mem: 11430.0, experiment: run, epoch: 7, num_updates: 1800, iterations: 1800, max_updates: 22000, lr: 0.00004, ups: 0.60, time: 02m 47s 010ms, time_since_start: 51m 14s 783ms, eta: 09h 22m 16s 154ms
2020-06-10T21:33:56 INFO: progress: 1900/22000, train/total_loss: 0.3432, train/total_loss/avg: 0.3461, train/hateful_memes/cross_entropy: 0.3432, train/hateful_memes/cross_entropy/avg: 0.3461, max mem: 11430.0, experiment: run, epoch: 8, num_updates: 1900, iterations: 1900, max_updates: 22000, lr: 0.00005, ups: 0.60, time: 02m 46s 732ms, time_since_start: 54m 01s 516ms, eta: 09h 18m 33s 310ms
2020-06-10T21:36:43 INFO: progress: 2000/22000, train/total_loss: 0.3132, train/total_loss/avg: 0.3343, train/hateful_memes/cross_entropy: 0.3132, train/hateful_memes/cross_entropy/avg: 0.3343, max mem: 11430.0, experiment: run, epoch: 8, num_updates: 2000, iterations: 2000, max_updates: 22000, lr: 0.00005, ups: 0.60, time: 02m 47s 203ms, time_since_start: 56m 48s 719ms, eta: 09h 17m 20s 674ms
2020-06-10T21:36:43 INFO: Checkpoint time. Saving a checkpoint.
2020-06-10T21:36:56 INFO: Evaluation time. Running on full validation set...
2020-06-10T21:37:28 INFO: progress: 2000/22000, val/total_loss: 1.1965, val/hateful_memes/cross_entropy: 1.1965, val/hateful_memes/accuracy: 0.6180, val/hateful_memes/binary_f1: 0.5589, val/hateful_memes/roc_auc: 0.7113, num_updates: 2000, epoch: 8, iterations: 2000, max_updates: 22000, val_time: 10s 776ms, best_update: 1000, best_iteration: 1000, best_val/hateful_memes/roc_auc: 0.718400
2020-06-10T21:37:30 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-10T21:40:16 INFO: progress: 2100/22000, train/total_loss: 0.3057, train/total_loss/avg: 0.3201, train/hateful_memes/cross_entropy: 0.3057, train/hateful_memes/cross_entropy/avg: 0.3201, max mem: 11430.0, experiment: run, epoch: 8, num_updates: 2100, iterations: 2100, max_updates: 22000, lr: 0.00005, ups: 0.60, time: 02m 47s 615ms, time_since_start: 01h 21s 520ms, eta: 09h 15m 55s 476ms
2020-06-10T21:43:03 INFO: progress: 2200/22000, train/total_loss: 0.2333, train/total_loss/avg: 0.3139, train/hateful_memes/cross_entropy: 0.2333, train/hateful_memes/cross_entropy/avg: 0.3139, max mem: 11430.0, experiment: run, epoch: 9, num_updates: 2200, iterations: 2200, max_updates: 22000, lr: 0.00005, ups: 0.60, time: 02m 47s 037ms, time_since_start: 01h 03m 08s 557ms, eta: 09h 11m 13s 417ms
2020-06-10T21:45:50 INFO: progress: 2300/22000, train/total_loss: 0.2302, train/total_loss/avg: 0.3081, train/hateful_memes/cross_entropy: 0.2302, train/hateful_memes/cross_entropy/avg: 0.3081, max mem: 11430.0, experiment: run, epoch: 9, num_updates: 2300, iterations: 2300, max_updates: 22000, lr: 0.00005, ups: 0.60, time: 02m 47s 330ms, time_since_start: 01h 05m 55s 887ms, eta: 09h 09m 24s 033ms
2020-06-10T21:48:37 INFO: progress: 2400/22000, train/total_loss: 0.1832, train/total_loss/avg: 0.2973, train/hateful_memes/cross_entropy: 0.1832, train/hateful_memes/cross_entropy/avg: 0.2973, max mem: 11430.0, experiment: run, epoch: 10, num_updates: 2400, iterations: 2400, max_updates: 22000, lr: 0.00005, ups: 0.60, time: 02m 47s 173ms, time_since_start: 01h 08m 43s 061ms, eta: 09h 06m 05s 987ms
2020-06-10T21:51:24 INFO: progress: 2500/22000, train/total_loss: 0.1810, train/total_loss/avg: 0.2864, train/hateful_memes/cross_entropy: 0.1810, train/hateful_memes/cross_entropy/avg: 0.2864, max mem: 11430.0, experiment: run, epoch: 10, num_updates: 2500, iterations: 2500, max_updates: 22000, lr: 0.00005, ups: 0.60, time: 02m 46s 996ms, time_since_start: 01h 11m 30s 058ms, eta: 09h 02m 44s 403ms
2020-06-10T21:54:11 INFO: progress: 2600/22000, train/total_loss: 0.1810, train/total_loss/avg: 0.2880, train/hateful_memes/cross_entropy: 0.1810, train/hateful_memes/cross_entropy/avg: 0.2880, max mem: 11430.0, experiment: run, epoch: 10, num_updates: 2600, iterations: 2600, max_updates: 22000, lr: 0.00005, ups: 0.60, time: 02m 46s 761ms, time_since_start: 01h 14m 16s 819ms, eta: 08h 59m 11s 794ms
2020-06-10T21:56:58 INFO: progress: 2700/22000, train/total_loss: 0.1363, train/total_loss/avg: 0.2795, train/hateful_memes/cross_entropy: 0.1363, train/hateful_memes/cross_entropy/avg: 0.2795, max mem: 11430.0, experiment: run, epoch: 11, num_updates: 2700, iterations: 2700, max_updates: 22000, lr: 0.00005, ups: 0.60, time: 02m 46s 892ms, time_since_start: 01h 17m 03s 712ms, eta: 08h 56m 50s 330ms
2020-06-10T21:59:45 INFO: progress: 2800/22000, train/total_loss: 0.1293, train/total_loss/avg: 0.2714, train/hateful_memes/cross_entropy: 0.1293, train/hateful_memes/cross_entropy/avg: 0.2714, max mem: 11430.0, experiment: run, epoch: 11, num_updates: 2800, iterations: 2800, max_updates: 22000, lr: 0.00005, ups: 0.60, time: 02m 47s 202ms, time_since_start: 01h 19m 50s 915ms, eta: 08h 55m 02s 902ms
2020-06-10T22:02:33 INFO: progress: 2900/22000, train/total_loss: 0.1293, train/total_loss/avg: 0.2758, train/hateful_memes/cross_entropy: 0.1293, train/hateful_memes/cross_entropy/avg: 0.2758, max mem: 11430.0, experiment: run, epoch: 11, num_updates: 2900, iterations: 2900, max_updates: 22000, lr: 0.00005, ups: 0.60, time: 02m 47s 425ms, time_since_start: 01h 22m 38s 340ms, eta: 08h 52m 58s 222ms
2020-06-10T22:05:20 INFO: progress: 3000/22000, train/total_loss: 0.1205, train/total_loss/avg: 0.2673, train/hateful_memes/cross_entropy: 0.1205, train/hateful_memes/cross_entropy/avg: 0.2673, max mem: 11430.0, experiment: run, epoch: 12, num_updates: 3000, iterations: 3000, max_updates: 22000, lr: 0.00005, ups: 0.60, time: 02m 46s 940ms, time_since_start: 01h 25m 25s 281ms, eta: 08h 48m 38s 677ms
2020-06-10T22:05:20 INFO: Checkpoint time. Saving a checkpoint.
2020-06-10T22:05:32 INFO: Evaluation time. Running on full validation set...
2020-06-10T22:06:05 INFO: progress: 3000/22000, val/total_loss: 2.0200, val/hateful_memes/cross_entropy: 2.0200, val/hateful_memes/accuracy: 0.6220, val/hateful_memes/binary_f1: 0.4850, val/hateful_memes/roc_auc: 0.7069, num_updates: 3000, epoch: 12, iterations: 3000, max_updates: 22000, val_time: 08s 675ms, best_update: 1000, best_iteration: 1000, best_val/hateful_memes/roc_auc: 0.718400
2020-06-10T22:06:07 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-10T22:08:53 INFO: progress: 3100/22000, train/total_loss: 0.1097, train/total_loss/avg: 0.2589, train/hateful_memes/cross_entropy: 0.1097, train/hateful_memes/cross_entropy/avg: 0.2589, max mem: 11430.0, experiment: run, epoch: 12, num_updates: 3100, iterations: 3100, max_updates: 22000, lr: 0.00005, ups: 0.60, time: 02m 47s 278ms, time_since_start: 01h 28m 58s 455ms, eta: 08h 46m 55s 595ms
2020-06-10T22:11:39 INFO: progress: 3200/22000, train/total_loss: 0.1097, train/total_loss/avg: 0.2556, train/hateful_memes/cross_entropy: 0.1097, train/hateful_memes/cross_entropy/avg: 0.2556, max mem: 11430.0, experiment: run, epoch: 13, num_updates: 3200, iterations: 3200, max_updates: 22000, lr: 0.00005, ups: 0.60, time: 02m 46s 487ms, time_since_start: 01h 31m 44s 943ms, eta: 08h 41m 39s 722ms
2020-06-10T22:14:27 INFO: progress: 3300/22000, train/total_loss: 0.1002, train/total_loss/avg: 0.2491, train/hateful_memes/cross_entropy: 0.1002, train/hateful_memes/cross_entropy/avg: 0.2491, max mem: 11430.0, experiment: run, epoch: 13, num_updates: 3300, iterations: 3300, max_updates: 22000, lr: 0.00005, ups: 0.60, time: 02m 47s 273ms, time_since_start: 01h 34m 32s 217ms, eta: 08h 41m 20s 223ms
2020-06-10T22:17:14 INFO: progress: 3400/22000, train/total_loss: 0.0590, train/total_loss/avg: 0.2425, train/hateful_memes/cross_entropy: 0.0590, train/hateful_memes/cross_entropy/avg: 0.2425, max mem: 11430.0, experiment: run, epoch: 13, num_updates: 3400, iterations: 3400, max_updates: 22000, lr: 0.00005, ups: 0.60, time: 02m 47s 332ms, time_since_start: 01h 37m 19s 549ms, eta: 08h 38m 43s 808ms
2020-06-10T22:20:00 INFO: progress: 3500/22000, train/total_loss: 0.0507, train/total_loss/avg: 0.2368, train/hateful_memes/cross_entropy: 0.0507, train/hateful_memes/cross_entropy/avg: 0.2368, max mem: 11430.0, experiment: run, epoch: 14, num_updates: 3500, iterations: 3500, max_updates: 22000, lr: 0.00005, ups: 0.60, time: 02m 46s 439ms, time_since_start: 01h 40m 05s 989ms, eta: 08h 33m 11s 356ms
2020-06-10T22:22:47 INFO: progress: 3600/22000, train/total_loss: 0.0507, train/total_loss/avg: 0.2321, train/hateful_memes/cross_entropy: 0.0507, train/hateful_memes/cross_entropy/avg: 0.2321, max mem: 11430.0, experiment: run, epoch: 14, num_updates: 3600, iterations: 3600, max_updates: 22000, lr: 0.00005, ups: 0.60, time: 02m 46s 442ms, time_since_start: 01h 42m 52s 432ms, eta: 08h 30m 25s 441ms
2020-06-10T22:25:33 INFO: progress: 3700/22000, train/total_loss: 0.0507, train/total_loss/avg: 0.2264, train/hateful_memes/cross_entropy: 0.0507, train/hateful_memes/cross_entropy/avg: 0.2264, max mem: 11430.0, experiment: run, epoch: 14, num_updates: 3700, iterations: 3700, max_updates: 22000, lr: 0.00005, ups: 0.60, time: 02m 46s 418ms, time_since_start: 01h 45m 38s 851ms, eta: 08h 27m 34s 658ms
2020-06-10T22:28:20 INFO: progress: 3800/22000, train/total_loss: 0.0491, train/total_loss/avg: 0.2206, train/hateful_memes/cross_entropy: 0.0491, train/hateful_memes/cross_entropy/avg: 0.2206, max mem: 11430.0, experiment: run, epoch: 15, num_updates: 3800, iterations: 3800, max_updates: 22000, lr: 0.00005, ups: 0.60, time: 02m 46s 791ms, time_since_start: 01h 48m 25s 642ms, eta: 08h 25m 56s 026ms
2020-06-10T22:31:07 INFO: progress: 3900/22000, train/total_loss: 0.0491, train/total_loss/avg: 0.2164, train/hateful_memes/cross_entropy: 0.0491, train/hateful_memes/cross_entropy/avg: 0.2164, max mem: 11430.0, experiment: run, epoch: 15, num_updates: 3900, iterations: 3900, max_updates: 22000, lr: 0.00005, ups: 0.60, time: 02m 47s 404ms, time_since_start: 01h 51m 13s 047ms, eta: 08h 25m 192ms
2020-06-10T22:33:55 INFO: progress: 4000/22000, train/total_loss: 0.0491, train/total_loss/avg: 0.2129, train/hateful_memes/cross_entropy: 0.0491, train/hateful_memes/cross_entropy/avg: 0.2129, max mem: 11430.0, experiment: run, epoch: 16, num_updates: 4000, iterations: 4000, max_updates: 22000, lr: 0.00005, ups: 0.60, time: 02m 47s 212ms, time_since_start: 01h 54m 260ms, eta: 08h 21m 38s 333ms
2020-06-10T22:33:55 INFO: Checkpoint time. Saving a checkpoint.
2020-06-10T22:34:08 INFO: Evaluation time. Running on full validation set...
2020-06-10T22:34:50 INFO: progress: 4000/22000, val/total_loss: 1.4989, val/hateful_memes/cross_entropy: 1.4989, val/hateful_memes/accuracy: 0.6480, val/hateful_memes/binary_f1: 0.5707, val/hateful_memes/roc_auc: 0.7266, num_updates: 4000, epoch: 16, iterations: 4000, max_updates: 22000, val_time: 09s 219ms, best_update: 4000, best_iteration: 4000, best_val/hateful_memes/roc_auc: 0.726628
2020-06-10T22:34:52 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-10T22:37:38 INFO: progress: 4100/22000, train/total_loss: 0.0507, train/total_loss/avg: 0.2169, train/hateful_memes/cross_entropy: 0.0507, train/hateful_memes/cross_entropy/avg: 0.2169, max mem: 11430.0, experiment: run, epoch: 16, num_updates: 4100, iterations: 4100, max_updates: 22000, lr: 0.00004, ups: 0.60, time: 02m 47s 792ms, time_since_start: 01h 57m 43s 595ms, eta: 08h 20m 34s 943ms
2020-06-10T22:40:25 INFO: progress: 4200/22000, train/total_loss: 0.0491, train/total_loss/avg: 0.2126, train/hateful_memes/cross_entropy: 0.0491, train/hateful_memes/cross_entropy/avg: 0.2126, max mem: 11430.0, experiment: run, epoch: 16, num_updates: 4200, iterations: 4200, max_updates: 22000, lr: 0.00004, ups: 0.60, time: 02m 47s 361ms, time_since_start: 02h 30s 957ms, eta: 08h 16m 30s 369ms
2020-06-10T22:43:12 INFO: progress: 4300/22000, train/total_loss: 0.0436, train/total_loss/avg: 0.2086, train/hateful_memes/cross_entropy: 0.0436, train/hateful_memes/cross_entropy/avg: 0.2086, max mem: 11430.0, experiment: run, epoch: 17, num_updates: 4300, iterations: 4300, max_updates: 22000, lr: 0.00004, ups: 0.60, time: 02m 47s 030ms, time_since_start: 02h 03m 17s 987ms, eta: 08h 12m 44s 356ms
2020-06-10T22:45:59 INFO: progress: 4400/22000, train/total_loss: 0.0436, train/total_loss/avg: 0.2055, train/hateful_memes/cross_entropy: 0.0436, train/hateful_memes/cross_entropy/avg: 0.2055, max mem: 11430.0, experiment: run, epoch: 17, num_updates: 4400, iterations: 4400, max_updates: 22000, lr: 0.00004, ups: 0.60, time: 02m 47s 056ms, time_since_start: 02h 06m 05s 044ms, eta: 08h 10m 01s 986ms
2020-06-10T22:48:46 INFO: progress: 4500/22000, train/total_loss: 0.0436, train/total_loss/avg: 0.2014, train/hateful_memes/cross_entropy: 0.0436, train/hateful_memes/cross_entropy/avg: 0.2014, max mem: 11430.0, experiment: run, epoch: 17, num_updates: 4500, iterations: 4500, max_updates: 22000, lr: 0.00004, ups: 0.60, time: 02m 46s 950ms, time_since_start: 02h 08m 51s 994ms, eta: 08h 06m 56s 329ms
2020-06-10T22:51:34 INFO: progress: 4600/22000, train/total_loss: 0.0436, train/total_loss/avg: 0.1981, train/hateful_memes/cross_entropy: 0.0436, train/hateful_memes/cross_entropy/avg: 0.1981, max mem: 11430.0, experiment: run, epoch: 18, num_updates: 4600, iterations: 4600, max_updates: 22000, lr: 0.00004, ups: 0.60, time: 02m 47s 314ms, time_since_start: 02h 11m 39s 308ms, eta: 08h 05m 12s 668ms
2020-06-10T22:54:21 INFO: progress: 4700/22000, train/total_loss: 0.0432, train/total_loss/avg: 0.1940, train/hateful_memes/cross_entropy: 0.0432, train/hateful_memes/cross_entropy/avg: 0.1940, max mem: 11430.0, experiment: run, epoch: 18, num_updates: 4700, iterations: 4700, max_updates: 22000, lr: 0.00004, ups: 0.60, time: 02m 47s 510ms, time_since_start: 02h 14m 26s 819ms, eta: 08h 02m 59s 318ms
2020-06-10T22:57:08 INFO: progress: 4800/22000, train/total_loss: 0.0382, train/total_loss/avg: 0.1904, train/hateful_memes/cross_entropy: 0.0382, train/hateful_memes/cross_entropy/avg: 0.1904, max mem: 11430.0, experiment: run, epoch: 19, num_updates: 4800, iterations: 4800, max_updates: 22000, lr: 0.00004, ups: 0.60, time: 02m 47s 009ms, time_since_start: 02h 17m 13s 828ms, eta: 07h 58m 45s 604ms
2020-06-10T22:59:55 INFO: progress: 4900/22000, train/total_loss: 0.0382, train/total_loss/avg: 0.1917, train/hateful_memes/cross_entropy: 0.0382, train/hateful_memes/cross_entropy/avg: 0.1917, max mem: 11430.0, experiment: run, epoch: 19, num_updates: 4900, iterations: 4900, max_updates: 22000, lr: 0.00004, ups: 0.60, time: 02m 47s 186ms, time_since_start: 02h 20m 01s 015ms, eta: 07h 56m 28s 943ms
2020-06-10T23:02:43 INFO: progress: 5000/22000, train/total_loss: 0.0382, train/total_loss/avg: 0.1879, train/hateful_memes/cross_entropy: 0.0382, train/hateful_memes/cross_entropy/avg: 0.1879, max mem: 11430.0, experiment: run, epoch: 19, num_updates: 5000, iterations: 5000, max_updates: 22000, lr: 0.00004, ups: 0.60, time: 02m 47s 227ms, time_since_start: 02h 22m 48s 242ms, eta: 07h 53m 48s 616ms
2020-06-10T23:02:43 INFO: Checkpoint time. Saving a checkpoint.
2020-06-10T23:02:56 INFO: Evaluation time. Running on full validation set...
2020-06-10T23:03:27 INFO: progress: 5000/22000, val/total_loss: 1.7024, val/hateful_memes/cross_entropy: 1.7024, val/hateful_memes/accuracy: 0.6500, val/hateful_memes/binary_f1: 0.5679, val/hateful_memes/roc_auc: 0.7258, num_updates: 5000, epoch: 19, iterations: 5000, max_updates: 22000, val_time: 08s 684ms, best_update: 4000, best_iteration: 4000, best_val/hateful_memes/roc_auc: 0.726628
2020-06-10T23:03:29 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-10T23:06:15 INFO: progress: 5100/22000, train/total_loss: 0.0432, train/total_loss/avg: 0.1853, train/hateful_memes/cross_entropy: 0.0432, train/hateful_memes/cross_entropy/avg: 0.1853, max mem: 11430.0, experiment: run, epoch: 20, num_updates: 5100, iterations: 5100, max_updates: 22000, lr: 0.00004, ups: 0.60, time: 02m 47s 459ms, time_since_start: 02h 26m 20s 492ms, eta: 07h 51m 40s 720ms
2020-06-10T23:09:02 INFO: progress: 5200/22000, train/total_loss: 0.0432, train/total_loss/avg: 0.1828, train/hateful_memes/cross_entropy: 0.0432, train/hateful_memes/cross_entropy/avg: 0.1828, max mem: 11430.0, experiment: run, epoch: 20, num_updates: 5200, iterations: 5200, max_updates: 22000, lr: 0.00004, ups: 0.60, time: 02m 47s 265ms, time_since_start: 02h 29m 07s 758ms, eta: 07h 48m 20s 597ms
2020-06-10T23:11:49 INFO: progress: 5300/22000, train/total_loss: 0.0382, train/total_loss/avg: 0.1796, train/hateful_memes/cross_entropy: 0.0382, train/hateful_memes/cross_entropy/avg: 0.1796, max mem: 11430.0, experiment: run, epoch: 20, num_updates: 5300, iterations: 5300, max_updates: 22000, lr: 0.00004, ups: 0.60, time: 02m 47s 359ms, time_since_start: 02h 31m 55s 117ms, eta: 07h 45m 48s 962ms
2020-06-10T23:14:37 INFO: progress: 5400/22000, train/total_loss: 0.0382, train/total_loss/avg: 0.1763, train/hateful_memes/cross_entropy: 0.0382, train/hateful_memes/cross_entropy/avg: 0.1763, max mem: 11430.0, experiment: run, epoch: 21, num_updates: 5400, iterations: 5400, max_updates: 22000, lr: 0.00004, ups: 0.60, time: 02m 47s 160ms, time_since_start: 02h 34m 42s 277ms, eta: 07h 42m 28s 639ms
2020-06-10T23:17:24 INFO: progress: 5500/22000, train/total_loss: 0.0382, train/total_loss/avg: 0.1748, train/hateful_memes/cross_entropy: 0.0382, train/hateful_memes/cross_entropy/avg: 0.1748, max mem: 11430.0, experiment: run, epoch: 21, num_updates: 5500, iterations: 5500, max_updates: 22000, lr: 0.00004, ups: 0.60, time: 02m 47s 547ms, time_since_start: 02h 37m 29s 825ms, eta: 07h 40m 45s 328ms
2020-06-10T23:20:12 INFO: progress: 5600/22000, train/total_loss: 0.0382, train/total_loss/avg: 0.1736, train/hateful_memes/cross_entropy: 0.0382, train/hateful_memes/cross_entropy/avg: 0.1736, max mem: 11430.0, experiment: run, epoch: 22, num_updates: 5600, iterations: 5600, max_updates: 22000, lr: 0.00004, ups: 0.60, time: 02m 47s 528ms, time_since_start: 02h 40m 17s 354ms, eta: 07h 37m 54s 745ms
2020-06-10T23:22:59 INFO: progress: 5700/22000, train/total_loss: 0.0382, train/total_loss/avg: 0.1706, train/hateful_memes/cross_entropy: 0.0382, train/hateful_memes/cross_entropy/avg: 0.1706, max mem: 11430.0, experiment: run, epoch: 22, num_updates: 5700, iterations: 5700, max_updates: 22000, lr: 0.00004, ups: 0.60, time: 02m 47s 430ms, time_since_start: 02h 43m 04s 785ms, eta: 07h 34m 51s 190ms
2020-06-10T23:25:47 INFO: progress: 5800/22000, train/total_loss: 0.0396, train/total_loss/avg: 0.1683, train/hateful_memes/cross_entropy: 0.0396, train/hateful_memes/cross_entropy/avg: 0.1683, max mem: 11430.0, experiment: run, epoch: 22, num_updates: 5800, iterations: 5800, max_updates: 22000, lr: 0.00004, ups: 0.60, time: 02m 47s 566ms, time_since_start: 02h 45m 52s 351ms, eta: 07h 32m 25s 786ms
2020-06-10T23:28:33 INFO: progress: 5900/22000, train/total_loss: 0.0382, train/total_loss/avg: 0.1656, train/hateful_memes/cross_entropy: 0.0382, train/hateful_memes/cross_entropy/avg: 0.1656, max mem: 11430.0, experiment: run, epoch: 23, num_updates: 5900, iterations: 5900, max_updates: 22000, lr: 0.00004, ups: 0.60, time: 02m 46s 763ms, time_since_start: 02h 48m 39s 115ms, eta: 07h 27m 28s 962ms
2020-06-10T23:31:20 INFO: progress: 6000/22000, train/total_loss: 0.0381, train/total_loss/avg: 0.1629, train/hateful_memes/cross_entropy: 0.0381, train/hateful_memes/cross_entropy/avg: 0.1629, max mem: 11430.0, experiment: run, epoch: 23, num_updates: 6000, iterations: 6000, max_updates: 22000, lr: 0.00004, ups: 0.60, time: 02m 46s 913ms, time_since_start: 02h 51m 26s 028ms, eta: 07h 25m 06s 116ms
2020-06-10T23:31:20 INFO: Checkpoint time. Saving a checkpoint.
2020-06-10T23:31:34 INFO: Evaluation time. Running on full validation set...
2020-06-10T23:32:16 INFO: progress: 6000/22000, val/total_loss: 1.8527, val/hateful_memes/cross_entropy: 1.8527, val/hateful_memes/accuracy: 0.6460, val/hateful_memes/binary_f1: 0.5203, val/hateful_memes/roc_auc: 0.7386, num_updates: 6000, epoch: 23, iterations: 6000, max_updates: 22000, val_time: 08s 737ms, best_update: 6000, best_iteration: 6000, best_val/hateful_memes/roc_auc: 0.738552
2020-06-10T23:32:18 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-10T23:35:04 INFO: progress: 6100/22000, train/total_loss: 0.0226, train/total_loss/avg: 0.1603, train/hateful_memes/cross_entropy: 0.0226, train/hateful_memes/cross_entropy/avg: 0.1603, max mem: 11430.0, experiment: run, epoch: 23, num_updates: 6100, iterations: 6100, max_updates: 22000, lr: 0.00004, ups: 0.60, time: 02m 47s 619ms, time_since_start: 02h 55m 09s 729ms, eta: 07h 24m 11s 542ms
2020-06-10T23:37:51 INFO: progress: 6200/22000, train/total_loss: 0.0212, train/total_loss/avg: 0.1581, train/hateful_memes/cross_entropy: 0.0212, train/hateful_memes/cross_entropy/avg: 0.1581, max mem: 11430.0, experiment: run, epoch: 24, num_updates: 6200, iterations: 6200, max_updates: 22000, lr: 0.00004, ups: 0.60, time: 02m 47s 070ms, time_since_start: 02h 57m 56s 800ms, eta: 07h 19m 57s 136ms
2020-06-10T23:40:39 INFO: progress: 6300/22000, train/total_loss: 0.0212, train/total_loss/avg: 0.1559, train/hateful_memes/cross_entropy: 0.0212, train/hateful_memes/cross_entropy/avg: 0.1559, max mem: 11430.0, experiment: run, epoch: 24, num_updates: 6300, iterations: 6300, max_updates: 22000, lr: 0.00004, ups: 0.60, time: 02m 47s 596ms, time_since_start: 03h 44s 397ms, eta: 07h 18m 32s 689ms
2020-06-10T23:43:26 INFO: progress: 6400/22000, train/total_loss: 0.0212, train/total_loss/avg: 0.1538, train/hateful_memes/cross_entropy: 0.0212, train/hateful_memes/cross_entropy/avg: 0.1538, max mem: 11430.0, experiment: run, epoch: 25, num_updates: 6400, iterations: 6400, max_updates: 22000, lr: 0.00004, ups: 0.60, time: 02m 47s 259ms, time_since_start: 03h 03m 31s 657ms, eta: 07h 14m 52s 535ms
2020-06-10T23:46:13 INFO: progress: 6500/22000, train/total_loss: 0.0212, train/total_loss/avg: 0.1522, train/hateful_memes/cross_entropy: 0.0212, train/hateful_memes/cross_entropy/avg: 0.1522, max mem: 11430.0, experiment: run, epoch: 25, num_updates: 6500, iterations: 6500, max_updates: 22000, lr: 0.00004, ups: 0.60, time: 02m 46s 789ms, time_since_start: 03h 06m 18s 446ms, eta: 07h 10m 52s 346ms
2020-06-10T23:49:00 INFO: progress: 6600/22000, train/total_loss: 0.0209, train/total_loss/avg: 0.1499, train/hateful_memes/cross_entropy: 0.0209, train/hateful_memes/cross_entropy/avg: 0.1499, max mem: 11430.0, experiment: run, epoch: 25, num_updates: 6600, iterations: 6600, max_updates: 22000, lr: 0.00004, ups: 0.60, time: 02m 47s 128ms, time_since_start: 03h 09m 05s 575ms, eta: 07h 08m 57s 866ms
2020-06-10T23:51:47 INFO: progress: 6700/22000, train/total_loss: 0.0212, train/total_loss/avg: 0.1484, train/hateful_memes/cross_entropy: 0.0212, train/hateful_memes/cross_entropy/avg: 0.1484, max mem: 11430.0, experiment: run, epoch: 26, num_updates: 6700, iterations: 6700, max_updates: 22000, lr: 0.00004, ups: 0.60, time: 02m 46s 673ms, time_since_start: 03h 11m 52s 249ms, eta: 07h 05m 01s 094ms
2020-06-10T23:54:34 INFO: progress: 6800/22000, train/total_loss: 0.0222, train/total_loss/avg: 0.1466, train/hateful_memes/cross_entropy: 0.0222, train/hateful_memes/cross_entropy/avg: 0.1466, max mem: 11430.0, experiment: run, epoch: 26, num_updates: 6800, iterations: 6800, max_updates: 22000, lr: 0.00004, ups: 0.60, time: 02m 47s 203ms, time_since_start: 03h 14m 39s 452ms, eta: 07h 03m 34s 960ms
2020-06-10T23:57:21 INFO: progress: 6900/22000, train/total_loss: 0.0209, train/total_loss/avg: 0.1448, train/hateful_memes/cross_entropy: 0.0209, train/hateful_memes/cross_entropy/avg: 0.1448, max mem: 11430.0, experiment: run, epoch: 26, num_updates: 6900, iterations: 6900, max_updates: 22000, lr: 0.00004, ups: 0.60, time: 02m 47s 146ms, time_since_start: 03h 17m 26s 599ms, eta: 07h 39s 110ms
2020-06-11T00:00:08 INFO: progress: 7000/22000, train/total_loss: 0.0222, train/total_loss/avg: 0.1436, train/hateful_memes/cross_entropy: 0.0222, train/hateful_memes/cross_entropy/avg: 0.1436, max mem: 11430.0, experiment: run, epoch: 27, num_updates: 7000, iterations: 7000, max_updates: 22000, lr: 0.00004, ups: 0.60, time: 02m 46s 682ms, time_since_start: 03h 20m 13s 282ms, eta: 06h 56m 42s 423ms
2020-06-11T00:00:08 INFO: Checkpoint time. Saving a checkpoint.
2020-06-11T00:00:20 INFO: Evaluation time. Running on full validation set...
2020-06-11T00:00:52 INFO: progress: 7000/22000, val/total_loss: 2.1326, val/hateful_memes/cross_entropy: 2.1326, val/hateful_memes/accuracy: 0.6600, val/hateful_memes/binary_f1: 0.5685, val/hateful_memes/roc_auc: 0.7319, num_updates: 7000, epoch: 27, iterations: 7000, max_updates: 22000, val_time: 08s 691ms, best_update: 6000, best_iteration: 6000, best_val/hateful_memes/roc_auc: 0.738552
2020-06-11T00:00:54 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-11T00:03:39 INFO: progress: 7100/22000, train/total_loss: 0.0222, train/total_loss/avg: 0.1421, train/hateful_memes/cross_entropy: 0.0222, train/hateful_memes/cross_entropy/avg: 0.1421, max mem: 11430.0, experiment: run, epoch: 27, num_updates: 7100, iterations: 7100, max_updates: 22000, lr: 0.00004, ups: 0.60, time: 02m 47s 415ms, time_since_start: 03h 23m 45s 176ms, eta: 06h 55m 44s 898ms
2020-06-11T00:06:26 INFO: progress: 7200/22000, train/total_loss: 0.0209, train/total_loss/avg: 0.1401, train/hateful_memes/cross_entropy: 0.0209, train/hateful_memes/cross_entropy/avg: 0.1401, max mem: 11430.0, experiment: run, epoch: 28, num_updates: 7200, iterations: 7200, max_updates: 22000, lr: 0.00004, ups: 0.60, time: 02m 46s 772ms, time_since_start: 03h 26m 31s 948ms, eta: 06h 51m 22s 280ms
2020-06-11T00:09:14 INFO: progress: 7300/22000, train/total_loss: 0.0209, train/total_loss/avg: 0.1383, train/hateful_memes/cross_entropy: 0.0209, train/hateful_memes/cross_entropy/avg: 0.1383, max mem: 11430.0, experiment: run, epoch: 28, num_updates: 7300, iterations: 7300, max_updates: 22000, lr: 0.00004, ups: 0.60, time: 02m 47s 325ms, time_since_start: 03h 29m 19s 273ms, eta: 06h 49m 56s 783ms
2020-06-11T00:12:01 INFO: progress: 7400/22000, train/total_loss: 0.0209, train/total_loss/avg: 0.1365, train/hateful_memes/cross_entropy: 0.0209, train/hateful_memes/cross_entropy/avg: 0.1365, max mem: 11430.0, experiment: run, epoch: 28, num_updates: 7400, iterations: 7400, max_updates: 22000, lr: 0.00004, ups: 0.60, time: 02m 47s 514ms, time_since_start: 03h 32m 06s 788ms, eta: 06h 47m 37s 100ms
2020-06-11T00:14:48 INFO: progress: 7500/22000, train/total_loss: 0.0198, train/total_loss/avg: 0.1347, train/hateful_memes/cross_entropy: 0.0198, train/hateful_memes/cross_entropy/avg: 0.1347, max mem: 11430.0, experiment: run, epoch: 29, num_updates: 7500, iterations: 7500, max_updates: 22000, lr: 0.00004, ups: 0.60, time: 02m 46s 690ms, time_since_start: 03h 34m 53s 478ms, eta: 06h 42m 50s 123ms
2020-06-11T00:17:35 INFO: progress: 7600/22000, train/total_loss: 0.0082, train/total_loss/avg: 0.1330, train/hateful_memes/cross_entropy: 0.0082, train/hateful_memes/cross_entropy/avg: 0.1330, max mem: 11430.0, experiment: run, epoch: 29, num_updates: 7600, iterations: 7600, max_updates: 22000, lr: 0.00004, ups: 0.60, time: 02m 47s 165ms, time_since_start: 03h 37m 40s 643ms, eta: 06h 41m 11s 772ms
2020-06-11T00:20:22 INFO: progress: 7700/22000, train/total_loss: 0.0082, train/total_loss/avg: 0.1313, train/hateful_memes/cross_entropy: 0.0082, train/hateful_memes/cross_entropy/avg: 0.1313, max mem: 11430.0, experiment: run, epoch: 29, num_updates: 7700, iterations: 7700, max_updates: 22000, lr: 0.00004, ups: 0.60, time: 02m 47s 152ms, time_since_start: 03h 40m 27s 796ms, eta: 06h 38m 22s 745ms
2020-06-11T00:23:09 INFO: progress: 7800/22000, train/total_loss: 0.0073, train/total_loss/avg: 0.1297, train/hateful_memes/cross_entropy: 0.0073, train/hateful_memes/cross_entropy/avg: 0.1297, max mem: 11430.0, experiment: run, epoch: 30, num_updates: 7800, iterations: 7800, max_updates: 22000, lr: 0.00004, ups: 0.60, time: 02m 46s 985ms, time_since_start: 03h 43m 14s 781ms, eta: 06h 35m 11s 895ms
2020-06-11T00:25:56 INFO: progress: 7900/22000, train/total_loss: 0.0082, train/total_loss/avg: 0.1300, train/hateful_memes/cross_entropy: 0.0082, train/hateful_memes/cross_entropy/avg: 0.1300, max mem: 11430.0, experiment: run, epoch: 30, num_updates: 7900, iterations: 7900, max_updates: 22000, lr: 0.00004, ups: 0.60, time: 02m 47s 147ms, time_since_start: 03h 46m 01s 929ms, eta: 06h 32m 47s 867ms
2020-06-11T00:28:43 INFO: progress: 8000/22000, train/total_loss: 0.0198, train/total_loss/avg: 0.1287, train/hateful_memes/cross_entropy: 0.0198, train/hateful_memes/cross_entropy/avg: 0.1287, max mem: 11430.0, experiment: run, epoch: 31, num_updates: 8000, iterations: 8000, max_updates: 22000, lr: 0.00004, ups: 0.60, time: 02m 46s 856ms, time_since_start: 03h 48m 48s 785ms, eta: 06h 29m 19s 882ms
2020-06-11T00:28:43 INFO: Checkpoint time. Saving a checkpoint.
2020-06-11T00:28:56 INFO: Evaluation time. Running on full validation set...
2020-06-11T00:29:30 INFO: progress: 8000/22000, val/total_loss: 2.6936, val/hateful_memes/cross_entropy: 2.6936, val/hateful_memes/accuracy: 0.6280, val/hateful_memes/binary_f1: 0.4890, val/hateful_memes/roc_auc: 0.7156, num_updates: 8000, epoch: 31, iterations: 8000, max_updates: 22000, val_time: 08s 712ms, best_update: 6000, best_iteration: 6000, best_val/hateful_memes/roc_auc: 0.738552
2020-06-11T00:29:32 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-11T00:32:17 INFO: progress: 8100/22000, train/total_loss: 0.0209, train/total_loss/avg: 0.1274, train/hateful_memes/cross_entropy: 0.0209, train/hateful_memes/cross_entropy/avg: 0.1274, max mem: 11430.0, experiment: run, epoch: 31, num_updates: 8100, iterations: 8100, max_updates: 22000, lr: 0.00003, ups: 0.60, time: 02m 47s 518ms, time_since_start: 03h 52m 23s 145ms, eta: 06h 28m 05s 129ms
2020-06-11T00:35:04 INFO: progress: 8200/22000, train/total_loss: 0.0198, train/total_loss/avg: 0.1259, train/hateful_memes/cross_entropy: 0.0198, train/hateful_memes/cross_entropy/avg: 0.1259, max mem: 11430.0, experiment: run, epoch: 31, num_updates: 8200, iterations: 8200, max_updates: 22000, lr: 0.00003, ups: 0.60, time: 02m 47s 012ms, time_since_start: 03h 55m 10s 157ms, eta: 06h 24m 07s 782ms
2020-06-11T00:37:52 INFO: progress: 8300/22000, train/total_loss: 0.0198, train/total_loss/avg: 0.1247, train/hateful_memes/cross_entropy: 0.0198, train/hateful_memes/cross_entropy/avg: 0.1247, max mem: 11430.0, experiment: run, epoch: 32, num_updates: 8300, iterations: 8300, max_updates: 22000, lr: 0.00003, ups: 0.60, time: 02m 47s 265ms, time_since_start: 03h 57m 57s 423ms, eta: 06h 21m 55s 341ms
2020-06-11T00:40:39 INFO: progress: 8400/22000, train/total_loss: 0.0073, train/total_loss/avg: 0.1233, train/hateful_memes/cross_entropy: 0.0073, train/hateful_memes/cross_entropy/avg: 0.1233, max mem: 11430.0, experiment: run, epoch: 32, num_updates: 8400, iterations: 8400, max_updates: 22000, lr: 0.00003, ups: 0.60, time: 02m 47s 627ms, time_since_start: 04h 45s 050ms, eta: 06h 19m 57s 323ms
2020-06-11T00:43:27 INFO: progress: 8500/22000, train/total_loss: 0.0072, train/total_loss/avg: 0.1219, train/hateful_memes/cross_entropy: 0.0072, train/hateful_memes/cross_entropy/avg: 0.1219, max mem: 11430.0, experiment: run, epoch: 32, num_updates: 8500, iterations: 8500, max_updates: 22000, lr: 0.00003, ups: 0.60, time: 02m 47s 634ms, time_since_start: 04h 03m 32s 685ms, eta: 06h 17m 10s 705ms
2020-06-11T00:46:14 INFO: progress: 8600/22000, train/total_loss: 0.0073, train/total_loss/avg: 0.1206, train/hateful_memes/cross_entropy: 0.0073, train/hateful_memes/cross_entropy/avg: 0.1206, max mem: 11430.0, experiment: run, epoch: 33, num_updates: 8600, iterations: 8600, max_updates: 22000, lr: 0.00003, ups: 0.60, time: 02m 46s 863ms, time_since_start: 04h 06m 19s 549ms, eta: 06h 12m 39s 761ms
2020-06-11T00:49:01 INFO: progress: 8700/22000, train/total_loss: 0.0073, train/total_loss/avg: 0.1196, train/hateful_memes/cross_entropy: 0.0073, train/hateful_memes/cross_entropy/avg: 0.1196, max mem: 11430.0, experiment: run, epoch: 33, num_updates: 8700, iterations: 8700, max_updates: 22000, lr: 0.00003, ups: 0.60, time: 02m 47s 320ms, time_since_start: 04h 09m 06s 869ms, eta: 06h 10m 53s 608ms
2020-06-11T00:51:48 INFO: progress: 8800/22000, train/total_loss: 0.0072, train/total_loss/avg: 0.1183, train/hateful_memes/cross_entropy: 0.0072, train/hateful_memes/cross_entropy/avg: 0.1183, max mem: 11430.0, experiment: run, epoch: 34, num_updates: 8800, iterations: 8800, max_updates: 22000, lr: 0.00003, ups: 0.60, time: 02m 46s 945ms, time_since_start: 04h 11m 53s 815ms, eta: 06h 07m 16s 874ms
2020-06-11T00:54:35 INFO: progress: 8900/22000, train/total_loss: 0.0046, train/total_loss/avg: 0.1170, train/hateful_memes/cross_entropy: 0.0046, train/hateful_memes/cross_entropy/avg: 0.1170, max mem: 11430.0, experiment: run, epoch: 34, num_updates: 8900, iterations: 8900, max_updates: 22000, lr: 0.00003, ups: 0.60, time: 02m 47s 099ms, time_since_start: 04h 14m 40s 915ms, eta: 06h 04m 50s 066ms
2020-06-11T00:57:22 INFO: progress: 9000/22000, train/total_loss: 0.0036, train/total_loss/avg: 0.1157, train/hateful_memes/cross_entropy: 0.0036, train/hateful_memes/cross_entropy/avg: 0.1157, max mem: 11430.0, experiment: run, epoch: 34, num_updates: 9000, iterations: 9000, max_updates: 22000, lr: 0.00003, ups: 0.60, time: 02m 47s 202ms, time_since_start: 04h 17m 28s 118ms, eta: 06h 02m 16s 331ms
2020-06-11T00:57:22 INFO: Checkpoint time. Saving a checkpoint.
2020-06-11T00:57:36 INFO: Evaluation time. Running on full validation set...
2020-06-11T00:58:08 INFO: progress: 9000/22000, val/total_loss: 2.5441, val/hateful_memes/cross_entropy: 2.5441, val/hateful_memes/accuracy: 0.6440, val/hateful_memes/binary_f1: 0.5742, val/hateful_memes/roc_auc: 0.7076, num_updates: 9000, epoch: 34, iterations: 9000, max_updates: 22000, val_time: 08s 747ms, best_update: 6000, best_iteration: 6000, best_val/hateful_memes/roc_auc: 0.738552
2020-06-11T00:58:10 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-11T01:00:56 INFO: progress: 9100/22000, train/total_loss: 0.0036, train/total_loss/avg: 0.1144, train/hateful_memes/cross_entropy: 0.0036, train/hateful_memes/cross_entropy/avg: 0.1144, max mem: 11430.0, experiment: run, epoch: 35, num_updates: 9100, iterations: 9100, max_updates: 22000, lr: 0.00003, ups: 0.60, time: 02m 47s 707ms, time_since_start: 04h 21m 01s 528ms, eta: 06h 34s 228ms
2020-06-11T01:03:43 INFO: progress: 9200/22000, train/total_loss: 0.0036, train/total_loss/avg: 0.1132, train/hateful_memes/cross_entropy: 0.0036, train/hateful_memes/cross_entropy/avg: 0.1132, max mem: 11430.0, experiment: run, epoch: 35, num_updates: 9200, iterations: 9200, max_updates: 22000, lr: 0.00003, ups: 0.60, time: 02m 47s 360ms, time_since_start: 04h 23m 48s 889ms, eta: 05h 57m 02s 133ms
2020-06-11T01:06:31 INFO: progress: 9300/22000, train/total_loss: 0.0036, train/total_loss/avg: 0.1132, train/hateful_memes/cross_entropy: 0.0036, train/hateful_memes/cross_entropy/avg: 0.1132, max mem: 11430.0, experiment: run, epoch: 35, num_updates: 9300, iterations: 9300, max_updates: 22000, lr: 0.00003, ups: 0.60, time: 02m 47s 410ms, time_since_start: 04h 26m 36s 300ms, eta: 05h 54m 21s 197ms
2020-06-11T01:09:17 INFO: progress: 9400/22000, train/total_loss: 0.0036, train/total_loss/avg: 0.1120, train/hateful_memes/cross_entropy: 0.0036, train/hateful_memes/cross_entropy/avg: 0.1120, max mem: 11430.0, experiment: run, epoch: 36, num_updates: 9400, iterations: 9400, max_updates: 22000, lr: 0.00003, ups: 0.60, time: 02m 46s 847ms, time_since_start: 04h 29m 23s 147ms, eta: 05h 50m 22s 763ms
2020-06-11T01:12:05 INFO: progress: 9500/22000, train/total_loss: 0.0036, train/total_loss/avg: 0.1108, train/hateful_memes/cross_entropy: 0.0036, train/hateful_memes/cross_entropy/avg: 0.1108, max mem: 11430.0, experiment: run, epoch: 36, num_updates: 9500, iterations: 9500, max_updates: 22000, lr: 0.00003, ups: 0.60, time: 02m 47s 091ms, time_since_start: 04h 32m 10s 239ms, eta: 05h 48m 06s 472ms
2020-06-11T01:14:51 INFO: progress: 9600/22000, train/total_loss: 0.0036, train/total_loss/avg: 0.1100, train/hateful_memes/cross_entropy: 0.0036, train/hateful_memes/cross_entropy/avg: 0.1100, max mem: 11430.0, experiment: run, epoch: 37, num_updates: 9600, iterations: 9600, max_updates: 22000, lr: 0.00003, ups: 0.60, time: 02m 46s 635ms, time_since_start: 04h 34m 56s 874ms, eta: 05h 44m 22s 766ms
2020-06-11T01:17:38 INFO: progress: 9700/22000, train/total_loss: 0.0010, train/total_loss/avg: 0.1089, train/hateful_memes/cross_entropy: 0.0010, train/hateful_memes/cross_entropy/avg: 0.1089, max mem: 11430.0, experiment: run, epoch: 37, num_updates: 9700, iterations: 9700, max_updates: 22000, lr: 0.00003, ups: 0.60, time: 02m 47s 150ms, time_since_start: 04h 37m 44s 025ms, eta: 05h 42m 39s 500ms
2020-06-11T01:20:25 INFO: progress: 9800/22000, train/total_loss: 0.0010, train/total_loss/avg: 0.1078, train/hateful_memes/cross_entropy: 0.0010, train/hateful_memes/cross_entropy/avg: 0.1078, max mem: 11430.0, experiment: run, epoch: 37, num_updates: 9800, iterations: 9800, max_updates: 22000, lr: 0.00003, ups: 0.60, time: 02m 47s 119ms, time_since_start: 04h 40m 31s 144ms, eta: 05h 39m 48s 549ms
2020-06-11T01:23:12 INFO: progress: 9900/22000, train/total_loss: 0.0008, train/total_loss/avg: 0.1067, train/hateful_memes/cross_entropy: 0.0008, train/hateful_memes/cross_entropy/avg: 0.1067, max mem: 11430.0, experiment: run, epoch: 38, num_updates: 9900, iterations: 9900, max_updates: 22000, lr: 0.00003, ups: 0.60, time: 02m 47s 007ms, time_since_start: 04h 43m 18s 151ms, eta: 05h 36m 47s 904ms
2020-06-11T01:26:00 INFO: progress: 10000/22000, train/total_loss: 0.0008, train/total_loss/avg: 0.1057, train/hateful_memes/cross_entropy: 0.0008, train/hateful_memes/cross_entropy/avg: 0.1057, max mem: 11430.0, experiment: run, epoch: 38, num_updates: 10000, iterations: 10000, max_updates: 22000, lr: 0.00003, ups: 0.60, time: 02m 47s 487ms, time_since_start: 04h 46m 05s 639ms, eta: 05h 34m 58s 500ms
2020-06-11T01:26:00 INFO: Checkpoint time. Saving a checkpoint.
2020-06-11T01:26:13 INFO: Evaluation time. Running on full validation set...
2020-06-11T01:26:46 INFO: progress: 10000/22000, val/total_loss: 2.9041, val/hateful_memes/cross_entropy: 2.9041, val/hateful_memes/accuracy: 0.6100, val/hateful_memes/binary_f1: 0.4800, val/hateful_memes/roc_auc: 0.6965, num_updates: 10000, epoch: 38, iterations: 10000, max_updates: 22000, val_time: 08s 756ms, best_update: 6000, best_iteration: 6000, best_val/hateful_memes/roc_auc: 0.738552
2020-06-11T01:26:49 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-11T01:29:35 INFO: progress: 10100/22000, train/total_loss: 0.0008, train/total_loss/avg: 0.1048, train/hateful_memes/cross_entropy: 0.0008, train/hateful_memes/cross_entropy/avg: 0.1048, max mem: 11430.0, experiment: run, epoch: 38, num_updates: 10100, iterations: 10100, max_updates: 22000, lr: 0.00003, ups: 0.60, time: 02m 48s 050ms, time_since_start: 04h 49m 40s 531ms, eta: 05h 33m 18s 001ms
2020-06-11T01:32:22 INFO: progress: 10200/22000, train/total_loss: 0.0009, train/total_loss/avg: 0.1040, train/hateful_memes/cross_entropy: 0.0009, train/hateful_memes/cross_entropy/avg: 0.1040, max mem: 11430.0, experiment: run, epoch: 39, num_updates: 10200, iterations: 10200, max_updates: 22000, lr: 0.00003, ups: 0.60, time: 02m 46s 989ms, time_since_start: 04h 52m 27s 520ms, eta: 05h 28m 24s 719ms
2020-06-11T01:35:09 INFO: progress: 10300/22000, train/total_loss: 0.0008, train/total_loss/avg: 0.1030, train/hateful_memes/cross_entropy: 0.0008, train/hateful_memes/cross_entropy/avg: 0.1030, max mem: 11430.0, experiment: run, epoch: 39, num_updates: 10300, iterations: 10300, max_updates: 22000, lr: 0.00003, ups: 0.60, time: 02m 47s 100ms, time_since_start: 04h 55m 14s 621ms, eta: 05h 25m 50s 778ms
2020-06-11T01:37:56 INFO: progress: 10400/22000, train/total_loss: 0.0008, train/total_loss/avg: 0.1020, train/hateful_memes/cross_entropy: 0.0008, train/hateful_memes/cross_entropy/avg: 0.1020, max mem: 11430.0, experiment: run, epoch: 40, num_updates: 10400, iterations: 10400, max_updates: 22000, lr: 0.00003, ups: 0.60, time: 02m 46s 848ms, time_since_start: 04h 58m 01s 469ms, eta: 05h 22m 34s 373ms
2020-06-11T01:40:43 INFO: progress: 10500/22000, train/total_loss: 0.0008, train/total_loss/avg: 0.1011, train/hateful_memes/cross_entropy: 0.0008, train/hateful_memes/cross_entropy/avg: 0.1011, max mem: 11430.0, experiment: run, epoch: 40, num_updates: 10500, iterations: 10500, max_updates: 22000, lr: 0.00003, ups: 0.60, time: 02m 47s 138ms, time_since_start: 05h 48s 607ms, eta: 05h 20m 20s 927ms
2020-06-11T01:43:30 INFO: progress: 10600/22000, train/total_loss: 0.0008, train/total_loss/avg: 0.1001, train/hateful_memes/cross_entropy: 0.0008, train/hateful_memes/cross_entropy/avg: 0.1001, max mem: 11430.0, experiment: run, epoch: 40, num_updates: 10600, iterations: 10600, max_updates: 22000, lr: 0.00003, ups: 0.60, time: 02m 47s 058ms, time_since_start: 05h 03m 35s 665ms, eta: 05h 17m 24s 625ms
2020-06-11T01:46:17 INFO: progress: 10700/22000, train/total_loss: 0.0008, train/total_loss/avg: 0.0995, train/hateful_memes/cross_entropy: 0.0008, train/hateful_memes/cross_entropy/avg: 0.0995, max mem: 11430.0, experiment: run, epoch: 41, num_updates: 10700, iterations: 10700, max_updates: 22000, lr: 0.00003, ups: 0.60, time: 02m 46s 992ms, time_since_start: 05h 06m 22s 658ms, eta: 05h 14m 30s 176ms
2020-06-11T01:49:04 INFO: progress: 10800/22000, train/total_loss: 0.0009, train/total_loss/avg: 0.0986, train/hateful_memes/cross_entropy: 0.0009, train/hateful_memes/cross_entropy/avg: 0.0986, max mem: 11430.0, experiment: run, epoch: 41, num_updates: 10800, iterations: 10800, max_updates: 22000, lr: 0.00003, ups: 0.60, time: 02m 47s 043ms, time_since_start: 05h 09m 09s 702ms, eta: 05h 11m 48s 874ms
2020-06-11T01:51:51 INFO: progress: 10900/22000, train/total_loss: 0.0009, train/total_loss/avg: 0.0977, train/hateful_memes/cross_entropy: 0.0009, train/hateful_memes/cross_entropy/avg: 0.0977, max mem: 11430.0, experiment: run, epoch: 41, num_updates: 10900, iterations: 10900, max_updates: 22000, lr: 0.00003, ups: 0.60, time: 02m 47s 117ms, time_since_start: 05h 11m 56s 819ms, eta: 05h 09m 10s 008ms
2020-06-11T01:54:38 INFO: progress: 11000/22000, train/total_loss: 0.0009, train/total_loss/avg: 0.0968, train/hateful_memes/cross_entropy: 0.0009, train/hateful_memes/cross_entropy/avg: 0.0968, max mem: 11430.0, experiment: run, epoch: 42, num_updates: 11000, iterations: 11000, max_updates: 22000, lr: 0.00003, ups: 0.60, time: 02m 46s 819ms, time_since_start: 05h 14m 43s 638ms, eta: 05h 05m 50s 151ms
2020-06-11T01:54:38 INFO: Checkpoint time. Saving a checkpoint.
2020-06-11T01:54:51 INFO: Evaluation time. Running on full validation set...
2020-06-11T01:54:59 INFO: progress: 11000/22000, val/total_loss: 3.0366, val/hateful_memes/cross_entropy: 3.0366, val/hateful_memes/accuracy: 0.6120, val/hateful_memes/binary_f1: 0.4840, val/hateful_memes/roc_auc: 0.6958, num_updates: 11000, epoch: 42, iterations: 11000, max_updates: 22000, val_time: 08s 710ms, best_update: 6000, best_iteration: 6000, best_val/hateful_memes/roc_auc: 0.738552
2020-06-11T01:55:01 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-11T01:57:47 INFO: progress: 11100/22000, train/total_loss: 0.0009, train/total_loss/avg: 0.0960, train/hateful_memes/cross_entropy: 0.0009, train/hateful_memes/cross_entropy/avg: 0.0960, max mem: 11430.0, experiment: run, epoch: 42, num_updates: 11100, iterations: 11100, max_updates: 22000, lr: 0.00003, ups: 0.60, time: 02m 47s 637ms, time_since_start: 05h 17m 53s 032ms, eta: 05h 04m 32s 540ms
2020-06-11T02:00:34 INFO: progress: 11200/22000, train/total_loss: 0.0009, train/total_loss/avg: 0.0951, train/hateful_memes/cross_entropy: 0.0009, train/hateful_memes/cross_entropy/avg: 0.0951, max mem: 11430.0, experiment: run, epoch: 43, num_updates: 11200, iterations: 11200, max_updates: 22000, lr: 0.00003, ups: 0.60, time: 02m 46s 724ms, time_since_start: 05h 20m 39s 756ms, eta: 05h 06s 258ms
2020-06-11T02:03:21 INFO: progress: 11300/22000, train/total_loss: 0.0009, train/total_loss/avg: 0.0943, train/hateful_memes/cross_entropy: 0.0009, train/hateful_memes/cross_entropy/avg: 0.0943, max mem: 11430.0, experiment: run, epoch: 43, num_updates: 11300, iterations: 11300, max_updates: 22000, lr: 0.00003, ups: 0.60, time: 02m 47s 172ms, time_since_start: 05h 23m 26s 929ms, eta: 04h 58m 07s 425ms
2020-06-11T02:06:08 INFO: progress: 11400/22000, train/total_loss: 0.0010, train/total_loss/avg: 0.0935, train/hateful_memes/cross_entropy: 0.0010, train/hateful_memes/cross_entropy/avg: 0.0935, max mem: 11430.0, experiment: run, epoch: 43, num_updates: 11400, iterations: 11400, max_updates: 22000, lr: 0.00003, ups: 0.60, time: 02m 46s 964ms, time_since_start: 05h 26m 13s 893ms, eta: 04h 54m 58s 264ms
2020-06-11T02:08:55 INFO: progress: 11500/22000, train/total_loss: 0.0011, train/total_loss/avg: 0.0927, train/hateful_memes/cross_entropy: 0.0011, train/hateful_memes/cross_entropy/avg: 0.0927, max mem: 11430.0, experiment: run, epoch: 44, num_updates: 11500, iterations: 11500, max_updates: 22000, lr: 0.00003, ups: 0.60, time: 02m 47s 105ms, time_since_start: 05h 29m 999ms, eta: 04h 52m 26s 080ms
2020-06-11T02:11:42 INFO: progress: 11600/22000, train/total_loss: 0.0011, train/total_loss/avg: 0.0919, train/hateful_memes/cross_entropy: 0.0011, train/hateful_memes/cross_entropy/avg: 0.0919, max mem: 11430.0, experiment: run, epoch: 44, num_updates: 11600, iterations: 11600, max_updates: 22000, lr: 0.00003, ups: 0.60, time: 02m 47s 123ms, time_since_start: 05h 31m 48s 122ms, eta: 04h 49m 40s 799ms
2020-06-11T02:14:29 INFO: progress: 11700/22000, train/total_loss: 0.0015, train/total_loss/avg: 0.0912, train/hateful_memes/cross_entropy: 0.0015, train/hateful_memes/cross_entropy/avg: 0.0912, max mem: 11430.0, experiment: run, epoch: 44, num_updates: 11700, iterations: 11700, max_updates: 22000, lr: 0.00003, ups: 0.60, time: 02m 46s 859ms, time_since_start: 05h 34m 34s 982ms, eta: 04h 46m 26s 581ms
2020-06-11T02:17:16 INFO: progress: 11800/22000, train/total_loss: 0.0011, train/total_loss/avg: 0.0904, train/hateful_memes/cross_entropy: 0.0011, train/hateful_memes/cross_entropy/avg: 0.0904, max mem: 11430.0, experiment: run, epoch: 45, num_updates: 11800, iterations: 11800, max_updates: 22000, lr: 0.00003, ups: 0.60, time: 02m 46s 821ms, time_since_start: 05h 37m 21s 804ms, eta: 04h 43m 35s 809ms
2020-06-11T02:20:03 INFO: progress: 11900/22000, train/total_loss: 0.0015, train/total_loss/avg: 0.0897, train/hateful_memes/cross_entropy: 0.0015, train/hateful_memes/cross_entropy/avg: 0.0897, max mem: 11430.0, experiment: run, epoch: 45, num_updates: 11900, iterations: 11900, max_updates: 22000, lr: 0.00003, ups: 0.60, time: 02m 46s 949ms, time_since_start: 05h 40m 08s 753ms, eta: 04h 41m 01s 854ms
2020-06-11T02:22:50 INFO: progress: 12000/22000, train/total_loss: 0.0021, train/total_loss/avg: 0.0891, train/hateful_memes/cross_entropy: 0.0021, train/hateful_memes/cross_entropy/avg: 0.0891, max mem: 11430.0, experiment: run, epoch: 46, num_updates: 12000, iterations: 12000, max_updates: 22000, lr: 0.00003, ups: 0.60, time: 02m 46s 992ms, time_since_start: 05h 42m 55s 745ms, eta: 04h 38m 19s 215ms
2020-06-11T02:22:50 INFO: Checkpoint time. Saving a checkpoint.
2020-06-11T02:23:03 INFO: Evaluation time. Running on full validation set...
2020-06-11T02:23:13 INFO: progress: 12000/22000, val/total_loss: 2.5485, val/hateful_memes/cross_entropy: 2.5485, val/hateful_memes/accuracy: 0.6280, val/hateful_memes/binary_f1: 0.5441, val/hateful_memes/roc_auc: 0.7003, num_updates: 12000, epoch: 46, iterations: 12000, max_updates: 22000, val_time: 10s 205ms, best_update: 6000, best_iteration: 6000, best_val/hateful_memes/roc_auc: 0.738552
2020-06-11T02:23:15 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-11T02:26:01 INFO: progress: 12100/22000, train/total_loss: 0.0015, train/total_loss/avg: 0.0884, train/hateful_memes/cross_entropy: 0.0015, train/hateful_memes/cross_entropy/avg: 0.0884, max mem: 11430.0, experiment: run, epoch: 46, num_updates: 12100, iterations: 12100, max_updates: 22000, lr: 0.00002, ups: 0.60, time: 02m 47s 568ms, time_since_start: 05h 46m 07s 034ms, eta: 04h 36m 29s 314ms
2020-06-11T02:28:48 INFO: progress: 12200/22000, train/total_loss: 0.0015, train/total_loss/avg: 0.0878, train/hateful_memes/cross_entropy: 0.0015, train/hateful_memes/cross_entropy/avg: 0.0878, max mem: 11430.0, experiment: run, epoch: 46, num_updates: 12200, iterations: 12200, max_updates: 22000, lr: 0.00002, ups: 0.60, time: 02m 47s 132ms, time_since_start: 05h 48m 54s 166ms, eta: 04h 32m 58s 941ms
2020-06-11T02:31:35 INFO: progress: 12300/22000, train/total_loss: 0.0021, train/total_loss/avg: 0.0872, train/hateful_memes/cross_entropy: 0.0021, train/hateful_memes/cross_entropy/avg: 0.0872, max mem: 11430.0, experiment: run, epoch: 47, num_updates: 12300, iterations: 12300, max_updates: 22000, lr: 0.00002, ups: 0.60, time: 02m 46s 859ms, time_since_start: 05h 51m 41s 025ms, eta: 04h 29m 45s 333ms
2020-06-11T02:34:22 INFO: progress: 12400/22000, train/total_loss: 0.0021, train/total_loss/avg: 0.0865, train/hateful_memes/cross_entropy: 0.0021, train/hateful_memes/cross_entropy/avg: 0.0865, max mem: 11430.0, experiment: run, epoch: 47, num_updates: 12400, iterations: 12400, max_updates: 22000, lr: 0.00002, ups: 0.60, time: 02m 47s 133ms, time_since_start: 05h 54m 28s 159ms, eta: 04h 27m 24s 853ms
2020-06-11T02:37:10 INFO: progress: 12500/22000, train/total_loss: 0.0021, train/total_loss/avg: 0.0858, train/hateful_memes/cross_entropy: 0.0021, train/hateful_memes/cross_entropy/avg: 0.0858, max mem: 11430.0, experiment: run, epoch: 47, num_updates: 12500, iterations: 12500, max_updates: 22000, lr: 0.00002, ups: 0.60, time: 02m 47s 141ms, time_since_start: 05h 57m 15s 300ms, eta: 04h 24m 38s 472ms
2020-06-11T02:39:57 INFO: progress: 12600/22000, train/total_loss: 0.0021, train/total_loss/avg: 0.0852, train/hateful_memes/cross_entropy: 0.0021, train/hateful_memes/cross_entropy/avg: 0.0852, max mem: 11430.0, experiment: run, epoch: 48, num_updates: 12600, iterations: 12600, max_updates: 22000, lr: 0.00002, ups: 0.60, time: 02m 46s 937ms, time_since_start: 06h 02s 238ms, eta: 04h 21m 32s 103ms
2020-06-11T02:42:43 INFO: progress: 12700/22000, train/total_loss: 0.0021, train/total_loss/avg: 0.0846, train/hateful_memes/cross_entropy: 0.0021, train/hateful_memes/cross_entropy/avg: 0.0846, max mem: 11430.0, experiment: run, epoch: 48, num_updates: 12700, iterations: 12700, max_updates: 22000, lr: 0.00002, ups: 0.60, time: 02m 46s 742ms, time_since_start: 06h 02m 48s 980ms, eta: 04h 18m 27s 066ms
2020-06-11T02:45:30 INFO: progress: 12800/22000, train/total_loss: 0.0016, train/total_loss/avg: 0.0840, train/hateful_memes/cross_entropy: 0.0016, train/hateful_memes/cross_entropy/avg: 0.0840, max mem: 11430.0, experiment: run, epoch: 49, num_updates: 12800, iterations: 12800, max_updates: 22000, lr: 0.00002, ups: 0.60, time: 02m 46s 858ms, time_since_start: 06h 05m 35s 839ms, eta: 04h 15m 50s 990ms
2020-06-11T02:48:18 INFO: progress: 12900/22000, train/total_loss: 0.0016, train/total_loss/avg: 0.0833, train/hateful_memes/cross_entropy: 0.0016, train/hateful_memes/cross_entropy/avg: 0.0833, max mem: 11430.0, experiment: run, epoch: 49, num_updates: 12900, iterations: 12900, max_updates: 22000, lr: 0.00002, ups: 0.60, time: 02m 47s 617ms, time_since_start: 06h 08m 23s 456ms, eta: 04h 14m 13s 156ms
2020-06-11T02:51:05 INFO: progress: 13000/22000, train/total_loss: 0.0016, train/total_loss/avg: 0.0827, train/hateful_memes/cross_entropy: 0.0016, train/hateful_memes/cross_entropy/avg: 0.0827, max mem: 11430.0, experiment: run, epoch: 49, num_updates: 13000, iterations: 13000, max_updates: 22000, lr: 0.00002, ups: 0.60, time: 02m 47s 298ms, time_since_start: 06h 11m 10s 754ms, eta: 04h 10m 56s 841ms
2020-06-11T02:51:05 INFO: Checkpoint time. Saving a checkpoint.
2020-06-11T02:51:19 INFO: Evaluation time. Running on full validation set...
2020-06-11T02:51:28 INFO: progress: 13000/22000, val/total_loss: 2.4441, val/hateful_memes/cross_entropy: 2.4441, val/hateful_memes/accuracy: 0.6140, val/hateful_memes/binary_f1: 0.4961, val/hateful_memes/roc_auc: 0.6980, num_updates: 13000, epoch: 49, iterations: 13000, max_updates: 22000, val_time: 08s 747ms, best_update: 6000, best_iteration: 6000, best_val/hateful_memes/roc_auc: 0.738552
2020-06-11T02:51:30 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-11T02:54:15 INFO: progress: 13100/22000, train/total_loss: 0.0016, train/total_loss/avg: 0.0820, train/hateful_memes/cross_entropy: 0.0016, train/hateful_memes/cross_entropy/avg: 0.0820, max mem: 11430.0, experiment: run, epoch: 50, num_updates: 13100, iterations: 13100, max_updates: 22000, lr: 0.00002, ups: 0.60, time: 02m 47s 580ms, time_since_start: 06h 14m 21s 069ms, eta: 04h 08m 34s 642ms
2020-06-11T02:57:02 INFO: progress: 13200/22000, train/total_loss: 0.0016, train/total_loss/avg: 0.0814, train/hateful_memes/cross_entropy: 0.0016, train/hateful_memes/cross_entropy/avg: 0.0814, max mem: 11430.0, experiment: run, epoch: 50, num_updates: 13200, iterations: 13200, max_updates: 22000, lr: 0.00002, ups: 0.60, time: 02m 46s 907ms, time_since_start: 06h 17m 07s 977ms, eta: 04h 04m 47s 861ms
2020-06-11T02:59:49 INFO: progress: 13300/22000, train/total_loss: 0.0016, train/total_loss/avg: 0.0810, train/hateful_memes/cross_entropy: 0.0016, train/hateful_memes/cross_entropy/avg: 0.0810, max mem: 11430.0, experiment: run, epoch: 50, num_updates: 13300, iterations: 13300, max_updates: 22000, lr: 0.00002, ups: 0.60, time: 02m 46s 258ms, time_since_start: 06h 19m 54s 235ms, eta: 04h 01m 04s 464ms
2020-06-11T03:02:36 INFO: progress: 13400/22000, train/total_loss: 0.0016, train/total_loss/avg: 0.0806, train/hateful_memes/cross_entropy: 0.0016, train/hateful_memes/cross_entropy/avg: 0.0806, max mem: 11430.0, experiment: run, epoch: 51, num_updates: 13400, iterations: 13400, max_updates: 22000, lr: 0.00002, ups: 0.60, time: 02m 47s 771ms, time_since_start: 06h 22m 42s 007ms, eta: 04h 28s 390ms
2020-06-11T03:05:24 INFO: progress: 13500/22000, train/total_loss: 0.0016, train/total_loss/avg: 0.0802, train/hateful_memes/cross_entropy: 0.0016, train/hateful_memes/cross_entropy/avg: 0.0802, max mem: 11430.0, experiment: run, epoch: 51, num_updates: 13500, iterations: 13500, max_updates: 22000, lr: 0.00002, ups: 0.60, time: 02m 47s 206ms, time_since_start: 06h 25m 29s 214ms, eta: 03h 56m 52s 581ms
2020-06-11T03:08:11 INFO: progress: 13600/22000, train/total_loss: 0.0015, train/total_loss/avg: 0.0796, train/hateful_memes/cross_entropy: 0.0015, train/hateful_memes/cross_entropy/avg: 0.0796, max mem: 11430.0, experiment: run, epoch: 52, num_updates: 13600, iterations: 13600, max_updates: 22000, lr: 0.00002, ups: 0.60, time: 02m 47s 098ms, time_since_start: 06h 28m 16s 313ms, eta: 03h 53m 56s 301ms
2020-06-11T03:10:58 INFO: progress: 13700/22000, train/total_loss: 0.0005, train/total_loss/avg: 0.0791, train/hateful_memes/cross_entropy: 0.0005, train/hateful_memes/cross_entropy/avg: 0.0791, max mem: 11430.0, experiment: run, epoch: 52, num_updates: 13700, iterations: 13700, max_updates: 22000, lr: 0.00002, ups: 0.60, time: 02m 47s 274ms, time_since_start: 06h 31m 03s 588ms, eta: 03h 51m 23s 792ms
2020-06-11T03:13:45 INFO: progress: 13800/22000, train/total_loss: 0.0007, train/total_loss/avg: 0.0785, train/hateful_memes/cross_entropy: 0.0007, train/hateful_memes/cross_entropy/avg: 0.0785, max mem: 11430.0, experiment: run, epoch: 52, num_updates: 13800, iterations: 13800, max_updates: 22000, lr: 0.00002, ups: 0.60, time: 02m 47s 220ms, time_since_start: 06h 33m 50s 809ms, eta: 03h 48m 32s 116ms
2020-06-11T03:16:32 INFO: progress: 13900/22000, train/total_loss: 0.0006, train/total_loss/avg: 0.0779, train/hateful_memes/cross_entropy: 0.0006, train/hateful_memes/cross_entropy/avg: 0.0779, max mem: 11430.0, experiment: run, epoch: 53, num_updates: 13900, iterations: 13900, max_updates: 22000, lr: 0.00002, ups: 0.60, time: 02m 46s 810ms, time_since_start: 06h 36m 37s 619ms, eta: 03h 45m 11s 634ms
2020-06-11T03:19:19 INFO: progress: 14000/22000, train/total_loss: 0.0006, train/total_loss/avg: 0.0774, train/hateful_memes/cross_entropy: 0.0006, train/hateful_memes/cross_entropy/avg: 0.0774, max mem: 11430.0, experiment: run, epoch: 53, num_updates: 14000, iterations: 14000, max_updates: 22000, lr: 0.00002, ups: 0.60, time: 02m 46s 902ms, time_since_start: 06h 39m 24s 521ms, eta: 03h 42m 32s 175ms
2020-06-11T03:19:19 INFO: Checkpoint time. Saving a checkpoint.
2020-06-11T03:19:32 INFO: Evaluation time. Running on full validation set...
2020-06-11T03:19:41 INFO: progress: 14000/22000, val/total_loss: 2.6109, val/hateful_memes/cross_entropy: 2.6109, val/hateful_memes/accuracy: 0.6260, val/hateful_memes/binary_f1: 0.5117, val/hateful_memes/roc_auc: 0.7018, num_updates: 14000, epoch: 53, iterations: 14000, max_updates: 22000, val_time: 08s 734ms, best_update: 6000, best_iteration: 6000, best_val/hateful_memes/roc_auc: 0.738552
2020-06-11T03:19:43 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-11T03:22:28 INFO: progress: 14100/22000, train/total_loss: 0.0006, train/total_loss/avg: 0.0768, train/hateful_memes/cross_entropy: 0.0006, train/hateful_memes/cross_entropy/avg: 0.0768, max mem: 11430.0, experiment: run, epoch: 54, num_updates: 14100, iterations: 14100, max_updates: 22000, lr: 0.00002, ups: 0.60, time: 02m 47s 369ms, time_since_start: 06h 42m 34s 127ms, eta: 03h 40m 22s 173ms
2020-06-11T03:25:15 INFO: progress: 14200/22000, train/total_loss: 0.0006, train/total_loss/avg: 0.0763, train/hateful_memes/cross_entropy: 0.0006, train/hateful_memes/cross_entropy/avg: 0.0763, max mem: 11430.0, experiment: run, epoch: 54, num_updates: 14200, iterations: 14200, max_updates: 22000, lr: 0.00002, ups: 0.60, time: 02m 46s 928ms, time_since_start: 06h 45m 21s 055ms, eta: 03h 37m 397ms
2020-06-11T03:28:02 INFO: progress: 14300/22000, train/total_loss: 0.0005, train/total_loss/avg: 0.0758, train/hateful_memes/cross_entropy: 0.0005, train/hateful_memes/cross_entropy/avg: 0.0758, max mem: 11430.0, experiment: run, epoch: 54, num_updates: 14300, iterations: 14300, max_updates: 22000, lr: 0.00002, ups: 0.60, time: 02m 47s 089ms, time_since_start: 06h 48m 08s 145ms, eta: 03h 34m 25s 921ms
2020-06-11T03:30:49 INFO: progress: 14400/22000, train/total_loss: 0.0005, train/total_loss/avg: 0.0753, train/hateful_memes/cross_entropy: 0.0005, train/hateful_memes/cross_entropy/avg: 0.0753, max mem: 11430.0, experiment: run, epoch: 55, num_updates: 14400, iterations: 14400, max_updates: 22000, lr: 0.00002, ups: 0.60, time: 02m 46s 672ms, time_since_start: 06h 50m 54s 818ms, eta: 03h 31m 07s 138ms
2020-06-11T03:33:36 INFO: progress: 14500/22000, train/total_loss: 0.0005, train/total_loss/avg: 0.0747, train/hateful_memes/cross_entropy: 0.0005, train/hateful_memes/cross_entropy/avg: 0.0747, max mem: 11430.0, experiment: run, epoch: 55, num_updates: 14500, iterations: 14500, max_updates: 22000, lr: 0.00002, ups: 0.60, time: 02m 47s 004ms, time_since_start: 06h 53m 41s 822ms, eta: 03h 28m 45s 304ms
2020-06-11T03:36:23 INFO: progress: 14600/22000, train/total_loss: 0.0005, train/total_loss/avg: 0.0742, train/hateful_memes/cross_entropy: 0.0005, train/hateful_memes/cross_entropy/avg: 0.0742, max mem: 11430.0, experiment: run, epoch: 55, num_updates: 14600, iterations: 14600, max_updates: 22000, lr: 0.00002, ups: 0.60, time: 02m 47s 027ms, time_since_start: 06h 56m 28s 850ms, eta: 03h 26m 067ms
2020-06-11T03:39:10 INFO: progress: 14700/22000, train/total_loss: 0.0005, train/total_loss/avg: 0.0737, train/hateful_memes/cross_entropy: 0.0005, train/hateful_memes/cross_entropy/avg: 0.0737, max mem: 11430.0, experiment: run, epoch: 56, num_updates: 14700, iterations: 14700, max_updates: 22000, lr: 0.00002, ups: 0.60, time: 02m 47s 269ms, time_since_start: 06h 59m 16s 119ms, eta: 03h 23m 30s 646ms
2020-06-11T03:41:58 INFO: progress: 14800/22000, train/total_loss: 0.0005, train/total_loss/avg: 0.0735, train/hateful_memes/cross_entropy: 0.0005, train/hateful_memes/cross_entropy/avg: 0.0735, max mem: 11430.0, experiment: run, epoch: 56, num_updates: 14800, iterations: 14800, max_updates: 22000, lr: 0.00002, ups: 0.60, time: 02m 47s 550ms, time_since_start: 07h 02m 03s 670ms, eta: 03h 21m 03s 668ms
2020-06-11T03:44:45 INFO: progress: 14900/22000, train/total_loss: 0.0005, train/total_loss/avg: 0.0730, train/hateful_memes/cross_entropy: 0.0005, train/hateful_memes/cross_entropy/avg: 0.0730, max mem: 11430.0, experiment: run, epoch: 57, num_updates: 14900, iterations: 14900, max_updates: 22000, lr: 0.00002, ups: 0.60, time: 02m 47s 384ms, time_since_start: 07h 04m 51s 055ms, eta: 03h 18m 04s 304ms
2020-06-11T03:47:33 INFO: progress: 15000/22000, train/total_loss: 0.0005, train/total_loss/avg: 0.0725, train/hateful_memes/cross_entropy: 0.0005, train/hateful_memes/cross_entropy/avg: 0.0725, max mem: 11430.0, experiment: run, epoch: 57, num_updates: 15000, iterations: 15000, max_updates: 22000, lr: 0.00002, ups: 0.60, time: 02m 47s 502ms, time_since_start: 07h 07m 38s 557ms, eta: 03h 15m 25s 158ms
2020-06-11T03:47:33 INFO: Checkpoint time. Saving a checkpoint.
2020-06-11T03:47:46 INFO: Evaluation time. Running on full validation set...
2020-06-11T03:47:55 INFO: progress: 15000/22000, val/total_loss: 3.2926, val/hateful_memes/cross_entropy: 3.2926, val/hateful_memes/accuracy: 0.6440, val/hateful_memes/binary_f1: 0.5505, val/hateful_memes/roc_auc: 0.7046, num_updates: 15000, epoch: 57, iterations: 15000, max_updates: 22000, val_time: 08s 775ms, best_update: 6000, best_iteration: 6000, best_val/hateful_memes/roc_auc: 0.738552
2020-06-11T03:47:57 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-11T03:50:43 INFO: progress: 15100/22000, train/total_loss: 0.0005, train/total_loss/avg: 0.0720, train/hateful_memes/cross_entropy: 0.0005, train/hateful_memes/cross_entropy/avg: 0.0720, max mem: 11430.0, experiment: run, epoch: 57, num_updates: 15100, iterations: 15100, max_updates: 22000, lr: 0.00002, ups: 0.60, time: 02m 47s 776ms, time_since_start: 07h 10m 48s 644ms, eta: 03h 12m 56s 571ms
2020-06-11T03:53:30 INFO: progress: 15200/22000, train/total_loss: 0.0005, train/total_loss/avg: 0.0715, train/hateful_memes/cross_entropy: 0.0005, train/hateful_memes/cross_entropy/avg: 0.0715, max mem: 11430.0, experiment: run, epoch: 58, num_updates: 15200, iterations: 15200, max_updates: 22000, lr: 0.00002, ups: 0.60, time: 02m 47s 213ms, time_since_start: 07h 13m 35s 858ms, eta: 03h 09m 30s 545ms
2020-06-11T03:56:18 INFO: progress: 15300/22000, train/total_loss: 0.0005, train/total_loss/avg: 0.0711, train/hateful_memes/cross_entropy: 0.0005, train/hateful_memes/cross_entropy/avg: 0.0711, max mem: 11430.0, experiment: run, epoch: 58, num_updates: 15300, iterations: 15300, max_updates: 22000, lr: 0.00002, ups: 0.60, time: 02m 47s 359ms, time_since_start: 07h 16m 23s 217ms, eta: 03h 06m 53s 055ms
2020-06-11T03:59:05 INFO: progress: 15400/22000, train/total_loss: 0.0005, train/total_loss/avg: 0.0706, train/hateful_memes/cross_entropy: 0.0005, train/hateful_memes/cross_entropy/avg: 0.0706, max mem: 11430.0, experiment: run, epoch: 58, num_updates: 15400, iterations: 15400, max_updates: 22000, lr: 0.00002, ups: 0.60, time: 02m 47s 534ms, time_since_start: 07h 19m 10s 751ms, eta: 03h 04m 17s 249ms
2020-06-11T04:01:52 INFO: progress: 15500/22000, train/total_loss: 0.0005, train/total_loss/avg: 0.0702, train/hateful_memes/cross_entropy: 0.0005, train/hateful_memes/cross_entropy/avg: 0.0702, max mem: 11430.0, experiment: run, epoch: 59, num_updates: 15500, iterations: 15500, max_updates: 22000, lr: 0.00002, ups: 0.60, time: 02m 46s 903ms, time_since_start: 07h 21m 57s 654ms, eta: 03h 48s 737ms
2020-06-11T04:04:39 INFO: progress: 15600/22000, train/total_loss: 0.0005, train/total_loss/avg: 0.0697, train/hateful_memes/cross_entropy: 0.0005, train/hateful_memes/cross_entropy/avg: 0.0697, max mem: 11430.0, experiment: run, epoch: 59, num_updates: 15600, iterations: 15600, max_updates: 22000, lr: 0.00002, ups: 0.60, time: 02m 47s 234ms, time_since_start: 07h 24m 44s 889ms, eta: 02h 58m 23s 018ms
2020-06-11T04:07:26 INFO: progress: 15700/22000, train/total_loss: 0.0005, train/total_loss/avg: 0.0693, train/hateful_memes/cross_entropy: 0.0005, train/hateful_memes/cross_entropy/avg: 0.0693, max mem: 11430.0, experiment: run, epoch: 60, num_updates: 15700, iterations: 15700, max_updates: 22000, lr: 0.00002, ups: 0.60, time: 02m 46s 999ms, time_since_start: 07h 27m 31s 888ms, eta: 02h 55m 20s 963ms
2020-06-11T04:10:14 INFO: progress: 15800/22000, train/total_loss: 0.0005, train/total_loss/avg: 0.0688, train/hateful_memes/cross_entropy: 0.0005, train/hateful_memes/cross_entropy/avg: 0.0688, max mem: 11430.0, experiment: run, epoch: 60, num_updates: 15800, iterations: 15800, max_updates: 22000, lr: 0.00002, ups: 0.60, time: 02m 47s 640ms, time_since_start: 07h 30m 19s 529ms, eta: 02h 53m 13s 736ms
2020-06-11T04:13:01 INFO: progress: 15900/22000, train/total_loss: 0.0004, train/total_loss/avg: 0.0684, train/hateful_memes/cross_entropy: 0.0004, train/hateful_memes/cross_entropy/avg: 0.0684, max mem: 11430.0, experiment: run, epoch: 60, num_updates: 15900, iterations: 15900, max_updates: 22000, lr: 0.00002, ups: 0.60, time: 02m 47s 579ms, time_since_start: 07h 33m 07s 109ms, eta: 02h 50m 22s 335ms
2020-06-11T04:15:48 INFO: progress: 16000/22000, train/total_loss: 0.0004, train/total_loss/avg: 0.0681, train/hateful_memes/cross_entropy: 0.0004, train/hateful_memes/cross_entropy/avg: 0.0681, max mem: 11430.0, experiment: run, epoch: 61, num_updates: 16000, iterations: 16000, max_updates: 22000, lr: 0.00002, ups: 0.60, time: 02m 47s 039ms, time_since_start: 07h 35m 54s 148ms, eta: 02h 47m 02s 370ms
2020-06-11T04:15:48 INFO: Checkpoint time. Saving a checkpoint.
2020-06-11T04:16:01 INFO: Evaluation time. Running on full validation set...
2020-06-11T04:16:10 INFO: progress: 16000/22000, val/total_loss: 3.1911, val/hateful_memes/cross_entropy: 3.1911, val/hateful_memes/accuracy: 0.6480, val/hateful_memes/binary_f1: 0.5644, val/hateful_memes/roc_auc: 0.7011, num_updates: 16000, epoch: 61, iterations: 16000, max_updates: 22000, val_time: 08s 721ms, best_update: 6000, best_iteration: 6000, best_val/hateful_memes/roc_auc: 0.738552
2020-06-11T04:16:12 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-11T04:18:58 INFO: progress: 16100/22000, train/total_loss: 0.0002, train/total_loss/avg: 0.0677, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0677, max mem: 11430.0, experiment: run, epoch: 61, num_updates: 16100, iterations: 16100, max_updates: 22000, lr: 0.00001, ups: 0.60, time: 02m 47s 446ms, time_since_start: 07h 39m 03s 324ms, eta: 02h 44m 39s 319ms
2020-06-11T04:21:45 INFO: progress: 16200/22000, train/total_loss: 0.0002, train/total_loss/avg: 0.0673, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0673, max mem: 11430.0, experiment: run, epoch: 61, num_updates: 16200, iterations: 16200, max_updates: 22000, lr: 0.00001, ups: 0.60, time: 02m 46s 978ms, time_since_start: 07h 41m 50s 302ms, eta: 02h 41m 24s 757ms
2020-06-11T04:24:32 INFO: progress: 16300/22000, train/total_loss: 0.0003, train/total_loss/avg: 0.0668, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0668, max mem: 11430.0, experiment: run, epoch: 62, num_updates: 16300, iterations: 16300, max_updates: 22000, lr: 0.00001, ups: 0.60, time: 02m 47s 130ms, time_since_start: 07h 44m 37s 433ms, eta: 02h 38m 46s 439ms
2020-06-11T04:27:19 INFO: progress: 16400/22000, train/total_loss: 0.0003, train/total_loss/avg: 0.0664, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0664, max mem: 11430.0, experiment: run, epoch: 62, num_updates: 16400, iterations: 16400, max_updates: 22000, lr: 0.00001, ups: 0.60, time: 02m 47s 225ms, time_since_start: 07h 47m 24s 658ms, eta: 02h 36m 04s 616ms
2020-06-11T04:30:06 INFO: progress: 16500/22000, train/total_loss: 0.0004, train/total_loss/avg: 0.0660, train/hateful_memes/cross_entropy: 0.0004, train/hateful_memes/cross_entropy/avg: 0.0660, max mem: 11430.0, experiment: run, epoch: 63, num_updates: 16500, iterations: 16500, max_updates: 22000, lr: 0.00001, ups: 0.60, time: 02m 46s 906ms, time_since_start: 07h 50m 11s 565ms, eta: 02h 32m 59s 881ms
2020-06-11T04:32:53 INFO: progress: 16600/22000, train/total_loss: 0.0003, train/total_loss/avg: 0.0656, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0656, max mem: 11430.0, experiment: run, epoch: 63, num_updates: 16600, iterations: 16600, max_updates: 22000, lr: 0.00001, ups: 0.60, time: 02m 46s 890ms, time_since_start: 07h 52m 58s 456ms, eta: 02h 30m 12s 101ms
2020-06-11T04:35:40 INFO: progress: 16700/22000, train/total_loss: 0.0002, train/total_loss/avg: 0.0652, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0652, max mem: 11430.0, experiment: run, epoch: 63, num_updates: 16700, iterations: 16700, max_updates: 22000, lr: 0.00001, ups: 0.60, time: 02m 47s 005ms, time_since_start: 07h 55m 45s 462ms, eta: 02h 27m 31s 298ms
2020-06-11T04:38:27 INFO: progress: 16800/22000, train/total_loss: 0.0001, train/total_loss/avg: 0.0649, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0649, max mem: 11430.0, experiment: run, epoch: 64, num_updates: 16800, iterations: 16800, max_updates: 22000, lr: 0.00001, ups: 0.60, time: 02m 46s 769ms, time_since_start: 07h 58m 32s 231ms, eta: 02h 24m 32s 032ms
2020-06-11T04:41:14 INFO: progress: 16900/22000, train/total_loss: 0.0001, train/total_loss/avg: 0.0645, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0645, max mem: 11430.0, experiment: run, epoch: 64, num_updates: 16900, iterations: 16900, max_updates: 22000, lr: 0.00001, ups: 0.60, time: 02m 47s 257ms, time_since_start: 08h 01m 19s 489ms, eta: 02h 22m 10s 116ms
2020-06-11T04:44:01 INFO: progress: 17000/22000, train/total_loss: 0.0001, train/total_loss/avg: 0.0641, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0641, max mem: 11430.0, experiment: run, epoch: 64, num_updates: 17000, iterations: 17000, max_updates: 22000, lr: 0.00001, ups: 0.60, time: 02m 47s 111ms, time_since_start: 08h 04m 06s 600ms, eta: 02h 19m 15s 566ms
2020-06-11T04:44:01 INFO: Checkpoint time. Saving a checkpoint.
2020-06-11T04:44:15 INFO: Evaluation time. Running on full validation set...
2020-06-11T04:44:23 INFO: progress: 17000/22000, val/total_loss: 2.9802, val/hateful_memes/cross_entropy: 2.9802, val/hateful_memes/accuracy: 0.6400, val/hateful_memes/binary_f1: 0.5522, val/hateful_memes/roc_auc: 0.7043, num_updates: 17000, epoch: 64, iterations: 17000, max_updates: 22000, val_time: 08s 651ms, best_update: 6000, best_iteration: 6000, best_val/hateful_memes/roc_auc: 0.738552
2020-06-11T04:44:25 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-11T04:47:11 INFO: progress: 17100/22000, train/total_loss: 0.0001, train/total_loss/avg: 0.0637, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0637, max mem: 11430.0, experiment: run, epoch: 65, num_updates: 17100, iterations: 17100, max_updates: 22000, lr: 0.00001, ups: 0.60, time: 02m 47s 351ms, time_since_start: 08h 07m 16s 568ms, eta: 02h 16m 40s 209ms
2020-06-11T04:49:58 INFO: progress: 17200/22000, train/total_loss: 0.0001, train/total_loss/avg: 0.0634, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0634, max mem: 11430.0, experiment: run, epoch: 65, num_updates: 17200, iterations: 17200, max_updates: 22000, lr: 0.00001, ups: 0.60, time: 02m 47s 344ms, time_since_start: 08h 10m 03s 912ms, eta: 02h 13m 52s 554ms
2020-06-11T04:52:45 INFO: progress: 17300/22000, train/total_loss: 0.0001, train/total_loss/avg: 0.0630, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0630, max mem: 11430.0, experiment: run, epoch: 66, num_updates: 17300, iterations: 17300, max_updates: 22000, lr: 0.00001, ups: 0.60, time: 02m 47s 218ms, time_since_start: 08h 12m 51s 131ms, eta: 02h 10m 59s 274ms
2020-06-11T04:55:32 INFO: progress: 17400/22000, train/total_loss: 0.0001, train/total_loss/avg: 0.0626, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0626, max mem: 11430.0, experiment: run, epoch: 66, num_updates: 17400, iterations: 17400, max_updates: 22000, lr: 0.00001, ups: 0.60, time: 02m 46s 928ms, time_since_start: 08h 15m 38s 059ms, eta: 02h 07m 58s 706ms
2020-06-11T04:58:19 INFO: progress: 17500/22000, train/total_loss: 0.0001, train/total_loss/avg: 0.0623, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0623, max mem: 11430.0, experiment: run, epoch: 66, num_updates: 17500, iterations: 17500, max_updates: 22000, lr: 0.00001, ups: 0.60, time: 02m 46s 888ms, time_since_start: 08h 18m 24s 949ms, eta: 02h 05m 10s 005ms
2020-06-11T05:01:06 INFO: progress: 17600/22000, train/total_loss: 0.0001, train/total_loss/avg: 0.0619, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0619, max mem: 11430.0, experiment: run, epoch: 67, num_updates: 17600, iterations: 17600, max_updates: 22000, lr: 0.00001, ups: 0.60, time: 02m 46s 785ms, time_since_start: 08h 21m 11s 734ms, eta: 02h 02m 18s 551ms
2020-06-11T05:03:53 INFO: progress: 17700/22000, train/total_loss: 0.0001, train/total_loss/avg: 0.0616, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0616, max mem: 11430.0, experiment: run, epoch: 67, num_updates: 17700, iterations: 17700, max_updates: 22000, lr: 0.00001, ups: 0.60, time: 02m 47s 193ms, time_since_start: 08h 23m 58s 927ms, eta: 01h 59m 49s 315ms
2020-06-11T05:06:40 INFO: progress: 17800/22000, train/total_loss: 0.0001, train/total_loss/avg: 0.0612, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0612, max mem: 11430.0, experiment: run, epoch: 67, num_updates: 17800, iterations: 17800, max_updates: 22000, lr: 0.00001, ups: 0.60, time: 02m 47s 027ms, time_since_start: 08h 26m 45s 955ms, eta: 01h 56m 55s 167ms
2020-06-11T05:09:28 INFO: progress: 17900/22000, train/total_loss: 0.0001, train/total_loss/avg: 0.0609, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0609, max mem: 11430.0, experiment: run, epoch: 68, num_updates: 17900, iterations: 17900, max_updates: 22000, lr: 0.00001, ups: 0.60, time: 02m 47s 295ms, time_since_start: 08h 29m 33s 250ms, eta: 01h 54m 19s 098ms
2020-06-11T05:12:15 INFO: progress: 18000/22000, train/total_loss: 0.0001, train/total_loss/avg: 0.0605, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0605, max mem: 11430.0, experiment: run, epoch: 68, num_updates: 18000, iterations: 18000, max_updates: 22000, lr: 0.00001, ups: 0.60, time: 02m 47s 361ms, time_since_start: 08h 32m 20s 612ms, eta: 01h 51m 34s 459ms
2020-06-11T05:12:15 INFO: Checkpoint time. Saving a checkpoint.
2020-06-11T05:12:28 INFO: Evaluation time. Running on full validation set...
2020-06-11T05:12:37 INFO: progress: 18000/22000, val/total_loss: 3.0479, val/hateful_memes/cross_entropy: 3.0479, val/hateful_memes/accuracy: 0.6360, val/hateful_memes/binary_f1: 0.5285, val/hateful_memes/roc_auc: 0.7118, num_updates: 18000, epoch: 68, iterations: 18000, max_updates: 22000, val_time: 08s 732ms, best_update: 6000, best_iteration: 6000, best_val/hateful_memes/roc_auc: 0.738552
2020-06-11T05:12:39 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-11T05:15:24 INFO: progress: 18100/22000, train/total_loss: 0.0001, train/total_loss/avg: 0.0602, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0602, max mem: 11430.0, experiment: run, epoch: 69, num_updates: 18100, iterations: 18100, max_updates: 22000, lr: 0.00001, ups: 0.60, time: 02m 47s 295ms, time_since_start: 08h 35m 30s 148ms, eta: 01h 48m 44s 534ms
2020-06-11T05:18:12 INFO: progress: 18200/22000, train/total_loss: 0.0001, train/total_loss/avg: 0.0599, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0599, max mem: 11430.0, experiment: run, epoch: 69, num_updates: 18200, iterations: 18200, max_updates: 22000, lr: 0.00001, ups: 0.60, time: 02m 47s 579ms, time_since_start: 08h 38m 17s 728ms, eta: 01h 46m 08s 024ms
2020-06-11T05:21:00 INFO: progress: 18300/22000, train/total_loss: 0.0001, train/total_loss/avg: 0.0596, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0596, max mem: 11430.0, experiment: run, epoch: 69, num_updates: 18300, iterations: 18300, max_updates: 22000, lr: 0.00001, ups: 0.60, time: 02m 47s 548ms, time_since_start: 08h 41m 05s 276ms, eta: 01h 43m 19s 285ms
2020-06-11T05:23:47 INFO: progress: 18400/22000, train/total_loss: 0.0001, train/total_loss/avg: 0.0592, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0592, max mem: 11430.0, experiment: run, epoch: 70, num_updates: 18400, iterations: 18400, max_updates: 22000, lr: 0.00001, ups: 0.60, time: 02m 47s 391ms, time_since_start: 08h 43m 52s 667ms, eta: 01h 40m 26s 085ms
2020-06-11T05:26:34 INFO: progress: 18500/22000, train/total_loss: 0.0001, train/total_loss/avg: 0.0589, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0589, max mem: 11430.0, experiment: run, epoch: 70, num_updates: 18500, iterations: 18500, max_updates: 22000, lr: 0.00001, ups: 0.60, time: 02m 47s 109ms, time_since_start: 08h 46m 39s 777ms, eta: 01h 37m 28s 830ms
2020-06-11T05:29:21 INFO: progress: 18600/22000, train/total_loss: 0.0001, train/total_loss/avg: 0.0586, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0586, max mem: 11430.0, experiment: run, epoch: 70, num_updates: 18600, iterations: 18600, max_updates: 22000, lr: 0.00001, ups: 0.60, time: 02m 47s 233ms, time_since_start: 08h 49m 27s 011ms, eta: 01h 34m 45s 956ms
2020-06-11T05:32:08 INFO: progress: 18700/22000, train/total_loss: 0.0001, train/total_loss/avg: 0.0583, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0583, max mem: 11430.0, experiment: run, epoch: 71, num_updates: 18700, iterations: 18700, max_updates: 22000, lr: 0.00001, ups: 0.60, time: 02m 47s 050ms, time_since_start: 08h 52m 14s 061ms, eta: 01h 31m 52s 670ms
2020-06-11T05:34:56 INFO: progress: 18800/22000, train/total_loss: 0.0001, train/total_loss/avg: 0.0580, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0580, max mem: 11430.0, experiment: run, epoch: 71, num_updates: 18800, iterations: 18800, max_updates: 22000, lr: 0.00001, ups: 0.60, time: 02m 47s 454ms, time_since_start: 08h 55m 01s 516ms, eta: 01h 29m 18s 546ms
2020-06-11T05:37:43 INFO: progress: 18900/22000, train/total_loss: 0.0001, train/total_loss/avg: 0.0577, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0577, max mem: 11430.0, experiment: run, epoch: 72, num_updates: 18900, iterations: 18900, max_updates: 22000, lr: 0.00001, ups: 0.60, time: 02m 47s 211ms, time_since_start: 08h 57m 48s 728ms, eta: 01h 26m 23s 567ms
2020-06-11T05:40:31 INFO: progress: 19000/22000, train/total_loss: 0.0001, train/total_loss/avg: 0.0574, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0574, max mem: 11430.0, experiment: run, epoch: 72, num_updates: 19000, iterations: 19000, max_updates: 22000, lr: 0.00001, ups: 0.60, time: 02m 47s 634ms, time_since_start: 09h 36s 363ms, eta: 01h 23m 49s 046ms
2020-06-11T05:40:31 INFO: Checkpoint time. Saving a checkpoint.
2020-06-11T05:40:44 INFO: Evaluation time. Running on full validation set...
2020-06-11T05:40:53 INFO: progress: 19000/22000, val/total_loss: 3.2038, val/hateful_memes/cross_entropy: 3.2038, val/hateful_memes/accuracy: 0.6360, val/hateful_memes/binary_f1: 0.5539, val/hateful_memes/roc_auc: 0.7092, num_updates: 19000, epoch: 72, iterations: 19000, max_updates: 22000, val_time: 08s 690ms, best_update: 6000, best_iteration: 6000, best_val/hateful_memes/roc_auc: 0.738552
2020-06-11T05:40:55 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-11T05:43:41 INFO: progress: 19100/22000, train/total_loss: 0.0001, train/total_loss/avg: 0.0571, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0571, max mem: 11430.0, experiment: run, epoch: 72, num_updates: 19100, iterations: 19100, max_updates: 22000, lr: 0.00001, ups: 0.60, time: 02m 47s 880ms, time_since_start: 09h 03m 46s 605ms, eta: 01h 21m 08s 534ms
2020-06-11T05:46:28 INFO: progress: 19200/22000, train/total_loss: 0.0001, train/total_loss/avg: 0.0568, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0568, max mem: 11430.0, experiment: run, epoch: 73, num_updates: 19200, iterations: 19200, max_updates: 22000, lr: 0.00001, ups: 0.60, time: 02m 46s 979ms, time_since_start: 09h 06m 33s 584ms, eta: 01h 17m 55s 432ms
2020-06-11T05:49:15 INFO: progress: 19300/22000, train/total_loss: 0.0001, train/total_loss/avg: 0.0565, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0565, max mem: 11430.0, experiment: run, epoch: 73, num_updates: 19300, iterations: 19300, max_updates: 22000, lr: 0.00001, ups: 0.60, time: 02m 46s 992ms, time_since_start: 09h 09m 20s 577ms, eta: 01h 15m 08s 799ms
2020-06-11T05:52:02 INFO: progress: 19400/22000, train/total_loss: 0.0001, train/total_loss/avg: 0.0562, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0562, max mem: 11430.0, experiment: run, epoch: 73, num_updates: 19400, iterations: 19400, max_updates: 22000, lr: 0.00001, ups: 0.60, time: 02m 47s 126ms, time_since_start: 09h 12m 07s 704ms, eta: 01h 12m 25s 299ms
2020-06-11T05:54:49 INFO: progress: 19500/22000, train/total_loss: 0.0001, train/total_loss/avg: 0.0559, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0559, max mem: 11430.0, experiment: run, epoch: 74, num_updates: 19500, iterations: 19500, max_updates: 22000, lr: 0.00001, ups: 0.60, time: 02m 46s 865ms, time_since_start: 09h 14m 54s 570ms, eta: 01h 09m 31s 640ms
2020-06-11T05:57:36 INFO: progress: 19600/22000, train/total_loss: 0.0001, train/total_loss/avg: 0.0556, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0556, max mem: 11430.0, experiment: run, epoch: 74, num_updates: 19600, iterations: 19600, max_updates: 22000, lr: 0.00001, ups: 0.60, time: 02m 47s 213ms, time_since_start: 09h 17m 41s 783ms, eta: 01h 06m 53s 130ms
2020-06-11T06:00:23 INFO: progress: 19700/22000, train/total_loss: 0.0001, train/total_loss/avg: 0.0553, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0553, max mem: 11430.0, experiment: run, epoch: 75, num_updates: 19700, iterations: 19700, max_updates: 22000, lr: 0.00001, ups: 0.60, time: 02m 46s 850ms, time_since_start: 09h 20m 28s 634ms, eta: 01h 03m 57s 572ms
2020-06-11T06:03:10 INFO: progress: 19800/22000, train/total_loss: 0.0001, train/total_loss/avg: 0.0551, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0551, max mem: 11430.0, experiment: run, epoch: 75, num_updates: 19800, iterations: 19800, max_updates: 22000, lr: 0.00001, ups: 0.60, time: 02m 47s 407ms, time_since_start: 09h 23m 16s 042ms, eta: 01h 01m 22s 968ms
2020-06-11T06:05:58 INFO: progress: 19900/22000, train/total_loss: 0.0001, train/total_loss/avg: 0.0548, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0548, max mem: 11430.0, experiment: run, epoch: 75, num_updates: 19900, iterations: 19900, max_updates: 22000, lr: 0.00001, ups: 0.60, time: 02m 47s 316ms, time_since_start: 09h 26m 03s 359ms, eta: 58m 33s 654ms
2020-06-11T06:08:45 INFO: progress: 20000/22000, train/total_loss: 0.0001, train/total_loss/avg: 0.0545, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0545, max mem: 11430.0, experiment: run, epoch: 76, num_updates: 20000, iterations: 20000, max_updates: 22000, lr: 0.00001, ups: 0.60, time: 02m 47s 149ms, time_since_start: 09h 28m 50s 508ms, eta: 55m 42s 990ms
2020-06-11T06:08:45 INFO: Checkpoint time. Saving a checkpoint.
2020-06-11T06:08:59 INFO: Evaluation time. Running on full validation set...
2020-06-11T06:09:07 INFO: progress: 20000/22000, val/total_loss: 3.6228, val/hateful_memes/cross_entropy: 3.6228, val/hateful_memes/accuracy: 0.6360, val/hateful_memes/binary_f1: 0.5404, val/hateful_memes/roc_auc: 0.7067, num_updates: 20000, epoch: 76, iterations: 20000, max_updates: 22000, val_time: 08s 754ms, best_update: 6000, best_iteration: 6000, best_val/hateful_memes/roc_auc: 0.738552
2020-06-11T06:09:09 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-11T06:11:55 INFO: progress: 20100/22000, train/total_loss: 0.0001, train/total_loss/avg: 0.0542, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0542, max mem: 11430.0, experiment: run, epoch: 76, num_updates: 20100, iterations: 20100, max_updates: 22000, lr: 0., ups: 0.60, time: 02m 47s 704ms, time_since_start: 09h 32m 01s 024ms, eta: 53m 06s 378ms
2020-06-11T06:14:43 INFO: progress: 20200/22000, train/total_loss: 0.0000, train/total_loss/avg: 0.0540, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0540, max mem: 11430.0, experiment: run, epoch: 76, num_updates: 20200, iterations: 20200, max_updates: 22000, lr: 0., ups: 0.60, time: 02m 47s 181ms, time_since_start: 09h 34m 48s 206ms, eta: 50m 09s 271ms
2020-06-11T06:17:30 INFO: progress: 20300/22000, train/total_loss: 0.0000, train/total_loss/avg: 0.0537, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0537, max mem: 11430.0, experiment: run, epoch: 77, num_updates: 20300, iterations: 20300, max_updates: 22000, lr: 0., ups: 0.60, time: 02m 46s 994ms, time_since_start: 09h 37m 35s 200ms, eta: 47m 18s 899ms
2020-06-11T06:20:17 INFO: progress: 20400/22000, train/total_loss: 0.0000, train/total_loss/avg: 0.0534, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0534, max mem: 11430.0, experiment: run, epoch: 77, num_updates: 20400, iterations: 20400, max_updates: 22000, lr: 0., ups: 0.60, time: 02m 47s 117ms, time_since_start: 09h 40m 22s 317ms, eta: 44m 33s 875ms
2020-06-11T06:23:04 INFO: progress: 20500/22000, train/total_loss: 0.0000, train/total_loss/avg: 0.0532, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0532, max mem: 11430.0, experiment: run, epoch: 78, num_updates: 20500, iterations: 20500, max_updates: 22000, lr: 0., ups: 0.60, time: 02m 47s 077ms, time_since_start: 09h 43m 09s 395ms, eta: 41m 46s 167ms
2020-06-11T06:25:51 INFO: progress: 20600/22000, train/total_loss: 0.0000, train/total_loss/avg: 0.0529, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0529, max mem: 11430.0, experiment: run, epoch: 78, num_updates: 20600, iterations: 20600, max_updates: 22000, lr: 0., ups: 0.60, time: 02m 47s 281ms, time_since_start: 09h 45m 56s 677ms, eta: 39m 01s 938ms
2020-06-11T06:28:38 INFO: progress: 20700/22000, train/total_loss: 0.0000, train/total_loss/avg: 0.0527, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0527, max mem: 11430.0, experiment: run, epoch: 78, num_updates: 20700, iterations: 20700, max_updates: 22000, lr: 0., ups: 0.60, time: 02m 47s 049ms, time_since_start: 09h 48m 43s 726ms, eta: 36m 11s 643ms
2020-06-11T06:31:25 INFO: progress: 20800/22000, train/total_loss: 0.0000, train/total_loss/avg: 0.0524, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0524, max mem: 11430.0, experiment: run, epoch: 79, num_updates: 20800, iterations: 20800, max_updates: 22000, lr: 0., ups: 0.60, time: 02m 46s 801ms, time_since_start: 09h 51m 30s 527ms, eta: 33m 21s 613ms
2020-06-11T06:34:12 INFO: progress: 20900/22000, train/total_loss: 0.0000, train/total_loss/avg: 0.0522, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0522, max mem: 11430.0, experiment: run, epoch: 79, num_updates: 20900, iterations: 20900, max_updates: 22000, lr: 0., ups: 0.60, time: 02m 47s 258ms, time_since_start: 09h 54m 17s 786ms, eta: 30m 39s 846ms
2020-06-11T06:36:59 INFO: progress: 21000/22000, train/total_loss: 0.0000, train/total_loss/avg: 0.0519, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0519, max mem: 11430.0, experiment: run, epoch: 79, num_updates: 21000, iterations: 21000, max_updates: 22000, lr: 0., ups: 0.60, time: 02m 47s 308ms, time_since_start: 09h 57m 05s 095ms, eta: 27m 53s 087ms
2020-06-11T06:36:59 INFO: Checkpoint time. Saving a checkpoint.
2020-06-11T06:37:12 INFO: Evaluation time. Running on full validation set...
2020-06-11T06:37:21 INFO: progress: 21000/22000, val/total_loss: 3.7244, val/hateful_memes/cross_entropy: 3.7244, val/hateful_memes/accuracy: 0.6280, val/hateful_memes/binary_f1: 0.5206, val/hateful_memes/roc_auc: 0.7041, num_updates: 21000, epoch: 79, iterations: 21000, max_updates: 22000, val_time: 08s 735ms, best_update: 6000, best_iteration: 6000, best_val/hateful_memes/roc_auc: 0.738552
2020-06-11T06:37:23 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-11T06:40:09 INFO: progress: 21100/22000, train/total_loss: 0.0000, train/total_loss/avg: 0.0517, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0517, max mem: 11430.0, experiment: run, epoch: 80, num_updates: 21100, iterations: 21100, max_updates: 22000, lr: 0., ups: 0.60, time: 02m 47s 979ms, time_since_start: 10h 14s 764ms, eta: 25m 11s 814ms
2020-06-11T06:42:57 INFO: progress: 21200/22000, train/total_loss: 0.0000, train/total_loss/avg: 0.0514, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0514, max mem: 11430.0, experiment: run, epoch: 80, num_updates: 21200, iterations: 21200, max_updates: 22000, lr: 0., ups: 0.60, time: 02m 47s 521ms, time_since_start: 10h 03m 02s 285ms, eta: 22m 20s 170ms
2020-06-11T06:45:44 INFO: progress: 21300/22000, train/total_loss: 0.0000, train/total_loss/avg: 0.0512, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0512, max mem: 11430.0, experiment: run, epoch: 81, num_updates: 21300, iterations: 21300, max_updates: 22000, lr: 0., ups: 0.60, time: 02m 47s 142ms, time_since_start: 10h 05m 49s 428ms, eta: 19m 29s 997ms
2020-06-11T06:48:31 INFO: progress: 21400/22000, train/total_loss: 0.0000, train/total_loss/avg: 0.0509, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0509, max mem: 11430.0, experiment: run, epoch: 81, num_updates: 21400, iterations: 21400, max_updates: 22000, lr: 0., ups: 0.60, time: 02m 47s 184ms, time_since_start: 10h 08m 36s 613ms, eta: 16m 43s 110ms
2020-06-11T06:51:18 INFO: progress: 21500/22000, train/total_loss: 0.0000, train/total_loss/avg: 0.0507, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0507, max mem: 11430.0, experiment: run, epoch: 81, num_updates: 21500, iterations: 21500, max_updates: 22000, lr: 0., ups: 0.60, time: 02m 46s 940ms, time_since_start: 10h 11m 23s 554ms, eta: 13m 54s 704ms
2020-06-11T06:54:05 INFO: progress: 21600/22000, train/total_loss: 0.0000, train/total_loss/avg: 0.0505, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0505, max mem: 11430.0, experiment: run, epoch: 82, num_updates: 21600, iterations: 21600, max_updates: 22000, lr: 0., ups: 0.60, time: 02m 47s 384ms, time_since_start: 10h 14m 10s 938ms, eta: 11m 09s 539ms
2020-06-11T06:56:53 INFO: progress: 21700/22000, train/total_loss: 0.0000, train/total_loss/avg: 0.0502, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0502, max mem: 11430.0, experiment: run, epoch: 82, num_updates: 21700, iterations: 21700, max_updates: 22000, lr: 0., ups: 0.60, time: 02m 47s 719ms, time_since_start: 10h 16m 58s 658ms, eta: 08m 23s 159ms
2020-06-11T06:59:41 INFO: progress: 21800/22000, train/total_loss: 0.0000, train/total_loss/avg: 0.0500, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0500, max mem: 11430.0, experiment: run, epoch: 82, num_updates: 21800, iterations: 21800, max_updates: 22000, lr: 0., ups: 0.60, time: 02m 47s 587ms, time_since_start: 10h 19m 46s 245ms, eta: 05m 35s 174ms
2020-06-11T07:02:28 INFO: progress: 21900/22000, train/total_loss: 0.0000, train/total_loss/avg: 0.0498, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0498, max mem: 11430.0, experiment: run, epoch: 83, num_updates: 21900, iterations: 21900, max_updates: 22000, lr: 0., ups: 0.60, time: 02m 47s 171ms, time_since_start: 10h 22m 33s 417ms, eta: 02m 47s 171ms
2020-06-11T07:05:16 INFO: progress: 22000/22000, train/total_loss: 0.0000, train/total_loss/avg: 0.0496, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0496, max mem: 11430.0, experiment: run, epoch: 83, num_updates: 22000, iterations: 22000, max_updates: 22000, lr: 0., ups: 0.60, time: 02m 47s 871ms, time_since_start: 10h 25m 21s 289ms, eta: 0ms
2020-06-11T07:05:16 INFO: Checkpoint time. Saving a checkpoint.
2020-06-11T07:05:29 INFO: Evaluation time. Running on full validation set...
2020-06-11T07:05:39 INFO: progress: 22000/22000, val/total_loss: 3.6002, val/hateful_memes/cross_entropy: 3.6002, val/hateful_memes/accuracy: 0.6320, val/hateful_memes/binary_f1: 0.5306, val/hateful_memes/roc_auc: 0.7065, num_updates: 22000, epoch: 83, iterations: 22000, max_updates: 22000, val_time: 09s 865ms, best_update: 6000, best_iteration: 6000, best_val/hateful_memes/roc_auc: 0.738552
2020-06-11T07:05:41 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-11T07:05:41 INFO: Stepping into final validation check
2020-06-11T07:05:41 INFO: Evaluation time. Running on full validation set...
2020-06-11T07:05:50 INFO: progress: 22001/22000, val/total_loss: 3.6002, val/hateful_memes/cross_entropy: 3.6002, val/hateful_memes/accuracy: 0.6320, val/hateful_memes/binary_f1: 0.5306, val/hateful_memes/roc_auc: 0.7065, num_updates: 22001, epoch: 83, iterations: 22001, max_updates: 22000, val_time: 08s 879ms, best_update: 6000, best_iteration: 6000, best_val/hateful_memes/roc_auc: 0.738552
2020-06-11T07:05:50 INFO: Restoring checkpoint
2020-06-11T07:05:50 INFO: Loading checkpoint
