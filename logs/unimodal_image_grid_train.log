2020-06-07T21:18:59 INFO: =====  Training Parameters    =====
2020-06-07T21:18:59 INFO: {
    "batch_size": 32,
    "checkpoint_interval": 1000,
    "clip_gradients": false,
    "clip_norm_mode": "all",
    "dataset_size_proportional_sampling": true,
    "device": "cuda",
    "early_stop": {
        "criteria": "hateful_memes/roc_auc",
        "enabled": false,
        "minimize": false,
        "patience": 4000
    },
    "evaluate_metrics": true,
    "evaluation_interval": 1000,
    "experiment_name": "run",
    "fast_read": false,
    "find_unused_parameters": false,
    "local_rank": null,
    "log_detailed_config": true,
    "log_format": "json",
    "log_interval": 100,
    "logger_level": "info",
    "lr_ratio": 0.1,
    "lr_scheduler": true,
    "lr_steps": [],
    "max_epochs": null,
    "max_updates": 22000,
    "num_workers": 4,
    "pin_memory": false,
    "seed": 59807534,
    "should_not_log": false,
    "tensorboard": true,
    "trainer": "base_trainer",
    "use_warmup": false,
    "verbose_dump": true,
    "warmup_factor": 0.2,
    "warmup_iterations": 1000
}
2020-06-07T21:18:59 INFO: ======  Dataset Attributes  ======
2020-06-07T21:18:59 INFO: ======== hateful_memes =======
2020-06-07T21:18:59 INFO: {
    "annotations": {
        "test": [
            "hateful_memes/defaults/annotations/test.jsonl"
        ],
        "train": [
            "hateful_memes/defaults/annotations/train.jsonl"
        ],
        "val": [
            "hateful_memes/defaults/annotations/dev.jsonl"
        ]
    },
    "data_dir": "/home/jupyter/meme_hateful_detection/data/raw/datasets",
    "depth_first": false,
    "fast_read": false,
    "features": {
        "test": [
            "hateful_memes/defaults/features/detectron.lmdb"
        ],
        "train": [
            "hateful_memes/defaults/features/detectron.lmdb"
        ],
        "val": [
            "hateful_memes/defaults/features/detectron.lmdb"
        ]
    },
    "images": {
        "test": [
            "hateful_memes/defaults/images/"
        ],
        "train": [
            "hateful_memes/defaults/images/"
        ],
        "val": [
            "hateful_memes/defaults/images/"
        ]
    },
    "max_features": 100,
    "processors": {
        "bbox_processor": {
            "params": {
                "max_length": 50
            },
            "type": "bbox"
        },
        "image_processor": {
            "params": {
                "transforms": [
                    {
                        "params": {
                            "size": [
                                256,
                                256
                            ]
                        },
                        "type": "Resize"
                    },
                    {
                        "params": {
                            "size": [
                                224,
                                224
                            ]
                        },
                        "type": "CenterCrop"
                    },
                    "ToTensor",
                    "GrayScaleTo3Channels",
                    {
                        "params": {
                            "mean": [
                                0.46777044,
                                0.44531429,
                                0.40661017
                            ],
                            "std": [
                                0.12221994,
                                0.12145835,
                                0.14380469
                            ]
                        },
                        "type": "Normalize"
                    }
                ]
            },
            "type": "torchvision_transforms"
        },
        "text_processor": {
            "params": {
                "max_length": 14,
                "preprocessor": {
                    "params": {},
                    "type": "simple_sentence"
                },
                "vocab": {
                    "embedding_name": "glove.6B.300d",
                    "type": "intersected",
                    "vocab_file": "hateful_memes/defaults/extras/vocabs/vocabulary_100k.txt"
                }
            },
            "type": "vocab"
        }
    },
    "return_features_info": false,
    "use_features": false,
    "use_images": true
}
2020-06-07T21:18:59 INFO: ======  Optimizer Attributes  ======
2020-06-07T21:18:59 INFO: {
    "params": {
        "eps": 1e-08,
        "lr": 1e-05
    },
    "type": "adam_w"
}
2020-06-07T21:18:59 INFO: ======  Model (unimodal_image) Attributes  ======
2020-06-07T21:18:59 INFO: {
    "classifier": {
        "params": {
            "hidden_dim": 768,
            "in_dim": 2048,
            "num_layers": 2,
            "out_dim": 2
        },
        "type": "mlp"
    },
    "direct_features_input": false,
    "finetune_lr_multiplier": 1,
    "freeze_base": false,
    "losses": [
        {
            "type": "cross_entropy"
        }
    ],
    "modal_encoder": {
        "params": {
            "num_output_features": 1,
            "pool_type": "avg",
            "pretrained": true
        },
        "type": "resnet152"
    },
    "modal_hidden_size": 2048,
    "num_labels": 2
}
2020-06-07T21:18:59 INFO: Loading datasets
2020-06-07T21:19:03 INFO: CUDA Device 0 is: Tesla T4
2020-06-07T21:19:07 INFO: Torch version is: 1.5.0+cu101
2020-06-07T21:19:07 INFO: Loading checkpoint
2020-06-07T21:19:08 WARNING: /home/jupyter/mmf/mmf/utils/checkpoint.py:224: UserWarning: 'optimizer' key is not present in the checkpoint asked to be loaded. Skipping.
  "'optimizer' key is not present in the "

2020-06-07T21:19:08 INFO: Checkpoint loaded
2020-06-07T21:19:08 INFO: ===== Model =====
2020-06-07T21:19:08 INFO: UnimodalModal(
  (base): UnimodalBase(
    (encoder): ResNet152ImageEncoder(
      (model): Sequential(
        (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
        (4): Sequential(
          (0): Bottleneck(
            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (downsample): Sequential(
              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): Bottleneck(
            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (2): Bottleneck(
            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
        (5): Sequential(
          (0): Bottleneck(
            (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (downsample): Sequential(
              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): Bottleneck(
            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (2): Bottleneck(
            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (3): Bottleneck(
            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (4): Bottleneck(
            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (5): Bottleneck(
            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (6): Bottleneck(
            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (7): Bottleneck(
            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
        (6): Sequential(
          (0): Bottleneck(
            (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (downsample): Sequential(
              (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (2): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (3): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (4): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (5): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (6): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (7): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (8): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (9): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (10): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (11): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (12): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (13): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (14): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (15): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (16): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (17): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (18): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (19): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (20): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (21): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (22): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (23): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (24): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (25): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (26): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (27): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (28): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (29): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (30): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (31): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (32): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (33): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (34): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (35): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
        (7): Sequential(
          (0): Bottleneck(
            (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (downsample): Sequential(
              (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
              (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): Bottleneck(
            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (2): Bottleneck(
            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
      )
      (pool): AdaptiveAvgPool2d(output_size=(1, 1))
    )
  )
  (classifier): MLPClassifer(
    (layers): ModuleList(
      (0): Linear(in_features=2048, out_features=768, bias=True)
      (1): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.5, inplace=False)
      (4): Linear(in_features=768, out_features=768, bias=True)
      (5): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Dropout(p=0.5, inplace=False)
      (8): Linear(in_features=768, out_features=2, bias=True)
    )
  )
  (losses): Losses()
)
2020-06-07T21:19:08 INFO: Total Parameters: 60312642. Trained Parameters: 60312642
2020-06-07T21:19:08 INFO: Starting training...
2020-06-07T21:19:13 WARNING: /pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha)

2020-06-07T21:19:13 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T21:20:54 INFO: {"progress": "100/22000", "train/total_loss": "0.5934", "train/total_loss/avg": "0.5934", "train/hateful_memes/cross_entropy": "0.5934", "train/hateful_memes/cross_entropy/avg": "0.5934", "train/hateful_memes/accuracy": "0.6875", "train/hateful_memes/accuracy/avg": "0.6875", "train/hateful_memes/binary_f1": "0.5000", "train/hateful_memes/binary_f1/avg": "0.5000", "train/hateful_memes/roc_auc": "0.6773", "train/hateful_memes/roc_auc/avg": "0.6773", "max mem": 6412.0, "experiment": "run", "epoch": 1, "num_updates": 100, "iterations": 100, "max_updates": 22000, "lr": "0.", "ups": "0.95", "time": "01m 45s 491ms", "time_since_start": "01m 54s 659ms", "eta": "06h 25m 02s 700ms"}
2020-06-07T21:20:55 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T21:22:38 INFO: {"progress": "200/22000", "train/total_loss": "0.5842", "train/total_loss/avg": "0.5888", "train/hateful_memes/cross_entropy": "0.5842", "train/hateful_memes/cross_entropy/avg": "0.5888", "train/hateful_memes/accuracy": "0.6875", "train/hateful_memes/accuracy/avg": "0.6875", "train/hateful_memes/binary_f1": "0.5000", "train/hateful_memes/binary_f1/avg": "0.5227", "train/hateful_memes/roc_auc": "0.6773", "train/hateful_memes/roc_auc/avg": "0.6990", "max mem": 6412.0, "experiment": "run", "epoch": 1, "num_updates": 200, "iterations": 200, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 871ms", "time_since_start": "03m 38s 530ms", "eta": "06h 17m 23s 953ms"}
2020-06-07T21:22:39 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T21:24:22 INFO: {"progress": "300/22000", "train/total_loss": "0.5934", "train/total_loss/avg": "0.6261", "train/hateful_memes/cross_entropy": "0.5934", "train/hateful_memes/cross_entropy/avg": "0.6261", "train/hateful_memes/accuracy": "0.6875", "train/hateful_memes/accuracy/avg": "0.6458", "train/hateful_memes/binary_f1": "0.5000", "train/hateful_memes/binary_f1/avg": "0.4485", "train/hateful_memes/roc_auc": "0.6773", "train/hateful_memes/roc_auc/avg": "0.6781", "max mem": 6412.0, "experiment": "run", "epoch": 2, "num_updates": 300, "iterations": 300, "max_updates": 22000, "lr": "0.", "ups": "0.96", "time": "01m 44s 348ms", "time_since_start": "05m 22s 879ms", "eta": "06h 17m 23s 599ms"}
2020-06-07T21:24:23 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T21:26:06 INFO: {"progress": "400/22000", "train/total_loss": "0.5934", "train/total_loss/avg": "0.6310", "train/hateful_memes/cross_entropy": "0.5934", "train/hateful_memes/cross_entropy/avg": "0.6310", "train/hateful_memes/accuracy": "0.6562", "train/hateful_memes/accuracy/avg": "0.6484", "train/hateful_memes/binary_f1": "0.5000", "train/hateful_memes/binary_f1/avg": "0.4845", "train/hateful_memes/roc_auc": "0.6773", "train/hateful_memes/roc_auc/avg": "0.6782", "max mem": 6412.0, "experiment": "run", "epoch": 2, "num_updates": 400, "iterations": 400, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 885ms", "time_since_start": "07m 06s 764ms", "eta": "06h 13m 59s 189ms"}
2020-06-07T21:26:07 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T21:27:50 INFO: {"progress": "500/22000", "train/total_loss": "0.5934", "train/total_loss/avg": "0.6231", "train/hateful_memes/cross_entropy": "0.5934", "train/hateful_memes/cross_entropy/avg": "0.6231", "train/hateful_memes/accuracy": "0.6875", "train/hateful_memes/accuracy/avg": "0.6687", "train/hateful_memes/binary_f1": "0.5455", "train/hateful_memes/binary_f1/avg": "0.4987", "train/hateful_memes/roc_auc": "0.6784", "train/hateful_memes/roc_auc/avg": "0.6785", "max mem": 6412.0, "experiment": "run", "epoch": 2, "num_updates": 500, "iterations": 500, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 842ms", "time_since_start": "08m 50s 606ms", "eta": "06h 12m 06s 185ms"}
2020-06-07T21:27:51 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T21:29:34 INFO: {"progress": "600/22000", "train/total_loss": "0.5917", "train/total_loss/avg": "0.6143", "train/hateful_memes/cross_entropy": "0.5917", "train/hateful_memes/cross_entropy/avg": "0.6143", "train/hateful_memes/accuracy": "0.6875", "train/hateful_memes/accuracy/avg": "0.6719", "train/hateful_memes/binary_f1": "0.5455", "train/hateful_memes/binary_f1/avg": "0.5065", "train/hateful_memes/roc_auc": "0.6784", "train/hateful_memes/roc_auc/avg": "0.6990", "max mem": 6412.0, "experiment": "run", "epoch": 3, "num_updates": 600, "iterations": 600, "max_updates": 22000, "lr": "0.", "ups": "0.96", "time": "01m 44s 382ms", "time_since_start": "10m 34s 989ms", "eta": "06h 12m 17s 820ms"}
2020-06-07T21:29:35 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T21:31:18 INFO: {"progress": "700/22000", "train/total_loss": "0.5934", "train/total_loss/avg": "0.6322", "train/hateful_memes/cross_entropy": "0.5934", "train/hateful_memes/cross_entropy/avg": "0.6322", "train/hateful_memes/accuracy": "0.6875", "train/hateful_memes/accuracy/avg": "0.6562", "train/hateful_memes/binary_f1": "0.5455", "train/hateful_memes/binary_f1/avg": "0.4770", "train/hateful_memes/roc_auc": "0.6784", "train/hateful_memes/roc_auc/avg": "0.6837", "max mem": 6412.0, "experiment": "run", "epoch": 3, "num_updates": 700, "iterations": 700, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 986ms", "time_since_start": "12m 18s 976ms", "eta": "06h 09m 09s 203ms"}
2020-06-07T21:31:19 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T21:33:02 INFO: {"progress": "800/22000", "train/total_loss": "0.5917", "train/total_loss/avg": "0.6070", "train/hateful_memes/cross_entropy": "0.5917", "train/hateful_memes/cross_entropy/avg": "0.6070", "train/hateful_memes/accuracy": "0.6875", "train/hateful_memes/accuracy/avg": "0.6758", "train/hateful_memes/binary_f1": "0.5455", "train/hateful_memes/binary_f1/avg": "0.5049", "train/hateful_memes/roc_auc": "0.6784", "train/hateful_memes/roc_auc/avg": "0.7081", "max mem": 6412.0, "experiment": "run", "epoch": 4, "num_updates": 800, "iterations": 800, "max_updates": 22000, "lr": "0.", "ups": "0.96", "time": "01m 44s 183ms", "time_since_start": "14m 03s 159ms", "eta": "06h 08m 06s 880ms"}
2020-06-07T21:33:03 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T21:34:46 INFO: {"progress": "900/22000", "train/total_loss": "0.5917", "train/total_loss/avg": "0.5873", "train/hateful_memes/cross_entropy": "0.5917", "train/hateful_memes/cross_entropy/avg": "0.5873", "train/hateful_memes/accuracy": "0.6875", "train/hateful_memes/accuracy/avg": "0.6875", "train/hateful_memes/binary_f1": "0.5455", "train/hateful_memes/binary_f1/avg": "0.5261", "train/hateful_memes/roc_auc": "0.6797", "train/hateful_memes/roc_auc/avg": "0.7285", "max mem": 6412.0, "experiment": "run", "epoch": 4, "num_updates": 900, "iterations": 900, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 911ms", "time_since_start": "15m 47s 071ms", "eta": "06h 05m 25s 382ms"}
2020-06-07T21:34:47 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T21:36:30 INFO: {"progress": "1000/22000", "train/total_loss": "0.5842", "train/total_loss/avg": "0.5753", "train/hateful_memes/cross_entropy": "0.5842", "train/hateful_memes/cross_entropy/avg": "0.5753", "train/hateful_memes/accuracy": "0.6875", "train/hateful_memes/accuracy/avg": "0.6844", "train/hateful_memes/binary_f1": "0.5455", "train/hateful_memes/binary_f1/avg": "0.5001", "train/hateful_memes/roc_auc": "0.6797", "train/hateful_memes/roc_auc/avg": "0.7373", "max mem": 6412.0, "experiment": "run", "epoch": 4, "num_updates": 1000, "iterations": 1000, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 816ms", "time_since_start": "17m 30s 887ms", "eta": "06h 03m 21s 425ms"}
2020-06-07T21:36:30 INFO: Checkpoint time. Saving a checkpoint.
2020-06-07T21:36:41 INFO: Evaluation time. Running on full validation set...
2020-06-07T21:37:09 INFO: {"progress": "1000/22000", "val/total_loss": "0.8344", "val/hateful_memes/cross_entropy": "0.8344", "val/hateful_memes/accuracy": "0.5360", "val/hateful_memes/binary_f1": "0.4082", "val/hateful_memes/roc_auc": "0.5448", "num_updates": 1000, "epoch": 4, "iterations": 1000, "max_updates": 22000, "val_time": "11s 022ms", "best_update": 1000, "best_iteration": 1000, "best_val/hateful_memes/roc_auc": "0.544800"}
2020-06-07T21:37:10 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T21:38:55 INFO: {"progress": "1100/22000", "train/total_loss": "0.5842", "train/total_loss/avg": "0.5480", "train/hateful_memes/cross_entropy": "0.5842", "train/hateful_memes/cross_entropy/avg": "0.5480", "train/hateful_memes/accuracy": "0.6875", "train/hateful_memes/accuracy/avg": "0.7017", "train/hateful_memes/binary_f1": "0.5455", "train/hateful_memes/binary_f1/avg": "0.5291", "train/hateful_memes/roc_auc": "0.7206", "train/hateful_memes/roc_auc/avg": "0.7589", "max mem": 6412.0, "experiment": "run", "epoch": 5, "num_updates": 1100, "iterations": 1100, "max_updates": 22000, "lr": "0.00001", "ups": "0.95", "time": "01m 45s 283ms", "time_since_start": "19m 55s 457ms", "eta": "06h 06m 44s 329ms"}
2020-06-07T21:38:56 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T21:40:39 INFO: {"progress": "1200/22000", "train/total_loss": "0.5704", "train/total_loss/avg": "0.5375", "train/hateful_memes/cross_entropy": "0.5704", "train/hateful_memes/cross_entropy/avg": "0.5375", "train/hateful_memes/accuracy": "0.6875", "train/hateful_memes/accuracy/avg": "0.7057", "train/hateful_memes/binary_f1": "0.5455", "train/hateful_memes/binary_f1/avg": "0.5405", "train/hateful_memes/roc_auc": "0.7206", "train/hateful_memes/roc_auc/avg": "0.7712", "max mem": 6412.0, "experiment": "run", "epoch": 5, "num_updates": 1200, "iterations": 1200, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 790ms", "time_since_start": "21m 39s 247ms", "eta": "05h 59m 48s 455ms"}
2020-06-07T21:40:40 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T21:42:22 INFO: {"progress": "1300/22000", "train/total_loss": "0.5704", "train/total_loss/avg": "0.5296", "train/hateful_memes/cross_entropy": "0.5704", "train/hateful_memes/cross_entropy/avg": "0.5296", "train/hateful_memes/accuracy": "0.6875", "train/hateful_memes/accuracy/avg": "0.7091", "train/hateful_memes/binary_f1": "0.5556", "train/hateful_memes/binary_f1/avg": "0.5502", "train/hateful_memes/roc_auc": "0.8016", "train/hateful_memes/roc_auc/avg": "0.7813", "max mem": 6412.0, "experiment": "run", "epoch": 5, "num_updates": 1300, "iterations": 1300, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 632ms", "time_since_start": "23m 22s 880ms", "eta": "05h 57m 31s 845ms"}
2020-06-07T21:42:23 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T21:44:06 INFO: {"progress": "1400/22000", "train/total_loss": "0.4667", "train/total_loss/avg": "0.5201", "train/hateful_memes/cross_entropy": "0.4667", "train/hateful_memes/cross_entropy/avg": "0.5201", "train/hateful_memes/accuracy": "0.6875", "train/hateful_memes/accuracy/avg": "0.7165", "train/hateful_memes/binary_f1": "0.5556", "train/hateful_memes/binary_f1/avg": "0.5629", "train/hateful_memes/roc_auc": "0.8016", "train/hateful_memes/roc_auc/avg": "0.7901", "max mem": 6412.0, "experiment": "run", "epoch": 6, "num_updates": 1400, "iterations": 1400, "max_updates": 22000, "lr": "0.00001", "ups": "0.96", "time": "01m 44s 091ms", "time_since_start": "25m 06s 971ms", "eta": "05h 57m 22s 790ms"}
2020-06-07T21:44:07 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T21:45:50 INFO: {"progress": "1500/22000", "train/total_loss": "0.4667", "train/total_loss/avg": "0.5014", "train/hateful_memes/cross_entropy": "0.4667", "train/hateful_memes/cross_entropy/avg": "0.5014", "train/hateful_memes/accuracy": "0.7500", "train/hateful_memes/accuracy/avg": "0.7292", "train/hateful_memes/binary_f1": "0.5926", "train/hateful_memes/binary_f1/avg": "0.5815", "train/hateful_memes/roc_auc": "0.8164", "train/hateful_memes/roc_auc/avg": "0.8034", "max mem": 6412.0, "experiment": "run", "epoch": 6, "num_updates": 1500, "iterations": 1500, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 832ms", "time_since_start": "26m 50s 803ms", "eta": "05h 54m 45s 634ms"}
2020-06-07T21:45:51 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T21:47:34 INFO: {"progress": "1600/22000", "train/total_loss": "0.4353", "train/total_loss/avg": "0.4787", "train/hateful_memes/cross_entropy": "0.4353", "train/hateful_memes/cross_entropy/avg": "0.4787", "train/hateful_memes/accuracy": "0.7500", "train/hateful_memes/accuracy/avg": "0.7441", "train/hateful_memes/binary_f1": "0.5926", "train/hateful_memes/binary_f1/avg": "0.6049", "train/hateful_memes/roc_auc": "0.8164", "train/hateful_memes/roc_auc/avg": "0.8157", "max mem": 6412.0, "experiment": "run", "epoch": 7, "num_updates": 1600, "iterations": 1600, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 910ms", "time_since_start": "28m 34s 713ms", "eta": "05h 53m 17s 664ms"}
2020-06-07T21:47:35 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T21:49:18 INFO: {"progress": "1700/22000", "train/total_loss": "0.4353", "train/total_loss/avg": "0.4566", "train/hateful_memes/cross_entropy": "0.4353", "train/hateful_memes/cross_entropy/avg": "0.4566", "train/hateful_memes/accuracy": "0.7500", "train/hateful_memes/accuracy/avg": "0.7555", "train/hateful_memes/binary_f1": "0.6667", "train/hateful_memes/binary_f1/avg": "0.6233", "train/hateful_memes/roc_auc": "0.8792", "train/hateful_memes/roc_auc/avg": "0.8265", "max mem": 6412.0, "experiment": "run", "epoch": 7, "num_updates": 1700, "iterations": 1700, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 592ms", "time_since_start": "30m 18s 306ms", "eta": "05h 50m 29s 357ms"}
2020-06-07T21:49:19 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T21:51:01 INFO: {"progress": "1800/22000", "train/total_loss": "0.4303", "train/total_loss/avg": "0.4492", "train/hateful_memes/cross_entropy": "0.4303", "train/hateful_memes/cross_entropy/avg": "0.4492", "train/hateful_memes/accuracy": "0.7500", "train/hateful_memes/accuracy/avg": "0.7604", "train/hateful_memes/binary_f1": "0.6667", "train/hateful_memes/binary_f1/avg": "0.6310", "train/hateful_memes/roc_auc": "0.8792", "train/hateful_memes/roc_auc/avg": "0.8327", "max mem": 6412.0, "experiment": "run", "epoch": 7, "num_updates": 1800, "iterations": 1800, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 580ms", "time_since_start": "32m 01s 887ms", "eta": "05h 48m 43s 232ms"}
2020-06-07T21:51:02 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T21:52:45 INFO: {"progress": "1900/22000", "train/total_loss": "0.4303", "train/total_loss/avg": "0.4280", "train/hateful_memes/cross_entropy": "0.4303", "train/hateful_memes/cross_entropy/avg": "0.4280", "train/hateful_memes/accuracy": "0.7500", "train/hateful_memes/accuracy/avg": "0.7730", "train/hateful_memes/binary_f1": "0.6667", "train/hateful_memes/binary_f1/avg": "0.6504", "train/hateful_memes/roc_auc": "0.8918", "train/hateful_memes/roc_auc/avg": "0.8415", "max mem": 6412.0, "experiment": "run", "epoch": 8, "num_updates": 1900, "iterations": 1900, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 920ms", "time_since_start": "33m 45s 807ms", "eta": "05h 48m 08s 061ms"}
2020-06-07T21:52:46 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T21:54:29 INFO: {"progress": "2000/22000", "train/total_loss": "0.4302", "train/total_loss/avg": "0.4113", "train/hateful_memes/cross_entropy": "0.4302", "train/hateful_memes/cross_entropy/avg": "0.4113", "train/hateful_memes/accuracy": "0.7500", "train/hateful_memes/accuracy/avg": "0.7828", "train/hateful_memes/binary_f1": "0.6667", "train/hateful_memes/binary_f1/avg": "0.6657", "train/hateful_memes/roc_auc": "0.8918", "train/hateful_memes/roc_auc/avg": "0.8492", "max mem": 6412.0, "experiment": "run", "epoch": 8, "num_updates": 2000, "iterations": 2000, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 564ms", "time_since_start": "35m 29s 371ms", "eta": "05h 45m 12s 836ms"}
2020-06-07T21:54:29 INFO: Checkpoint time. Saving a checkpoint.
2020-06-07T21:54:41 INFO: Evaluation time. Running on full validation set...
2020-06-07T21:54:58 INFO: {"progress": "2000/22000", "val/total_loss": "1.3580", "val/hateful_memes/cross_entropy": "1.3580", "val/hateful_memes/accuracy": "0.5040", "val/hateful_memes/binary_f1": "0.3297", "val/hateful_memes/roc_auc": "0.4997", "num_updates": 2000, "epoch": 8, "iterations": 2000, "max_updates": 22000, "val_time": "05s 076ms", "best_update": 1000, "best_iteration": 1000, "best_val/hateful_memes/roc_auc": "0.544800"}
2020-06-07T21:54:59 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T21:56:42 INFO: {"progress": "2100/22000", "train/total_loss": "0.4221", "train/total_loss/avg": "0.3949", "train/hateful_memes/cross_entropy": "0.4221", "train/hateful_memes/cross_entropy/avg": "0.3949", "train/hateful_memes/accuracy": "0.7812", "train/hateful_memes/accuracy/avg": "0.7917", "train/hateful_memes/binary_f1": "0.6957", "train/hateful_memes/binary_f1/avg": "0.6795", "train/hateful_memes/roc_auc": "0.9028", "train/hateful_memes/roc_auc/avg": "0.8564", "max mem": 6412.0, "experiment": "run", "epoch": 8, "num_updates": 2100, "iterations": 2100, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 874ms", "time_since_start": "37m 42s 812ms", "eta": "05h 44m 31s 029ms"}
2020-06-07T21:56:43 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T21:58:26 INFO: {"progress": "2200/22000", "train/total_loss": "0.3959", "train/total_loss/avg": "0.3779", "train/hateful_memes/cross_entropy": "0.3959", "train/hateful_memes/cross_entropy/avg": "0.3779", "train/hateful_memes/accuracy": "0.8125", "train/hateful_memes/accuracy/avg": "0.8011", "train/hateful_memes/binary_f1": "0.7000", "train/hateful_memes/binary_f1/avg": "0.6941", "train/hateful_memes/roc_auc": "0.9042", "train/hateful_memes/roc_auc/avg": "0.8629", "max mem": 6412.0, "experiment": "run", "epoch": 9, "num_updates": 2200, "iterations": 2200, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 975ms", "time_since_start": "39m 26s 787ms", "eta": "05h 43m 07s 103ms"}
2020-06-07T21:58:27 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T22:00:10 INFO: {"progress": "2300/22000", "train/total_loss": "0.3241", "train/total_loss/avg": "0.3634", "train/hateful_memes/cross_entropy": "0.3241", "train/hateful_memes/cross_entropy/avg": "0.3634", "train/hateful_memes/accuracy": "0.8125", "train/hateful_memes/accuracy/avg": "0.8098", "train/hateful_memes/binary_f1": "0.7273", "train/hateful_memes/binary_f1/avg": "0.7074", "train/hateful_memes/roc_auc": "0.9059", "train/hateful_memes/roc_auc/avg": "0.8689", "max mem": 6412.0, "experiment": "run", "epoch": 9, "num_updates": 2300, "iterations": 2300, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 616ms", "time_since_start": "41m 10s 404ms", "eta": "05h 40m 12s 438ms"}
2020-06-07T22:00:11 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T22:01:54 INFO: {"progress": "2400/22000", "train/total_loss": "0.2754", "train/total_loss/avg": "0.3501", "train/hateful_memes/cross_entropy": "0.2754", "train/hateful_memes/cross_entropy/avg": "0.3501", "train/hateful_memes/accuracy": "0.8438", "train/hateful_memes/accuracy/avg": "0.8177", "train/hateful_memes/binary_f1": "0.7619", "train/hateful_memes/binary_f1/avg": "0.7196", "train/hateful_memes/roc_auc": "0.9375", "train/hateful_memes/roc_auc/avg": "0.8743", "max mem": 6412.0, "experiment": "run", "epoch": 10, "num_updates": 2400, "iterations": 2400, "max_updates": 22000, "lr": "0.00001", "ups": "0.96", "time": "01m 44s 094ms", "time_since_start": "42m 54s 498ms", "eta": "05h 40m 02s 504ms"}
2020-06-07T22:01:55 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T22:03:38 INFO: {"progress": "2500/22000", "train/total_loss": "0.2390", "train/total_loss/avg": "0.3373", "train/hateful_memes/cross_entropy": "0.2390", "train/hateful_memes/cross_entropy/avg": "0.3373", "train/hateful_memes/accuracy": "0.8750", "train/hateful_memes/accuracy/avg": "0.8250", "train/hateful_memes/binary_f1": "0.8182", "train/hateful_memes/binary_f1/avg": "0.7308", "train/hateful_memes/roc_auc": "0.9750", "train/hateful_memes/roc_auc/avg": "0.8794", "max mem": 6412.0, "experiment": "run", "epoch": 10, "num_updates": 2500, "iterations": 2500, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 737ms", "time_since_start": "44m 38s 236ms", "eta": "05h 37m 08s 909ms"}
2020-06-07T22:03:39 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T22:05:21 INFO: {"progress": "2600/22000", "train/total_loss": "0.1383", "train/total_loss/avg": "0.3249", "train/hateful_memes/cross_entropy": "0.1383", "train/hateful_memes/cross_entropy/avg": "0.3249", "train/hateful_memes/accuracy": "0.9062", "train/hateful_memes/accuracy/avg": "0.8317", "train/hateful_memes/binary_f1": "0.8421", "train/hateful_memes/binary_f1/avg": "0.7412", "train/hateful_memes/roc_auc": "0.9896", "train/hateful_memes/roc_auc/avg": "0.8840", "max mem": 6412.0, "experiment": "run", "epoch": 10, "num_updates": 2600, "iterations": 2600, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 560ms", "time_since_start": "46m 21s 797ms", "eta": "05h 34m 50s 787ms"}
2020-06-07T22:05:22 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T22:07:05 INFO: {"progress": "2700/22000", "train/total_loss": "0.1035", "train/total_loss/avg": "0.3136", "train/hateful_memes/cross_entropy": "0.1035", "train/hateful_memes/cross_entropy/avg": "0.3136", "train/hateful_memes/accuracy": "0.9375", "train/hateful_memes/accuracy/avg": "0.8380", "train/hateful_memes/binary_f1": "0.9167", "train/hateful_memes/binary_f1/avg": "0.7508", "train/hateful_memes/roc_auc": "0.9958", "train/hateful_memes/roc_auc/avg": "0.8883", "max mem": 6412.0, "experiment": "run", "epoch": 11, "num_updates": 2700, "iterations": 2700, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 916ms", "time_since_start": "48m 05s 713ms", "eta": "05h 34m 15s 846ms"}
2020-06-07T22:07:06 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T22:08:48 INFO: {"progress": "2800/22000", "train/total_loss": "0.0950", "train/total_loss/avg": "0.3035", "train/hateful_memes/cross_entropy": "0.0950", "train/hateful_memes/cross_entropy/avg": "0.3035", "train/hateful_memes/accuracy": "0.9688", "train/hateful_memes/accuracy/avg": "0.8438", "train/hateful_memes/binary_f1": "0.9565", "train/hateful_memes/binary_f1/avg": "0.7597", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.8923", "max mem": 6412.0, "experiment": "run", "epoch": 11, "num_updates": 2800, "iterations": 2800, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 396ms", "time_since_start": "49m 49s 110ms", "eta": "05h 30m 52s 058ms"}
2020-06-07T22:08:49 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T22:10:32 INFO: {"progress": "2900/22000", "train/total_loss": "0.0674", "train/total_loss/avg": "0.2934", "train/hateful_memes/cross_entropy": "0.0674", "train/hateful_memes/cross_entropy/avg": "0.2934", "train/hateful_memes/accuracy": "0.9688", "train/hateful_memes/accuracy/avg": "0.8491", "train/hateful_memes/binary_f1": "0.9565", "train/hateful_memes/binary_f1/avg": "0.7679", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.8960", "max mem": 6412.0, "experiment": "run", "epoch": 11, "num_updates": 2900, "iterations": 2900, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 597ms", "time_since_start": "51m 32s 707ms", "eta": "05h 29m 47s 097ms"}
2020-06-07T22:10:33 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T22:12:16 INFO: {"progress": "3000/22000", "train/total_loss": "0.0453", "train/total_loss/avg": "0.2839", "train/hateful_memes/cross_entropy": "0.0453", "train/hateful_memes/cross_entropy/avg": "0.2839", "train/hateful_memes/accuracy": "0.9688", "train/hateful_memes/accuracy/avg": "0.8542", "train/hateful_memes/binary_f1": "0.9565", "train/hateful_memes/binary_f1/avg": "0.7757", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.8995", "max mem": 6412.0, "experiment": "run", "epoch": 12, "num_updates": 3000, "iterations": 3000, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 973ms", "time_since_start": "53m 16s 681ms", "eta": "05h 29m 14s 999ms"}
2020-06-07T22:12:16 INFO: Checkpoint time. Saving a checkpoint.
2020-06-07T22:12:28 INFO: Evaluation time. Running on full validation set...
2020-06-07T22:12:45 INFO: {"progress": "3000/22000", "val/total_loss": "1.6496", "val/hateful_memes/cross_entropy": "1.6496", "val/hateful_memes/accuracy": "0.5160", "val/hateful_memes/binary_f1": "0.3352", "val/hateful_memes/roc_auc": "0.5063", "num_updates": 3000, "epoch": 12, "iterations": 3000, "max_updates": 22000, "val_time": "05s 123ms", "best_update": 1000, "best_iteration": 1000, "best_val/hateful_memes/roc_auc": "0.544800"}
2020-06-07T22:12:47 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T22:14:30 INFO: {"progress": "3100/22000", "train/total_loss": "0.0438", "train/total_loss/avg": "0.2755", "train/hateful_memes/cross_entropy": "0.0438", "train/hateful_memes/cross_entropy/avg": "0.2755", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.8589", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.7829", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9027", "max mem": 6412.0, "experiment": "run", "epoch": 12, "num_updates": 3100, "iterations": 3100, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 852ms", "time_since_start": "55m 30s 315ms", "eta": "05h 27m 08s 063ms"}
2020-06-07T22:14:31 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T22:16:13 INFO: {"progress": "3200/22000", "train/total_loss": "0.0434", "train/total_loss/avg": "0.2671", "train/hateful_memes/cross_entropy": "0.0434", "train/hateful_memes/cross_entropy/avg": "0.2671", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.8633", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.7897", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9057", "max mem": 6412.0, "experiment": "run", "epoch": 13, "num_updates": 3200, "iterations": 3200, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 824ms", "time_since_start": "57m 14s 139ms", "eta": "05h 25m 19s 069ms"}
2020-06-07T22:16:14 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T22:17:57 INFO: {"progress": "3300/22000", "train/total_loss": "0.0297", "train/total_loss/avg": "0.2593", "train/hateful_memes/cross_entropy": "0.0297", "train/hateful_memes/cross_entropy/avg": "0.2593", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.8674", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.7961", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9086", "max mem": 6412.0, "experiment": "run", "epoch": 13, "num_updates": 3300, "iterations": 3300, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 405ms", "time_since_start": "58m 57s 545ms", "eta": "05h 22m 16s 915ms"}
2020-06-07T22:17:58 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T22:19:40 INFO: {"progress": "3400/22000", "train/total_loss": "0.0297", "train/total_loss/avg": "0.2523", "train/hateful_memes/cross_entropy": "0.0297", "train/hateful_memes/cross_entropy/avg": "0.2523", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.8713", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.8021", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9113", "max mem": 6412.0, "experiment": "run", "epoch": 13, "num_updates": 3400, "iterations": 3400, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 595ms", "time_since_start": "01h 41s 141ms", "eta": "05h 21m 08s 723ms"}
2020-06-07T22:19:41 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T22:21:24 INFO: {"progress": "3500/22000", "train/total_loss": "0.0297", "train/total_loss/avg": "0.2460", "train/hateful_memes/cross_entropy": "0.0297", "train/hateful_memes/cross_entropy/avg": "0.2460", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.8750", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.8077", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9138", "max mem": 6412.0, "experiment": "run", "epoch": 14, "num_updates": 3500, "iterations": 3500, "max_updates": 22000, "lr": "0.00001", "ups": "0.96", "time": "01m 44s 018ms", "time_since_start": "01h 02m 25s 160ms", "eta": "05h 20m 43s 504ms"}
2020-06-07T22:21:25 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T22:23:08 INFO: {"progress": "3600/22000", "train/total_loss": "0.0297", "train/total_loss/avg": "0.2400", "train/hateful_memes/cross_entropy": "0.0297", "train/hateful_memes/cross_entropy/avg": "0.2400", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.8785", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.8131", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9162", "max mem": 6412.0, "experiment": "run", "epoch": 14, "num_updates": 3600, "iterations": 3600, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 598ms", "time_since_start": "01h 04m 08s 759ms", "eta": "05h 17m 42s 212ms"}
2020-06-07T22:23:09 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T22:24:52 INFO: {"progress": "3700/22000", "train/total_loss": "0.0240", "train/total_loss/avg": "0.2337", "train/hateful_memes/cross_entropy": "0.0240", "train/hateful_memes/cross_entropy/avg": "0.2337", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.8818", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.8181", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9185", "max mem": 6412.0, "experiment": "run", "epoch": 14, "num_updates": 3700, "iterations": 3700, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 630ms", "time_since_start": "01h 05m 52s 389ms", "eta": "05h 16m 04s 416ms"}
2020-06-07T22:24:53 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T22:26:36 INFO: {"progress": "3800/22000", "train/total_loss": "0.0237", "train/total_loss/avg": "0.2278", "train/hateful_memes/cross_entropy": "0.0237", "train/hateful_memes/cross_entropy/avg": "0.2278", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.8849", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.8229", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9206", "max mem": 6412.0, "experiment": "run", "epoch": 15, "num_updates": 3800, "iterations": 3800, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 886ms", "time_since_start": "01h 07m 36s 275ms", "eta": "05h 15m 07s 260ms"}
2020-06-07T22:26:37 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T22:28:19 INFO: {"progress": "3900/22000", "train/total_loss": "0.0205", "train/total_loss/avg": "0.2225", "train/hateful_memes/cross_entropy": "0.0205", "train/hateful_memes/cross_entropy/avg": "0.2225", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.8878", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.8274", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9227", "max mem": 6412.0, "experiment": "run", "epoch": 15, "num_updates": 3900, "iterations": 3900, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 493ms", "time_since_start": "01h 09m 19s 769ms", "eta": "05h 12m 12s 244ms"}
2020-06-07T22:28:20 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T22:30:03 INFO: {"progress": "4000/22000", "train/total_loss": "0.0205", "train/total_loss/avg": "0.2175", "train/hateful_memes/cross_entropy": "0.0205", "train/hateful_memes/cross_entropy/avg": "0.2175", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.8906", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.8318", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9246", "max mem": 6412.0, "experiment": "run", "epoch": 16, "num_updates": 4000, "iterations": 4000, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 757ms", "time_since_start": "01h 11m 03s 526ms", "eta": "05h 11m 16s 338ms"}
2020-06-07T22:30:03 INFO: Checkpoint time. Saving a checkpoint.
2020-06-07T22:30:14 INFO: Evaluation time. Running on full validation set...
2020-06-07T22:30:31 INFO: {"progress": "4000/22000", "val/total_loss": "1.8507", "val/hateful_memes/cross_entropy": "1.8507", "val/hateful_memes/accuracy": "0.5000", "val/hateful_memes/binary_f1": "0.3056", "val/hateful_memes/roc_auc": "0.5056", "num_updates": 4000, "epoch": 16, "iterations": 4000, "max_updates": 22000, "val_time": "05s 095ms", "best_update": 1000, "best_iteration": 1000, "best_val/hateful_memes/roc_auc": "0.544800"}
2020-06-07T22:30:33 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T22:32:16 INFO: {"progress": "4100/22000", "train/total_loss": "0.0205", "train/total_loss/avg": "0.2131", "train/hateful_memes/cross_entropy": "0.0205", "train/hateful_memes/cross_entropy/avg": "0.2131", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.8933", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.8359", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9264", "max mem": 6412.0, "experiment": "run", "epoch": 16, "num_updates": 4100, "iterations": 4100, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 759ms", "time_since_start": "01h 13m 16s 232ms", "eta": "05h 09m 33s 002ms"}
2020-06-07T22:32:17 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T22:33:59 INFO: {"progress": "4200/22000", "train/total_loss": "0.0193", "train/total_loss/avg": "0.2082", "train/hateful_memes/cross_entropy": "0.0193", "train/hateful_memes/cross_entropy/avg": "0.2082", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.8958", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.8398", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9282", "max mem": 6412.0, "experiment": "run", "epoch": 16, "num_updates": 4200, "iterations": 4200, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 607ms", "time_since_start": "01h 14m 59s 840ms", "eta": "05h 07m 22s 221ms"}
2020-06-07T22:34:00 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T22:35:43 INFO: {"progress": "4300/22000", "train/total_loss": "0.0192", "train/total_loss/avg": "0.2034", "train/hateful_memes/cross_entropy": "0.0192", "train/hateful_memes/cross_entropy/avg": "0.2034", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.8983", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.8435", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9299", "max mem": 6412.0, "experiment": "run", "epoch": 17, "num_updates": 4300, "iterations": 4300, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 986ms", "time_since_start": "01h 16m 43s 827ms", "eta": "05h 06m 45s 640ms"}
2020-06-07T22:35:44 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T22:37:26 INFO: {"progress": "4400/22000", "train/total_loss": "0.0168", "train/total_loss/avg": "0.1991", "train/hateful_memes/cross_entropy": "0.0168", "train/hateful_memes/cross_entropy/avg": "0.1991", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9006", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.8471", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9315", "max mem": 6412.0, "experiment": "run", "epoch": 17, "num_updates": 4400, "iterations": 4400, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 362ms", "time_since_start": "01h 18m 27s 190ms", "eta": "05h 03m 11s 871ms"}
2020-06-07T22:37:27 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T22:39:10 INFO: {"progress": "4500/22000", "train/total_loss": "0.0151", "train/total_loss/avg": "0.1950", "train/hateful_memes/cross_entropy": "0.0151", "train/hateful_memes/cross_entropy/avg": "0.1950", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9028", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.8505", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9330", "max mem": 6412.0, "experiment": "run", "epoch": 17, "num_updates": 4500, "iterations": 4500, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 473ms", "time_since_start": "01h 20m 10s 664ms", "eta": "05h 01m 47s 894ms"}
2020-06-07T22:39:11 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T22:40:54 INFO: {"progress": "4600/22000", "train/total_loss": "0.0117", "train/total_loss/avg": "0.1910", "train/hateful_memes/cross_entropy": "0.0117", "train/hateful_memes/cross_entropy/avg": "0.1910", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9049", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.8537", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9344", "max mem": 6412.0, "experiment": "run", "epoch": 18, "num_updates": 4600, "iterations": 4600, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 669ms", "time_since_start": "01h 21m 54s 333ms", "eta": "05h 38s 471ms"}
2020-06-07T22:40:55 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T22:42:37 INFO: {"progress": "4700/22000", "train/total_loss": "0.0111", "train/total_loss/avg": "0.1870", "train/hateful_memes/cross_entropy": "0.0111", "train/hateful_memes/cross_entropy/avg": "0.1870", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9069", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.8568", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9358", "max mem": 6412.0, "experiment": "run", "epoch": 18, "num_updates": 4700, "iterations": 4700, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 247ms", "time_since_start": "01h 23m 37s 581ms", "eta": "04h 57m 41s 800ms"}
2020-06-07T22:42:38 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T22:44:21 INFO: {"progress": "4800/22000", "train/total_loss": "0.0109", "train/total_loss/avg": "0.1832", "train/hateful_memes/cross_entropy": "0.0109", "train/hateful_memes/cross_entropy/avg": "0.1832", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9089", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.8598", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9372", "max mem": 6412.0, "experiment": "run", "epoch": 19, "num_updates": 4800, "iterations": 4800, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 883ms", "time_since_start": "01h 25m 21s 464ms", "eta": "04h 57m 47s 946ms"}
2020-06-07T22:44:22 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T22:46:04 INFO: {"progress": "4900/22000", "train/total_loss": "0.0105", "train/total_loss/avg": "0.1795", "train/hateful_memes/cross_entropy": "0.0105", "train/hateful_memes/cross_entropy/avg": "0.1795", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9107", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.8627", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9384", "max mem": 6412.0, "experiment": "run", "epoch": 19, "num_updates": 4900, "iterations": 4900, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 347ms", "time_since_start": "01h 27m 04s 812ms", "eta": "04h 54m 32s 426ms"}
2020-06-07T22:46:05 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T22:47:47 INFO: {"progress": "5000/22000", "train/total_loss": "0.0105", "train/total_loss/avg": "0.1760", "train/hateful_memes/cross_entropy": "0.0105", "train/hateful_memes/cross_entropy/avg": "0.1760", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9125", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.8654", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9397", "max mem": 6412.0, "experiment": "run", "epoch": 19, "num_updates": 5000, "iterations": 5000, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 359ms", "time_since_start": "01h 28m 48s 171ms", "eta": "04h 52m 51s 120ms"}
2020-06-07T22:47:47 INFO: Checkpoint time. Saving a checkpoint.
2020-06-07T22:47:53 INFO: Evaluation time. Running on full validation set...
2020-06-07T22:48:10 INFO: {"progress": "5000/22000", "val/total_loss": "2.1078", "val/hateful_memes/cross_entropy": "2.1078", "val/hateful_memes/accuracy": "0.5240", "val/hateful_memes/binary_f1": "0.3533", "val/hateful_memes/roc_auc": "0.5079", "num_updates": 5000, "epoch": 19, "iterations": 5000, "max_updates": 22000, "val_time": "07s 134ms", "best_update": 1000, "best_iteration": 1000, "best_val/hateful_memes/roc_auc": "0.544800"}
2020-06-07T22:48:11 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T22:49:55 INFO: {"progress": "5100/22000", "train/total_loss": "0.0105", "train/total_loss/avg": "0.1731", "train/hateful_memes/cross_entropy": "0.0105", "train/hateful_memes/cross_entropy/avg": "0.1731", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9142", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.8680", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9409", "max mem": 6412.0, "experiment": "run", "epoch": 20, "num_updates": 5100, "iterations": 5100, "max_updates": 22000, "lr": "0.00001", "ups": "0.96", "time": "01m 44s 999ms", "time_since_start": "01h 30m 56s 000ms", "eta": "04h 55m 45s 003ms"}
2020-06-07T22:49:56 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T22:51:39 INFO: {"progress": "5200/22000", "train/total_loss": "0.0105", "train/total_loss/avg": "0.1698", "train/hateful_memes/cross_entropy": "0.0105", "train/hateful_memes/cross_entropy/avg": "0.1698", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9159", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.8706", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9420", "max mem": 6412.0, "experiment": "run", "epoch": 20, "num_updates": 5200, "iterations": 5200, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 392ms", "time_since_start": "01h 32m 39s 393ms", "eta": "04h 49m 29s 944ms"}
2020-06-07T22:51:40 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T22:53:22 INFO: {"progress": "5300/22000", "train/total_loss": "0.0105", "train/total_loss/avg": "0.1666", "train/hateful_memes/cross_entropy": "0.0105", "train/hateful_memes/cross_entropy/avg": "0.1666", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9175", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.8730", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9431", "max mem": 6412.0, "experiment": "run", "epoch": 20, "num_updates": 5300, "iterations": 5300, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 522ms", "time_since_start": "01h 34m 22s 915ms", "eta": "04h 48m 08s 263ms"}
2020-06-07T22:53:23 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T22:55:06 INFO: {"progress": "5400/22000", "train/total_loss": "0.0072", "train/total_loss/avg": "0.1636", "train/hateful_memes/cross_entropy": "0.0072", "train/hateful_memes/cross_entropy/avg": "0.1636", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9190", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.8754", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9441", "max mem": 6412.0, "experiment": "run", "epoch": 21, "num_updates": 5400, "iterations": 5400, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 798ms", "time_since_start": "01h 36m 06s 713ms", "eta": "04h 47m 10s 485ms"}
2020-06-07T22:55:07 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T22:56:49 INFO: {"progress": "5500/22000", "train/total_loss": "0.0072", "train/total_loss/avg": "0.1609", "train/hateful_memes/cross_entropy": "0.0072", "train/hateful_memes/cross_entropy/avg": "0.1609", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9205", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.8776", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9452", "max mem": 6412.0, "experiment": "run", "epoch": 21, "num_updates": 5500, "iterations": 5500, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 315ms", "time_since_start": "01h 37m 50s 029ms", "eta": "04h 44m 07s 026ms"}
2020-06-07T22:56:50 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T22:58:33 INFO: {"progress": "5600/22000", "train/total_loss": "0.0072", "train/total_loss/avg": "0.1583", "train/hateful_memes/cross_entropy": "0.0072", "train/hateful_memes/cross_entropy/avg": "0.1583", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9219", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.8798", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9461", "max mem": 6412.0, "experiment": "run", "epoch": 22, "num_updates": 5600, "iterations": 5600, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 750ms", "time_since_start": "01h 39m 33s 779ms", "eta": "04h 43m 35s 025ms"}
2020-06-07T22:58:34 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T23:00:17 INFO: {"progress": "5700/22000", "train/total_loss": "0.0105", "train/total_loss/avg": "0.1557", "train/hateful_memes/cross_entropy": "0.0105", "train/hateful_memes/cross_entropy/avg": "0.1557", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9232", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.8819", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9471", "max mem": 6412.0, "experiment": "run", "epoch": 22, "num_updates": 5700, "iterations": 5700, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 548ms", "time_since_start": "01h 41m 17s 328ms", "eta": "04h 41m 18s 478ms"}
2020-06-07T23:00:18 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T23:02:00 INFO: {"progress": "5800/22000", "train/total_loss": "0.0057", "train/total_loss/avg": "0.1531", "train/hateful_memes/cross_entropy": "0.0057", "train/hateful_memes/cross_entropy/avg": "0.1531", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9246", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.8840", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9480", "max mem": 6412.0, "experiment": "run", "epoch": 22, "num_updates": 5800, "iterations": 5800, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 176ms", "time_since_start": "01h 43m 505ms", "eta": "04h 38m 34s 673ms"}
2020-06-07T23:02:01 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T23:03:44 INFO: {"progress": "5900/22000", "train/total_loss": "0.0054", "train/total_loss/avg": "0.1506", "train/hateful_memes/cross_entropy": "0.0054", "train/hateful_memes/cross_entropy/avg": "0.1506", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9258", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.8859", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9489", "max mem": 6412.0, "experiment": "run", "epoch": 23, "num_updates": 5900, "iterations": 5900, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 779ms", "time_since_start": "01h 44m 44s 285ms", "eta": "04h 38m 28s 564ms"}
2020-06-07T23:03:45 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T23:05:27 INFO: {"progress": "6000/22000", "train/total_loss": "0.0054", "train/total_loss/avg": "0.1486", "train/hateful_memes/cross_entropy": "0.0054", "train/hateful_memes/cross_entropy/avg": "0.1486", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9266", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.8871", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9497", "max mem": 6412.0, "experiment": "run", "epoch": 23, "num_updates": 6000, "iterations": 6000, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 433ms", "time_since_start": "01h 46m 27s 718ms", "eta": "04h 35m 49s 317ms"}
2020-06-07T23:05:27 INFO: Checkpoint time. Saving a checkpoint.
2020-06-07T23:05:34 INFO: Evaluation time. Running on full validation set...
2020-06-07T23:05:39 INFO: {"progress": "6000/22000", "val/total_loss": "2.1971", "val/hateful_memes/cross_entropy": "2.1971", "val/hateful_memes/accuracy": "0.5240", "val/hateful_memes/binary_f1": "0.3602", "val/hateful_memes/roc_auc": "0.5085", "num_updates": 6000, "epoch": 23, "iterations": 6000, "max_updates": 22000, "val_time": "05s 023ms", "best_update": 1000, "best_iteration": 1000, "best_val/hateful_memes/roc_auc": "0.544800"}
2020-06-07T23:05:40 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T23:07:23 INFO: {"progress": "6100/22000", "train/total_loss": "0.0054", "train/total_loss/avg": "0.1465", "train/hateful_memes/cross_entropy": "0.0054", "train/hateful_memes/cross_entropy/avg": "0.1465", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9278", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.8890", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9506", "max mem": 6412.0, "experiment": "run", "epoch": 23, "num_updates": 6100, "iterations": 6100, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 715ms", "time_since_start": "01h 48m 23s 651ms", "eta": "04h 34m 50s 734ms"}
2020-06-07T23:07:24 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T23:09:07 INFO: {"progress": "6200/22000", "train/total_loss": "0.0057", "train/total_loss/avg": "0.1443", "train/hateful_memes/cross_entropy": "0.0057", "train/hateful_memes/cross_entropy/avg": "0.1443", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9289", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.8908", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9514", "max mem": 6412.0, "experiment": "run", "epoch": 24, "num_updates": 6200, "iterations": 6200, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 859ms", "time_since_start": "01h 50m 07s 510ms", "eta": "04h 33m 29s 818ms"}
2020-06-07T23:09:08 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T23:10:50 INFO: {"progress": "6300/22000", "train/total_loss": "0.0057", "train/total_loss/avg": "0.1421", "train/hateful_memes/cross_entropy": "0.0057", "train/hateful_memes/cross_entropy/avg": "0.1421", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9301", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.8925", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9521", "max mem": 6412.0, "experiment": "run", "epoch": 24, "num_updates": 6300, "iterations": 6300, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 305ms", "time_since_start": "01h 51m 50s 816ms", "eta": "04h 30m 18s 973ms"}
2020-06-07T23:10:51 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T23:12:34 INFO: {"progress": "6400/22000", "train/total_loss": "0.0054", "train/total_loss/avg": "0.1399", "train/hateful_memes/cross_entropy": "0.0054", "train/hateful_memes/cross_entropy/avg": "0.1399", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9312", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.8942", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9529", "max mem": 6412.0, "experiment": "run", "epoch": 25, "num_updates": 6400, "iterations": 6400, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 735ms", "time_since_start": "01h 53m 34s 552ms", "eta": "04h 29m 42s 734ms"}
2020-06-07T23:12:35 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T23:14:17 INFO: {"progress": "6500/22000", "train/total_loss": "0.0043", "train/total_loss/avg": "0.1378", "train/hateful_memes/cross_entropy": "0.0043", "train/hateful_memes/cross_entropy/avg": "0.1378", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9322", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.8958", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9536", "max mem": 6412.0, "experiment": "run", "epoch": 25, "num_updates": 6500, "iterations": 6500, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 328ms", "time_since_start": "01h 55m 17s 880ms", "eta": "04h 26m 55s 898ms"}
2020-06-07T23:14:18 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T23:16:01 INFO: {"progress": "6600/22000", "train/total_loss": "0.0043", "train/total_loss/avg": "0.1358", "train/hateful_memes/cross_entropy": "0.0043", "train/hateful_memes/cross_entropy/avg": "0.1358", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9332", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.8974", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9543", "max mem": 6412.0, "experiment": "run", "epoch": 25, "num_updates": 6600, "iterations": 6600, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 635ms", "time_since_start": "01h 57m 01s 516ms", "eta": "04h 25m 59s 927ms"}
2020-06-07T23:16:02 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T23:17:45 INFO: {"progress": "6700/22000", "train/total_loss": "0.0043", "train/total_loss/avg": "0.1338", "train/hateful_memes/cross_entropy": "0.0043", "train/hateful_memes/cross_entropy/avg": "0.1338", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9342", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.8989", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9550", "max mem": 6412.0, "experiment": "run", "epoch": 26, "num_updates": 6700, "iterations": 6700, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 714ms", "time_since_start": "01h 58m 45s 230ms", "eta": "04h 24m 28s 327ms"}
2020-06-07T23:17:46 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T23:19:28 INFO: {"progress": "6800/22000", "train/total_loss": "0.0043", "train/total_loss/avg": "0.1319", "train/hateful_memes/cross_entropy": "0.0043", "train/hateful_memes/cross_entropy/avg": "0.1319", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9352", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9004", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9556", "max mem": 6412.0, "experiment": "run", "epoch": 26, "num_updates": 6800, "iterations": 6800, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 390ms", "time_since_start": "02h 28s 621ms", "eta": "04h 21m 55s 328ms"}
2020-06-07T23:19:29 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T23:21:11 INFO: {"progress": "6900/22000", "train/total_loss": "0.0054", "train/total_loss/avg": "0.1303", "train/hateful_memes/cross_entropy": "0.0054", "train/hateful_memes/cross_entropy/avg": "0.1303", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9361", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9018", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9563", "max mem": 6412.0, "experiment": "run", "epoch": 26, "num_updates": 6900, "iterations": 6900, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 359ms", "time_since_start": "02h 02m 11s 980ms", "eta": "04h 20m 07s 238ms"}
2020-06-07T23:21:12 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T23:22:55 INFO: {"progress": "7000/22000", "train/total_loss": "0.0054", "train/total_loss/avg": "0.1285", "train/hateful_memes/cross_entropy": "0.0054", "train/hateful_memes/cross_entropy/avg": "0.1285", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9371", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9032", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9569", "max mem": 6412.0, "experiment": "run", "epoch": 27, "num_updates": 7000, "iterations": 7000, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 992ms", "time_since_start": "02h 03m 55s 972ms", "eta": "04h 19m 58s 843ms"}
2020-06-07T23:22:55 INFO: Checkpoint time. Saving a checkpoint.
2020-06-07T23:23:02 INFO: Evaluation time. Running on full validation set...
2020-06-07T23:23:07 INFO: {"progress": "7000/22000", "val/total_loss": "2.2754", "val/hateful_memes/cross_entropy": "2.2754", "val/hateful_memes/accuracy": "0.5100", "val/hateful_memes/binary_f1": "0.3734", "val/hateful_memes/roc_auc": "0.5058", "num_updates": 7000, "epoch": 27, "iterations": 7000, "max_updates": 22000, "val_time": "05s 130ms", "best_update": 1000, "best_iteration": 1000, "best_val/hateful_memes/roc_auc": "0.544800"}
2020-06-07T23:23:09 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T23:24:51 INFO: {"progress": "7100/22000", "train/total_loss": "0.0054", "train/total_loss/avg": "0.1269", "train/hateful_memes/cross_entropy": "0.0054", "train/hateful_memes/cross_entropy/avg": "0.1269", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9379", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9046", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9575", "max mem": 6412.0, "experiment": "run", "epoch": 27, "num_updates": 7100, "iterations": 7100, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 726ms", "time_since_start": "02h 05m 51s 916ms", "eta": "04h 17m 35s 301ms"}
2020-06-07T23:24:52 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T23:26:35 INFO: {"progress": "7200/22000", "train/total_loss": "0.0070", "train/total_loss/avg": "0.1259", "train/hateful_memes/cross_entropy": "0.0070", "train/hateful_memes/cross_entropy/avg": "0.1259", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9384", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9049", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9581", "max mem": 6412.0, "experiment": "run", "epoch": 28, "num_updates": 7200, "iterations": 7200, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 962ms", "time_since_start": "02h 07m 35s 878ms", "eta": "04h 16m 26s 393ms"}
2020-06-07T23:26:36 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T23:28:19 INFO: {"progress": "7300/22000", "train/total_loss": "0.0070", "train/total_loss/avg": "0.1242", "train/hateful_memes/cross_entropy": "0.0070", "train/hateful_memes/cross_entropy/avg": "0.1242", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9392", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9062", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9587", "max mem": 6412.0, "experiment": "run", "epoch": 28, "num_updates": 7300, "iterations": 7300, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 506ms", "time_since_start": "02h 09m 19s 385ms", "eta": "04h 13m 35s 512ms"}
2020-06-07T23:28:20 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T23:30:02 INFO: {"progress": "7400/22000", "train/total_loss": "0.0086", "train/total_loss/avg": "0.1238", "train/hateful_memes/cross_entropy": "0.0086", "train/hateful_memes/cross_entropy/avg": "0.1238", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9396", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9064", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9592", "max mem": 6412.0, "experiment": "run", "epoch": 28, "num_updates": 7400, "iterations": 7400, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 298ms", "time_since_start": "02h 11m 02s 683ms", "eta": "04h 11m 21s 562ms"}
2020-06-07T23:30:03 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T23:31:46 INFO: {"progress": "7500/22000", "train/total_loss": "0.0070", "train/total_loss/avg": "0.1222", "train/hateful_memes/cross_entropy": "0.0070", "train/hateful_memes/cross_entropy/avg": "0.1222", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9404", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9076", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9598", "max mem": 6412.0, "experiment": "run", "epoch": 29, "num_updates": 7500, "iterations": 7500, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 928ms", "time_since_start": "02h 12m 46s 612ms", "eta": "04h 11m 09s 611ms"}
2020-06-07T23:31:47 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T23:33:29 INFO: {"progress": "7600/22000", "train/total_loss": "0.0054", "train/total_loss/avg": "0.1206", "train/hateful_memes/cross_entropy": "0.0054", "train/hateful_memes/cross_entropy/avg": "0.1206", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9412", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9089", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9603", "max mem": 6412.0, "experiment": "run", "epoch": 29, "num_updates": 7600, "iterations": 7600, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 202ms", "time_since_start": "02h 14m 29s 814ms", "eta": "04h 07m 41s 181ms"}
2020-06-07T23:33:30 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T23:35:13 INFO: {"progress": "7700/22000", "train/total_loss": "0.0046", "train/total_loss/avg": "0.1191", "train/hateful_memes/cross_entropy": "0.0046", "train/hateful_memes/cross_entropy/avg": "0.1191", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9420", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9100", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9608", "max mem": 6412.0, "experiment": "run", "epoch": 29, "num_updates": 7700, "iterations": 7700, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 457ms", "time_since_start": "02h 16m 13s 272ms", "eta": "04h 06m 34s 402ms"}
2020-06-07T23:35:14 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T23:36:56 INFO: {"progress": "7800/22000", "train/total_loss": "0.0054", "train/total_loss/avg": "0.1184", "train/hateful_memes/cross_entropy": "0.0054", "train/hateful_memes/cross_entropy/avg": "0.1184", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9423", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9106", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9613", "max mem": 6412.0, "experiment": "run", "epoch": 30, "num_updates": 7800, "iterations": 7800, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 847ms", "time_since_start": "02h 17m 57s 120ms", "eta": "04h 05m 46s 365ms"}
2020-06-07T23:36:57 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T23:38:40 INFO: {"progress": "7900/22000", "train/total_loss": "0.0054", "train/total_loss/avg": "0.1170", "train/hateful_memes/cross_entropy": "0.0054", "train/hateful_memes/cross_entropy/avg": "0.1170", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9430", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9117", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9618", "max mem": 6412.0, "experiment": "run", "epoch": 30, "num_updates": 7900, "iterations": 7900, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 523ms", "time_since_start": "02h 19m 40s 643ms", "eta": "04h 03m 16s 779ms"}
2020-06-07T23:38:41 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T23:40:24 INFO: {"progress": "8000/22000", "train/total_loss": "0.0046", "train/total_loss/avg": "0.1155", "train/hateful_memes/cross_entropy": "0.0046", "train/hateful_memes/cross_entropy/avg": "0.1155", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9437", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9128", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9623", "max mem": 6412.0, "experiment": "run", "epoch": 31, "num_updates": 8000, "iterations": 8000, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 941ms", "time_since_start": "02h 21m 24s 584ms", "eta": "04h 02m 31s 803ms"}
2020-06-07T23:40:24 INFO: Checkpoint time. Saving a checkpoint.
2020-06-07T23:40:29 INFO: Evaluation time. Running on full validation set...
2020-06-07T23:40:36 INFO: {"progress": "8000/22000", "val/total_loss": "2.4488", "val/hateful_memes/cross_entropy": "2.4488", "val/hateful_memes/accuracy": "0.5080", "val/hateful_memes/binary_f1": "0.3315", "val/hateful_memes/roc_auc": "0.4992", "num_updates": 8000, "epoch": 31, "iterations": 8000, "max_updates": 22000, "val_time": "07s 118ms", "best_update": 1000, "best_iteration": 1000, "best_val/hateful_memes/roc_auc": "0.544800"}
2020-06-07T23:40:37 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T23:42:20 INFO: {"progress": "8100/22000", "train/total_loss": "0.0036", "train/total_loss/avg": "0.1141", "train/hateful_memes/cross_entropy": "0.0036", "train/hateful_memes/cross_entropy/avg": "0.1141", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9444", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9139", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9628", "max mem": 6412.0, "experiment": "run", "epoch": 31, "num_updates": 8100, "iterations": 8100, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 855ms", "time_since_start": "02h 23m 21s 014ms", "eta": "04h 35s 911ms"}
2020-06-07T23:42:21 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T23:44:04 INFO: {"progress": "8200/22000", "train/total_loss": "0.0036", "train/total_loss/avg": "0.1130", "train/hateful_memes/cross_entropy": "0.0036", "train/hateful_memes/cross_entropy/avg": "0.1130", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9451", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9149", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9632", "max mem": 6412.0, "experiment": "run", "epoch": 31, "num_updates": 8200, "iterations": 8200, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 377ms", "time_since_start": "02h 25m 04s 392ms", "eta": "03h 57m 46s 162ms"}
2020-06-07T23:44:05 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T23:45:48 INFO: {"progress": "8300/22000", "train/total_loss": "0.0035", "train/total_loss/avg": "0.1116", "train/hateful_memes/cross_entropy": "0.0035", "train/hateful_memes/cross_entropy/avg": "0.1116", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9458", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9160", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9637", "max mem": 6412.0, "experiment": "run", "epoch": 32, "num_updates": 8300, "iterations": 8300, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 856ms", "time_since_start": "02h 26m 48s 248ms", "eta": "03h 57m 08s 314ms"}
2020-06-07T23:45:49 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T23:47:31 INFO: {"progress": "8400/22000", "train/total_loss": "0.0035", "train/total_loss/avg": "0.1103", "train/hateful_memes/cross_entropy": "0.0035", "train/hateful_memes/cross_entropy/avg": "0.1103", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9464", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9170", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9641", "max mem": 6412.0, "experiment": "run", "epoch": 32, "num_updates": 8400, "iterations": 8400, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 381ms", "time_since_start": "02h 28m 31s 629ms", "eta": "03h 54m 19s 877ms"}
2020-06-07T23:47:32 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T23:49:14 INFO: {"progress": "8500/22000", "train/total_loss": "0.0035", "train/total_loss/avg": "0.1091", "train/hateful_memes/cross_entropy": "0.0035", "train/hateful_memes/cross_entropy/avg": "0.1091", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9471", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9179", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9645", "max mem": 6412.0, "experiment": "run", "epoch": 32, "num_updates": 8500, "iterations": 8500, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 489ms", "time_since_start": "02h 30m 15s 118ms", "eta": "03h 52m 51s 020ms"}
2020-06-07T23:49:15 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T23:50:58 INFO: {"progress": "8600/22000", "train/total_loss": "0.0032", "train/total_loss/avg": "0.1078", "train/hateful_memes/cross_entropy": "0.0032", "train/hateful_memes/cross_entropy/avg": "0.1078", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9477", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9189", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9649", "max mem": 6412.0, "experiment": "run", "epoch": 33, "num_updates": 8600, "iterations": 8600, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 810ms", "time_since_start": "02h 31m 58s 929ms", "eta": "03h 51m 50s 623ms"}
2020-06-07T23:50:59 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T23:52:42 INFO: {"progress": "8700/22000", "train/total_loss": "0.0035", "train/total_loss/avg": "0.1069", "train/hateful_memes/cross_entropy": "0.0035", "train/hateful_memes/cross_entropy/avg": "0.1069", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9483", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9198", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9653", "max mem": 6412.0, "experiment": "run", "epoch": 33, "num_updates": 8700, "iterations": 8700, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 326ms", "time_since_start": "02h 33m 42s 255ms", "eta": "03h 49m 02s 385ms"}
2020-06-07T23:52:43 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T23:54:25 INFO: {"progress": "8800/22000", "train/total_loss": "0.0035", "train/total_loss/avg": "0.1057", "train/hateful_memes/cross_entropy": "0.0035", "train/hateful_memes/cross_entropy/avg": "0.1057", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9489", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9207", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9657", "max mem": 6412.0, "experiment": "run", "epoch": 34, "num_updates": 8800, "iterations": 8800, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 897ms", "time_since_start": "02h 35m 26s 153ms", "eta": "03h 48m 34s 455ms"}
2020-06-07T23:54:26 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T23:56:09 INFO: {"progress": "8900/22000", "train/total_loss": "0.0026", "train/total_loss/avg": "0.1045", "train/hateful_memes/cross_entropy": "0.0026", "train/hateful_memes/cross_entropy/avg": "0.1045", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9494", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9216", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9661", "max mem": 6412.0, "experiment": "run", "epoch": 34, "num_updates": 8900, "iterations": 8900, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 387ms", "time_since_start": "02h 37m 09s 541ms", "eta": "03h 45m 43s 792ms"}
2020-06-07T23:56:10 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T23:57:52 INFO: {"progress": "9000/22000", "train/total_loss": "0.0026", "train/total_loss/avg": "0.1038", "train/hateful_memes/cross_entropy": "0.0026", "train/hateful_memes/cross_entropy/avg": "0.1038", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9497", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9221", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9665", "max mem": 6412.0, "experiment": "run", "epoch": 34, "num_updates": 9000, "iterations": 9000, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 608ms", "time_since_start": "02h 38m 53s 149ms", "eta": "03h 44m 29s 060ms"}
2020-06-07T23:57:52 INFO: Checkpoint time. Saving a checkpoint.
2020-06-07T23:57:58 INFO: Evaluation time. Running on full validation set...
2020-06-07T23:58:03 INFO: {"progress": "9000/22000", "val/total_loss": "2.3928", "val/hateful_memes/cross_entropy": "2.3928", "val/hateful_memes/accuracy": "0.5220", "val/hateful_memes/binary_f1": "0.3592", "val/hateful_memes/roc_auc": "0.5153", "num_updates": 9000, "epoch": 34, "iterations": 9000, "max_updates": 22000, "val_time": "05s 142ms", "best_update": 1000, "best_iteration": 1000, "best_val/hateful_memes/roc_auc": "0.544800"}
2020-06-07T23:58:04 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-07T23:59:47 INFO: {"progress": "9100/22000", "train/total_loss": "0.0026", "train/total_loss/avg": "0.1033", "train/hateful_memes/cross_entropy": "0.0026", "train/hateful_memes/cross_entropy/avg": "0.1033", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9499", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9220", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9669", "max mem": 6412.0, "experiment": "run", "epoch": 35, "num_updates": 9100, "iterations": 9100, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 964ms", "time_since_start": "02h 40m 47s 653ms", "eta": "03h 43m 31s 402ms"}
2020-06-07T23:59:48 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T00:01:31 INFO: {"progress": "9200/22000", "train/total_loss": "0.0026", "train/total_loss/avg": "0.1049", "train/hateful_memes/cross_entropy": "0.0026", "train/hateful_memes/cross_entropy/avg": "0.1049", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9497", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9212", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9672", "max mem": 6412.0, "experiment": "run", "epoch": 35, "num_updates": 9200, "iterations": 9200, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 572ms", "time_since_start": "02h 42m 31s 226ms", "eta": "03h 40m 57s 222ms"}
2020-06-08T00:01:32 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T00:03:14 INFO: {"progress": "9300/22000", "train/total_loss": "0.0026", "train/total_loss/avg": "0.1038", "train/hateful_memes/cross_entropy": "0.0026", "train/hateful_memes/cross_entropy/avg": "0.1038", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9503", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9221", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9676", "max mem": 6412.0, "experiment": "run", "epoch": 35, "num_updates": 9300, "iterations": 9300, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 602ms", "time_since_start": "02h 44m 14s 828ms", "eta": "03h 39m 17s 457ms"}
2020-06-08T00:03:15 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T00:04:58 INFO: {"progress": "9400/22000", "train/total_loss": "0.0026", "train/total_loss/avg": "0.1028", "train/hateful_memes/cross_entropy": "0.0026", "train/hateful_memes/cross_entropy/avg": "0.1028", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9508", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9229", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9679", "max mem": 6412.0, "experiment": "run", "epoch": 36, "num_updates": 9400, "iterations": 9400, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 762ms", "time_since_start": "02h 45m 58s 590ms", "eta": "03h 37m 54s 042ms"}
2020-06-08T00:04:59 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T00:06:41 INFO: {"progress": "9500/22000", "train/total_loss": "0.0026", "train/total_loss/avg": "0.1017", "train/hateful_memes/cross_entropy": "0.0026", "train/hateful_memes/cross_entropy/avg": "0.1017", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9513", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9237", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9683", "max mem": 6412.0, "experiment": "run", "epoch": 36, "num_updates": 9500, "iterations": 9500, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 360ms", "time_since_start": "02h 47m 41s 950ms", "eta": "03h 35m 20s 054ms"}
2020-06-08T00:06:42 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T00:08:25 INFO: {"progress": "9600/22000", "train/total_loss": "0.0033", "train/total_loss/avg": "0.1012", "train/hateful_memes/cross_entropy": "0.0033", "train/hateful_memes/cross_entropy/avg": "0.1012", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9515", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9242", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9686", "max mem": 6412.0, "experiment": "run", "epoch": 37, "num_updates": 9600, "iterations": 9600, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 899ms", "time_since_start": "02h 49m 25s 850ms", "eta": "03h 34m 43s 537ms"}
2020-06-08T00:08:26 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T00:10:08 INFO: {"progress": "9700/22000", "train/total_loss": "0.0026", "train/total_loss/avg": "0.1001", "train/hateful_memes/cross_entropy": "0.0026", "train/hateful_memes/cross_entropy/avg": "0.1001", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9520", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9250", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9689", "max mem": 6412.0, "experiment": "run", "epoch": 37, "num_updates": 9700, "iterations": 9700, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 307ms", "time_since_start": "02h 51m 09s 158ms", "eta": "03h 31m 46s 842ms"}
2020-06-08T00:10:09 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T00:11:52 INFO: {"progress": "9800/22000", "train/total_loss": "0.0022", "train/total_loss/avg": "0.0991", "train/hateful_memes/cross_entropy": "0.0022", "train/hateful_memes/cross_entropy/avg": "0.0991", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9525", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9258", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9692", "max mem": 6412.0, "experiment": "run", "epoch": 37, "num_updates": 9800, "iterations": 9800, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 293ms", "time_since_start": "02h 52m 52s 451ms", "eta": "03h 30m 01s 784ms"}
2020-06-08T00:11:53 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T00:13:36 INFO: {"progress": "9900/22000", "train/total_loss": "0.0018", "train/total_loss/avg": "0.0981", "train/hateful_memes/cross_entropy": "0.0018", "train/hateful_memes/cross_entropy/avg": "0.0981", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9530", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9265", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9695", "max mem": 6412.0, "experiment": "run", "epoch": 38, "num_updates": 9900, "iterations": 9900, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 938ms", "time_since_start": "02h 54m 36s 389ms", "eta": "03h 29m 36s 516ms"}
2020-06-08T00:13:37 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T00:15:19 INFO: {"progress": "10000/22000", "train/total_loss": "0.0018", "train/total_loss/avg": "0.0972", "train/hateful_memes/cross_entropy": "0.0018", "train/hateful_memes/cross_entropy/avg": "0.0972", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9534", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9272", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9698", "max mem": 6412.0, "experiment": "run", "epoch": 38, "num_updates": 10000, "iterations": 10000, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 448ms", "time_since_start": "02h 56m 19s 837ms", "eta": "03h 26m 53s 815ms"}
2020-06-08T00:15:19 INFO: Checkpoint time. Saving a checkpoint.
2020-06-08T00:15:26 INFO: Evaluation time. Running on full validation set...
2020-06-08T00:15:31 INFO: {"progress": "10000/22000", "val/total_loss": "2.3823", "val/hateful_memes/cross_entropy": "2.3823", "val/hateful_memes/accuracy": "0.5020", "val/hateful_memes/binary_f1": "0.3599", "val/hateful_memes/roc_auc": "0.5135", "num_updates": 10000, "epoch": 38, "iterations": 10000, "max_updates": 22000, "val_time": "05s 077ms", "best_update": 1000, "best_iteration": 1000, "best_val/hateful_memes/roc_auc": "0.544800"}
2020-06-08T00:15:33 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T00:17:15 INFO: {"progress": "10100/22000", "train/total_loss": "0.0018", "train/total_loss/avg": "0.0968", "train/hateful_memes/cross_entropy": "0.0018", "train/hateful_memes/cross_entropy/avg": "0.0968", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9536", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9275", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9701", "max mem": 6412.0, "experiment": "run", "epoch": 38, "num_updates": 10100, "iterations": 10100, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 721ms", "time_since_start": "02h 58m 16s 182ms", "eta": "03h 25m 42s 831ms"}
2020-06-08T00:17:17 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T00:18:59 INFO: {"progress": "10200/22000", "train/total_loss": "0.0018", "train/total_loss/avg": "0.0959", "train/hateful_memes/cross_entropy": "0.0018", "train/hateful_memes/cross_entropy/avg": "0.0959", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9540", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9282", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9704", "max mem": 6412.0, "experiment": "run", "epoch": 39, "num_updates": 10200, "iterations": 10200, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 717ms", "time_since_start": "02h 59m 59s 899ms", "eta": "03h 23m 58s 628ms"}
2020-06-08T00:19:00 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T00:20:42 INFO: {"progress": "10300/22000", "train/total_loss": "0.0018", "train/total_loss/avg": "0.0950", "train/hateful_memes/cross_entropy": "0.0018", "train/hateful_memes/cross_entropy/avg": "0.0950", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9545", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9289", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9707", "max mem": 6412.0, "experiment": "run", "epoch": 39, "num_updates": 10300, "iterations": 10300, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 292ms", "time_since_start": "03h 01m 43s 191ms", "eta": "03h 21m 25s 213ms"}
2020-06-08T00:20:44 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T00:22:26 INFO: {"progress": "10400/22000", "train/total_loss": "0.0016", "train/total_loss/avg": "0.0941", "train/hateful_memes/cross_entropy": "0.0016", "train/hateful_memes/cross_entropy/avg": "0.0941", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9549", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9296", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9710", "max mem": 6412.0, "experiment": "run", "epoch": 40, "num_updates": 10400, "iterations": 10400, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 796ms", "time_since_start": "03h 03m 26s 988ms", "eta": "03h 20m 40s 446ms"}
2020-06-08T00:22:27 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T00:24:10 INFO: {"progress": "10500/22000", "train/total_loss": "0.0016", "train/total_loss/avg": "0.0932", "train/hateful_memes/cross_entropy": "0.0016", "train/hateful_memes/cross_entropy/avg": "0.0932", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9554", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9303", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9713", "max mem": 6412.0, "experiment": "run", "epoch": 40, "num_updates": 10500, "iterations": 10500, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 302ms", "time_since_start": "03h 05m 10s 291ms", "eta": "03h 17m 59s 826ms"}
2020-06-08T00:24:11 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T00:25:53 INFO: {"progress": "10600/22000", "train/total_loss": "0.0012", "train/total_loss/avg": "0.0923", "train/hateful_memes/cross_entropy": "0.0012", "train/hateful_memes/cross_entropy/avg": "0.0923", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9558", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9309", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9715", "max mem": 6412.0, "experiment": "run", "epoch": 40, "num_updates": 10600, "iterations": 10600, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 501ms", "time_since_start": "03h 06m 53s 793ms", "eta": "03h 16m 39s 145ms"}
2020-06-08T00:25:54 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T00:27:37 INFO: {"progress": "10700/22000", "train/total_loss": "0.0012", "train/total_loss/avg": "0.0914", "train/hateful_memes/cross_entropy": "0.0012", "train/hateful_memes/cross_entropy/avg": "0.0914", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9562", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9316", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9718", "max mem": 6412.0, "experiment": "run", "epoch": 41, "num_updates": 10700, "iterations": 10700, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 753ms", "time_since_start": "03h 08m 37s 546ms", "eta": "03h 15m 24s 134ms"}
2020-06-08T00:27:38 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T00:29:20 INFO: {"progress": "10800/22000", "train/total_loss": "0.0012", "train/total_loss/avg": "0.0906", "train/hateful_memes/cross_entropy": "0.0012", "train/hateful_memes/cross_entropy/avg": "0.0906", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9566", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9322", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9721", "max mem": 6412.0, "experiment": "run", "epoch": 41, "num_updates": 10800, "iterations": 10800, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 206ms", "time_since_start": "03h 10m 20s 752ms", "eta": "03h 12m 39s 123ms"}
2020-06-08T00:29:21 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T00:31:03 INFO: {"progress": "10900/22000", "train/total_loss": "0.0012", "train/total_loss/avg": "0.0898", "train/hateful_memes/cross_entropy": "0.0012", "train/hateful_memes/cross_entropy/avg": "0.0898", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9570", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9328", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9723", "max mem": 6412.0, "experiment": "run", "epoch": 41, "num_updates": 10900, "iterations": 10900, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 323ms", "time_since_start": "03h 12m 04s 076ms", "eta": "03h 11m 08s 885ms"}
2020-06-08T00:31:04 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T00:32:47 INFO: {"progress": "11000/22000", "train/total_loss": "0.0012", "train/total_loss/avg": "0.0890", "train/hateful_memes/cross_entropy": "0.0012", "train/hateful_memes/cross_entropy/avg": "0.0890", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9574", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9334", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9726", "max mem": 6412.0, "experiment": "run", "epoch": 42, "num_updates": 11000, "iterations": 11000, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 906ms", "time_since_start": "03h 13m 47s 982ms", "eta": "03h 10m 29s 665ms"}
2020-06-08T00:32:47 INFO: Checkpoint time. Saving a checkpoint.
2020-06-08T00:32:52 INFO: Evaluation time. Running on full validation set...
2020-06-08T00:33:00 INFO: {"progress": "11000/22000", "val/total_loss": "2.5321", "val/hateful_memes/cross_entropy": "2.5321", "val/hateful_memes/accuracy": "0.5100", "val/hateful_memes/binary_f1": "0.3251", "val/hateful_memes/roc_auc": "0.5068", "num_updates": 11000, "epoch": 42, "iterations": 11000, "max_updates": 22000, "val_time": "07s 158ms", "best_update": 1000, "best_iteration": 1000, "best_val/hateful_memes/roc_auc": "0.544800"}
2020-06-08T00:33:01 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T00:34:44 INFO: {"progress": "11100/22000", "train/total_loss": "0.0012", "train/total_loss/avg": "0.0882", "train/hateful_memes/cross_entropy": "0.0012", "train/hateful_memes/cross_entropy/avg": "0.0882", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9578", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9340", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9728", "max mem": 6412.0, "experiment": "run", "epoch": 42, "num_updates": 11100, "iterations": 11100, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 756ms", "time_since_start": "03h 15m 44s 330ms", "eta": "03h 08m 29s 494ms"}
2020-06-08T00:34:45 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T00:36:27 INFO: {"progress": "11200/22000", "train/total_loss": "0.0010", "train/total_loss/avg": "0.0874", "train/hateful_memes/cross_entropy": "0.0010", "train/hateful_memes/cross_entropy/avg": "0.0874", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9581", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9346", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9731", "max mem": 6412.0, "experiment": "run", "epoch": 43, "num_updates": 11200, "iterations": 11200, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 696ms", "time_since_start": "03h 17m 28s 027ms", "eta": "03h 06m 39s 280ms"}
2020-06-08T00:36:28 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T00:38:11 INFO: {"progress": "11300/22000", "train/total_loss": "0.0012", "train/total_loss/avg": "0.0867", "train/hateful_memes/cross_entropy": "0.0012", "train/hateful_memes/cross_entropy/avg": "0.0867", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9585", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9352", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9733", "max mem": 6412.0, "experiment": "run", "epoch": 43, "num_updates": 11300, "iterations": 11300, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 363ms", "time_since_start": "03h 19m 11s 391ms", "eta": "03h 04m 19s 909ms"}
2020-06-08T00:38:12 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T00:39:54 INFO: {"progress": "11400/22000", "train/total_loss": "0.0012", "train/total_loss/avg": "0.0860", "train/hateful_memes/cross_entropy": "0.0012", "train/hateful_memes/cross_entropy/avg": "0.0860", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9589", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9358", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9735", "max mem": 6412.0, "experiment": "run", "epoch": 43, "num_updates": 11400, "iterations": 11400, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 301ms", "time_since_start": "03h 20m 54s 692ms", "eta": "03h 02m 29s 962ms"}
2020-06-08T00:39:55 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T00:41:38 INFO: {"progress": "11500/22000", "train/total_loss": "0.0012", "train/total_loss/avg": "0.0853", "train/hateful_memes/cross_entropy": "0.0012", "train/hateful_memes/cross_entropy/avg": "0.0853", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9592", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9363", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9738", "max mem": 6412.0, "experiment": "run", "epoch": 44, "num_updates": 11500, "iterations": 11500, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 624ms", "time_since_start": "03h 22m 38s 317ms", "eta": "03h 01m 20s 589ms"}
2020-06-08T00:41:39 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T00:43:21 INFO: {"progress": "11600/22000", "train/total_loss": "0.0010", "train/total_loss/avg": "0.0846", "train/hateful_memes/cross_entropy": "0.0010", "train/hateful_memes/cross_entropy/avg": "0.0846", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9596", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9369", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9740", "max mem": 6412.0, "experiment": "run", "epoch": 44, "num_updates": 11600, "iterations": 11600, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 277ms", "time_since_start": "03h 24m 21s 594ms", "eta": "02h 59m 829ms"}
2020-06-08T00:43:22 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T00:45:04 INFO: {"progress": "11700/22000", "train/total_loss": "0.0009", "train/total_loss/avg": "0.0838", "train/hateful_memes/cross_entropy": "0.0009", "train/hateful_memes/cross_entropy/avg": "0.0838", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9599", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9374", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9742", "max mem": 6412.0, "experiment": "run", "epoch": 44, "num_updates": 11700, "iterations": 11700, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 462ms", "time_since_start": "03h 26m 05s 057ms", "eta": "02h 57m 36s 671ms"}
2020-06-08T00:45:05 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T00:46:48 INFO: {"progress": "11800/22000", "train/total_loss": "0.0010", "train/total_loss/avg": "0.0831", "train/hateful_memes/cross_entropy": "0.0010", "train/hateful_memes/cross_entropy/avg": "0.0831", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9603", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9379", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9744", "max mem": 6412.0, "experiment": "run", "epoch": 45, "num_updates": 11800, "iterations": 11800, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 716ms", "time_since_start": "03h 27m 48s 774ms", "eta": "02h 56m 19s 131ms"}
2020-06-08T00:46:49 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T00:48:32 INFO: {"progress": "11900/22000", "train/total_loss": "0.0009", "train/total_loss/avg": "0.0824", "train/hateful_memes/cross_entropy": "0.0009", "train/hateful_memes/cross_entropy/avg": "0.0824", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9606", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9385", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9747", "max mem": 6412.0, "experiment": "run", "epoch": 45, "num_updates": 11900, "iterations": 11900, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 500ms", "time_since_start": "03h 29m 32s 274ms", "eta": "02h 54m 13s 529ms"}
2020-06-08T00:48:33 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T00:50:15 INFO: {"progress": "12000/22000", "train/total_loss": "0.0010", "train/total_loss/avg": "0.0818", "train/hateful_memes/cross_entropy": "0.0010", "train/hateful_memes/cross_entropy/avg": "0.0818", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9609", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9390", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9749", "max mem": 6412.0, "experiment": "run", "epoch": 46, "num_updates": 12000, "iterations": 12000, "max_updates": 22000, "lr": "0.00001", "ups": "0.97", "time": "01m 43s 733ms", "time_since_start": "03h 31m 16s 008ms", "eta": "02h 52m 53s 314ms"}
2020-06-08T00:50:15 INFO: Checkpoint time. Saving a checkpoint.
2020-06-08T00:50:20 INFO: Evaluation time. Running on full validation set...
2020-06-08T00:50:28 INFO: {"progress": "12000/22000", "val/total_loss": "2.7027", "val/hateful_memes/cross_entropy": "2.7027", "val/hateful_memes/accuracy": "0.5020", "val/hateful_memes/binary_f1": "0.3025", "val/hateful_memes/roc_auc": "0.4985", "num_updates": 12000, "epoch": 46, "iterations": 12000, "max_updates": 22000, "val_time": "07s 176ms", "best_update": 1000, "best_iteration": 1000, "best_val/hateful_memes/roc_auc": "0.544800"}
2020-06-08T00:50:29 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T00:52:11 INFO: {"progress": "12100/22000", "train/total_loss": "0.0010", "train/total_loss/avg": "0.0812", "train/hateful_memes/cross_entropy": "0.0010", "train/hateful_memes/cross_entropy/avg": "0.0812", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9613", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9395", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9751", "max mem": 6412.0, "experiment": "run", "epoch": 46, "num_updates": 12100, "iterations": 12100, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 591ms", "time_since_start": "03h 33m 12s 210ms", "eta": "02h 50m 55s 521ms"}
2020-06-08T00:52:13 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T00:53:55 INFO: {"progress": "12200/22000", "train/total_loss": "0.0009", "train/total_loss/avg": "0.0806", "train/hateful_memes/cross_entropy": "0.0009", "train/hateful_memes/cross_entropy/avg": "0.0806", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9616", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9400", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9753", "max mem": 6412.0, "experiment": "run", "epoch": 46, "num_updates": 12200, "iterations": 12200, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 282ms", "time_since_start": "03h 34m 55s 493ms", "eta": "02h 48m 41s 666ms"}
2020-06-08T00:53:56 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T00:55:38 INFO: {"progress": "12300/22000", "train/total_loss": "0.0010", "train/total_loss/avg": "0.0800", "train/hateful_memes/cross_entropy": "0.0010", "train/hateful_memes/cross_entropy/avg": "0.0800", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9619", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9405", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9755", "max mem": 6412.0, "experiment": "run", "epoch": 47, "num_updates": 12300, "iterations": 12300, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 664ms", "time_since_start": "03h 36m 39s 157ms", "eta": "02h 47m 35s 442ms"}
2020-06-08T00:55:39 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T00:57:22 INFO: {"progress": "12400/22000", "train/total_loss": "0.0010", "train/total_loss/avg": "0.0793", "train/hateful_memes/cross_entropy": "0.0010", "train/hateful_memes/cross_entropy/avg": "0.0793", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9622", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9409", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9757", "max mem": 6412.0, "experiment": "run", "epoch": 47, "num_updates": 12400, "iterations": 12400, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 221ms", "time_since_start": "03h 38m 22s 379ms", "eta": "02h 45m 09s 276ms"}
2020-06-08T00:57:23 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T00:59:05 INFO: {"progress": "12500/22000", "train/total_loss": "0.0010", "train/total_loss/avg": "0.0787", "train/hateful_memes/cross_entropy": "0.0010", "train/hateful_memes/cross_entropy/avg": "0.0787", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9625", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9414", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9759", "max mem": 6412.0, "experiment": "run", "epoch": 47, "num_updates": 12500, "iterations": 12500, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 295ms", "time_since_start": "03h 40m 05s 675ms", "eta": "02h 43m 33s 109ms"}
2020-06-08T00:59:06 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T01:00:49 INFO: {"progress": "12600/22000", "train/total_loss": "0.0010", "train/total_loss/avg": "0.0781", "train/hateful_memes/cross_entropy": "0.0010", "train/hateful_memes/cross_entropy/avg": "0.0781", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9628", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9419", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9761", "max mem": 6412.0, "experiment": "run", "epoch": 48, "num_updates": 12600, "iterations": 12600, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 698ms", "time_since_start": "03h 41m 49s 373ms", "eta": "02h 42m 27s 688ms"}
2020-06-08T01:00:50 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T01:02:32 INFO: {"progress": "12700/22000", "train/total_loss": "0.0014", "train/total_loss/avg": "0.0776", "train/hateful_memes/cross_entropy": "0.0014", "train/hateful_memes/cross_entropy/avg": "0.0776", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9631", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9423", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9763", "max mem": 6412.0, "experiment": "run", "epoch": 48, "num_updates": 12700, "iterations": 12700, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 428ms", "time_since_start": "03h 43m 32s 802ms", "eta": "02h 40m 18s 891ms"}
2020-06-08T01:02:33 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T01:04:16 INFO: {"progress": "12800/22000", "train/total_loss": "0.0011", "train/total_loss/avg": "0.0770", "train/hateful_memes/cross_entropy": "0.0011", "train/hateful_memes/cross_entropy/avg": "0.0770", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9634", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9428", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9764", "max mem": 6412.0, "experiment": "run", "epoch": 49, "num_updates": 12800, "iterations": 12800, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 646ms", "time_since_start": "03h 45m 16s 449ms", "eta": "02h 38m 55s 468ms"}
2020-06-08T01:04:17 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T01:05:59 INFO: {"progress": "12900/22000", "train/total_loss": "0.0014", "train/total_loss/avg": "0.0764", "train/hateful_memes/cross_entropy": "0.0014", "train/hateful_memes/cross_entropy/avg": "0.0764", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9637", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9432", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9766", "max mem": 6412.0, "experiment": "run", "epoch": 49, "num_updates": 12900, "iterations": 12900, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 523ms", "time_since_start": "03h 46m 59s 972ms", "eta": "02h 37m 622ms"}
2020-06-08T01:06:00 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T01:07:43 INFO: {"progress": "13000/22000", "train/total_loss": "0.0011", "train/total_loss/avg": "0.0758", "train/hateful_memes/cross_entropy": "0.0011", "train/hateful_memes/cross_entropy/avg": "0.0758", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9639", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9437", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9768", "max mem": 6412.0, "experiment": "run", "epoch": 49, "num_updates": 13000, "iterations": 13000, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 391ms", "time_since_start": "03h 48m 43s 363ms", "eta": "02h 35m 05s 216ms"}
2020-06-08T01:07:43 INFO: Checkpoint time. Saving a checkpoint.
2020-06-08T01:07:48 INFO: Evaluation time. Running on full validation set...
2020-06-08T01:07:53 INFO: {"progress": "13000/22000", "val/total_loss": "2.6437", "val/hateful_memes/cross_entropy": "2.6437", "val/hateful_memes/accuracy": "0.5320", "val/hateful_memes/binary_f1": "0.3427", "val/hateful_memes/roc_auc": "0.5061", "num_updates": 13000, "epoch": 49, "iterations": 13000, "max_updates": 22000, "val_time": "05s 181ms", "best_update": 1000, "best_iteration": 1000, "best_val/hateful_memes/roc_auc": "0.544800"}
2020-06-08T01:07:54 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T01:09:37 INFO: {"progress": "13100/22000", "train/total_loss": "0.0010", "train/total_loss/avg": "0.0752", "train/hateful_memes/cross_entropy": "0.0010", "train/hateful_memes/cross_entropy/avg": "0.0752", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9642", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9441", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9770", "max mem": 6412.0, "experiment": "run", "epoch": 50, "num_updates": 13100, "iterations": 13100, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 859ms", "time_since_start": "03h 50m 37s 790ms", "eta": "02h 34m 03s 504ms"}
2020-06-08T01:09:38 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T01:11:20 INFO: {"progress": "13200/22000", "train/total_loss": "0.0011", "train/total_loss/avg": "0.0747", "train/hateful_memes/cross_entropy": "0.0011", "train/hateful_memes/cross_entropy/avg": "0.0747", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9645", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9445", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9772", "max mem": 6412.0, "experiment": "run", "epoch": 50, "num_updates": 13200, "iterations": 13200, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 381ms", "time_since_start": "03h 52m 21s 171ms", "eta": "02h 31m 37s 544ms"}
2020-06-08T01:11:21 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T01:13:03 INFO: {"progress": "13300/22000", "train/total_loss": "0.0010", "train/total_loss/avg": "0.0743", "train/hateful_memes/cross_entropy": "0.0010", "train/hateful_memes/cross_entropy/avg": "0.0743", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9647", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9448", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9773", "max mem": 6412.0, "experiment": "run", "epoch": 50, "num_updates": 13300, "iterations": 13300, "max_updates": 22000, "lr": "0.", "ups": "0.98", "time": "01m 42s 904ms", "time_since_start": "03h 54m 04s 076ms", "eta": "02h 29m 12s 725ms"}
2020-06-08T01:13:05 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T01:14:47 INFO: {"progress": "13400/22000", "train/total_loss": "0.0009", "train/total_loss/avg": "0.0738", "train/hateful_memes/cross_entropy": "0.0009", "train/hateful_memes/cross_entropy/avg": "0.0738", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9649", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9452", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9774", "max mem": 6412.0, "experiment": "run", "epoch": 51, "num_updates": 13400, "iterations": 13400, "max_updates": 22000, "lr": "0.", "ups": "0.96", "time": "01m 44s 008ms", "time_since_start": "03h 55m 48s 084ms", "eta": "02h 29m 04s 724ms"}
2020-06-08T01:14:48 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T01:16:31 INFO: {"progress": "13500/22000", "train/total_loss": "0.0009", "train/total_loss/avg": "0.0732", "train/hateful_memes/cross_entropy": "0.0009", "train/hateful_memes/cross_entropy/avg": "0.0732", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9652", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9456", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9776", "max mem": 6412.0, "experiment": "run", "epoch": 51, "num_updates": 13500, "iterations": 13500, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 201ms", "time_since_start": "03h 57m 31s 286ms", "eta": "02h 26m 12s 126ms"}
2020-06-08T01:16:32 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T01:18:14 INFO: {"progress": "13600/22000", "train/total_loss": "0.0009", "train/total_loss/avg": "0.0727", "train/hateful_memes/cross_entropy": "0.0009", "train/hateful_memes/cross_entropy/avg": "0.0727", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9654", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9460", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9778", "max mem": 6412.0, "experiment": "run", "epoch": 52, "num_updates": 13600, "iterations": 13600, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 591ms", "time_since_start": "03h 59m 14s 877ms", "eta": "02h 25m 01s 671ms"}
2020-06-08T01:18:15 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T01:19:57 INFO: {"progress": "13700/22000", "train/total_loss": "0.0009", "train/total_loss/avg": "0.0722", "train/hateful_memes/cross_entropy": "0.0009", "train/hateful_memes/cross_entropy/avg": "0.0722", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9657", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9464", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9779", "max mem": 6412.0, "experiment": "run", "epoch": 52, "num_updates": 13700, "iterations": 13700, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 280ms", "time_since_start": "04h 58s 158ms", "eta": "02h 22m 52s 314ms"}
2020-06-08T01:19:58 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T01:21:41 INFO: {"progress": "13800/22000", "train/total_loss": "0.0009", "train/total_loss/avg": "0.0720", "train/hateful_memes/cross_entropy": "0.0009", "train/hateful_memes/cross_entropy/avg": "0.0720", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9657", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9461", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9781", "max mem": 6412.0, "experiment": "run", "epoch": 52, "num_updates": 13800, "iterations": 13800, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 244ms", "time_since_start": "04h 02m 41s 403ms", "eta": "02h 21m 06s 049ms"}
2020-06-08T01:21:42 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T01:23:24 INFO: {"progress": "13900/22000", "train/total_loss": "0.0011", "train/total_loss/avg": "0.0715", "train/hateful_memes/cross_entropy": "0.0011", "train/hateful_memes/cross_entropy/avg": "0.0715", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9660", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9465", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9782", "max mem": 6412.0, "experiment": "run", "epoch": 53, "num_updates": 13900, "iterations": 13900, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 619ms", "time_since_start": "04h 04m 25s 022ms", "eta": "02h 19m 53s 162ms"}
2020-06-08T01:23:25 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T01:25:08 INFO: {"progress": "14000/22000", "train/total_loss": "0.0011", "train/total_loss/avg": "0.0710", "train/hateful_memes/cross_entropy": "0.0011", "train/hateful_memes/cross_entropy/avg": "0.0710", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9662", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9469", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9784", "max mem": 6412.0, "experiment": "run", "epoch": 53, "num_updates": 14000, "iterations": 14000, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 331ms", "time_since_start": "04h 06m 08s 353ms", "eta": "02h 17m 46s 505ms"}
2020-06-08T01:25:08 INFO: Checkpoint time. Saving a checkpoint.
2020-06-08T01:25:14 INFO: Evaluation time. Running on full validation set...
2020-06-08T01:25:20 INFO: {"progress": "14000/22000", "val/total_loss": "2.6580", "val/hateful_memes/cross_entropy": "2.6580", "val/hateful_memes/accuracy": "0.5000", "val/hateful_memes/binary_f1": "0.3094", "val/hateful_memes/roc_auc": "0.5045", "num_updates": 14000, "epoch": 53, "iterations": 14000, "max_updates": 22000, "val_time": "05s 183ms", "best_update": 1000, "best_iteration": 1000, "best_val/hateful_memes/roc_auc": "0.544800"}
2020-06-08T01:25:21 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T01:27:04 INFO: {"progress": "14100/22000", "train/total_loss": "0.0008", "train/total_loss/avg": "0.0705", "train/hateful_memes/cross_entropy": "0.0008", "train/hateful_memes/cross_entropy/avg": "0.0705", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9664", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9473", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9786", "max mem": 6412.0, "experiment": "run", "epoch": 54, "num_updates": 14100, "iterations": 14100, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 943ms", "time_since_start": "04h 08m 04s 578ms", "eta": "02h 16m 51s 514ms"}
2020-06-08T01:27:05 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T01:28:47 INFO: {"progress": "14200/22000", "train/total_loss": "0.0008", "train/total_loss/avg": "0.0700", "train/hateful_memes/cross_entropy": "0.0008", "train/hateful_memes/cross_entropy/avg": "0.0700", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9667", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9476", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9787", "max mem": 6412.0, "experiment": "run", "epoch": 54, "num_updates": 14200, "iterations": 14200, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 365ms", "time_since_start": "04h 09m 47s 944ms", "eta": "02h 14m 22s 543ms"}
2020-06-08T01:28:48 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T01:30:31 INFO: {"progress": "14300/22000", "train/total_loss": "0.0007", "train/total_loss/avg": "0.0695", "train/hateful_memes/cross_entropy": "0.0007", "train/hateful_memes/cross_entropy/avg": "0.0695", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9669", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9480", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9789", "max mem": 6412.0, "experiment": "run", "epoch": 54, "num_updates": 14300, "iterations": 14300, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 457ms", "time_since_start": "04h 11m 31s 401ms", "eta": "02h 12m 46s 213ms"}
2020-06-08T01:30:32 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T01:32:14 INFO: {"progress": "14400/22000", "train/total_loss": "0.0008", "train/total_loss/avg": "0.0690", "train/hateful_memes/cross_entropy": "0.0008", "train/hateful_memes/cross_entropy/avg": "0.0690", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9671", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9484", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9790", "max mem": 6412.0, "experiment": "run", "epoch": 55, "num_updates": 14400, "iterations": 14400, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 786ms", "time_since_start": "04h 13m 15s 187ms", "eta": "02h 11m 27s 741ms"}
2020-06-08T01:32:16 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T01:33:58 INFO: {"progress": "14500/22000", "train/total_loss": "0.0011", "train/total_loss/avg": "0.0688", "train/hateful_memes/cross_entropy": "0.0011", "train/hateful_memes/cross_entropy/avg": "0.0688", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9674", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9487", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9791", "max mem": 6412.0, "experiment": "run", "epoch": 55, "num_updates": 14500, "iterations": 14500, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 238ms", "time_since_start": "04h 14m 58s 425ms", "eta": "02h 09m 02s 856ms"}
2020-06-08T01:33:59 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T01:35:41 INFO: {"progress": "14600/22000", "train/total_loss": "0.0008", "train/total_loss/avg": "0.0683", "train/hateful_memes/cross_entropy": "0.0008", "train/hateful_memes/cross_entropy/avg": "0.0683", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9676", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9491", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9793", "max mem": 6412.0, "experiment": "run", "epoch": 55, "num_updates": 14600, "iterations": 14600, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 594ms", "time_since_start": "04h 16m 42s 019ms", "eta": "02h 07m 45s 965ms"}
2020-06-08T01:35:42 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T01:37:25 INFO: {"progress": "14700/22000", "train/total_loss": "0.0008", "train/total_loss/avg": "0.0678", "train/hateful_memes/cross_entropy": "0.0008", "train/hateful_memes/cross_entropy/avg": "0.0678", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9678", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9494", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9794", "max mem": 6412.0, "experiment": "run", "epoch": 56, "num_updates": 14700, "iterations": 14700, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 891ms", "time_since_start": "04h 18m 25s 911ms", "eta": "02h 06m 24s 115ms"}
2020-06-08T01:37:26 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T01:39:08 INFO: {"progress": "14800/22000", "train/total_loss": "0.0008", "train/total_loss/avg": "0.0674", "train/hateful_memes/cross_entropy": "0.0008", "train/hateful_memes/cross_entropy/avg": "0.0674", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9680", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9498", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9796", "max mem": 6412.0, "experiment": "run", "epoch": 56, "num_updates": 14800, "iterations": 14800, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 274ms", "time_since_start": "04h 20m 09s 185ms", "eta": "02h 03m 55s 738ms"}
2020-06-08T01:39:09 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T01:40:52 INFO: {"progress": "14900/22000", "train/total_loss": "0.0008", "train/total_loss/avg": "0.0670", "train/hateful_memes/cross_entropy": "0.0008", "train/hateful_memes/cross_entropy/avg": "0.0670", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9683", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9501", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9797", "max mem": 6412.0, "experiment": "run", "epoch": 57, "num_updates": 14900, "iterations": 14900, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 668ms", "time_since_start": "04h 21m 52s 854ms", "eta": "02h 02m 40s 490ms"}
2020-06-08T01:40:53 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T01:42:36 INFO: {"progress": "15000/22000", "train/total_loss": "0.0008", "train/total_loss/avg": "0.0666", "train/hateful_memes/cross_entropy": "0.0008", "train/hateful_memes/cross_entropy/avg": "0.0666", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9685", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9504", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9798", "max mem": 6412.0, "experiment": "run", "epoch": 57, "num_updates": 15000, "iterations": 15000, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 386ms", "time_since_start": "04h 23m 36s 241ms", "eta": "02h 37s 086ms"}
2020-06-08T01:42:36 INFO: Checkpoint time. Saving a checkpoint.
2020-06-08T01:42:42 INFO: Evaluation time. Running on full validation set...
2020-06-08T01:42:48 INFO: {"progress": "15000/22000", "val/total_loss": "2.8656", "val/hateful_memes/cross_entropy": "2.8656", "val/hateful_memes/accuracy": "0.5120", "val/hateful_memes/binary_f1": "0.3068", "val/hateful_memes/roc_auc": "0.5094", "num_updates": 15000, "epoch": 57, "iterations": 15000, "max_updates": 22000, "val_time": "05s 025ms", "best_update": 1000, "best_iteration": 1000, "best_val/hateful_memes/roc_auc": "0.544800"}
2020-06-08T01:42:49 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T01:44:31 INFO: {"progress": "15100/22000", "train/total_loss": "0.0008", "train/total_loss/avg": "0.0661", "train/hateful_memes/cross_entropy": "0.0008", "train/hateful_memes/cross_entropy/avg": "0.0661", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9687", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9508", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9800", "max mem": 6412.0, "experiment": "run", "epoch": 57, "num_updates": 15100, "iterations": 15100, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 567ms", "time_since_start": "04h 25m 32s 110ms", "eta": "01h 59m 06s 142ms"}
2020-06-08T01:44:32 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T01:46:15 INFO: {"progress": "15200/22000", "train/total_loss": "0.0008", "train/total_loss/avg": "0.0657", "train/hateful_memes/cross_entropy": "0.0008", "train/hateful_memes/cross_entropy/avg": "0.0657", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9689", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9511", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9801", "max mem": 6412.0, "experiment": "run", "epoch": 58, "num_updates": 15200, "iterations": 15200, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 784ms", "time_since_start": "04h 27m 15s 894ms", "eta": "01h 57m 37s 343ms"}
2020-06-08T01:46:16 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T01:47:59 INFO: {"progress": "15300/22000", "train/total_loss": "0.0008", "train/total_loss/avg": "0.0653", "train/hateful_memes/cross_entropy": "0.0008", "train/hateful_memes/cross_entropy/avg": "0.0653", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9691", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9514", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9802", "max mem": 6412.0, "experiment": "run", "epoch": 58, "num_updates": 15300, "iterations": 15300, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 358ms", "time_since_start": "04h 28m 59s 253ms", "eta": "01h 55m 25s 023ms"}
2020-06-08T01:48:00 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T01:49:42 INFO: {"progress": "15400/22000", "train/total_loss": "0.0008", "train/total_loss/avg": "0.0649", "train/hateful_memes/cross_entropy": "0.0008", "train/hateful_memes/cross_entropy/avg": "0.0649", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9693", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9517", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9804", "max mem": 6412.0, "experiment": "run", "epoch": 58, "num_updates": 15400, "iterations": 15400, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 457ms", "time_since_start": "04h 30m 42s 710ms", "eta": "01h 53m 48s 171ms"}
2020-06-08T01:49:43 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T01:51:26 INFO: {"progress": "15500/22000", "train/total_loss": "0.0008", "train/total_loss/avg": "0.0645", "train/hateful_memes/cross_entropy": "0.0008", "train/hateful_memes/cross_entropy/avg": "0.0645", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9695", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9521", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9805", "max mem": 6412.0, "experiment": "run", "epoch": 59, "num_updates": 15500, "iterations": 15500, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 700ms", "time_since_start": "04h 32m 26s 411ms", "eta": "01h 52m 20s 549ms"}
2020-06-08T01:51:27 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T01:53:09 INFO: {"progress": "15600/22000", "train/total_loss": "0.0008", "train/total_loss/avg": "0.0641", "train/hateful_memes/cross_entropy": "0.0008", "train/hateful_memes/cross_entropy/avg": "0.0641", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9697", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9524", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9806", "max mem": 6412.0, "experiment": "run", "epoch": 59, "num_updates": 15600, "iterations": 15600, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 318ms", "time_since_start": "04h 34m 09s 729ms", "eta": "01h 50m 12s 355ms"}
2020-06-08T01:53:10 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T01:54:53 INFO: {"progress": "15700/22000", "train/total_loss": "0.0007", "train/total_loss/avg": "0.0637", "train/hateful_memes/cross_entropy": "0.0007", "train/hateful_memes/cross_entropy/avg": "0.0637", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9699", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9527", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9807", "max mem": 6412.0, "experiment": "run", "epoch": 60, "num_updates": 15700, "iterations": 15700, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 627ms", "time_since_start": "04h 35m 53s 356ms", "eta": "01h 48m 48s 539ms"}
2020-06-08T01:54:54 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T01:56:36 INFO: {"progress": "15800/22000", "train/total_loss": "0.0007", "train/total_loss/avg": "0.0633", "train/hateful_memes/cross_entropy": "0.0007", "train/hateful_memes/cross_entropy/avg": "0.0633", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9701", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9530", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9809", "max mem": 6412.0, "experiment": "run", "epoch": 60, "num_updates": 15800, "iterations": 15800, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 337ms", "time_since_start": "04h 37m 36s 694ms", "eta": "01h 46m 46s 909ms"}
2020-06-08T01:56:37 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T01:58:19 INFO: {"progress": "15900/22000", "train/total_loss": "0.0007", "train/total_loss/avg": "0.0629", "train/hateful_memes/cross_entropy": "0.0007", "train/hateful_memes/cross_entropy/avg": "0.0629", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9703", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9533", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9810", "max mem": 6412.0, "experiment": "run", "epoch": 60, "num_updates": 15900, "iterations": 15900, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 329ms", "time_since_start": "04h 39m 20s 023ms", "eta": "01h 45m 03s 081ms"}
2020-06-08T01:58:20 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T02:00:03 INFO: {"progress": "16000/22000", "train/total_loss": "0.0007", "train/total_loss/avg": "0.0625", "train/hateful_memes/cross_entropy": "0.0007", "train/hateful_memes/cross_entropy/avg": "0.0625", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9704", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9536", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9811", "max mem": 6412.0, "experiment": "run", "epoch": 61, "num_updates": 16000, "iterations": 16000, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 530ms", "time_since_start": "04h 41m 03s 554ms", "eta": "01h 43m 31s 856ms"}
2020-06-08T02:00:03 INFO: Checkpoint time. Saving a checkpoint.
2020-06-08T02:00:08 INFO: Evaluation time. Running on full validation set...
2020-06-08T02:00:15 INFO: {"progress": "16000/22000", "val/total_loss": "3.1207", "val/hateful_memes/cross_entropy": "3.1207", "val/hateful_memes/accuracy": "0.5240", "val/hateful_memes/binary_f1": "0.2917", "val/hateful_memes/roc_auc": "0.5123", "num_updates": 16000, "epoch": 61, "iterations": 16000, "max_updates": 22000, "val_time": "07s 163ms", "best_update": 1000, "best_iteration": 1000, "best_val/hateful_memes/roc_auc": "0.544800"}
2020-06-08T02:00:16 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T02:01:59 INFO: {"progress": "16100/22000", "train/total_loss": "0.0005", "train/total_loss/avg": "0.0621", "train/hateful_memes/cross_entropy": "0.0005", "train/hateful_memes/cross_entropy/avg": "0.0621", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9706", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9538", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9812", "max mem": 6412.0, "experiment": "run", "epoch": 61, "num_updates": 16100, "iterations": 16100, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 702ms", "time_since_start": "04h 42m 59s 872ms", "eta": "01h 41m 58s 443ms"}
2020-06-08T02:02:00 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T02:03:43 INFO: {"progress": "16200/22000", "train/total_loss": "0.0005", "train/total_loss/avg": "0.0618", "train/hateful_memes/cross_entropy": "0.0005", "train/hateful_memes/cross_entropy/avg": "0.0618", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9708", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9541", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9813", "max mem": 6412.0, "experiment": "run", "epoch": 61, "num_updates": 16200, "iterations": 16200, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 596ms", "time_since_start": "04h 44m 43s 469ms", "eta": "01h 40m 08s 624ms"}
2020-06-08T02:03:44 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T02:05:27 INFO: {"progress": "16300/22000", "train/total_loss": "0.0007", "train/total_loss/avg": "0.0614", "train/hateful_memes/cross_entropy": "0.0007", "train/hateful_memes/cross_entropy/avg": "0.0614", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9710", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9544", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9815", "max mem": 6412.0, "experiment": "run", "epoch": 62, "num_updates": 16300, "iterations": 16300, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 872ms", "time_since_start": "04h 46m 27s 342ms", "eta": "01h 38m 40s 713ms"}
2020-06-08T02:05:28 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T02:07:10 INFO: {"progress": "16400/22000", "train/total_loss": "0.0005", "train/total_loss/avg": "0.0610", "train/hateful_memes/cross_entropy": "0.0005", "train/hateful_memes/cross_entropy/avg": "0.0610", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9712", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9547", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9816", "max mem": 6412.0, "experiment": "run", "epoch": 62, "num_updates": 16400, "iterations": 16400, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 438ms", "time_since_start": "04h 48m 10s 780ms", "eta": "01h 36m 32s 542ms"}
2020-06-08T02:07:11 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T02:08:54 INFO: {"progress": "16500/22000", "train/total_loss": "0.0005", "train/total_loss/avg": "0.0606", "train/hateful_memes/cross_entropy": "0.0005", "train/hateful_memes/cross_entropy/avg": "0.0606", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9713", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9550", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9817", "max mem": 6412.0, "experiment": "run", "epoch": 63, "num_updates": 16500, "iterations": 16500, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 798ms", "time_since_start": "04h 49m 54s 578ms", "eta": "01h 35m 08s 902ms"}
2020-06-08T02:08:55 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T02:10:37 INFO: {"progress": "16600/22000", "train/total_loss": "0.0005", "train/total_loss/avg": "0.0603", "train/hateful_memes/cross_entropy": "0.0005", "train/hateful_memes/cross_entropy/avg": "0.0603", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9715", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9552", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9818", "max mem": 6412.0, "experiment": "run", "epoch": 63, "num_updates": 16600, "iterations": 16600, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 419ms", "time_since_start": "04h 51m 37s 998ms", "eta": "01h 33m 04s 666ms"}
2020-06-08T02:10:38 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T02:12:21 INFO: {"progress": "16700/22000", "train/total_loss": "0.0004", "train/total_loss/avg": "0.0599", "train/hateful_memes/cross_entropy": "0.0004", "train/hateful_memes/cross_entropy/avg": "0.0599", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9717", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9555", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9819", "max mem": 6412.0, "experiment": "run", "epoch": 63, "num_updates": 16700, "iterations": 16700, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 366ms", "time_since_start": "04h 53m 21s 365ms", "eta": "01h 31m 18s 439ms"}
2020-06-08T02:12:22 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T02:14:05 INFO: {"progress": "16800/22000", "train/total_loss": "0.0004", "train/total_loss/avg": "0.0596", "train/hateful_memes/cross_entropy": "0.0004", "train/hateful_memes/cross_entropy/avg": "0.0596", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9718", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9558", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9820", "max mem": 6412.0, "experiment": "run", "epoch": 64, "num_updates": 16800, "iterations": 16800, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 978ms", "time_since_start": "04h 55m 05s 344ms", "eta": "01h 30m 06s 900ms"}
2020-06-08T02:14:06 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T02:15:48 INFO: {"progress": "16900/22000", "train/total_loss": "0.0004", "train/total_loss/avg": "0.0592", "train/hateful_memes/cross_entropy": "0.0004", "train/hateful_memes/cross_entropy/avg": "0.0592", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9720", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9560", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9821", "max mem": 6412.0, "experiment": "run", "epoch": 64, "num_updates": 16900, "iterations": 16900, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 595ms", "time_since_start": "04h 56m 48s 940ms", "eta": "01h 28m 03s 393ms"}
2020-06-08T02:15:49 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T02:17:32 INFO: {"progress": "17000/22000", "train/total_loss": "0.0004", "train/total_loss/avg": "0.0589", "train/hateful_memes/cross_entropy": "0.0004", "train/hateful_memes/cross_entropy/avg": "0.0589", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9722", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9563", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9822", "max mem": 6412.0, "experiment": "run", "epoch": 64, "num_updates": 17000, "iterations": 17000, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 490ms", "time_since_start": "04h 58m 32s 430ms", "eta": "01h 26m 14s 529ms"}
2020-06-08T02:17:32 INFO: Checkpoint time. Saving a checkpoint.
2020-06-08T02:17:37 INFO: Evaluation time. Running on full validation set...
2020-06-08T02:17:42 INFO: {"progress": "17000/22000", "val/total_loss": "2.7716", "val/hateful_memes/cross_entropy": "2.7716", "val/hateful_memes/accuracy": "0.5260", "val/hateful_memes/binary_f1": "0.3435", "val/hateful_memes/roc_auc": "0.5090", "num_updates": 17000, "epoch": 64, "iterations": 17000, "max_updates": 22000, "val_time": "05s 135ms", "best_update": 1000, "best_iteration": 1000, "best_val/hateful_memes/roc_auc": "0.544800"}
2020-06-08T02:17:43 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T02:19:26 INFO: {"progress": "17100/22000", "train/total_loss": "0.0004", "train/total_loss/avg": "0.0585", "train/hateful_memes/cross_entropy": "0.0004", "train/hateful_memes/cross_entropy/avg": "0.0585", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9723", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9565", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9823", "max mem": 6412.0, "experiment": "run", "epoch": 65, "num_updates": 17100, "iterations": 17100, "max_updates": 22000, "lr": "0.", "ups": "0.96", "time": "01m 44s 046ms", "time_since_start": "05h 26s 994ms", "eta": "01h 24m 58s 264ms"}
2020-06-08T02:19:27 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T02:21:10 INFO: {"progress": "17200/22000", "train/total_loss": "0.0004", "train/total_loss/avg": "0.0582", "train/hateful_memes/cross_entropy": "0.0004", "train/hateful_memes/cross_entropy/avg": "0.0582", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9725", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9568", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9824", "max mem": 6412.0, "experiment": "run", "epoch": 65, "num_updates": 17200, "iterations": 17200, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 532ms", "time_since_start": "05h 02m 10s 527ms", "eta": "01h 22m 49s 571ms"}
2020-06-08T02:21:11 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T02:22:54 INFO: {"progress": "17300/22000", "train/total_loss": "0.0004", "train/total_loss/avg": "0.0579", "train/hateful_memes/cross_entropy": "0.0004", "train/hateful_memes/cross_entropy/avg": "0.0579", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9727", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9571", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9825", "max mem": 6412.0, "experiment": "run", "epoch": 66, "num_updates": 17300, "iterations": 17300, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 763ms", "time_since_start": "05h 03m 54s 291ms", "eta": "01h 21m 16s 901ms"}
2020-06-08T02:22:55 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T02:24:37 INFO: {"progress": "17400/22000", "train/total_loss": "0.0004", "train/total_loss/avg": "0.0575", "train/hateful_memes/cross_entropy": "0.0004", "train/hateful_memes/cross_entropy/avg": "0.0575", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9728", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9573", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9826", "max mem": 6412.0, "experiment": "run", "epoch": 66, "num_updates": 17400, "iterations": 17400, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 387ms", "time_since_start": "05h 05m 37s 679ms", "eta": "01h 19m 15s 826ms"}
2020-06-08T02:24:38 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T02:26:20 INFO: {"progress": "17500/22000", "train/total_loss": "0.0004", "train/total_loss/avg": "0.0572", "train/hateful_memes/cross_entropy": "0.0004", "train/hateful_memes/cross_entropy/avg": "0.0572", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9730", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9575", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9827", "max mem": 6412.0, "experiment": "run", "epoch": 66, "num_updates": 17500, "iterations": 17500, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 408ms", "time_since_start": "05h 07m 21s 088ms", "eta": "01h 17m 33s 405ms"}
2020-06-08T02:26:21 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T02:28:04 INFO: {"progress": "17600/22000", "train/total_loss": "0.0004", "train/total_loss/avg": "0.0569", "train/hateful_memes/cross_entropy": "0.0004", "train/hateful_memes/cross_entropy/avg": "0.0569", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9731", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9578", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9828", "max mem": 6412.0, "experiment": "run", "epoch": 67, "num_updates": 17600, "iterations": 17600, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 828ms", "time_since_start": "05h 09m 04s 917ms", "eta": "01h 16m 08s 474ms"}
2020-06-08T02:28:05 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T02:29:47 INFO: {"progress": "17700/22000", "train/total_loss": "0.0004", "train/total_loss/avg": "0.0566", "train/hateful_memes/cross_entropy": "0.0004", "train/hateful_memes/cross_entropy/avg": "0.0566", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9733", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9580", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9829", "max mem": 6412.0, "experiment": "run", "epoch": 67, "num_updates": 17700, "iterations": 17700, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 294ms", "time_since_start": "05h 10m 48s 211ms", "eta": "01h 14m 01s 657ms"}
2020-06-08T02:29:49 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T02:31:31 INFO: {"progress": "17800/22000", "train/total_loss": "0.0002", "train/total_loss/avg": "0.0562", "train/hateful_memes/cross_entropy": "0.0002", "train/hateful_memes/cross_entropy/avg": "0.0562", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9734", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9583", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9830", "max mem": 6412.0, "experiment": "run", "epoch": 67, "num_updates": 17800, "iterations": 17800, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 490ms", "time_since_start": "05h 12m 31s 701ms", "eta": "01h 12m 26s 602ms"}
2020-06-08T02:31:32 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T02:33:15 INFO: {"progress": "17900/22000", "train/total_loss": "0.0002", "train/total_loss/avg": "0.0559", "train/hateful_memes/cross_entropy": "0.0002", "train/hateful_memes/cross_entropy/avg": "0.0559", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9736", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9585", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9831", "max mem": 6412.0, "experiment": "run", "epoch": 68, "num_updates": 17900, "iterations": 17900, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 777ms", "time_since_start": "05h 14m 15s 479ms", "eta": "01h 10m 54s 878ms"}
2020-06-08T02:33:16 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T02:34:58 INFO: {"progress": "18000/22000", "train/total_loss": "0.0002", "train/total_loss/avg": "0.0556", "train/hateful_memes/cross_entropy": "0.0002", "train/hateful_memes/cross_entropy/avg": "0.0556", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9737", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9587", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9832", "max mem": 6412.0, "experiment": "run", "epoch": 68, "num_updates": 18000, "iterations": 18000, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 426ms", "time_since_start": "05h 15m 58s 905ms", "eta": "01h 08m 57s 045ms"}
2020-06-08T02:34:58 INFO: Checkpoint time. Saving a checkpoint.
2020-06-08T02:35:05 INFO: Evaluation time. Running on full validation set...
2020-06-08T02:35:11 INFO: {"progress": "18000/22000", "val/total_loss": "2.7961", "val/hateful_memes/cross_entropy": "2.7961", "val/hateful_memes/accuracy": "0.5220", "val/hateful_memes/binary_f1": "0.3523", "val/hateful_memes/roc_auc": "0.5103", "num_updates": 18000, "epoch": 68, "iterations": 18000, "max_updates": 22000, "val_time": "05s 152ms", "best_update": 1000, "best_iteration": 1000, "best_val/hateful_memes/roc_auc": "0.544800"}
2020-06-08T02:35:12 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T02:36:55 INFO: {"progress": "18100/22000", "train/total_loss": "0.0002", "train/total_loss/avg": "0.0553", "train/hateful_memes/cross_entropy": "0.0002", "train/hateful_memes/cross_entropy/avg": "0.0553", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9739", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9590", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9833", "max mem": 6412.0, "experiment": "run", "epoch": 69, "num_updates": 18100, "iterations": 18100, "max_updates": 22000, "lr": "0.", "ups": "0.96", "time": "01m 44s 155ms", "time_since_start": "05h 17m 55s 725ms", "eta": "01h 07m 42s 051ms"}
2020-06-08T02:36:56 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T02:38:38 INFO: {"progress": "18200/22000", "train/total_loss": "0.0003", "train/total_loss/avg": "0.0550", "train/hateful_memes/cross_entropy": "0.0003", "train/hateful_memes/cross_entropy/avg": "0.0550", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9740", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9592", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9834", "max mem": 6412.0, "experiment": "run", "epoch": 69, "num_updates": 18200, "iterations": 18200, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 417ms", "time_since_start": "05h 19m 39s 143ms", "eta": "01h 05m 29s 877ms"}
2020-06-08T02:38:39 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T02:40:22 INFO: {"progress": "18300/22000", "train/total_loss": "0.0003", "train/total_loss/avg": "0.0547", "train/hateful_memes/cross_entropy": "0.0003", "train/hateful_memes/cross_entropy/avg": "0.0547", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9742", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9594", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9835", "max mem": 6412.0, "experiment": "run", "epoch": 69, "num_updates": 18300, "iterations": 18300, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 305ms", "time_since_start": "05h 21m 22s 449ms", "eta": "01h 03m 42s 297ms"}
2020-06-08T02:40:23 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T02:42:05 INFO: {"progress": "18400/22000", "train/total_loss": "0.0002", "train/total_loss/avg": "0.0544", "train/hateful_memes/cross_entropy": "0.0002", "train/hateful_memes/cross_entropy/avg": "0.0544", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9743", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9596", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9836", "max mem": 6412.0, "experiment": "run", "epoch": 70, "num_updates": 18400, "iterations": 18400, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 757ms", "time_since_start": "05h 23m 06s 206ms", "eta": "01h 02m 15s 271ms"}
2020-06-08T02:42:07 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T02:43:49 INFO: {"progress": "18500/22000", "train/total_loss": "0.0002", "train/total_loss/avg": "0.0541", "train/hateful_memes/cross_entropy": "0.0002", "train/hateful_memes/cross_entropy/avg": "0.0541", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9744", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9598", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9837", "max mem": 6412.0, "experiment": "run", "epoch": 70, "num_updates": 18500, "iterations": 18500, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 476ms", "time_since_start": "05h 24m 49s 683ms", "eta": "01h 21s 675ms"}
2020-06-08T02:43:50 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T02:45:32 INFO: {"progress": "18600/22000", "train/total_loss": "0.0002", "train/total_loss/avg": "0.0539", "train/hateful_memes/cross_entropy": "0.0002", "train/hateful_memes/cross_entropy/avg": "0.0539", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9746", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9601", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9838", "max mem": 6412.0, "experiment": "run", "epoch": 70, "num_updates": 18600, "iterations": 18600, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 440ms", "time_since_start": "05h 26m 33s 123ms", "eta": "58m 36s 979ms"}
2020-06-08T02:45:33 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T02:47:16 INFO: {"progress": "18700/22000", "train/total_loss": "0.0002", "train/total_loss/avg": "0.0536", "train/hateful_memes/cross_entropy": "0.0002", "train/hateful_memes/cross_entropy/avg": "0.0536", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9747", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9603", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9838", "max mem": 6412.0, "experiment": "run", "epoch": 71, "num_updates": 18700, "iterations": 18700, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 757ms", "time_since_start": "05h 28m 16s 881ms", "eta": "57m 03s 997ms"}
2020-06-08T02:47:17 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T02:49:00 INFO: {"progress": "18800/22000", "train/total_loss": "0.0002", "train/total_loss/avg": "0.0533", "train/hateful_memes/cross_entropy": "0.0002", "train/hateful_memes/cross_entropy/avg": "0.0533", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9749", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9605", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9839", "max mem": 6412.0, "experiment": "run", "epoch": 71, "num_updates": 18800, "iterations": 18800, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 349ms", "time_since_start": "05h 30m 230ms", "eta": "55m 07s 177ms"}
2020-06-08T02:49:01 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T02:50:43 INFO: {"progress": "18900/22000", "train/total_loss": "0.0002", "train/total_loss/avg": "0.0530", "train/hateful_memes/cross_entropy": "0.0002", "train/hateful_memes/cross_entropy/avg": "0.0530", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9750", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9607", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9840", "max mem": 6412.0, "experiment": "run", "epoch": 72, "num_updates": 18900, "iterations": 18900, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 811ms", "time_since_start": "05h 31m 44s 042ms", "eta": "53m 38s 166ms"}
2020-06-08T02:50:44 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T02:52:27 INFO: {"progress": "19000/22000", "train/total_loss": "0.0002", "train/total_loss/avg": "0.0527", "train/hateful_memes/cross_entropy": "0.0002", "train/hateful_memes/cross_entropy/avg": "0.0527", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9751", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9609", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9841", "max mem": 6412.0, "experiment": "run", "epoch": 72, "num_updates": 19000, "iterations": 19000, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 443ms", "time_since_start": "05h 33m 27s 486ms", "eta": "51m 43s 312ms"}
2020-06-08T02:52:27 INFO: Checkpoint time. Saving a checkpoint.
2020-06-08T02:52:34 INFO: Evaluation time. Running on full validation set...
2020-06-08T02:52:39 INFO: {"progress": "19000/22000", "val/total_loss": "2.9787", "val/hateful_memes/cross_entropy": "2.9787", "val/hateful_memes/accuracy": "0.5200", "val/hateful_memes/binary_f1": "0.3143", "val/hateful_memes/roc_auc": "0.5065", "num_updates": 19000, "epoch": 72, "iterations": 19000, "max_updates": 22000, "val_time": "05s 003ms", "best_update": 1000, "best_iteration": 1000, "best_val/hateful_memes/roc_auc": "0.544800"}
2020-06-08T02:52:40 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T02:54:23 INFO: {"progress": "19100/22000", "train/total_loss": "0.0002", "train/total_loss/avg": "0.0525", "train/hateful_memes/cross_entropy": "0.0002", "train/hateful_memes/cross_entropy/avg": "0.0525", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9752", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9611", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9842", "max mem": 6412.0, "experiment": "run", "epoch": 72, "num_updates": 19100, "iterations": 19100, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 706ms", "time_since_start": "05h 35m 23s 724ms", "eta": "50m 07s 487ms"}
2020-06-08T02:54:24 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T02:56:07 INFO: {"progress": "19200/22000", "train/total_loss": "0.0002", "train/total_loss/avg": "0.0523", "train/hateful_memes/cross_entropy": "0.0002", "train/hateful_memes/cross_entropy/avg": "0.0523", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9754", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9613", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9843", "max mem": 6412.0, "experiment": "run", "epoch": 73, "num_updates": 19200, "iterations": 19200, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 873ms", "time_since_start": "05h 37m 07s 598ms", "eta": "48m 28s 457ms"}
2020-06-08T02:56:08 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T02:57:50 INFO: {"progress": "19300/22000", "train/total_loss": "0.0002", "train/total_loss/avg": "0.0520", "train/hateful_memes/cross_entropy": "0.0002", "train/hateful_memes/cross_entropy/avg": "0.0520", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9755", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9615", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9843", "max mem": 6412.0, "experiment": "run", "epoch": 73, "num_updates": 19300, "iterations": 19300, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 350ms", "time_since_start": "05h 38m 50s 948ms", "eta": "46m 30s 465ms"}
2020-06-08T02:57:51 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T02:59:34 INFO: {"progress": "19400/22000", "train/total_loss": "0.0002", "train/total_loss/avg": "0.0517", "train/hateful_memes/cross_entropy": "0.0002", "train/hateful_memes/cross_entropy/avg": "0.0517", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9756", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9617", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9844", "max mem": 6412.0, "experiment": "run", "epoch": 73, "num_updates": 19400, "iterations": 19400, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 468ms", "time_since_start": "05h 40m 34s 417ms", "eta": "44m 50s 184ms"}
2020-06-08T02:59:35 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T03:01:18 INFO: {"progress": "19500/22000", "train/total_loss": "0.0002", "train/total_loss/avg": "0.0514", "train/hateful_memes/cross_entropy": "0.0002", "train/hateful_memes/cross_entropy/avg": "0.0514", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9758", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9619", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9845", "max mem": 6412.0, "experiment": "run", "epoch": 74, "num_updates": 19500, "iterations": 19500, "max_updates": 22000, "lr": "0.", "ups": "0.96", "time": "01m 44s 029ms", "time_since_start": "05h 42m 18s 447ms", "eta": "43m 20s 747ms"}
2020-06-08T03:01:19 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T03:03:01 INFO: {"progress": "19600/22000", "train/total_loss": "0.0002", "train/total_loss/avg": "0.0512", "train/hateful_memes/cross_entropy": "0.0002", "train/hateful_memes/cross_entropy/avg": "0.0512", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9759", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9621", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9846", "max mem": 6412.0, "experiment": "run", "epoch": 74, "num_updates": 19600, "iterations": 19600, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 373ms", "time_since_start": "05h 44m 01s 821ms", "eta": "41m 20s 972ms"}
2020-06-08T03:03:02 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T03:04:45 INFO: {"progress": "19700/22000", "train/total_loss": "0.0002", "train/total_loss/avg": "0.0509", "train/hateful_memes/cross_entropy": "0.0002", "train/hateful_memes/cross_entropy/avg": "0.0509", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9760", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9623", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9847", "max mem": 6412.0, "experiment": "run", "epoch": 75, "num_updates": 19700, "iterations": 19700, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 856ms", "time_since_start": "05h 45m 45s 677ms", "eta": "39m 48s 699ms"}
2020-06-08T03:04:46 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T03:06:28 INFO: {"progress": "19800/22000", "train/total_loss": "0.0002", "train/total_loss/avg": "0.0507", "train/hateful_memes/cross_entropy": "0.0002", "train/hateful_memes/cross_entropy/avg": "0.0507", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9761", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9625", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9847", "max mem": 6412.0, "experiment": "run", "epoch": 75, "num_updates": 19800, "iterations": 19800, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 261ms", "time_since_start": "05h 47m 28s 938ms", "eta": "37m 51s 742ms"}
2020-06-08T03:06:29 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T03:08:12 INFO: {"progress": "19900/22000", "train/total_loss": "0.0002", "train/total_loss/avg": "0.0504", "train/hateful_memes/cross_entropy": "0.0002", "train/hateful_memes/cross_entropy/avg": "0.0504", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9762", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9627", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9848", "max mem": 6412.0, "experiment": "run", "epoch": 75, "num_updates": 19900, "iterations": 19900, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 365ms", "time_since_start": "05h 49m 12s 304ms", "eta": "36m 10s 673ms"}
2020-06-08T03:08:13 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T03:09:55 INFO: {"progress": "20000/22000", "train/total_loss": "0.0003", "train/total_loss/avg": "0.0502", "train/hateful_memes/cross_entropy": "0.0003", "train/hateful_memes/cross_entropy/avg": "0.0502", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9764", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9629", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9849", "max mem": 6412.0, "experiment": "run", "epoch": 76, "num_updates": 20000, "iterations": 20000, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 694ms", "time_since_start": "05h 50m 55s 998ms", "eta": "34m 33s 887ms"}
2020-06-08T03:09:55 INFO: Checkpoint time. Saving a checkpoint.
2020-06-08T03:10:00 INFO: Evaluation time. Running on full validation set...
2020-06-08T03:10:07 INFO: {"progress": "20000/22000", "val/total_loss": "3.1987", "val/hateful_memes/cross_entropy": "3.1987", "val/hateful_memes/accuracy": "0.5180", "val/hateful_memes/binary_f1": "0.2719", "val/hateful_memes/roc_auc": "0.5099", "num_updates": 20000, "epoch": 76, "iterations": 20000, "max_updates": 22000, "val_time": "06s 918ms", "best_update": 1000, "best_iteration": 1000, "best_val/hateful_memes/roc_auc": "0.544800"}
2020-06-08T03:10:09 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T03:11:51 INFO: {"progress": "20100/22000", "train/total_loss": "0.0003", "train/total_loss/avg": "0.0499", "train/hateful_memes/cross_entropy": "0.0003", "train/hateful_memes/cross_entropy/avg": "0.0499", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9765", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9630", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9850", "max mem": 6412.0, "experiment": "run", "epoch": 76, "num_updates": 20100, "iterations": 20100, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 570ms", "time_since_start": "05h 52m 51s 910ms", "eta": "32m 47s 845ms"}
2020-06-08T03:11:52 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T03:13:35 INFO: {"progress": "20200/22000", "train/total_loss": "0.0003", "train/total_loss/avg": "0.0497", "train/hateful_memes/cross_entropy": "0.0003", "train/hateful_memes/cross_entropy/avg": "0.0497", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9766", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9632", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9850", "max mem": 6412.0, "experiment": "run", "epoch": 76, "num_updates": 20200, "iterations": 20200, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 393ms", "time_since_start": "05h 54m 35s 303ms", "eta": "31m 01s 076ms"}
2020-06-08T03:13:36 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T03:15:18 INFO: {"progress": "20300/22000", "train/total_loss": "0.0002", "train/total_loss/avg": "0.0494", "train/hateful_memes/cross_entropy": "0.0002", "train/hateful_memes/cross_entropy/avg": "0.0494", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9767", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9634", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9851", "max mem": 6412.0, "experiment": "run", "epoch": 77, "num_updates": 20300, "iterations": 20300, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 755ms", "time_since_start": "05h 56m 19s 058ms", "eta": "29m 23s 843ms"}
2020-06-08T03:15:19 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T03:17:01 INFO: {"progress": "20400/22000", "train/total_loss": "0.0002", "train/total_loss/avg": "0.0492", "train/hateful_memes/cross_entropy": "0.0002", "train/hateful_memes/cross_entropy/avg": "0.0492", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9768", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9636", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9852", "max mem": 6412.0, "experiment": "run", "epoch": 77, "num_updates": 20400, "iterations": 20400, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 146ms", "time_since_start": "05h 58m 02s 205ms", "eta": "27m 30s 347ms"}
2020-06-08T03:17:03 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T03:18:45 INFO: {"progress": "20500/22000", "train/total_loss": "0.0003", "train/total_loss/avg": "0.0491", "train/hateful_memes/cross_entropy": "0.0003", "train/hateful_memes/cross_entropy/avg": "0.0491", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9769", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9638", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9853", "max mem": 6412.0, "experiment": "run", "epoch": 78, "num_updates": 20500, "iterations": 20500, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 755ms", "time_since_start": "05h 59m 45s 961ms", "eta": "25m 56s 334ms"}
2020-06-08T03:18:46 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T03:20:29 INFO: {"progress": "20600/22000", "train/total_loss": "0.0003", "train/total_loss/avg": "0.0488", "train/hateful_memes/cross_entropy": "0.0003", "train/hateful_memes/cross_entropy/avg": "0.0488", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9771", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9639", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9853", "max mem": 6412.0, "experiment": "run", "epoch": 78, "num_updates": 20600, "iterations": 20600, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 367ms", "time_since_start": "06h 01m 29s 328ms", "eta": "24m 07s 143ms"}
2020-06-08T03:20:30 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T03:22:12 INFO: {"progress": "20700/22000", "train/total_loss": "0.0002", "train/total_loss/avg": "0.0486", "train/hateful_memes/cross_entropy": "0.0002", "train/hateful_memes/cross_entropy/avg": "0.0486", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9772", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9641", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9854", "max mem": 6412.0, "experiment": "run", "epoch": 78, "num_updates": 20700, "iterations": 20700, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 195ms", "time_since_start": "06h 03m 12s 524ms", "eta": "22m 21s 542ms"}
2020-06-08T03:22:13 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T03:23:56 INFO: {"progress": "20800/22000", "train/total_loss": "0.0002", "train/total_loss/avg": "0.0484", "train/hateful_memes/cross_entropy": "0.0002", "train/hateful_memes/cross_entropy/avg": "0.0484", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9773", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9643", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9855", "max mem": 6412.0, "experiment": "run", "epoch": 79, "num_updates": 20800, "iterations": 20800, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 852ms", "time_since_start": "06h 04m 56s 376ms", "eta": "20m 46s 230ms"}
2020-06-08T03:23:57 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T03:25:39 INFO: {"progress": "20900/22000", "train/total_loss": "0.0002", "train/total_loss/avg": "0.0481", "train/hateful_memes/cross_entropy": "0.0002", "train/hateful_memes/cross_entropy/avg": "0.0481", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9774", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9645", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9855", "max mem": 6412.0, "experiment": "run", "epoch": 79, "num_updates": 20900, "iterations": 20900, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 439ms", "time_since_start": "06h 06m 39s 816ms", "eta": "18m 57s 834ms"}
2020-06-08T03:25:40 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T03:27:23 INFO: {"progress": "21000/22000", "train/total_loss": "0.0002", "train/total_loss/avg": "0.0479", "train/hateful_memes/cross_entropy": "0.0002", "train/hateful_memes/cross_entropy/avg": "0.0479", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9775", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9646", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9856", "max mem": 6412.0, "experiment": "run", "epoch": 79, "num_updates": 21000, "iterations": 21000, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 408ms", "time_since_start": "06h 08m 23s 225ms", "eta": "17m 14s 087ms"}
2020-06-08T03:27:23 INFO: Checkpoint time. Saving a checkpoint.
2020-06-08T03:27:28 INFO: Evaluation time. Running on full validation set...
2020-06-08T03:27:35 INFO: {"progress": "21000/22000", "val/total_loss": "2.8799", "val/hateful_memes/cross_entropy": "2.8799", "val/hateful_memes/accuracy": "0.5240", "val/hateful_memes/binary_f1": "0.3352", "val/hateful_memes/roc_auc": "0.5070", "num_updates": 21000, "epoch": 79, "iterations": 21000, "max_updates": 22000, "val_time": "07s 189ms", "best_update": 1000, "best_iteration": 1000, "best_val/hateful_memes/roc_auc": "0.544800"}
2020-06-08T03:27:36 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T03:29:19 INFO: {"progress": "21100/22000", "train/total_loss": "0.0002", "train/total_loss/avg": "0.0477", "train/hateful_memes/cross_entropy": "0.0002", "train/hateful_memes/cross_entropy/avg": "0.0477", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9776", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9648", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9857", "max mem": 6412.0, "experiment": "run", "epoch": 80, "num_updates": 21100, "iterations": 21100, "max_updates": 22000, "lr": "0.", "ups": "0.96", "time": "01m 44s 116ms", "time_since_start": "06h 10m 19s 943ms", "eta": "15m 37s 046ms"}
2020-06-08T03:29:20 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T03:31:03 INFO: {"progress": "21200/22000", "train/total_loss": "0.0002", "train/total_loss/avg": "0.0475", "train/hateful_memes/cross_entropy": "0.0002", "train/hateful_memes/cross_entropy/avg": "0.0475", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9777", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9650", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9857", "max mem": 6412.0, "experiment": "run", "epoch": 80, "num_updates": 21200, "iterations": 21200, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 575ms", "time_since_start": "06h 12m 03s 519ms", "eta": "13m 48s 604ms"}
2020-06-08T03:31:04 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T03:32:47 INFO: {"progress": "21300/22000", "train/total_loss": "0.0002", "train/total_loss/avg": "0.0472", "train/hateful_memes/cross_entropy": "0.0002", "train/hateful_memes/cross_entropy/avg": "0.0472", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9778", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9651", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9858", "max mem": 6412.0, "experiment": "run", "epoch": 81, "num_updates": 21300, "iterations": 21300, "max_updates": 22000, "lr": "0.", "ups": "0.96", "time": "01m 44s 024ms", "time_since_start": "06h 13m 47s 543ms", "eta": "12m 08s 168ms"}
2020-06-08T03:32:48 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T03:34:30 INFO: {"progress": "21400/22000", "train/total_loss": "0.0002", "train/total_loss/avg": "0.0470", "train/hateful_memes/cross_entropy": "0.0002", "train/hateful_memes/cross_entropy/avg": "0.0470", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9779", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9653", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9859", "max mem": 6412.0, "experiment": "run", "epoch": 81, "num_updates": 21400, "iterations": 21400, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 668ms", "time_since_start": "06h 15m 31s 211ms", "eta": "10m 22s 012ms"}
2020-06-08T03:34:32 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T03:36:14 INFO: {"progress": "21500/22000", "train/total_loss": "0.0002", "train/total_loss/avg": "0.0468", "train/hateful_memes/cross_entropy": "0.0002", "train/hateful_memes/cross_entropy/avg": "0.0468", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9780", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9655", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9859", "max mem": 6412.0, "experiment": "run", "epoch": 81, "num_updates": 21500, "iterations": 21500, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 482ms", "time_since_start": "06h 17m 14s 694ms", "eta": "08m 37s 411ms"}
2020-06-08T03:36:15 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T03:37:58 INFO: {"progress": "21600/22000", "train/total_loss": "0.0002", "train/total_loss/avg": "0.0466", "train/hateful_memes/cross_entropy": "0.0002", "train/hateful_memes/cross_entropy/avg": "0.0466", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9781", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9656", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9860", "max mem": 6412.0, "experiment": "run", "epoch": 82, "num_updates": 21600, "iterations": 21600, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 942ms", "time_since_start": "06h 18m 58s 636ms", "eta": "06m 55s 770ms"}
2020-06-08T03:37:59 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T03:39:42 INFO: {"progress": "21700/22000", "train/total_loss": "0.0002", "train/total_loss/avg": "0.0464", "train/hateful_memes/cross_entropy": "0.0002", "train/hateful_memes/cross_entropy/avg": "0.0464", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9782", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9658", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9861", "max mem": 6412.0, "experiment": "run", "epoch": 82, "num_updates": 21700, "iterations": 21700, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 611ms", "time_since_start": "06h 20m 42s 248ms", "eta": "05m 10s 835ms"}
2020-06-08T03:39:43 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T03:41:25 INFO: {"progress": "21800/22000", "train/total_loss": "0.0002", "train/total_loss/avg": "0.0462", "train/hateful_memes/cross_entropy": "0.0002", "train/hateful_memes/cross_entropy/avg": "0.0462", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9783", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9659", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9861", "max mem": 6412.0, "experiment": "run", "epoch": 82, "num_updates": 21800, "iterations": 21800, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 212ms", "time_since_start": "06h 22m 25s 461ms", "eta": "03m 26s 425ms"}
2020-06-08T03:41:26 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T03:43:09 INFO: {"progress": "21900/22000", "train/total_loss": "0.0002", "train/total_loss/avg": "0.0459", "train/hateful_memes/cross_entropy": "0.0002", "train/hateful_memes/cross_entropy/avg": "0.0459", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9784", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9661", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9862", "max mem": 6412.0, "experiment": "run", "epoch": 83, "num_updates": 21900, "iterations": 21900, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 932ms", "time_since_start": "06h 24m 09s 394ms", "eta": "01m 43s 932ms"}
2020-06-08T03:43:10 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T03:44:52 INFO: {"progress": "22000/22000", "train/total_loss": "0.0002", "train/total_loss/avg": "0.0457", "train/hateful_memes/cross_entropy": "0.0002", "train/hateful_memes/cross_entropy/avg": "0.0457", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9785", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9662", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9863", "max mem": 6412.0, "experiment": "run", "epoch": 83, "num_updates": 22000, "iterations": 22000, "max_updates": 22000, "lr": "0.", "ups": "0.97", "time": "01m 43s 359ms", "time_since_start": "06h 25m 52s 753ms", "eta": "0ms"}
2020-06-08T03:44:52 INFO: Checkpoint time. Saving a checkpoint.
2020-06-08T03:44:57 INFO: Evaluation time. Running on full validation set...
2020-06-08T03:45:04 INFO: {"progress": "22000/22000", "val/total_loss": "3.2305", "val/hateful_memes/cross_entropy": "3.2305", "val/hateful_memes/accuracy": "0.5200", "val/hateful_memes/binary_f1": "0.2857", "val/hateful_memes/roc_auc": "0.5131", "num_updates": 22000, "epoch": 83, "iterations": 22000, "max_updates": 22000, "val_time": "06s 566ms", "best_update": 1000, "best_iteration": 1000, "best_val/hateful_memes/roc_auc": "0.544800"}
2020-06-08T03:45:05 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T03:45:05 INFO: Stepping into final validation check
2020-06-08T03:45:05 INFO: Evaluation time. Running on full validation set...
2020-06-08T03:45:10 INFO: {"progress": "22001/22000", "val/total_loss": "3.3146", "val/hateful_memes/cross_entropy": "3.3146", "val/hateful_memes/accuracy": "0.5160", "val/hateful_memes/binary_f1": "0.2622", "val/hateful_memes/roc_auc": "0.5137", "num_updates": 22001, "epoch": 83, "iterations": 22001, "max_updates": 22000, "val_time": "05s 066ms", "best_update": 1000, "best_iteration": 1000, "best_val/hateful_memes/roc_auc": "0.544800"}
2020-06-08T03:45:11 INFO: Restoring checkpoint
2020-06-08T03:45:11 INFO: Loading checkpoint
