2020-06-08T21:50:29 INFO: =====  Training Parameters    =====
2020-06-08T21:50:29 INFO: {
    "batch_size": 32,
    "checkpoint_interval": 1000,
    "clip_gradients": false,
    "clip_norm_mode": "all",
    "dataset_size_proportional_sampling": true,
    "device": "cuda",
    "early_stop": {
        "criteria": "hateful_memes/roc_auc",
        "enabled": false,
        "minimize": false,
        "patience": 4000
    },
    "evaluate_metrics": true,
    "evaluation_interval": 1000,
    "experiment_name": "run",
    "fast_read": false,
    "find_unused_parameters": false,
    "local_rank": null,
    "log_detailed_config": true,
    "log_format": "json",
    "log_interval": 100,
    "logger_level": "info",
    "lr_ratio": 0.1,
    "lr_scheduler": true,
    "lr_steps": [],
    "max_epochs": null,
    "max_updates": 22000,
    "num_workers": 4,
    "pin_memory": false,
    "seed": 29920586,
    "should_not_log": false,
    "tensorboard": true,
    "trainer": "base_trainer",
    "use_warmup": false,
    "verbose_dump": true,
    "warmup_factor": 0.2,
    "warmup_iterations": 1000
}
2020-06-08T21:50:29 INFO: ======  Dataset Attributes  ======
2020-06-08T21:50:29 INFO: ======== hateful_memes =======
2020-06-08T21:50:29 INFO: {
    "annotations": {
        "test": [
            "hateful_memes/defaults/annotations/test.jsonl"
        ],
        "train": [
            "hateful_memes/defaults/annotations/train.jsonl"
        ],
        "val": [
            "hateful_memes/defaults/annotations/dev.jsonl"
        ]
    },
    "data_dir": "/home/jupyter/meme_hateful_detection/data/raw/datasets",
    "depth_first": false,
    "fast_read": false,
    "features": {
        "test": [
            "hateful_memes/defaults/features/detectron.lmdb"
        ],
        "train": [
            "hateful_memes/defaults/features/detectron.lmdb"
        ],
        "val": [
            "hateful_memes/defaults/features/detectron.lmdb"
        ]
    },
    "images": {
        "test": [
            "hateful_memes/defaults/images/"
        ],
        "train": [
            "hateful_memes/defaults/images/"
        ],
        "val": [
            "hateful_memes/defaults/images/"
        ]
    },
    "max_features": 100,
    "processors": {
        "bbox_processor": {
            "params": {
                "max_length": 50
            },
            "type": "bbox"
        },
        "image_processor": {
            "params": {
                "transforms": [
                    {
                        "params": {
                            "size": [
                                256,
                                256
                            ]
                        },
                        "type": "Resize"
                    },
                    {
                        "params": {
                            "size": [
                                224,
                                224
                            ]
                        },
                        "type": "CenterCrop"
                    },
                    "ToTensor",
                    "GrayScaleTo3Channels",
                    {
                        "params": {
                            "mean": [
                                0.46777044,
                                0.44531429,
                                0.40661017
                            ],
                            "std": [
                                0.12221994,
                                0.12145835,
                                0.14380469
                            ]
                        },
                        "type": "Normalize"
                    }
                ]
            },
            "type": "torchvision_transforms"
        },
        "text_processor": {
            "params": {
                "mask_probability": 0,
                "max_length": 14,
                "max_seq_length": 128,
                "preprocessor": {
                    "params": {},
                    "type": "simple_sentence"
                },
                "tokenizer_config": {
                    "params": {
                        "do_lower_case": true
                    },
                    "type": "bert-base-uncased"
                },
                "vocab": {
                    "embedding_name": "glove.6B.300d",
                    "type": "intersected",
                    "vocab_file": "hateful_memes/defaults/extras/vocabs/vocabulary_100k.txt"
                }
            },
            "type": "bert_tokenizer"
        }
    },
    "return_features_info": false,
    "use_features": false,
    "use_images": true
}
2020-06-08T21:50:29 INFO: ======  Optimizer Attributes  ======
2020-06-08T21:50:29 INFO: {
    "params": {
        "eps": 1e-08,
        "lr": 5e-05
    },
    "type": "adam_w"
}
2020-06-08T21:50:29 INFO: ======  Model (late_fusion) Attributes  ======
2020-06-08T21:50:29 INFO: {
    "bert_model_name": "bert-base-uncased",
    "direct_features_input": false,
    "finetune_lr_multiplier": 1,
    "freeze_complete_base": false,
    "freeze_modal": false,
    "freeze_text": false,
    "losses": [
        {
            "type": "cross_entropy"
        }
    ],
    "modal_classifier": {
        "params": {
            "hidden_dim": 768,
            "in_dim": 2048,
            "num_layers": 2,
            "out_dim": 2
        },
        "type": "mlp"
    },
    "modal_encoder": {
        "params": {
            "num_output_features": 1,
            "pool_type": "avg",
            "pretrained": true
        },
        "type": "resnet152"
    },
    "modal_hidden_size": 2048,
    "num_features": 100,
    "num_labels": 2,
    "text_classifier": {
        "params": {
            "hidden_dim": 768,
            "in_dim": 768,
            "num_layers": 2,
            "out_dim": 2
        },
        "type": "mlp"
    },
    "text_encoder": {
        "params": {
            "bert_model_name": "bert-base-uncased",
            "hidden_size": 768,
            "num_attention_heads": 12,
            "num_hidden_layers": 12,
            "output_attentions": false,
            "output_hidden_states": false
        },
        "type": "transformer"
    },
    "text_hidden_size": 768
}
2020-06-08T21:50:29 INFO: Loading datasets
2020-06-08T21:50:40 INFO: CUDA Device 0 is: Tesla T4
2020-06-08T21:50:44 INFO: Torch version is: 1.5.0+cu101
2020-06-08T21:50:44 INFO: Loading checkpoint
2020-06-08T21:50:51 WARNING: /home/jupyter/mmf/mmf/utils/checkpoint.py:224: UserWarning: 'optimizer' key is not present in the checkpoint asked to be loaded. Skipping.
  "'optimizer' key is not present in the "

2020-06-08T21:50:51 INFO: Checkpoint loaded
2020-06-08T21:50:51 INFO: ===== Model =====
2020-06-08T21:50:51 INFO: LateFusion(
  (base): FusionBase(
    (text): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(30522, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
    (modal): ResNet152ImageEncoder(
      (model): Sequential(
        (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
        (4): Sequential(
          (0): Bottleneck(
            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (downsample): Sequential(
              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): Bottleneck(
            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (2): Bottleneck(
            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
        (5): Sequential(
          (0): Bottleneck(
            (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (downsample): Sequential(
              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): Bottleneck(
            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (2): Bottleneck(
            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (3): Bottleneck(
            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (4): Bottleneck(
            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (5): Bottleneck(
            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (6): Bottleneck(
            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (7): Bottleneck(
            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
        (6): Sequential(
          (0): Bottleneck(
            (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (downsample): Sequential(
              (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (2): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (3): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (4): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (5): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (6): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (7): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (8): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (9): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (10): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (11): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (12): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (13): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (14): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (15): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (16): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (17): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (18): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (19): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (20): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (21): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (22): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (23): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (24): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (25): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (26): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (27): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (28): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (29): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (30): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (31): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (32): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (33): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (34): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (35): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
        (7): Sequential(
          (0): Bottleneck(
            (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (downsample): Sequential(
              (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
              (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): Bottleneck(
            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (2): Bottleneck(
            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
      )
      (pool): AdaptiveAvgPool2d(output_size=(1, 1))
    )
  )
  (modal_classifier): MLPClassifer(
    (layers): ModuleList(
      (0): Linear(in_features=2048, out_features=768, bias=True)
      (1): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.5, inplace=False)
      (4): Linear(in_features=768, out_features=768, bias=True)
      (5): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Dropout(p=0.5, inplace=False)
      (8): Linear(in_features=768, out_features=2, bias=True)
    )
  )
  (text_classifier): MLPClassifer(
    (layers): ModuleList(
      (0): Linear(in_features=768, out_features=768, bias=True)
      (1): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.5, inplace=False)
      (4): Linear(in_features=768, out_features=768, bias=True)
      (5): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Dropout(p=0.5, inplace=False)
      (8): Linear(in_features=768, out_features=2, bias=True)
    )
  )
  (losses): Losses()
)
2020-06-08T21:50:51 INFO: Total Parameters: 170980676. Trained Parameters: 170980676
2020-06-08T21:50:51 INFO: Starting training...
2020-06-08T21:50:54 WARNING: /pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha)

2020-06-08T21:50:54 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T21:53:55 INFO: {"progress": "100/22000", "train/total_loss": "0.0965", "train/total_loss/avg": "0.0965", "train/hateful_memes/cross_entropy": "0.0965", "train/hateful_memes/cross_entropy/avg": "0.0965", "train/hateful_memes/accuracy": "0.9688", "train/hateful_memes/accuracy/avg": "0.9688", "train/hateful_memes/binary_f1": "0.9677", "train/hateful_memes/binary_f1/avg": "0.9677", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "1.0000", "max mem": 12643.0, "experiment": "run", "epoch": 1, "num_updates": 100, "iterations": 100, "max_updates": 22000, "lr": "0.", "ups": "0.55", "time": "03m 03s 645ms", "time_since_start": "03m 25s 548ms", "eta": "11h 10m 18s 459ms"}
2020-06-08T21:53:57 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T21:57:01 INFO: {"progress": "200/22000", "train/total_loss": "0.0504", "train/total_loss/avg": "0.0735", "train/hateful_memes/cross_entropy": "0.0504", "train/hateful_memes/cross_entropy/avg": "0.0735", "train/hateful_memes/accuracy": "0.9688", "train/hateful_memes/accuracy/avg": "0.9844", "train/hateful_memes/binary_f1": "0.9677", "train/hateful_memes/binary_f1/avg": "0.9839", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "1.0000", "max mem": 12643.0, "experiment": "run", "epoch": 1, "num_updates": 200, "iterations": 200, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 086ms", "time_since_start": "06m 31s 634ms", "eta": "11h 16m 06s 874ms"}
2020-06-08T21:57:03 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T22:00:07 INFO: {"progress": "300/22000", "train/total_loss": "0.0504", "train/total_loss/avg": "0.0567", "train/hateful_memes/cross_entropy": "0.0504", "train/hateful_memes/cross_entropy/avg": "0.0567", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9896", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9892", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "1.0000", "max mem": 12643.0, "experiment": "run", "epoch": 2, "num_updates": 300, "iterations": 300, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 110ms", "time_since_start": "09m 37s 745ms", "eta": "11h 13m 06s 025ms"}
2020-06-08T22:00:09 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T22:03:13 INFO: {"progress": "400/22000", "train/total_loss": "0.0504", "train/total_loss/avg": "0.0589", "train/hateful_memes/cross_entropy": "0.0504", "train/hateful_memes/cross_entropy/avg": "0.0589", "train/hateful_memes/accuracy": "0.9688", "train/hateful_memes/accuracy/avg": "0.9844", "train/hateful_memes/binary_f1": "0.9677", "train/hateful_memes/binary_f1/avg": "0.9788", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "1.0000", "max mem": 12643.0, "experiment": "run", "epoch": 2, "num_updates": 400, "iterations": 400, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 05s 959ms", "time_since_start": "12m 43s 704ms", "eta": "11h 09m 27s 153ms"}
2020-06-08T22:03:15 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T22:06:19 INFO: {"progress": "500/22000", "train/total_loss": "0.0504", "train/total_loss/avg": "0.0550", "train/hateful_memes/cross_entropy": "0.0504", "train/hateful_memes/cross_entropy/avg": "0.0550", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9875", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9830", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "1.0000", "max mem": 12643.0, "experiment": "run", "epoch": 2, "num_updates": 500, "iterations": 500, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 05s 615ms", "time_since_start": "15m 49s 320ms", "eta": "11h 05m 07s 348ms"}
2020-06-08T22:06:21 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T22:09:25 INFO: {"progress": "600/22000", "train/total_loss": "0.0392", "train/total_loss/avg": "0.0501", "train/hateful_memes/cross_entropy": "0.0392", "train/hateful_memes/cross_entropy/avg": "0.0501", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9896", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9859", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "1.0000", "max mem": 12643.0, "experiment": "run", "epoch": 3, "num_updates": 600, "iterations": 600, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 131ms", "time_since_start": "18m 55s 451ms", "eta": "11h 03m 52s 112ms"}
2020-06-08T22:09:27 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T22:12:31 INFO: {"progress": "700/22000", "train/total_loss": "0.0392", "train/total_loss/avg": "0.0459", "train/hateful_memes/cross_entropy": "0.0392", "train/hateful_memes/cross_entropy/avg": "0.0459", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9911", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9879", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "1.0000", "max mem": 12643.0, "experiment": "run", "epoch": 3, "num_updates": 700, "iterations": 700, "max_updates": 22000, "lr": "0.00002", "ups": "0.54", "time": "03m 05s 794ms", "time_since_start": "22m 01s 246ms", "eta": "10h 59m 34s 274ms"}
2020-06-08T22:12:32 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T22:15:36 INFO: {"progress": "800/22000", "train/total_loss": "0.0279", "train/total_loss/avg": "0.0437", "train/hateful_memes/cross_entropy": "0.0279", "train/hateful_memes/cross_entropy/avg": "0.0437", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9922", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9894", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "1.0000", "max mem": 12643.0, "experiment": "run", "epoch": 4, "num_updates": 800, "iterations": 800, "max_updates": 22000, "lr": "0.00002", "ups": "0.54", "time": "03m 05s 854ms", "time_since_start": "25m 07s 100ms", "eta": "10h 56m 41s 132ms"}
2020-06-08T22:15:38 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T22:18:42 INFO: {"progress": "900/22000", "train/total_loss": "0.0392", "train/total_loss/avg": "0.0440", "train/hateful_memes/cross_entropy": "0.0392", "train/hateful_memes/cross_entropy/avg": "0.0440", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9896", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9865", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "1.0000", "max mem": 12643.0, "experiment": "run", "epoch": 4, "num_updates": 900, "iterations": 900, "max_updates": 22000, "lr": "0.00002", "ups": "0.54", "time": "03m 05s 619ms", "time_since_start": "28m 12s 720ms", "eta": "10h 52m 45s 740ms"}
2020-06-08T22:18:44 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T22:21:48 INFO: {"progress": "1000/22000", "train/total_loss": "0.0392", "train/total_loss/avg": "0.0460", "train/hateful_memes/cross_entropy": "0.0392", "train/hateful_memes/cross_entropy/avg": "0.0460", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9875", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9835", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "1.0000", "max mem": 12643.0, "experiment": "run", "epoch": 4, "num_updates": 1000, "iterations": 1000, "max_updates": 22000, "lr": "0.00002", "ups": "0.54", "time": "03m 05s 617ms", "time_since_start": "31m 18s 338ms", "eta": "10h 49m 39s 691ms"}
2020-06-08T22:21:48 INFO: Checkpoint time. Saving a checkpoint.
2020-06-08T22:21:52 INFO: Evaluation time. Running on full validation set...
2020-06-08T22:22:50 INFO: {"progress": "1000/22000", "val/total_loss": "2.3707", "val/hateful_memes/cross_entropy": "2.3707", "val/hateful_memes/accuracy": "0.5720", "val/hateful_memes/binary_f1": "0.3743", "val/hateful_memes/roc_auc": "0.6221", "num_updates": 1000, "epoch": 4, "iterations": 1000, "max_updates": 22000, "val_time": "10s 966ms", "best_update": 1000, "best_iteration": 1000, "best_val/hateful_memes/roc_auc": "0.622120"}
2020-06-08T22:22:52 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T22:25:57 INFO: {"progress": "1100/22000", "train/total_loss": "0.0392", "train/total_loss/avg": "0.0446", "train/hateful_memes/cross_entropy": "0.0392", "train/hateful_memes/cross_entropy/avg": "0.0446", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9886", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9850", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "1.0000", "max mem": 12643.0, "experiment": "run", "epoch": 5, "num_updates": 1100, "iterations": 1100, "max_updates": 22000, "lr": "0.00003", "ups": "0.54", "time": "03m 06s 499ms", "time_since_start": "35m 27s 538ms", "eta": "10h 49m 38s 364ms"}
2020-06-08T22:25:59 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T22:29:02 INFO: {"progress": "1200/22000", "train/total_loss": "0.0392", "train/total_loss/avg": "0.0442", "train/hateful_memes/cross_entropy": "0.0392", "train/hateful_memes/cross_entropy/avg": "0.0442", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9896", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9862", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "1.0000", "max mem": 12643.0, "experiment": "run", "epoch": 5, "num_updates": 1200, "iterations": 1200, "max_updates": 22000, "lr": "0.00003", "ups": "0.54", "time": "03m 05s 581ms", "time_since_start": "38m 33s 119ms", "eta": "10h 43m 20s 918ms"}
2020-06-08T22:29:04 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T22:32:08 INFO: {"progress": "1300/22000", "train/total_loss": "0.0400", "train/total_loss/avg": "0.0527", "train/hateful_memes/cross_entropy": "0.0400", "train/hateful_memes/cross_entropy/avg": "0.0527", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9856", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9803", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9990", "max mem": 12643.0, "experiment": "run", "epoch": 5, "num_updates": 1300, "iterations": 1300, "max_updates": 22000, "lr": "0.00003", "ups": "0.54", "time": "03m 05s 718ms", "time_since_start": "41m 38s 838ms", "eta": "10h 40m 43s 738ms"}
2020-06-08T22:32:10 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T22:35:14 INFO: {"progress": "1400/22000", "train/total_loss": "0.0400", "train/total_loss/avg": "0.0585", "train/hateful_memes/cross_entropy": "0.0400", "train/hateful_memes/cross_entropy/avg": "0.0585", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9821", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9766", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9991", "max mem": 12643.0, "experiment": "run", "epoch": 6, "num_updates": 1400, "iterations": 1400, "max_updates": 22000, "lr": "0.00003", "ups": "0.54", "time": "03m 06s 091ms", "time_since_start": "44m 44s 930ms", "eta": "10h 38m 54s 901ms"}
2020-06-08T22:35:16 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T22:38:20 INFO: {"progress": "1500/22000", "train/total_loss": "0.0462", "train/total_loss/avg": "0.0588", "train/hateful_memes/cross_entropy": "0.0462", "train/hateful_memes/cross_entropy/avg": "0.0588", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9812", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9746", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9991", "max mem": 12643.0, "experiment": "run", "epoch": 6, "num_updates": 1500, "iterations": 1500, "max_updates": 22000, "lr": "0.00004", "ups": "0.54", "time": "03m 05s 853ms", "time_since_start": "47m 50s 783ms", "eta": "10h 34m 59s 917ms"}
2020-06-08T22:38:22 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T22:41:26 INFO: {"progress": "1600/22000", "train/total_loss": "0.0462", "train/total_loss/avg": "0.0697", "train/hateful_memes/cross_entropy": "0.0462", "train/hateful_memes/cross_entropy/avg": "0.0697", "train/hateful_memes/accuracy": "0.9688", "train/hateful_memes/accuracy/avg": "0.9746", "train/hateful_memes/binary_f1": "0.9677", "train/hateful_memes/binary_f1/avg": "0.9554", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9992", "max mem": 12643.0, "experiment": "run", "epoch": 7, "num_updates": 1600, "iterations": 1600, "max_updates": 22000, "lr": "0.00004", "ups": "0.54", "time": "03m 05s 957ms", "time_since_start": "50m 56s 741ms", "eta": "10h 32m 15s 413ms"}
2020-06-08T22:41:28 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T22:44:32 INFO: {"progress": "1700/22000", "train/total_loss": "0.0504", "train/total_loss/avg": "0.0696", "train/hateful_memes/cross_entropy": "0.0504", "train/hateful_memes/cross_entropy/avg": "0.0696", "train/hateful_memes/accuracy": "0.9688", "train/hateful_memes/accuracy/avg": "0.9743", "train/hateful_memes/binary_f1": "0.9677", "train/hateful_memes/binary_f1/avg": "0.9549", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9992", "max mem": 12643.0, "experiment": "run", "epoch": 7, "num_updates": 1700, "iterations": 1700, "max_updates": 22000, "lr": "0.00004", "ups": "0.54", "time": "03m 05s 924ms", "time_since_start": "54m 02s 665ms", "eta": "10h 29m 02s 592ms"}
2020-06-08T22:44:34 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T22:47:38 INFO: {"progress": "1800/22000", "train/total_loss": "0.0504", "train/total_loss/avg": "0.0700", "train/hateful_memes/cross_entropy": "0.0504", "train/hateful_memes/cross_entropy/avg": "0.0700", "train/hateful_memes/accuracy": "0.9688", "train/hateful_memes/accuracy/avg": "0.9740", "train/hateful_memes/binary_f1": "0.9630", "train/hateful_memes/binary_f1/avg": "0.9550", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9993", "max mem": 12643.0, "experiment": "run", "epoch": 7, "num_updates": 1800, "iterations": 1800, "max_updates": 22000, "lr": "0.00004", "ups": "0.54", "time": "03m 05s 620ms", "time_since_start": "57m 08s 285ms", "eta": "10h 24m 55s 339ms"}
2020-06-08T22:47:40 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T22:50:44 INFO: {"progress": "1900/22000", "train/total_loss": "0.0504", "train/total_loss/avg": "0.0679", "train/hateful_memes/cross_entropy": "0.0504", "train/hateful_memes/cross_entropy/avg": "0.0679", "train/hateful_memes/accuracy": "0.9688", "train/hateful_memes/accuracy/avg": "0.9753", "train/hateful_memes/binary_f1": "0.9677", "train/hateful_memes/binary_f1/avg": "0.9574", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9993", "max mem": 12643.0, "experiment": "run", "epoch": 8, "num_updates": 1900, "iterations": 1900, "max_updates": 22000, "lr": "0.00005", "ups": "0.54", "time": "03m 05s 888ms", "time_since_start": "01h 14s 174ms", "eta": "10h 22m 43s 512ms"}
2020-06-08T22:50:45 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T22:53:49 INFO: {"progress": "2000/22000", "train/total_loss": "0.0462", "train/total_loss/avg": "0.0662", "train/hateful_memes/cross_entropy": "0.0462", "train/hateful_memes/cross_entropy/avg": "0.0662", "train/hateful_memes/accuracy": "0.9688", "train/hateful_memes/accuracy/avg": "0.9766", "train/hateful_memes/binary_f1": "0.9677", "train/hateful_memes/binary_f1/avg": "0.9595", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9994", "max mem": 12643.0, "experiment": "run", "epoch": 8, "num_updates": 2000, "iterations": 2000, "max_updates": 22000, "lr": "0.00005", "ups": "0.54", "time": "03m 05s 741ms", "time_since_start": "01h 03m 19s 915ms", "eta": "10h 19m 08s 231ms"}
2020-06-08T22:53:49 INFO: Checkpoint time. Saving a checkpoint.
2020-06-08T22:54:10 INFO: Evaluation time. Running on full validation set...
2020-06-08T22:55:24 INFO: {"progress": "2000/22000", "val/total_loss": "1.8659", "val/hateful_memes/cross_entropy": "1.8659", "val/hateful_memes/accuracy": "0.6000", "val/hateful_memes/binary_f1": "0.4949", "val/hateful_memes/roc_auc": "0.6397", "num_updates": 2000, "epoch": 8, "iterations": 2000, "max_updates": 22000, "val_time": "22s 786ms", "best_update": 2000, "best_iteration": 2000, "best_val/hateful_memes/roc_auc": "0.639708"}
2020-06-08T22:55:26 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T22:58:31 INFO: {"progress": "2100/22000", "train/total_loss": "0.0405", "train/total_loss/avg": "0.0650", "train/hateful_memes/cross_entropy": "0.0405", "train/hateful_memes/cross_entropy/avg": "0.0650", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9777", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9614", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9994", "max mem": 12643.0, "experiment": "run", "epoch": 8, "num_updates": 2100, "iterations": 2100, "max_updates": 22000, "lr": "0.00005", "ups": "0.54", "time": "03m 06s 332ms", "time_since_start": "01h 08m 01s 547ms", "eta": "10h 18m 227ms"}
2020-06-08T22:58:33 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T23:01:37 INFO: {"progress": "2200/22000", "train/total_loss": "0.0400", "train/total_loss/avg": "0.0633", "train/hateful_memes/cross_entropy": "0.0400", "train/hateful_memes/cross_entropy/avg": "0.0633", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9787", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9632", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9994", "max mem": 12643.0, "experiment": "run", "epoch": 9, "num_updates": 2200, "iterations": 2200, "max_updates": 22000, "lr": "0.00005", "ups": "0.54", "time": "03m 06s 008ms", "time_since_start": "01h 11m 07s 556ms", "eta": "10h 13m 49s 758ms"}
2020-06-08T23:01:39 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T23:04:43 INFO: {"progress": "2300/22000", "train/total_loss": "0.0405", "train/total_loss/avg": "0.0651", "train/hateful_memes/cross_entropy": "0.0405", "train/hateful_memes/cross_entropy/avg": "0.0651", "train/hateful_memes/accuracy": "0.9688", "train/hateful_memes/accuracy/avg": "0.9783", "train/hateful_memes/binary_f1": "0.9630", "train/hateful_memes/binary_f1/avg": "0.9629", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9989", "max mem": 12643.0, "experiment": "run", "epoch": 9, "num_updates": 2300, "iterations": 2300, "max_updates": 22000, "lr": "0.00005", "ups": "0.54", "time": "03m 05s 767ms", "time_since_start": "01h 14m 13s 324ms", "eta": "10h 09m 56s 178ms"}
2020-06-08T23:04:45 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T23:07:49 INFO: {"progress": "2400/22000", "train/total_loss": "0.0405", "train/total_loss/avg": "0.0646", "train/hateful_memes/cross_entropy": "0.0405", "train/hateful_memes/cross_entropy/avg": "0.0646", "train/hateful_memes/accuracy": "0.9688", "train/hateful_memes/accuracy/avg": "0.9779", "train/hateful_memes/binary_f1": "0.9677", "train/hateful_memes/binary_f1/avg": "0.9631", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9989", "max mem": 12643.0, "experiment": "run", "epoch": 10, "num_updates": 2400, "iterations": 2400, "max_updates": 22000, "lr": "0.00005", "ups": "0.54", "time": "03m 05s 918ms", "time_since_start": "01h 17m 19s 242ms", "eta": "10h 07m 20s 029ms"}
2020-06-08T23:07:50 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T23:10:55 INFO: {"progress": "2500/22000", "train/total_loss": "0.0462", "train/total_loss/avg": "0.0659", "train/hateful_memes/cross_entropy": "0.0462", "train/hateful_memes/cross_entropy/avg": "0.0659", "train/hateful_memes/accuracy": "0.9688", "train/hateful_memes/accuracy/avg": "0.9775", "train/hateful_memes/binary_f1": "0.9630", "train/hateful_memes/binary_f1/avg": "0.9627", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9990", "max mem": 12643.0, "experiment": "run", "epoch": 10, "num_updates": 2500, "iterations": 2500, "max_updates": 22000, "lr": "0.00005", "ups": "0.54", "time": "03m 06s 144ms", "time_since_start": "01h 20m 25s 386ms", "eta": "10h 04m 58s 109ms"}
2020-06-08T23:10:57 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T23:14:01 INFO: {"progress": "2600/22000", "train/total_loss": "0.0462", "train/total_loss/avg": "0.0648", "train/hateful_memes/cross_entropy": "0.0462", "train/hateful_memes/cross_entropy/avg": "0.0648", "train/hateful_memes/accuracy": "0.9688", "train/hateful_memes/accuracy/avg": "0.9772", "train/hateful_memes/binary_f1": "0.9565", "train/hateful_memes/binary_f1/avg": "0.9624", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9990", "max mem": 12643.0, "experiment": "run", "epoch": 10, "num_updates": 2600, "iterations": 2600, "max_updates": 22000, "lr": "0.00005", "ups": "0.54", "time": "03m 05s 887ms", "time_since_start": "01h 23m 31s 274ms", "eta": "10h 01m 02s 203ms"}
2020-06-08T23:14:03 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T23:17:07 INFO: {"progress": "2700/22000", "train/total_loss": "0.0533", "train/total_loss/avg": "0.0665", "train/hateful_memes/cross_entropy": "0.0533", "train/hateful_memes/cross_entropy/avg": "0.0665", "train/hateful_memes/accuracy": "0.9688", "train/hateful_memes/accuracy/avg": "0.9769", "train/hateful_memes/binary_f1": "0.9565", "train/hateful_memes/binary_f1/avg": "0.9619", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9991", "max mem": 12643.0, "experiment": "run", "epoch": 11, "num_updates": 2700, "iterations": 2700, "max_updates": 22000, "lr": "0.00005", "ups": "0.54", "time": "03m 05s 967ms", "time_since_start": "01h 26m 37s 241ms", "eta": "09h 58m 11s 729ms"}
2020-06-08T23:17:08 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T23:20:13 INFO: {"progress": "2800/22000", "train/total_loss": "0.0632", "train/total_loss/avg": "0.0752", "train/hateful_memes/cross_entropy": "0.0632", "train/hateful_memes/cross_entropy/avg": "0.0752", "train/hateful_memes/accuracy": "0.9688", "train/hateful_memes/accuracy/avg": "0.9732", "train/hateful_memes/binary_f1": "0.9565", "train/hateful_memes/binary_f1/avg": "0.9543", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9989", "max mem": 12643.0, "experiment": "run", "epoch": 11, "num_updates": 2800, "iterations": 2800, "max_updates": 22000, "lr": "0.00005", "ups": "0.54", "time": "03m 05s 951ms", "time_since_start": "01h 29m 43s 193ms", "eta": "09h 55m 02s 783ms"}
2020-06-08T23:20:14 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T23:23:18 INFO: {"progress": "2900/22000", "train/total_loss": "0.0632", "train/total_loss/avg": "0.0734", "train/hateful_memes/cross_entropy": "0.0632", "train/hateful_memes/cross_entropy/avg": "0.0734", "train/hateful_memes/accuracy": "0.9688", "train/hateful_memes/accuracy/avg": "0.9741", "train/hateful_memes/binary_f1": "0.9565", "train/hateful_memes/binary_f1/avg": "0.9559", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9989", "max mem": 12643.0, "experiment": "run", "epoch": 11, "num_updates": 2900, "iterations": 2900, "max_updates": 22000, "lr": "0.00005", "ups": "0.54", "time": "03m 05s 860ms", "time_since_start": "01h 32m 49s 054ms", "eta": "09h 51m 39s 383ms"}
2020-06-08T23:23:20 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T23:26:24 INFO: {"progress": "3000/22000", "train/total_loss": "0.0533", "train/total_loss/avg": "0.0716", "train/hateful_memes/cross_entropy": "0.0533", "train/hateful_memes/cross_entropy/avg": "0.0716", "train/hateful_memes/accuracy": "0.9688", "train/hateful_memes/accuracy/avg": "0.9750", "train/hateful_memes/binary_f1": "0.9565", "train/hateful_memes/binary_f1/avg": "0.9574", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9989", "max mem": 12643.0, "experiment": "run", "epoch": 12, "num_updates": 3000, "iterations": 3000, "max_updates": 22000, "lr": "0.00005", "ups": "0.54", "time": "03m 05s 762ms", "time_since_start": "01h 35m 54s 816ms", "eta": "09h 48m 14s 836ms"}
2020-06-08T23:26:24 INFO: Checkpoint time. Saving a checkpoint.
2020-06-08T23:26:44 INFO: Evaluation time. Running on full validation set...
2020-06-08T23:27:34 INFO: {"progress": "3000/22000", "val/total_loss": "2.1830", "val/hateful_memes/cross_entropy": "2.1830", "val/hateful_memes/accuracy": "0.5800", "val/hateful_memes/binary_f1": "0.4776", "val/hateful_memes/roc_auc": "0.6189", "num_updates": 3000, "epoch": 12, "iterations": 3000, "max_updates": 22000, "val_time": "08s 859ms", "best_update": 2000, "best_iteration": 2000, "best_val/hateful_memes/roc_auc": "0.639708"}
2020-06-08T23:27:36 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T23:30:41 INFO: {"progress": "3100/22000", "train/total_loss": "0.0533", "train/total_loss/avg": "0.0708", "train/hateful_memes/cross_entropy": "0.0533", "train/hateful_memes/cross_entropy/avg": "0.0708", "train/hateful_memes/accuracy": "0.9688", "train/hateful_memes/accuracy/avg": "0.9748", "train/hateful_memes/binary_f1": "0.9565", "train/hateful_memes/binary_f1/avg": "0.9572", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9990", "max mem": 12643.0, "experiment": "run", "epoch": 12, "num_updates": 3100, "iterations": 3100, "max_updates": 22000, "lr": "0.00005", "ups": "0.54", "time": "03m 06s 084ms", "time_since_start": "01h 40m 11s 150ms", "eta": "09h 46m 10s 058ms"}
2020-06-08T23:30:42 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T23:33:47 INFO: {"progress": "3200/22000", "train/total_loss": "0.0533", "train/total_loss/avg": "0.0692", "train/hateful_memes/cross_entropy": "0.0533", "train/hateful_memes/cross_entropy/avg": "0.0692", "train/hateful_memes/accuracy": "0.9688", "train/hateful_memes/accuracy/avg": "0.9756", "train/hateful_memes/binary_f1": "0.9565", "train/hateful_memes/binary_f1/avg": "0.9585", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9990", "max mem": 12643.0, "experiment": "run", "epoch": 13, "num_updates": 3200, "iterations": 3200, "max_updates": 22000, "lr": "0.00005", "ups": "0.54", "time": "03m 06s 031ms", "time_since_start": "01h 43m 17s 182ms", "eta": "09h 42m 53s 970ms"}
2020-06-08T23:33:48 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T23:36:52 INFO: {"progress": "3300/22000", "train/total_loss": "0.0481", "train/total_loss/avg": "0.0681", "train/hateful_memes/cross_entropy": "0.0481", "train/hateful_memes/cross_entropy/avg": "0.0681", "train/hateful_memes/accuracy": "0.9688", "train/hateful_memes/accuracy/avg": "0.9763", "train/hateful_memes/binary_f1": "0.9565", "train/hateful_memes/binary_f1/avg": "0.9598", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9990", "max mem": 12643.0, "experiment": "run", "epoch": 13, "num_updates": 3300, "iterations": 3300, "max_updates": 22000, "lr": "0.00005", "ups": "0.54", "time": "03m 05s 766ms", "time_since_start": "01h 46m 22s 949ms", "eta": "09h 38m 58s 365ms"}
2020-06-08T23:36:54 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T23:39:58 INFO: {"progress": "3400/22000", "train/total_loss": "0.0405", "train/total_loss/avg": "0.0666", "train/hateful_memes/cross_entropy": "0.0405", "train/hateful_memes/cross_entropy/avg": "0.0666", "train/hateful_memes/accuracy": "0.9688", "train/hateful_memes/accuracy/avg": "0.9770", "train/hateful_memes/binary_f1": "0.9565", "train/hateful_memes/binary_f1/avg": "0.9610", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9991", "max mem": 12643.0, "experiment": "run", "epoch": 13, "num_updates": 3400, "iterations": 3400, "max_updates": 22000, "lr": "0.00005", "ups": "0.54", "time": "03m 05s 631ms", "time_since_start": "01h 49m 28s 580ms", "eta": "09h 35m 27s 429ms"}
2020-06-08T23:40:00 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T23:43:04 INFO: {"progress": "3500/22000", "train/total_loss": "0.0378", "train/total_loss/avg": "0.0657", "train/hateful_memes/cross_entropy": "0.0378", "train/hateful_memes/cross_entropy/avg": "0.0657", "train/hateful_memes/accuracy": "0.9688", "train/hateful_memes/accuracy/avg": "0.9768", "train/hateful_memes/binary_f1": "0.9565", "train/hateful_memes/binary_f1/avg": "0.9608", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9991", "max mem": 12643.0, "experiment": "run", "epoch": 14, "num_updates": 3500, "iterations": 3500, "max_updates": 22000, "lr": "0.00005", "ups": "0.54", "time": "03m 05s 947ms", "time_since_start": "01h 52m 34s 528ms", "eta": "09h 33m 20s 333ms"}
2020-06-08T23:43:06 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T23:46:10 INFO: {"progress": "3600/22000", "train/total_loss": "0.0378", "train/total_loss/avg": "0.0655", "train/hateful_memes/cross_entropy": "0.0378", "train/hateful_memes/cross_entropy/avg": "0.0655", "train/hateful_memes/accuracy": "0.9688", "train/hateful_memes/accuracy/avg": "0.9766", "train/hateful_memes/binary_f1": "0.9630", "train/hateful_memes/binary_f1/avg": "0.9609", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9991", "max mem": 12643.0, "experiment": "run", "epoch": 14, "num_updates": 3600, "iterations": 3600, "max_updates": 22000, "lr": "0.00005", "ups": "0.54", "time": "03m 05s 759ms", "time_since_start": "01h 55m 40s 287ms", "eta": "09h 29m 39s 733ms"}
2020-06-08T23:46:12 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T23:49:16 INFO: {"progress": "3700/22000", "train/total_loss": "0.0378", "train/total_loss/avg": "0.0657", "train/hateful_memes/cross_entropy": "0.0378", "train/hateful_memes/cross_entropy/avg": "0.0657", "train/hateful_memes/accuracy": "0.9688", "train/hateful_memes/accuracy/avg": "0.9764", "train/hateful_memes/binary_f1": "0.9630", "train/hateful_memes/binary_f1/avg": "0.9609", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9990", "max mem": 12643.0, "experiment": "run", "epoch": 14, "num_updates": 3700, "iterations": 3700, "max_updates": 22000, "lr": "0.00005", "ups": "0.54", "time": "03m 05s 855ms", "time_since_start": "01h 58m 46s 143ms", "eta": "09h 26m 51s 581ms"}
2020-06-08T23:49:17 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T23:52:21 INFO: {"progress": "3800/22000", "train/total_loss": "0.0358", "train/total_loss/avg": "0.0643", "train/hateful_memes/cross_entropy": "0.0358", "train/hateful_memes/cross_entropy/avg": "0.0643", "train/hateful_memes/accuracy": "0.9688", "train/hateful_memes/accuracy/avg": "0.9770", "train/hateful_memes/binary_f1": "0.9677", "train/hateful_memes/binary_f1/avg": "0.9619", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9991", "max mem": 12643.0, "experiment": "run", "epoch": 15, "num_updates": 3800, "iterations": 3800, "max_updates": 22000, "lr": "0.00005", "ups": "0.54", "time": "03m 05s 970ms", "time_since_start": "02h 01m 52s 113ms", "eta": "09h 24m 06s 614ms"}
2020-06-08T23:52:23 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T23:55:27 INFO: {"progress": "3900/22000", "train/total_loss": "0.0358", "train/total_loss/avg": "0.0629", "train/hateful_memes/cross_entropy": "0.0358", "train/hateful_memes/cross_entropy/avg": "0.0629", "train/hateful_memes/accuracy": "0.9688", "train/hateful_memes/accuracy/avg": "0.9776", "train/hateful_memes/binary_f1": "0.9677", "train/hateful_memes/binary_f1/avg": "0.9629", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9991", "max mem": 12643.0, "experiment": "run", "epoch": 15, "num_updates": 3900, "iterations": 3900, "max_updates": 22000, "lr": "0.00005", "ups": "0.54", "time": "03m 05s 600ms", "time_since_start": "02h 04m 57s 714ms", "eta": "09h 19m 53s 778ms"}
2020-06-08T23:55:29 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-08T23:58:33 INFO: {"progress": "4000/22000", "train/total_loss": "0.0358", "train/total_loss/avg": "0.0615", "train/hateful_memes/cross_entropy": "0.0358", "train/hateful_memes/cross_entropy/avg": "0.0615", "train/hateful_memes/accuracy": "0.9688", "train/hateful_memes/accuracy/avg": "0.9781", "train/hateful_memes/binary_f1": "0.9677", "train/hateful_memes/binary_f1/avg": "0.9638", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9991", "max mem": 12643.0, "experiment": "run", "epoch": 16, "num_updates": 4000, "iterations": 4000, "max_updates": 22000, "lr": "0.00005", "ups": "0.54", "time": "03m 06s 199ms", "time_since_start": "02h 08m 03s 913ms", "eta": "09h 18m 35s 829ms"}
2020-06-08T23:58:33 INFO: Checkpoint time. Saving a checkpoint.
2020-06-08T23:58:53 INFO: Evaluation time. Running on full validation set...
2020-06-09T00:00:02 INFO: {"progress": "4000/22000", "val/total_loss": "2.4207", "val/hateful_memes/cross_entropy": "2.4207", "val/hateful_memes/accuracy": "0.5860", "val/hateful_memes/binary_f1": "0.4298", "val/hateful_memes/roc_auc": "0.6488", "num_updates": 4000, "epoch": 16, "iterations": 4000, "max_updates": 22000, "val_time": "08s 832ms", "best_update": 4000, "best_iteration": 4000, "best_val/hateful_memes/roc_auc": "0.648812"}
2020-06-09T00:00:05 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T00:03:09 INFO: {"progress": "4100/22000", "train/total_loss": "0.0358", "train/total_loss/avg": "0.0637", "train/hateful_memes/cross_entropy": "0.0358", "train/hateful_memes/cross_entropy/avg": "0.0637", "train/hateful_memes/accuracy": "0.9688", "train/hateful_memes/accuracy/avg": "0.9771", "train/hateful_memes/binary_f1": "0.9630", "train/hateful_memes/binary_f1/avg": "0.9612", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9991", "max mem": 12643.0, "experiment": "run", "epoch": 16, "num_updates": 4100, "iterations": 4100, "max_updates": 22000, "lr": "0.00004", "ups": "0.54", "time": "03m 06s 216ms", "time_since_start": "02h 12m 39s 560ms", "eta": "09h 15m 32s 744ms"}
2020-06-09T00:03:11 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T00:06:15 INFO: {"progress": "4200/22000", "train/total_loss": "0.0378", "train/total_loss/avg": "0.0632", "train/hateful_memes/cross_entropy": "0.0378", "train/hateful_memes/cross_entropy/avg": "0.0632", "train/hateful_memes/accuracy": "0.9688", "train/hateful_memes/accuracy/avg": "0.9777", "train/hateful_memes/binary_f1": "0.9630", "train/hateful_memes/binary_f1/avg": "0.9621", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9991", "max mem": 12643.0, "experiment": "run", "epoch": 16, "num_updates": 4200, "iterations": 4200, "max_updates": 22000, "lr": "0.00004", "ups": "0.54", "time": "03m 05s 976ms", "time_since_start": "02h 15m 45s 537ms", "eta": "09h 11m 43s 764ms"}
2020-06-09T00:06:17 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T00:09:21 INFO: {"progress": "4300/22000", "train/total_loss": "0.0378", "train/total_loss/avg": "0.0637", "train/hateful_memes/cross_entropy": "0.0378", "train/hateful_memes/cross_entropy/avg": "0.0637", "train/hateful_memes/accuracy": "0.9688", "train/hateful_memes/accuracy/avg": "0.9775", "train/hateful_memes/binary_f1": "0.9630", "train/hateful_memes/binary_f1/avg": "0.9619", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9991", "max mem": 12643.0, "experiment": "run", "epoch": 17, "num_updates": 4300, "iterations": 4300, "max_updates": 22000, "lr": "0.00004", "ups": "0.54", "time": "03m 05s 921ms", "time_since_start": "02h 18m 51s 458ms", "eta": "09h 08m 28s 053ms"}
2020-06-09T00:09:23 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T00:12:27 INFO: {"progress": "4400/22000", "train/total_loss": "0.0358", "train/total_loss/avg": "0.0624", "train/hateful_memes/cross_entropy": "0.0358", "train/hateful_memes/cross_entropy/avg": "0.0624", "train/hateful_memes/accuracy": "0.9688", "train/hateful_memes/accuracy/avg": "0.9780", "train/hateful_memes/binary_f1": "0.9630", "train/hateful_memes/binary_f1/avg": "0.9628", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9991", "max mem": 12643.0, "experiment": "run", "epoch": 17, "num_updates": 4400, "iterations": 4400, "max_updates": 22000, "lr": "0.00004", "ups": "0.54", "time": "03m 05s 819ms", "time_since_start": "02h 21m 57s 277ms", "eta": "09h 05m 04s 159ms"}
2020-06-09T00:12:29 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T00:15:32 INFO: {"progress": "4500/22000", "train/total_loss": "0.0358", "train/total_loss/avg": "0.0619", "train/hateful_memes/cross_entropy": "0.0358", "train/hateful_memes/cross_entropy/avg": "0.0619", "train/hateful_memes/accuracy": "0.9688", "train/hateful_memes/accuracy/avg": "0.9778", "train/hateful_memes/binary_f1": "0.9630", "train/hateful_memes/binary_f1/avg": "0.9628", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9991", "max mem": 12643.0, "experiment": "run", "epoch": 17, "num_updates": 4500, "iterations": 4500, "max_updates": 22000, "lr": "0.00004", "ups": "0.54", "time": "03m 05s 658ms", "time_since_start": "02h 25m 02s 935ms", "eta": "09h 01m 30s 210ms"}
2020-06-09T00:15:34 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T00:18:38 INFO: {"progress": "4600/22000", "train/total_loss": "0.0325", "train/total_loss/avg": "0.0606", "train/hateful_memes/cross_entropy": "0.0325", "train/hateful_memes/cross_entropy/avg": "0.0606", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9783", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9636", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9991", "max mem": 12643.0, "experiment": "run", "epoch": 18, "num_updates": 4600, "iterations": 4600, "max_updates": 22000, "lr": "0.00004", "ups": "0.54", "time": "03m 06s 028ms", "time_since_start": "02h 28m 08s 964ms", "eta": "08h 59m 28s 979ms"}
2020-06-09T00:18:40 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T00:21:44 INFO: {"progress": "4700/22000", "train/total_loss": "0.0218", "train/total_loss/avg": "0.0594", "train/hateful_memes/cross_entropy": "0.0218", "train/hateful_memes/cross_entropy/avg": "0.0594", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9787", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9644", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9991", "max mem": 12643.0, "experiment": "run", "epoch": 18, "num_updates": 4700, "iterations": 4700, "max_updates": 22000, "lr": "0.00004", "ups": "0.54", "time": "03m 05s 898ms", "time_since_start": "02h 31m 14s 863ms", "eta": "08h 56m 494ms"}
2020-06-09T00:21:46 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T00:24:50 INFO: {"progress": "4800/22000", "train/total_loss": "0.0218", "train/total_loss/avg": "0.0588", "train/hateful_memes/cross_entropy": "0.0218", "train/hateful_memes/cross_entropy/avg": "0.0588", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9792", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9651", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9992", "max mem": 12643.0, "experiment": "run", "epoch": 19, "num_updates": 4800, "iterations": 4800, "max_updates": 22000, "lr": "0.00004", "ups": "0.54", "time": "03m 05s 893ms", "time_since_start": "02h 34m 20s 756ms", "eta": "08h 52m 53s 659ms"}
2020-06-09T00:24:52 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T00:27:56 INFO: {"progress": "4900/22000", "train/total_loss": "0.0195", "train/total_loss/avg": "0.0577", "train/hateful_memes/cross_entropy": "0.0195", "train/hateful_memes/cross_entropy/avg": "0.0577", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9796", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9658", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9992", "max mem": 12643.0, "experiment": "run", "epoch": 19, "num_updates": 4900, "iterations": 4900, "max_updates": 22000, "lr": "0.00004", "ups": "0.54", "time": "03m 06s 032ms", "time_since_start": "02h 37m 26s 789ms", "eta": "08h 50m 11s 610ms"}
2020-06-09T00:27:58 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T00:31:02 INFO: {"progress": "5000/22000", "train/total_loss": "0.0277", "train/total_loss/avg": "0.0574", "train/hateful_memes/cross_entropy": "0.0277", "train/hateful_memes/cross_entropy/avg": "0.0574", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9794", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9657", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9992", "max mem": 12643.0, "experiment": "run", "epoch": 19, "num_updates": 5000, "iterations": 5000, "max_updates": 22000, "lr": "0.00004", "ups": "0.54", "time": "03m 05s 502ms", "time_since_start": "02h 40m 32s 291ms", "eta": "08h 45m 35s 373ms"}
2020-06-09T00:31:02 INFO: Checkpoint time. Saving a checkpoint.
2020-06-09T00:31:22 INFO: Evaluation time. Running on full validation set...
2020-06-09T00:32:08 INFO: {"progress": "5000/22000", "val/total_loss": "3.0272", "val/hateful_memes/cross_entropy": "3.0272", "val/hateful_memes/accuracy": "0.5780", "val/hateful_memes/binary_f1": "0.3884", "val/hateful_memes/roc_auc": "0.6385", "num_updates": 5000, "epoch": 19, "iterations": 5000, "max_updates": 22000, "val_time": "10s 262ms", "best_update": 4000, "best_iteration": 4000, "best_val/hateful_memes/roc_auc": "0.648812"}
2020-06-09T00:32:11 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T00:35:15 INFO: {"progress": "5100/22000", "train/total_loss": "0.0183", "train/total_loss/avg": "0.0564", "train/hateful_memes/cross_entropy": "0.0183", "train/hateful_memes/cross_entropy/avg": "0.0564", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9798", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9664", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9992", "max mem": 12643.0, "experiment": "run", "epoch": 20, "num_updates": 5100, "iterations": 5100, "max_updates": 22000, "lr": "0.00004", "ups": "0.54", "time": "03m 06s 400ms", "time_since_start": "02h 44m 45s 836ms", "eta": "08h 45m 01s 651ms"}
2020-06-09T00:35:17 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T00:38:21 INFO: {"progress": "5200/22000", "train/total_loss": "0.0277", "train/total_loss/avg": "0.0570", "train/hateful_memes/cross_entropy": "0.0277", "train/hateful_memes/cross_entropy/avg": "0.0570", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9796", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9662", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9991", "max mem": 12643.0, "experiment": "run", "epoch": 20, "num_updates": 5200, "iterations": 5200, "max_updates": 22000, "lr": "0.00004", "ups": "0.54", "time": "03m 05s 583ms", "time_since_start": "02h 47m 51s 420ms", "eta": "08h 39m 38s 034ms"}
2020-06-09T00:38:23 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T00:41:27 INFO: {"progress": "5300/22000", "train/total_loss": "0.0244", "train/total_loss/avg": "0.0564", "train/hateful_memes/cross_entropy": "0.0244", "train/hateful_memes/cross_entropy/avg": "0.0564", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9800", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9668", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9992", "max mem": 12643.0, "experiment": "run", "epoch": 20, "num_updates": 5300, "iterations": 5300, "max_updates": 22000, "lr": "0.00004", "ups": "0.54", "time": "03m 05s 750ms", "time_since_start": "02h 50m 57s 170ms", "eta": "08h 37m 390ms"}
2020-06-09T00:41:28 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T00:44:33 INFO: {"progress": "5400/22000", "train/total_loss": "0.0277", "train/total_loss/avg": "0.0563", "train/hateful_memes/cross_entropy": "0.0277", "train/hateful_memes/cross_entropy/avg": "0.0563", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9797", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9662", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9992", "max mem": 12643.0, "experiment": "run", "epoch": 21, "num_updates": 5400, "iterations": 5400, "max_updates": 22000, "lr": "0.00004", "ups": "0.54", "time": "03m 06s 045ms", "time_since_start": "02h 54m 03s 216ms", "eta": "08h 34m 43s 524ms"}
2020-06-09T00:44:34 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T00:47:39 INFO: {"progress": "5500/22000", "train/total_loss": "0.0277", "train/total_loss/avg": "0.0570", "train/hateful_memes/cross_entropy": "0.0277", "train/hateful_memes/cross_entropy/avg": "0.0570", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9790", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9642", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9991", "max mem": 12643.0, "experiment": "run", "epoch": 21, "num_updates": 5500, "iterations": 5500, "max_updates": 22000, "lr": "0.00004", "ups": "0.54", "time": "03m 05s 925ms", "time_since_start": "02h 57m 09s 141ms", "eta": "08h 31m 17s 639ms"}
2020-06-09T00:47:40 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T00:50:45 INFO: {"progress": "5600/22000", "train/total_loss": "0.0277", "train/total_loss/avg": "0.0567", "train/hateful_memes/cross_entropy": "0.0277", "train/hateful_memes/cross_entropy/avg": "0.0567", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9788", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9643", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9991", "max mem": 12643.0, "experiment": "run", "epoch": 22, "num_updates": 5600, "iterations": 5600, "max_updates": 22000, "lr": "0.00004", "ups": "0.54", "time": "03m 06s 108ms", "time_since_start": "03h 15s 249ms", "eta": "08h 28m 41s 776ms"}
2020-06-09T00:50:46 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T00:53:50 INFO: {"progress": "5700/22000", "train/total_loss": "0.0277", "train/total_loss/avg": "0.0564", "train/hateful_memes/cross_entropy": "0.0277", "train/hateful_memes/cross_entropy/avg": "0.0564", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9792", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9649", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9991", "max mem": 12643.0, "experiment": "run", "epoch": 22, "num_updates": 5700, "iterations": 5700, "max_updates": 22000, "lr": "0.00004", "ups": "0.54", "time": "03m 05s 470ms", "time_since_start": "03h 03m 20s 720ms", "eta": "08h 23m 51s 700ms"}
2020-06-09T00:53:52 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T00:56:56 INFO: {"progress": "5800/22000", "train/total_loss": "0.0394", "train/total_loss/avg": "0.0571", "train/hateful_memes/cross_entropy": "0.0394", "train/hateful_memes/cross_entropy/avg": "0.0571", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9790", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9644", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9991", "max mem": 12643.0, "experiment": "run", "epoch": 22, "num_updates": 5800, "iterations": 5800, "max_updates": 22000, "lr": "0.00004", "ups": "0.54", "time": "03m 05s 757ms", "time_since_start": "03h 06m 26s 478ms", "eta": "08h 21m 32s 763ms"}
2020-06-09T00:56:58 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T01:00:02 INFO: {"progress": "5900/22000", "train/total_loss": "0.0394", "train/total_loss/avg": "0.0563", "train/hateful_memes/cross_entropy": "0.0394", "train/hateful_memes/cross_entropy/avg": "0.0563", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9793", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9650", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9991", "max mem": 12643.0, "experiment": "run", "epoch": 23, "num_updates": 5900, "iterations": 5900, "max_updates": 22000, "lr": "0.00004", "ups": "0.54", "time": "03m 05s 672ms", "time_since_start": "03h 09m 32s 151ms", "eta": "08h 18m 13s 355ms"}
2020-06-09T01:00:03 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T01:03:07 INFO: {"progress": "6000/22000", "train/total_loss": "0.0394", "train/total_loss/avg": "0.0554", "train/hateful_memes/cross_entropy": "0.0394", "train/hateful_memes/cross_entropy/avg": "0.0554", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9797", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9656", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9992", "max mem": 12643.0, "experiment": "run", "epoch": 23, "num_updates": 6000, "iterations": 6000, "max_updates": 22000, "lr": "0.00004", "ups": "0.54", "time": "03m 05s 951ms", "time_since_start": "03h 12m 38s 102ms", "eta": "08h 15m 52s 181ms"}
2020-06-09T01:03:07 INFO: Checkpoint time. Saving a checkpoint.
2020-06-09T01:03:27 INFO: Evaluation time. Running on full validation set...
2020-06-09T01:04:16 INFO: {"progress": "6000/22000", "val/total_loss": "2.9979", "val/hateful_memes/cross_entropy": "2.9979", "val/hateful_memes/accuracy": "0.5780", "val/hateful_memes/binary_f1": "0.4548", "val/hateful_memes/roc_auc": "0.6205", "num_updates": 6000, "epoch": 23, "iterations": 6000, "max_updates": 22000, "val_time": "10s 224ms", "best_update": 4000, "best_iteration": 4000, "best_val/hateful_memes/roc_auc": "0.648812"}
2020-06-09T01:04:18 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T01:07:23 INFO: {"progress": "6100/22000", "train/total_loss": "0.0383", "train/total_loss/avg": "0.0552", "train/hateful_memes/cross_entropy": "0.0383", "train/hateful_memes/cross_entropy/avg": "0.0552", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9800", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9661", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9992", "max mem": 12643.0, "experiment": "run", "epoch": 23, "num_updates": 6100, "iterations": 6100, "max_updates": 22000, "lr": "0.00004", "ups": "0.54", "time": "03m 06s 284ms", "time_since_start": "03h 16m 53s 128ms", "eta": "08h 13m 39s 231ms"}
2020-06-09T01:07:24 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T01:10:28 INFO: {"progress": "6200/22000", "train/total_loss": "0.0277", "train/total_loss/avg": "0.0545", "train/hateful_memes/cross_entropy": "0.0277", "train/hateful_memes/cross_entropy/avg": "0.0545", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9803", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9667", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9992", "max mem": 12643.0, "experiment": "run", "epoch": 24, "num_updates": 6200, "iterations": 6200, "max_updates": 22000, "lr": "0.00004", "ups": "0.54", "time": "03m 05s 745ms", "time_since_start": "03h 19m 58s 874ms", "eta": "08h 09m 07s 723ms"}
2020-06-09T01:10:30 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T01:13:34 INFO: {"progress": "6300/22000", "train/total_loss": "0.0244", "train/total_loss/avg": "0.0538", "train/hateful_memes/cross_entropy": "0.0244", "train/hateful_memes/cross_entropy/avg": "0.0538", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9807", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9672", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9992", "max mem": 12643.0, "experiment": "run", "epoch": 24, "num_updates": 6300, "iterations": 6300, "max_updates": 22000, "lr": "0.00004", "ups": "0.54", "time": "03m 05s 597ms", "time_since_start": "03h 23m 04s 471ms", "eta": "08h 05m 38s 770ms"}
2020-06-09T01:13:36 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T01:16:40 INFO: {"progress": "6400/22000", "train/total_loss": "0.0244", "train/total_loss/avg": "0.0530", "train/hateful_memes/cross_entropy": "0.0244", "train/hateful_memes/cross_entropy/avg": "0.0530", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9810", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9677", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9992", "max mem": 12643.0, "experiment": "run", "epoch": 25, "num_updates": 6400, "iterations": 6400, "max_updates": 22000, "lr": "0.00004", "ups": "0.54", "time": "03m 05s 792ms", "time_since_start": "03h 26m 10s 263ms", "eta": "08h 03m 03s 597ms"}
2020-06-09T01:16:41 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T01:19:45 INFO: {"progress": "6500/22000", "train/total_loss": "0.0158", "train/total_loss/avg": "0.0522", "train/hateful_memes/cross_entropy": "0.0158", "train/hateful_memes/cross_entropy/avg": "0.0522", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9812", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9682", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9992", "max mem": 12643.0, "experiment": "run", "epoch": 25, "num_updates": 6500, "iterations": 6500, "max_updates": 22000, "lr": "0.00004", "ups": "0.54", "time": "03m 05s 626ms", "time_since_start": "03h 29m 15s 890ms", "eta": "07h 59m 32s 092ms"}
2020-06-09T01:19:47 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T01:22:51 INFO: {"progress": "6600/22000", "train/total_loss": "0.0212", "train/total_loss/avg": "0.0517", "train/hateful_memes/cross_entropy": "0.0212", "train/hateful_memes/cross_entropy/avg": "0.0517", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9815", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9687", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9992", "max mem": 12643.0, "experiment": "run", "epoch": 25, "num_updates": 6600, "iterations": 6600, "max_updates": 22000, "lr": "0.00004", "ups": "0.54", "time": "03m 05s 719ms", "time_since_start": "03h 32m 21s 610ms", "eta": "07h 56m 40s 870ms"}
2020-06-09T01:22:53 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T01:25:57 INFO: {"progress": "6700/22000", "train/total_loss": "0.0212", "train/total_loss/avg": "0.0511", "train/hateful_memes/cross_entropy": "0.0212", "train/hateful_memes/cross_entropy/avg": "0.0511", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9818", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9692", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9992", "max mem": 12643.0, "experiment": "run", "epoch": 26, "num_updates": 6700, "iterations": 6700, "max_updates": 22000, "lr": "0.00004", "ups": "0.54", "time": "03m 05s 813ms", "time_since_start": "03h 35m 27s 423ms", "eta": "07h 53m 49s 487ms"}
2020-06-09T01:25:59 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T01:29:03 INFO: {"progress": "6800/22000", "train/total_loss": "0.0212", "train/total_loss/avg": "0.0520", "train/hateful_memes/cross_entropy": "0.0212", "train/hateful_memes/cross_entropy/avg": "0.0520", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9816", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9680", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9993", "max mem": 12643.0, "experiment": "run", "epoch": 26, "num_updates": 6800, "iterations": 6800, "max_updates": 22000, "lr": "0.00004", "ups": "0.54", "time": "03m 06s 171ms", "time_since_start": "03h 38m 33s 595ms", "eta": "07h 51m 38s 038ms"}
2020-06-09T01:29:05 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T01:32:09 INFO: {"progress": "6900/22000", "train/total_loss": "0.0212", "train/total_loss/avg": "0.0512", "train/hateful_memes/cross_entropy": "0.0212", "train/hateful_memes/cross_entropy/avg": "0.0512", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9819", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9684", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9993", "max mem": 12643.0, "experiment": "run", "epoch": 26, "num_updates": 6900, "iterations": 6900, "max_updates": 22000, "lr": "0.00004", "ups": "0.54", "time": "03m 05s 735ms", "time_since_start": "03h 41m 39s 330ms", "eta": "07h 47m 26s 119ms"}
2020-06-09T01:32:11 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T01:35:15 INFO: {"progress": "7000/22000", "train/total_loss": "0.0158", "train/total_loss/avg": "0.0506", "train/hateful_memes/cross_entropy": "0.0158", "train/hateful_memes/cross_entropy/avg": "0.0506", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9821", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9689", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9993", "max mem": 12643.0, "experiment": "run", "epoch": 27, "num_updates": 7000, "iterations": 7000, "max_updates": 22000, "lr": "0.00004", "ups": "0.54", "time": "03m 05s 896ms", "time_since_start": "03h 44m 45s 227ms", "eta": "07h 44m 44s 434ms"}
2020-06-09T01:35:15 INFO: Checkpoint time. Saving a checkpoint.
2020-06-09T01:35:36 INFO: Evaluation time. Running on full validation set...
2020-06-09T01:36:23 INFO: {"progress": "7000/22000", "val/total_loss": "3.4538", "val/hateful_memes/cross_entropy": "3.4538", "val/hateful_memes/accuracy": "0.5840", "val/hateful_memes/binary_f1": "0.3918", "val/hateful_memes/roc_auc": "0.6211", "num_updates": 7000, "epoch": 27, "iterations": 7000, "max_updates": 22000, "val_time": "10s 203ms", "best_update": 4000, "best_iteration": 4000, "best_val/hateful_memes/roc_auc": "0.648812"}
2020-06-09T01:36:25 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T01:39:30 INFO: {"progress": "7100/22000", "train/total_loss": "0.0158", "train/total_loss/avg": "0.0499", "train/hateful_memes/cross_entropy": "0.0158", "train/hateful_memes/cross_entropy/avg": "0.0499", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9824", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9693", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9993", "max mem": 12643.0, "experiment": "run", "epoch": 27, "num_updates": 7100, "iterations": 7100, "max_updates": 22000, "lr": "0.00004", "ups": "0.54", "time": "03m 06s 433ms", "time_since_start": "03h 49m 138ms", "eta": "07h 42m 58s 654ms"}
2020-06-09T01:39:31 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T01:42:35 INFO: {"progress": "7200/22000", "train/total_loss": "0.0128", "train/total_loss/avg": "0.0492", "train/hateful_memes/cross_entropy": "0.0128", "train/hateful_memes/cross_entropy/avg": "0.0492", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9826", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9698", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9993", "max mem": 12643.0, "experiment": "run", "epoch": 28, "num_updates": 7200, "iterations": 7200, "max_updates": 22000, "lr": "0.00004", "ups": "0.54", "time": "03m 05s 955ms", "time_since_start": "03h 52m 06s 094ms", "eta": "07h 38m 41s 487ms"}
2020-06-09T01:42:37 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T01:45:42 INFO: {"progress": "7300/22000", "train/total_loss": "0.0128", "train/total_loss/avg": "0.0496", "train/hateful_memes/cross_entropy": "0.0128", "train/hateful_memes/cross_entropy/avg": "0.0496", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9824", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9697", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9993", "max mem": 12643.0, "experiment": "run", "epoch": 28, "num_updates": 7300, "iterations": 7300, "max_updates": 22000, "lr": "0.00004", "ups": "0.54", "time": "03m 06s 056ms", "time_since_start": "03h 55m 12s 150ms", "eta": "07h 35m 50s 313ms"}
2020-06-09T01:45:43 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T01:48:47 INFO: {"progress": "7400/22000", "train/total_loss": "0.0118", "train/total_loss/avg": "0.0489", "train/hateful_memes/cross_entropy": "0.0118", "train/hateful_memes/cross_entropy/avg": "0.0489", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9827", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9701", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9993", "max mem": 12643.0, "experiment": "run", "epoch": 28, "num_updates": 7400, "iterations": 7400, "max_updates": 22000, "lr": "0.00004", "ups": "0.54", "time": "03m 05s 556ms", "time_since_start": "03h 58m 17s 706ms", "eta": "07h 31m 31s 195ms"}
2020-06-09T01:48:49 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T01:51:53 INFO: {"progress": "7500/22000", "train/total_loss": "0.0093", "train/total_loss/avg": "0.0483", "train/hateful_memes/cross_entropy": "0.0093", "train/hateful_memes/cross_entropy/avg": "0.0483", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9829", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9705", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9993", "max mem": 12643.0, "experiment": "run", "epoch": 29, "num_updates": 7500, "iterations": 7500, "max_updates": 22000, "lr": "0.00004", "ups": "0.54", "time": "03m 05s 856ms", "time_since_start": "04h 01m 23s 563ms", "eta": "07h 29m 09s 257ms"}
2020-06-09T01:51:55 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T01:54:59 INFO: {"progress": "7600/22000", "train/total_loss": "0.0093", "train/total_loss/avg": "0.0482", "train/hateful_memes/cross_entropy": "0.0093", "train/hateful_memes/cross_entropy/avg": "0.0482", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9831", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9709", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9993", "max mem": 12643.0, "experiment": "run", "epoch": 29, "num_updates": 7600, "iterations": 7600, "max_updates": 22000, "lr": "0.00004", "ups": "0.54", "time": "03m 05s 936ms", "time_since_start": "04h 04m 29s 500ms", "eta": "07h 26m 14s 809ms"}
2020-06-09T01:55:01 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T01:58:05 INFO: {"progress": "7700/22000", "train/total_loss": "0.0093", "train/total_loss/avg": "0.0477", "train/hateful_memes/cross_entropy": "0.0093", "train/hateful_memes/cross_entropy/avg": "0.0477", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9834", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9712", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9993", "max mem": 12643.0, "experiment": "run", "epoch": 29, "num_updates": 7700, "iterations": 7700, "max_updates": 22000, "lr": "0.00004", "ups": "0.54", "time": "03m 05s 798ms", "time_since_start": "04h 07m 35s 298ms", "eta": "07h 22m 49s 117ms"}
2020-06-09T01:58:07 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T02:01:11 INFO: {"progress": "7800/22000", "train/total_loss": "0.0093", "train/total_loss/avg": "0.0494", "train/hateful_memes/cross_entropy": "0.0093", "train/hateful_memes/cross_entropy/avg": "0.0494", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9828", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9703", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9993", "max mem": 12643.0, "experiment": "run", "epoch": 30, "num_updates": 7800, "iterations": 7800, "max_updates": 22000, "lr": "0.00004", "ups": "0.54", "time": "03m 05s 855ms", "time_since_start": "04h 10m 41s 153ms", "eta": "07h 19m 51s 473ms"}
2020-06-09T02:01:12 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T02:04:16 INFO: {"progress": "7900/22000", "train/total_loss": "0.0043", "train/total_loss/avg": "0.0488", "train/hateful_memes/cross_entropy": "0.0043", "train/hateful_memes/cross_entropy/avg": "0.0488", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9830", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9707", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9993", "max mem": 12643.0, "experiment": "run", "epoch": 30, "num_updates": 7900, "iterations": 7900, "max_updates": 22000, "lr": "0.00004", "ups": "0.54", "time": "03m 05s 755ms", "time_since_start": "04h 13m 46s 908ms", "eta": "07h 16m 31s 465ms"}
2020-06-09T02:04:18 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T02:07:22 INFO: {"progress": "8000/22000", "train/total_loss": "0.0093", "train/total_loss/avg": "0.0485", "train/hateful_memes/cross_entropy": "0.0093", "train/hateful_memes/cross_entropy/avg": "0.0485", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9832", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9711", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9993", "max mem": 12643.0, "experiment": "run", "epoch": 31, "num_updates": 8000, "iterations": 8000, "max_updates": 22000, "lr": "0.00004", "ups": "0.54", "time": "03m 05s 713ms", "time_since_start": "04h 16m 52s 622ms", "eta": "07h 13m 19s 899ms"}
2020-06-09T02:07:22 INFO: Checkpoint time. Saving a checkpoint.
2020-06-09T02:07:42 INFO: Evaluation time. Running on full validation set...
2020-06-09T02:08:28 INFO: {"progress": "8000/22000", "val/total_loss": "2.9259", "val/hateful_memes/cross_entropy": "2.9259", "val/hateful_memes/accuracy": "0.6000", "val/hateful_memes/binary_f1": "0.4681", "val/hateful_memes/roc_auc": "0.6439", "num_updates": 8000, "epoch": 31, "iterations": 8000, "max_updates": 22000, "val_time": "10s 199ms", "best_update": 4000, "best_iteration": 4000, "best_val/hateful_memes/roc_auc": "0.648812"}
2020-06-09T02:08:31 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T02:11:35 INFO: {"progress": "8100/22000", "train/total_loss": "0.0093", "train/total_loss/avg": "0.0487", "train/hateful_memes/cross_entropy": "0.0093", "train/hateful_memes/cross_entropy/avg": "0.0487", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9830", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9706", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9993", "max mem": 12643.0, "experiment": "run", "epoch": 31, "num_updates": 8100, "iterations": 8100, "max_updates": 22000, "lr": "0.00003", "ups": "0.54", "time": "03m 06s 058ms", "time_since_start": "04h 21m 05s 394ms", "eta": "07h 11m 02s 126ms"}
2020-06-09T02:11:37 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T02:14:41 INFO: {"progress": "8200/22000", "train/total_loss": "0.0093", "train/total_loss/avg": "0.0489", "train/hateful_memes/cross_entropy": "0.0093", "train/hateful_memes/cross_entropy/avg": "0.0489", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9829", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9706", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9993", "max mem": 12643.0, "experiment": "run", "epoch": 31, "num_updates": 8200, "iterations": 8200, "max_updates": 22000, "lr": "0.00003", "ups": "0.54", "time": "03m 05s 855ms", "time_since_start": "04h 24m 11s 249ms", "eta": "07h 07m 28s 001ms"}
2020-06-09T02:14:42 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T02:17:46 INFO: {"progress": "8300/22000", "train/total_loss": "0.0093", "train/total_loss/avg": "0.0492", "train/hateful_memes/cross_entropy": "0.0093", "train/hateful_memes/cross_entropy/avg": "0.0492", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9827", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9706", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9993", "max mem": 12643.0, "experiment": "run", "epoch": 32, "num_updates": 8300, "iterations": 8300, "max_updates": 22000, "lr": "0.00003", "ups": "0.54", "time": "03m 05s 628ms", "time_since_start": "04h 27m 16s 878ms", "eta": "07h 03m 51s 140ms"}
2020-06-09T02:17:48 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T02:20:52 INFO: {"progress": "8400/22000", "train/total_loss": "0.0093", "train/total_loss/avg": "0.0487", "train/hateful_memes/cross_entropy": "0.0093", "train/hateful_memes/cross_entropy/avg": "0.0487", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9829", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9710", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9994", "max mem": 12643.0, "experiment": "run", "epoch": 32, "num_updates": 8400, "iterations": 8400, "max_updates": 22000, "lr": "0.00003", "ups": "0.54", "time": "03m 05s 608ms", "time_since_start": "04h 30m 22s 486ms", "eta": "07h 42s 691ms"}
2020-06-09T02:20:54 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T02:23:58 INFO: {"progress": "8500/22000", "train/total_loss": "0.0102", "train/total_loss/avg": "0.0488", "train/hateful_memes/cross_entropy": "0.0102", "train/hateful_memes/cross_entropy/avg": "0.0488", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9827", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9709", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9994", "max mem": 12643.0, "experiment": "run", "epoch": 32, "num_updates": 8500, "iterations": 8500, "max_updates": 22000, "lr": "0.00003", "ups": "0.54", "time": "03m 05s 649ms", "time_since_start": "04h 33m 28s 136ms", "eta": "06h 57m 42s 719ms"}
2020-06-09T02:23:59 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T02:27:03 INFO: {"progress": "8600/22000", "train/total_loss": "0.0102", "train/total_loss/avg": "0.0487", "train/hateful_memes/cross_entropy": "0.0102", "train/hateful_memes/cross_entropy/avg": "0.0487", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9826", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9702", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9994", "max mem": 12643.0, "experiment": "run", "epoch": 33, "num_updates": 8600, "iterations": 8600, "max_updates": 22000, "lr": "0.00003", "ups": "0.54", "time": "03m 05s 837ms", "time_since_start": "04h 36m 33s 973ms", "eta": "06h 55m 02s 281ms"}
2020-06-09T02:27:05 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T02:30:09 INFO: {"progress": "8700/22000", "train/total_loss": "0.0210", "train/total_loss/avg": "0.0485", "train/hateful_memes/cross_entropy": "0.0210", "train/hateful_memes/cross_entropy/avg": "0.0485", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9824", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9700", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9994", "max mem": 12643.0, "experiment": "run", "epoch": 33, "num_updates": 8700, "iterations": 8700, "max_updates": 22000, "lr": "0.00003", "ups": "0.54", "time": "03m 05s 696ms", "time_since_start": "04h 39m 39s 670ms", "eta": "06h 51m 37s 581ms"}
2020-06-09T02:30:11 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T02:33:15 INFO: {"progress": "8800/22000", "train/total_loss": "0.0102", "train/total_loss/avg": "0.0480", "train/hateful_memes/cross_entropy": "0.0102", "train/hateful_memes/cross_entropy/avg": "0.0480", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9826", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9703", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9994", "max mem": 12643.0, "experiment": "run", "epoch": 34, "num_updates": 8800, "iterations": 8800, "max_updates": 22000, "lr": "0.00003", "ups": "0.54", "time": "03m 05s 696ms", "time_since_start": "04h 42m 45s 366ms", "eta": "06h 48m 31s 946ms"}
2020-06-09T02:33:17 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T02:36:20 INFO: {"progress": "8900/22000", "train/total_loss": "0.0102", "train/total_loss/avg": "0.0475", "train/hateful_memes/cross_entropy": "0.0102", "train/hateful_memes/cross_entropy/avg": "0.0475", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9828", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9707", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9994", "max mem": 12643.0, "experiment": "run", "epoch": 34, "num_updates": 8900, "iterations": 8900, "max_updates": 22000, "lr": "0.00003", "ups": "0.54", "time": "03m 05s 624ms", "time_since_start": "04h 45m 50s 991ms", "eta": "06h 45m 16s 807ms"}
2020-06-09T02:36:22 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T02:39:26 INFO: {"progress": "9000/22000", "train/total_loss": "0.0102", "train/total_loss/avg": "0.0470", "train/hateful_memes/cross_entropy": "0.0102", "train/hateful_memes/cross_entropy/avg": "0.0470", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9830", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9710", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9994", "max mem": 12643.0, "experiment": "run", "epoch": 34, "num_updates": 9000, "iterations": 9000, "max_updates": 22000, "lr": "0.00003", "ups": "0.54", "time": "03m 05s 666ms", "time_since_start": "04h 48m 56s 657ms", "eta": "06h 42m 16s 597ms"}
2020-06-09T02:39:26 INFO: Checkpoint time. Saving a checkpoint.
2020-06-09T02:39:47 INFO: Evaluation time. Running on full validation set...
2020-06-09T02:39:58 INFO: {"progress": "9000/22000", "val/total_loss": "3.6411", "val/hateful_memes/cross_entropy": "3.6411", "val/hateful_memes/accuracy": "0.5800", "val/hateful_memes/binary_f1": "0.4000", "val/hateful_memes/roc_auc": "0.6482", "num_updates": 9000, "epoch": 34, "iterations": 9000, "max_updates": 22000, "val_time": "10s 747ms", "best_update": 4000, "best_iteration": 4000, "best_val/hateful_memes/roc_auc": "0.648812"}
2020-06-09T02:40:00 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T02:43:05 INFO: {"progress": "9100/22000", "train/total_loss": "0.0102", "train/total_loss/avg": "0.0465", "train/hateful_memes/cross_entropy": "0.0102", "train/hateful_memes/cross_entropy/avg": "0.0465", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9832", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9713", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9994", "max mem": 12643.0, "experiment": "run", "epoch": 35, "num_updates": 9100, "iterations": 9100, "max_updates": 22000, "lr": "0.00003", "ups": "0.54", "time": "03m 06s 441ms", "time_since_start": "04h 52m 35s 550ms", "eta": "06h 40m 51s 005ms"}
2020-06-09T02:43:07 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T02:46:11 INFO: {"progress": "9200/22000", "train/total_loss": "0.0102", "train/total_loss/avg": "0.0460", "train/hateful_memes/cross_entropy": "0.0102", "train/hateful_memes/cross_entropy/avg": "0.0460", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9834", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9716", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9994", "max mem": 12643.0, "experiment": "run", "epoch": 35, "num_updates": 9200, "iterations": 9200, "max_updates": 22000, "lr": "0.00003", "ups": "0.54", "time": "03m 05s 783ms", "time_since_start": "04h 55m 41s 334ms", "eta": "06h 36m 20s 307ms"}
2020-06-09T02:46:13 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T02:49:16 INFO: {"progress": "9300/22000", "train/total_loss": "0.0077", "train/total_loss/avg": "0.0455", "train/hateful_memes/cross_entropy": "0.0077", "train/hateful_memes/cross_entropy/avg": "0.0455", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9835", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9719", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9994", "max mem": 12643.0, "experiment": "run", "epoch": 35, "num_updates": 9300, "iterations": 9300, "max_updates": 22000, "lr": "0.00003", "ups": "0.54", "time": "03m 05s 759ms", "time_since_start": "04h 58m 47s 093ms", "eta": "06h 33m 11s 454ms"}
2020-06-09T02:49:18 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T02:52:22 INFO: {"progress": "9400/22000", "train/total_loss": "0.0077", "train/total_loss/avg": "0.0451", "train/hateful_memes/cross_entropy": "0.0077", "train/hateful_memes/cross_entropy/avg": "0.0451", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9837", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9722", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9994", "max mem": 12643.0, "experiment": "run", "epoch": 36, "num_updates": 9400, "iterations": 9400, "max_updates": 22000, "lr": "0.00003", "ups": "0.54", "time": "03m 05s 982ms", "time_since_start": "05h 01m 53s 076ms", "eta": "06h 30m 33s 786ms"}
2020-06-09T02:52:24 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T02:55:28 INFO: {"progress": "9500/22000", "train/total_loss": "0.0077", "train/total_loss/avg": "0.0446", "train/hateful_memes/cross_entropy": "0.0077", "train/hateful_memes/cross_entropy/avg": "0.0446", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9839", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9725", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9994", "max mem": 12643.0, "experiment": "run", "epoch": 36, "num_updates": 9500, "iterations": 9500, "max_updates": 22000, "lr": "0.00003", "ups": "0.54", "time": "03m 05s 550ms", "time_since_start": "05h 04m 58s 626ms", "eta": "06h 26m 33s 780ms"}
2020-06-09T02:55:30 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T02:58:34 INFO: {"progress": "9600/22000", "train/total_loss": "0.0077", "train/total_loss/avg": "0.0442", "train/hateful_memes/cross_entropy": "0.0077", "train/hateful_memes/cross_entropy/avg": "0.0442", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9840", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9728", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9994", "max mem": 12643.0, "experiment": "run", "epoch": 37, "num_updates": 9600, "iterations": 9600, "max_updates": 22000, "lr": "0.00003", "ups": "0.54", "time": "03m 05s 927ms", "time_since_start": "05h 08m 04s 554ms", "eta": "06h 24m 15s 027ms"}
2020-06-09T02:58:36 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T03:01:40 INFO: {"progress": "9700/22000", "train/total_loss": "0.0071", "train/total_loss/avg": "0.0438", "train/hateful_memes/cross_entropy": "0.0071", "train/hateful_memes/cross_entropy/avg": "0.0438", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9842", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9731", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9994", "max mem": 12643.0, "experiment": "run", "epoch": 37, "num_updates": 9700, "iterations": 9700, "max_updates": 22000, "lr": "0.00003", "ups": "0.54", "time": "03m 05s 911ms", "time_since_start": "05h 11m 10s 465ms", "eta": "06h 21m 07s 077ms"}
2020-06-09T03:01:42 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T03:04:46 INFO: {"progress": "9800/22000", "train/total_loss": "0.0051", "train/total_loss/avg": "0.0434", "train/hateful_memes/cross_entropy": "0.0051", "train/hateful_memes/cross_entropy/avg": "0.0434", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9844", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9734", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9994", "max mem": 12643.0, "experiment": "run", "epoch": 37, "num_updates": 9800, "iterations": 9800, "max_updates": 22000, "lr": "0.00003", "ups": "0.54", "time": "03m 05s 729ms", "time_since_start": "05h 14m 16s 195ms", "eta": "06h 17m 39s 018ms"}
2020-06-09T03:04:47 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T03:07:52 INFO: {"progress": "9900/22000", "train/total_loss": "0.0051", "train/total_loss/avg": "0.0430", "train/hateful_memes/cross_entropy": "0.0051", "train/hateful_memes/cross_entropy/avg": "0.0430", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9845", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9736", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9995", "max mem": 12643.0, "experiment": "run", "epoch": 38, "num_updates": 9900, "iterations": 9900, "max_updates": 22000, "lr": "0.00003", "ups": "0.54", "time": "03m 06s 027ms", "time_since_start": "05h 17m 22s 222ms", "eta": "06h 15m 09s 287ms"}
2020-06-09T03:07:53 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T03:10:57 INFO: {"progress": "10000/22000", "train/total_loss": "0.0039", "train/total_loss/avg": "0.0426", "train/hateful_memes/cross_entropy": "0.0039", "train/hateful_memes/cross_entropy/avg": "0.0426", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9847", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9739", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9995", "max mem": 12643.0, "experiment": "run", "epoch": 38, "num_updates": 10000, "iterations": 10000, "max_updates": 22000, "lr": "0.00003", "ups": "0.54", "time": "03m 05s 615ms", "time_since_start": "05h 20m 27s 837ms", "eta": "06h 11m 13s 845ms"}
2020-06-09T03:10:57 INFO: Checkpoint time. Saving a checkpoint.
2020-06-09T03:11:18 INFO: Evaluation time. Running on full validation set...
2020-06-09T03:11:27 INFO: {"progress": "10000/22000", "val/total_loss": "4.0005", "val/hateful_memes/cross_entropy": "4.0005", "val/hateful_memes/accuracy": "0.5760", "val/hateful_memes/binary_f1": "0.4011", "val/hateful_memes/roc_auc": "0.6255", "num_updates": 10000, "epoch": 38, "iterations": 10000, "max_updates": 22000, "val_time": "08s 922ms", "best_update": 4000, "best_iteration": 4000, "best_val/hateful_memes/roc_auc": "0.648812"}
2020-06-09T03:11:29 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T03:14:34 INFO: {"progress": "10100/22000", "train/total_loss": "0.0027", "train/total_loss/avg": "0.0422", "train/hateful_memes/cross_entropy": "0.0027", "train/hateful_memes/cross_entropy/avg": "0.0422", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9848", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9742", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9995", "max mem": 12643.0, "experiment": "run", "epoch": 38, "num_updates": 10100, "iterations": 10100, "max_updates": 22000, "lr": "0.00003", "ups": "0.54", "time": "03m 06s 259ms", "time_since_start": "05h 24m 04s 182ms", "eta": "06h 09m 24s 903ms"}
2020-06-09T03:14:35 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T03:17:39 INFO: {"progress": "10200/22000", "train/total_loss": "0.0023", "train/total_loss/avg": "0.0418", "train/hateful_memes/cross_entropy": "0.0023", "train/hateful_memes/cross_entropy/avg": "0.0418", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9850", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9744", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9995", "max mem": 12643.0, "experiment": "run", "epoch": 39, "num_updates": 10200, "iterations": 10200, "max_updates": 22000, "lr": "0.00003", "ups": "0.54", "time": "03m 05s 824ms", "time_since_start": "05h 27m 10s 006ms", "eta": "06h 05m 27s 245ms"}
2020-06-09T03:17:41 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T03:20:45 INFO: {"progress": "10300/22000", "train/total_loss": "0.0020", "train/total_loss/avg": "0.0414", "train/hateful_memes/cross_entropy": "0.0020", "train/hateful_memes/cross_entropy/avg": "0.0414", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9851", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9747", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9995", "max mem": 12643.0, "experiment": "run", "epoch": 39, "num_updates": 10300, "iterations": 10300, "max_updates": 22000, "lr": "0.00003", "ups": "0.54", "time": "03m 05s 697ms", "time_since_start": "05h 30m 15s 704ms", "eta": "06h 02m 06s 639ms"}
2020-06-09T03:20:47 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T03:23:51 INFO: {"progress": "10400/22000", "train/total_loss": "0.0017", "train/total_loss/avg": "0.0410", "train/hateful_memes/cross_entropy": "0.0017", "train/hateful_memes/cross_entropy/avg": "0.0410", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9853", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9749", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9995", "max mem": 12643.0, "experiment": "run", "epoch": 40, "num_updates": 10400, "iterations": 10400, "max_updates": 22000, "lr": "0.00003", "ups": "0.54", "time": "03m 05s 911ms", "time_since_start": "05h 33m 21s 615ms", "eta": "05h 59m 25s 694ms"}
2020-06-09T03:23:53 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T03:26:57 INFO: {"progress": "10500/22000", "train/total_loss": "0.0017", "train/total_loss/avg": "0.0409", "train/hateful_memes/cross_entropy": "0.0017", "train/hateful_memes/cross_entropy/avg": "0.0409", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9854", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9751", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9995", "max mem": 12643.0, "experiment": "run", "epoch": 40, "num_updates": 10500, "iterations": 10500, "max_updates": 22000, "lr": "0.00003", "ups": "0.54", "time": "03m 05s 920ms", "time_since_start": "05h 36m 27s 536ms", "eta": "05h 56m 20s 901ms"}
2020-06-09T03:26:59 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T03:30:03 INFO: {"progress": "10600/22000", "train/total_loss": "0.0017", "train/total_loss/avg": "0.0405", "train/hateful_memes/cross_entropy": "0.0017", "train/hateful_memes/cross_entropy/avg": "0.0405", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9856", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9754", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9995", "max mem": 12643.0, "experiment": "run", "epoch": 40, "num_updates": 10600, "iterations": 10600, "max_updates": 22000, "lr": "0.00003", "ups": "0.54", "time": "03m 05s 771ms", "time_since_start": "05h 39m 33s 308ms", "eta": "05h 52m 57s 984ms"}
2020-06-09T03:30:05 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T03:33:09 INFO: {"progress": "10700/22000", "train/total_loss": "0.0017", "train/total_loss/avg": "0.0402", "train/hateful_memes/cross_entropy": "0.0017", "train/hateful_memes/cross_entropy/avg": "0.0402", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9857", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9756", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9995", "max mem": 12643.0, "experiment": "run", "epoch": 41, "num_updates": 10700, "iterations": 10700, "max_updates": 22000, "lr": "0.00003", "ups": "0.54", "time": "03m 06s 081ms", "time_since_start": "05h 42m 39s 389ms", "eta": "05h 50m 27s 171ms"}
2020-06-09T03:33:11 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T03:36:15 INFO: {"progress": "10800/22000", "train/total_loss": "0.0017", "train/total_loss/avg": "0.0398", "train/hateful_memes/cross_entropy": "0.0017", "train/hateful_memes/cross_entropy/avg": "0.0398", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9858", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9758", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9995", "max mem": 12643.0, "experiment": "run", "epoch": 41, "num_updates": 10800, "iterations": 10800, "max_updates": 22000, "lr": "0.00003", "ups": "0.54", "time": "03m 05s 790ms", "time_since_start": "05h 45m 45s 180ms", "eta": "05h 46m 48s 555ms"}
2020-06-09T03:36:16 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T03:39:20 INFO: {"progress": "10900/22000", "train/total_loss": "0.0020", "train/total_loss/avg": "0.0428", "train/hateful_memes/cross_entropy": "0.0020", "train/hateful_memes/cross_entropy/avg": "0.0428", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9854", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9752", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9993", "max mem": 12643.0, "experiment": "run", "epoch": 41, "num_updates": 10900, "iterations": 10900, "max_updates": 22000, "lr": "0.00003", "ups": "0.54", "time": "03m 05s 589ms", "time_since_start": "05h 48m 50s 769ms", "eta": "05h 43m 20s 392ms"}
2020-06-09T03:39:22 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T03:42:26 INFO: {"progress": "11000/22000", "train/total_loss": "0.0017", "train/total_loss/avg": "0.0424", "train/hateful_memes/cross_entropy": "0.0017", "train/hateful_memes/cross_entropy/avg": "0.0424", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9855", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9754", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9993", "max mem": 12643.0, "experiment": "run", "epoch": 42, "num_updates": 11000, "iterations": 11000, "max_updates": 22000, "lr": "0.00003", "ups": "0.54", "time": "03m 06s 145ms", "time_since_start": "05h 51m 56s 915ms", "eta": "05h 41m 16s 037ms"}
2020-06-09T03:42:26 INFO: Checkpoint time. Saving a checkpoint.
2020-06-09T03:42:47 INFO: Evaluation time. Running on full validation set...
2020-06-09T03:42:56 INFO: {"progress": "11000/22000", "val/total_loss": "3.8900", "val/hateful_memes/cross_entropy": "3.8900", "val/hateful_memes/accuracy": "0.5840", "val/hateful_memes/binary_f1": "0.4468", "val/hateful_memes/roc_auc": "0.6303", "num_updates": 11000, "epoch": 42, "iterations": 11000, "max_updates": 22000, "val_time": "08s 833ms", "best_update": 4000, "best_iteration": 4000, "best_val/hateful_memes/roc_auc": "0.648812"}
2020-06-09T03:42:58 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T03:46:03 INFO: {"progress": "11100/22000", "train/total_loss": "0.0017", "train/total_loss/avg": "0.0420", "train/hateful_memes/cross_entropy": "0.0017", "train/hateful_memes/cross_entropy/avg": "0.0420", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9856", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9757", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9993", "max mem": 12643.0, "experiment": "run", "epoch": 42, "num_updates": 11100, "iterations": 11100, "max_updates": 22000, "lr": "0.00003", "ups": "0.54", "time": "03m 06s 405ms", "time_since_start": "05h 55m 33s 156ms", "eta": "05h 38m 38s 160ms"}
2020-06-09T03:46:04 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T03:49:09 INFO: {"progress": "11200/22000", "train/total_loss": "0.0017", "train/total_loss/avg": "0.0417", "train/hateful_memes/cross_entropy": "0.0017", "train/hateful_memes/cross_entropy/avg": "0.0417", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9858", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9759", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9993", "max mem": 12643.0, "experiment": "run", "epoch": 43, "num_updates": 11200, "iterations": 11200, "max_updates": 22000, "lr": "0.00003", "ups": "0.54", "time": "03m 06s 207ms", "time_since_start": "05h 58m 39s 364ms", "eta": "05h 35m 10s 459ms"}
2020-06-09T03:49:11 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T03:52:14 INFO: {"progress": "11300/22000", "train/total_loss": "0.0017", "train/total_loss/avg": "0.0413", "train/hateful_memes/cross_entropy": "0.0017", "train/hateful_memes/cross_entropy/avg": "0.0413", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9859", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9761", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9993", "max mem": 12643.0, "experiment": "run", "epoch": 43, "num_updates": 11300, "iterations": 11300, "max_updates": 22000, "lr": "0.00003", "ups": "0.54", "time": "03m 05s 697ms", "time_since_start": "06h 01m 45s 062ms", "eta": "05h 31m 09s 661ms"}
2020-06-09T03:52:16 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T03:55:20 INFO: {"progress": "11400/22000", "train/total_loss": "0.0017", "train/total_loss/avg": "0.0412", "train/hateful_memes/cross_entropy": "0.0017", "train/hateful_memes/cross_entropy/avg": "0.0412", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9857", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9758", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9993", "max mem": 12643.0, "experiment": "run", "epoch": 43, "num_updates": 11400, "iterations": 11400, "max_updates": 22000, "lr": "0.00003", "ups": "0.54", "time": "03m 05s 623ms", "time_since_start": "06h 04m 50s 685ms", "eta": "05h 27m 56s 053ms"}
2020-06-09T03:55:22 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T03:58:26 INFO: {"progress": "11500/22000", "train/total_loss": "0.0017", "train/total_loss/avg": "0.0409", "train/hateful_memes/cross_entropy": "0.0017", "train/hateful_memes/cross_entropy/avg": "0.0409", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9859", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9760", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9993", "max mem": 12643.0, "experiment": "run", "epoch": 44, "num_updates": 11500, "iterations": 11500, "max_updates": 22000, "lr": "0.00003", "ups": "0.54", "time": "03m 05s 857ms", "time_since_start": "06h 07m 56s 542ms", "eta": "05h 25m 15s 038ms"}
2020-06-09T03:58:28 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T04:01:31 INFO: {"progress": "11600/22000", "train/total_loss": "0.0017", "train/total_loss/avg": "0.0406", "train/hateful_memes/cross_entropy": "0.0017", "train/hateful_memes/cross_entropy/avg": "0.0406", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9860", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9762", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9993", "max mem": 12643.0, "experiment": "run", "epoch": 44, "num_updates": 11600, "iterations": 11600, "max_updates": 22000, "lr": "0.00003", "ups": "0.54", "time": "03m 05s 467ms", "time_since_start": "06h 11m 02s 009ms", "eta": "05h 21m 28s 577ms"}
2020-06-09T04:01:33 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T04:04:37 INFO: {"progress": "11700/22000", "train/total_loss": "0.0016", "train/total_loss/avg": "0.0403", "train/hateful_memes/cross_entropy": "0.0016", "train/hateful_memes/cross_entropy/avg": "0.0403", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9861", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9764", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9993", "max mem": 12643.0, "experiment": "run", "epoch": 44, "num_updates": 11700, "iterations": 11700, "max_updates": 22000, "lr": "0.00003", "ups": "0.54", "time": "03m 05s 466ms", "time_since_start": "06h 14m 07s 476ms", "eta": "05h 18m 23s 094ms"}
2020-06-09T04:04:39 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T04:07:43 INFO: {"progress": "11800/22000", "train/total_loss": "0.0016", "train/total_loss/avg": "0.0400", "train/hateful_memes/cross_entropy": "0.0016", "train/hateful_memes/cross_entropy/avg": "0.0400", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9862", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9766", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9993", "max mem": 12643.0, "experiment": "run", "epoch": 45, "num_updates": 11800, "iterations": 11800, "max_updates": 22000, "lr": "0.00003", "ups": "0.54", "time": "03m 05s 955ms", "time_since_start": "06h 17m 13s 432ms", "eta": "05h 16m 07s 510ms"}
2020-06-09T04:07:45 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T04:10:48 INFO: {"progress": "11900/22000", "train/total_loss": "0.0016", "train/total_loss/avg": "0.0397", "train/hateful_memes/cross_entropy": "0.0016", "train/hateful_memes/cross_entropy/avg": "0.0397", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9863", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9768", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9994", "max mem": 12643.0, "experiment": "run", "epoch": 45, "num_updates": 11900, "iterations": 11900, "max_updates": 22000, "lr": "0.00003", "ups": "0.54", "time": "03m 05s 571ms", "time_since_start": "06h 20m 19s 004ms", "eta": "05h 12m 22s 695ms"}
2020-06-09T04:10:50 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T04:13:54 INFO: {"progress": "12000/22000", "train/total_loss": "0.0016", "train/total_loss/avg": "0.0393", "train/hateful_memes/cross_entropy": "0.0016", "train/hateful_memes/cross_entropy/avg": "0.0393", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9865", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9770", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9994", "max mem": 12643.0, "experiment": "run", "epoch": 46, "num_updates": 12000, "iterations": 12000, "max_updates": 22000, "lr": "0.00003", "ups": "0.54", "time": "03m 05s 999ms", "time_since_start": "06h 23m 25s 003ms", "eta": "05h 09m 59s 938ms"}
2020-06-09T04:13:54 INFO: Checkpoint time. Saving a checkpoint.
2020-06-09T04:14:14 INFO: Evaluation time. Running on full validation set...
2020-06-09T04:14:23 INFO: {"progress": "12000/22000", "val/total_loss": "4.3616", "val/hateful_memes/cross_entropy": "4.3616", "val/hateful_memes/accuracy": "0.5580", "val/hateful_memes/binary_f1": "0.3775", "val/hateful_memes/roc_auc": "0.6209", "num_updates": 12000, "epoch": 46, "iterations": 12000, "max_updates": 22000, "val_time": "08s 893ms", "best_update": 4000, "best_iteration": 4000, "best_val/hateful_memes/roc_auc": "0.648812"}
2020-06-09T04:14:26 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T04:17:30 INFO: {"progress": "12100/22000", "train/total_loss": "0.0016", "train/total_loss/avg": "0.0391", "train/hateful_memes/cross_entropy": "0.0016", "train/hateful_memes/cross_entropy/avg": "0.0391", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9866", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9772", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9994", "max mem": 12643.0, "experiment": "run", "epoch": 46, "num_updates": 12100, "iterations": 12100, "max_updates": 22000, "lr": "0.00002", "ups": "0.54", "time": "03m 06s 514ms", "time_since_start": "06h 27m 849ms", "eta": "05h 07m 44s 965ms"}
2020-06-09T04:17:32 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T04:20:36 INFO: {"progress": "12200/22000", "train/total_loss": "0.0017", "train/total_loss/avg": "0.0388", "train/hateful_memes/cross_entropy": "0.0017", "train/hateful_memes/cross_entropy/avg": "0.0388", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9867", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9774", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9994", "max mem": 12643.0, "experiment": "run", "epoch": 46, "num_updates": 12200, "iterations": 12200, "max_updates": 22000, "lr": "0.00002", "ups": "0.54", "time": "03m 05s 691ms", "time_since_start": "06h 30m 06s 540ms", "eta": "05h 03m 17s 773ms"}
2020-06-09T04:20:38 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T04:23:42 INFO: {"progress": "12300/22000", "train/total_loss": "0.0016", "train/total_loss/avg": "0.0385", "train/hateful_memes/cross_entropy": "0.0016", "train/hateful_memes/cross_entropy/avg": "0.0385", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9868", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9776", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9994", "max mem": 12643.0, "experiment": "run", "epoch": 47, "num_updates": 12300, "iterations": 12300, "max_updates": 22000, "lr": "0.00002", "ups": "0.54", "time": "03m 05s 892ms", "time_since_start": "06h 33m 12s 432ms", "eta": "05h 31s 528ms"}
2020-06-09T04:23:44 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T04:26:47 INFO: {"progress": "12400/22000", "train/total_loss": "0.0016", "train/total_loss/avg": "0.0382", "train/hateful_memes/cross_entropy": "0.0016", "train/hateful_memes/cross_entropy/avg": "0.0382", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9869", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9777", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9994", "max mem": 12643.0, "experiment": "run", "epoch": 47, "num_updates": 12400, "iterations": 12400, "max_updates": 22000, "lr": "0.00002", "ups": "0.54", "time": "03m 05s 473ms", "time_since_start": "06h 36m 17s 906ms", "eta": "04h 56m 45s 435ms"}
2020-06-09T04:26:49 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T04:29:53 INFO: {"progress": "12500/22000", "train/total_loss": "0.0016", "train/total_loss/avg": "0.0380", "train/hateful_memes/cross_entropy": "0.0016", "train/hateful_memes/cross_entropy/avg": "0.0380", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9870", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9779", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9994", "max mem": 12643.0, "experiment": "run", "epoch": 47, "num_updates": 12500, "iterations": 12500, "max_updates": 22000, "lr": "0.00002", "ups": "0.54", "time": "03m 05s 536ms", "time_since_start": "06h 39m 23s 442ms", "eta": "04h 53m 46s 003ms"}
2020-06-09T04:29:55 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T04:32:58 INFO: {"progress": "12600/22000", "train/total_loss": "0.0010", "train/total_loss/avg": "0.0377", "train/hateful_memes/cross_entropy": "0.0010", "train/hateful_memes/cross_entropy/avg": "0.0377", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9871", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9781", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9994", "max mem": 12643.0, "experiment": "run", "epoch": 48, "num_updates": 12600, "iterations": 12600, "max_updates": 22000, "lr": "0.00002", "ups": "0.54", "time": "03m 05s 558ms", "time_since_start": "06h 42m 29s 001ms", "eta": "04h 50m 42s 466ms"}
2020-06-09T04:33:00 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T04:36:04 INFO: {"progress": "12700/22000", "train/total_loss": "0.0010", "train/total_loss/avg": "0.0375", "train/hateful_memes/cross_entropy": "0.0010", "train/hateful_memes/cross_entropy/avg": "0.0375", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9872", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9783", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9994", "max mem": 12643.0, "experiment": "run", "epoch": 48, "num_updates": 12700, "iterations": 12700, "max_updates": 22000, "lr": "0.00002", "ups": "0.54", "time": "03m 05s 653ms", "time_since_start": "06h 45m 34s 655ms", "eta": "04h 47m 45s 809ms"}
2020-06-09T04:36:06 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T04:39:10 INFO: {"progress": "12800/22000", "train/total_loss": "0.0008", "train/total_loss/avg": "0.0372", "train/hateful_memes/cross_entropy": "0.0008", "train/hateful_memes/cross_entropy/avg": "0.0372", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9873", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9784", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9994", "max mem": 12643.0, "experiment": "run", "epoch": 49, "num_updates": 12800, "iterations": 12800, "max_updates": 22000, "lr": "0.00002", "ups": "0.54", "time": "03m 05s 716ms", "time_since_start": "06h 48m 40s 371ms", "eta": "04h 44m 45s 942ms"}
2020-06-09T04:39:12 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T04:42:15 INFO: {"progress": "12900/22000", "train/total_loss": "0.0008", "train/total_loss/avg": "0.0369", "train/hateful_memes/cross_entropy": "0.0008", "train/hateful_memes/cross_entropy/avg": "0.0369", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9874", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9786", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9994", "max mem": 12643.0, "experiment": "run", "epoch": 49, "num_updates": 12900, "iterations": 12900, "max_updates": 22000, "lr": "0.00002", "ups": "0.54", "time": "03m 05s 651ms", "time_since_start": "06h 51m 46s 023ms", "eta": "04h 41m 34s 331ms"}
2020-06-09T04:42:17 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T04:45:21 INFO: {"progress": "13000/22000", "train/total_loss": "0.0008", "train/total_loss/avg": "0.0366", "train/hateful_memes/cross_entropy": "0.0008", "train/hateful_memes/cross_entropy/avg": "0.0366", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9875", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9788", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9994", "max mem": 12643.0, "experiment": "run", "epoch": 49, "num_updates": 13000, "iterations": 13000, "max_updates": 22000, "lr": "0.00002", "ups": "0.54", "time": "03m 05s 644ms", "time_since_start": "06h 54m 51s 668ms", "eta": "04h 38m 27s 980ms"}
2020-06-09T04:45:21 INFO: Checkpoint time. Saving a checkpoint.
2020-06-09T04:45:42 INFO: Evaluation time. Running on full validation set...
2020-06-09T04:45:51 INFO: {"progress": "13000/22000", "val/total_loss": "4.3324", "val/hateful_memes/cross_entropy": "4.3324", "val/hateful_memes/accuracy": "0.5760", "val/hateful_memes/binary_f1": "0.4045", "val/hateful_memes/roc_auc": "0.6377", "num_updates": 13000, "epoch": 49, "iterations": 13000, "max_updates": 22000, "val_time": "08s 852ms", "best_update": 4000, "best_iteration": 4000, "best_val/hateful_memes/roc_auc": "0.648812"}
2020-06-09T04:45:53 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T04:48:57 INFO: {"progress": "13100/22000", "train/total_loss": "0.0008", "train/total_loss/avg": "0.0364", "train/hateful_memes/cross_entropy": "0.0008", "train/hateful_memes/cross_entropy/avg": "0.0364", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9876", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9789", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9994", "max mem": 12643.0, "experiment": "run", "epoch": 50, "num_updates": 13100, "iterations": 13100, "max_updates": 22000, "lr": "0.00002", "ups": "0.54", "time": "03m 06s 305ms", "time_since_start": "06h 58m 27s 839ms", "eta": "04h 36m 21s 173ms"}
2020-06-09T04:48:59 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T04:52:03 INFO: {"progress": "13200/22000", "train/total_loss": "0.0007", "train/total_loss/avg": "0.0361", "train/hateful_memes/cross_entropy": "0.0007", "train/hateful_memes/cross_entropy/avg": "0.0361", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9877", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9791", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9994", "max mem": 12643.0, "experiment": "run", "epoch": 50, "num_updates": 13200, "iterations": 13200, "max_updates": 22000, "lr": "0.00002", "ups": "0.54", "time": "03m 05s 734ms", "time_since_start": "07h 01m 33s 574ms", "eta": "04h 32m 24s 659ms"}
2020-06-09T04:52:05 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T04:55:08 INFO: {"progress": "13300/22000", "train/total_loss": "0.0006", "train/total_loss/avg": "0.0359", "train/hateful_memes/cross_entropy": "0.0006", "train/hateful_memes/cross_entropy/avg": "0.0359", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9877", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9792", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9994", "max mem": 12643.0, "experiment": "run", "epoch": 50, "num_updates": 13300, "iterations": 13300, "max_updates": 22000, "lr": "0.00002", "ups": "0.54", "time": "03m 05s 025ms", "time_since_start": "07h 04m 38s 600ms", "eta": "04h 28m 17s 255ms"}
2020-06-09T04:55:11 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T04:58:14 INFO: {"progress": "13400/22000", "train/total_loss": "0.0006", "train/total_loss/avg": "0.0357", "train/hateful_memes/cross_entropy": "0.0006", "train/hateful_memes/cross_entropy/avg": "0.0357", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9878", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9793", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9994", "max mem": 12643.0, "experiment": "run", "epoch": 51, "num_updates": 13400, "iterations": 13400, "max_updates": 22000, "lr": "0.00002", "ups": "0.54", "time": "03m 06s 377ms", "time_since_start": "07h 07m 44s 977ms", "eta": "04h 27m 08s 430ms"}
2020-06-09T04:58:16 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T05:01:20 INFO: {"progress": "13500/22000", "train/total_loss": "0.0006", "train/total_loss/avg": "0.0354", "train/hateful_memes/cross_entropy": "0.0006", "train/hateful_memes/cross_entropy/avg": "0.0354", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9879", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9795", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9994", "max mem": 12643.0, "experiment": "run", "epoch": 51, "num_updates": 13500, "iterations": 13500, "max_updates": 22000, "lr": "0.00002", "ups": "0.54", "time": "03m 05s 699ms", "time_since_start": "07h 10m 50s 676ms", "eta": "04h 23m 04s 418ms"}
2020-06-09T05:01:22 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T05:04:26 INFO: {"progress": "13600/22000", "train/total_loss": "0.0006", "train/total_loss/avg": "0.0352", "train/hateful_memes/cross_entropy": "0.0006", "train/hateful_memes/cross_entropy/avg": "0.0352", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9880", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9796", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9994", "max mem": 12643.0, "experiment": "run", "epoch": 52, "num_updates": 13600, "iterations": 13600, "max_updates": 22000, "lr": "0.00002", "ups": "0.54", "time": "03m 05s 683ms", "time_since_start": "07h 13m 56s 360ms", "eta": "04h 19m 57s 446ms"}
2020-06-09T05:04:28 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T05:07:31 INFO: {"progress": "13700/22000", "train/total_loss": "0.0006", "train/total_loss/avg": "0.0350", "train/hateful_memes/cross_entropy": "0.0006", "train/hateful_memes/cross_entropy/avg": "0.0350", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9881", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9798", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9994", "max mem": 12643.0, "experiment": "run", "epoch": 52, "num_updates": 13700, "iterations": 13700, "max_updates": 22000, "lr": "0.00002", "ups": "0.54", "time": "03m 05s 552ms", "time_since_start": "07h 17m 01s 913ms", "eta": "04h 16m 40s 896ms"}
2020-06-09T05:07:33 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T05:10:37 INFO: {"progress": "13800/22000", "train/total_loss": "0.0006", "train/total_loss/avg": "0.0347", "train/hateful_memes/cross_entropy": "0.0006", "train/hateful_memes/cross_entropy/avg": "0.0347", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9882", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9799", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9994", "max mem": 12643.0, "experiment": "run", "epoch": 52, "num_updates": 13800, "iterations": 13800, "max_updates": 22000, "lr": "0.00002", "ups": "0.54", "time": "03m 05s 492ms", "time_since_start": "07h 20m 07s 405ms", "eta": "04h 13m 30s 379ms"}
2020-06-09T05:10:39 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T05:13:42 INFO: {"progress": "13900/22000", "train/total_loss": "0.0008", "train/total_loss/avg": "0.0345", "train/hateful_memes/cross_entropy": "0.0008", "train/hateful_memes/cross_entropy/avg": "0.0345", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9883", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9801", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9994", "max mem": 12643.0, "experiment": "run", "epoch": 53, "num_updates": 13900, "iterations": 13900, "max_updates": 22000, "lr": "0.00002", "ups": "0.54", "time": "03m 05s 709ms", "time_since_start": "07h 23m 13s 115ms", "eta": "04h 10m 42s 472ms"}
2020-06-09T05:13:44 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T05:16:48 INFO: {"progress": "14000/22000", "train/total_loss": "0.0008", "train/total_loss/avg": "0.0344", "train/hateful_memes/cross_entropy": "0.0008", "train/hateful_memes/cross_entropy/avg": "0.0344", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9884", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9802", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9994", "max mem": 12643.0, "experiment": "run", "epoch": 53, "num_updates": 14000, "iterations": 14000, "max_updates": 22000, "lr": "0.00002", "ups": "0.54", "time": "03m 05s 574ms", "time_since_start": "07h 26m 18s 689ms", "eta": "04h 07m 25s 938ms"}
2020-06-09T05:16:48 INFO: Checkpoint time. Saving a checkpoint.
2020-06-09T05:17:11 INFO: Evaluation time. Running on full validation set...
2020-06-09T05:17:20 INFO: {"progress": "14000/22000", "val/total_loss": "3.8765", "val/hateful_memes/cross_entropy": "3.8765", "val/hateful_memes/accuracy": "0.6000", "val/hateful_memes/binary_f1": "0.4709", "val/hateful_memes/roc_auc": "0.6409", "num_updates": 14000, "epoch": 53, "iterations": 14000, "max_updates": 22000, "val_time": "08s 871ms", "best_update": 4000, "best_iteration": 4000, "best_val/hateful_memes/roc_auc": "0.648812"}
2020-06-09T05:17:22 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T05:20:27 INFO: {"progress": "14100/22000", "train/total_loss": "0.0008", "train/total_loss/avg": "0.0341", "train/hateful_memes/cross_entropy": "0.0008", "train/hateful_memes/cross_entropy/avg": "0.0341", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9884", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9804", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9995", "max mem": 12643.0, "experiment": "run", "epoch": 54, "num_updates": 14100, "iterations": 14100, "max_updates": 22000, "lr": "0.00002", "ups": "0.54", "time": "03m 06s 754ms", "time_since_start": "07h 29m 57s 304ms", "eta": "04h 05m 53s 595ms"}
2020-06-09T05:20:29 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T05:23:32 INFO: {"progress": "14200/22000", "train/total_loss": "0.0007", "train/total_loss/avg": "0.0339", "train/hateful_memes/cross_entropy": "0.0007", "train/hateful_memes/cross_entropy/avg": "0.0339", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9885", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9805", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9995", "max mem": 12643.0, "experiment": "run", "epoch": 54, "num_updates": 14200, "iterations": 14200, "max_updates": 22000, "lr": "0.00002", "ups": "0.54", "time": "03m 05s 765ms", "time_since_start": "07h 33m 03s 070ms", "eta": "04h 01m 29s 731ms"}
2020-06-09T05:23:34 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T05:26:38 INFO: {"progress": "14300/22000", "train/total_loss": "0.0007", "train/total_loss/avg": "0.0337", "train/hateful_memes/cross_entropy": "0.0007", "train/hateful_memes/cross_entropy/avg": "0.0337", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9886", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9806", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9995", "max mem": 12643.0, "experiment": "run", "epoch": 54, "num_updates": 14300, "iterations": 14300, "max_updates": 22000, "lr": "0.00002", "ups": "0.54", "time": "03m 05s 566ms", "time_since_start": "07h 36m 08s 637ms", "eta": "03h 58m 08s 643ms"}
2020-06-09T05:26:40 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T05:29:44 INFO: {"progress": "14400/22000", "train/total_loss": "0.0008", "train/total_loss/avg": "0.0335", "train/hateful_memes/cross_entropy": "0.0008", "train/hateful_memes/cross_entropy/avg": "0.0335", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9887", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9808", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9995", "max mem": 12643.0, "experiment": "run", "epoch": 55, "num_updates": 14400, "iterations": 14400, "max_updates": 22000, "lr": "0.00002", "ups": "0.54", "time": "03m 05s 804ms", "time_since_start": "07h 39m 14s 441ms", "eta": "03h 55m 21s 166ms"}
2020-06-09T05:29:46 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T05:32:50 INFO: {"progress": "14500/22000", "train/total_loss": "0.0008", "train/total_loss/avg": "0.0336", "train/hateful_memes/cross_entropy": "0.0008", "train/hateful_memes/cross_entropy/avg": "0.0336", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9885", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9807", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9995", "max mem": 12643.0, "experiment": "run", "epoch": 55, "num_updates": 14500, "iterations": 14500, "max_updates": 22000, "lr": "0.00002", "ups": "0.54", "time": "03m 05s 809ms", "time_since_start": "07h 42m 20s 251ms", "eta": "03h 52m 15s 693ms"}
2020-06-09T05:32:51 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T05:35:55 INFO: {"progress": "14600/22000", "train/total_loss": "0.0008", "train/total_loss/avg": "0.0334", "train/hateful_memes/cross_entropy": "0.0008", "train/hateful_memes/cross_entropy/avg": "0.0334", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9886", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9808", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9995", "max mem": 12643.0, "experiment": "run", "epoch": 55, "num_updates": 14600, "iterations": 14600, "max_updates": 22000, "lr": "0.00002", "ups": "0.54", "time": "03m 05s 845ms", "time_since_start": "07h 45m 26s 096ms", "eta": "03h 49m 12s 534ms"}
2020-06-09T05:35:57 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T05:39:01 INFO: {"progress": "14700/22000", "train/total_loss": "0.0008", "train/total_loss/avg": "0.0332", "train/hateful_memes/cross_entropy": "0.0008", "train/hateful_memes/cross_entropy/avg": "0.0332", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9887", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9809", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9995", "max mem": 12643.0, "experiment": "run", "epoch": 56, "num_updates": 14700, "iterations": 14700, "max_updates": 22000, "lr": "0.00002", "ups": "0.54", "time": "03m 05s 883ms", "time_since_start": "07h 48m 31s 979ms", "eta": "03h 46m 09s 478ms"}
2020-06-09T05:39:03 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T05:42:07 INFO: {"progress": "14800/22000", "train/total_loss": "0.0008", "train/total_loss/avg": "0.0330", "train/hateful_memes/cross_entropy": "0.0008", "train/hateful_memes/cross_entropy/avg": "0.0330", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9888", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9811", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9995", "max mem": 12643.0, "experiment": "run", "epoch": 56, "num_updates": 14800, "iterations": 14800, "max_updates": 22000, "lr": "0.00002", "ups": "0.54", "time": "03m 05s 625ms", "time_since_start": "07h 51m 37s 605ms", "eta": "03h 42m 45s 033ms"}
2020-06-09T05:42:09 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T05:45:13 INFO: {"progress": "14900/22000", "train/total_loss": "0.0007", "train/total_loss/avg": "0.0328", "train/hateful_memes/cross_entropy": "0.0007", "train/hateful_memes/cross_entropy/avg": "0.0328", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9889", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9812", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9995", "max mem": 12643.0, "experiment": "run", "epoch": 57, "num_updates": 14900, "iterations": 14900, "max_updates": 22000, "lr": "0.00002", "ups": "0.54", "time": "03m 05s 865ms", "time_since_start": "07h 54m 43s 470ms", "eta": "03h 39m 56s 437ms"}
2020-06-09T05:45:15 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T05:48:19 INFO: {"progress": "15000/22000", "train/total_loss": "0.0008", "train/total_loss/avg": "0.0326", "train/hateful_memes/cross_entropy": "0.0008", "train/hateful_memes/cross_entropy/avg": "0.0326", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9889", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9813", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9995", "max mem": 12643.0, "experiment": "run", "epoch": 57, "num_updates": 15000, "iterations": 15000, "max_updates": 22000, "lr": "0.00002", "ups": "0.54", "time": "03m 05s 819ms", "time_since_start": "07h 57m 49s 289ms", "eta": "03h 36m 47s 345ms"}
2020-06-09T05:48:19 INFO: Checkpoint time. Saving a checkpoint.
2020-06-09T05:48:38 INFO: Evaluation time. Running on full validation set...
2020-06-09T05:48:47 INFO: {"progress": "15000/22000", "val/total_loss": "4.4505", "val/hateful_memes/cross_entropy": "4.4505", "val/hateful_memes/accuracy": "0.5700", "val/hateful_memes/binary_f1": "0.4011", "val/hateful_memes/roc_auc": "0.6291", "num_updates": 15000, "epoch": 57, "iterations": 15000, "max_updates": 22000, "val_time": "09s 144ms", "best_update": 4000, "best_iteration": 4000, "best_val/hateful_memes/roc_auc": "0.648812"}
2020-06-09T05:48:50 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T05:51:54 INFO: {"progress": "15100/22000", "train/total_loss": "0.0007", "train/total_loss/avg": "0.0323", "train/hateful_memes/cross_entropy": "0.0007", "train/hateful_memes/cross_entropy/avg": "0.0323", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9890", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9814", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9995", "max mem": 12643.0, "experiment": "run", "epoch": 57, "num_updates": 15100, "iterations": 15100, "max_updates": 22000, "lr": "0.00002", "ups": "0.54", "time": "03m 06s 227ms", "time_since_start": "08h 01m 24s 653ms", "eta": "03h 34m 09s 674ms"}
2020-06-09T05:51:56 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T05:55:00 INFO: {"progress": "15200/22000", "train/total_loss": "0.0007", "train/total_loss/avg": "0.0321", "train/hateful_memes/cross_entropy": "0.0007", "train/hateful_memes/cross_entropy/avg": "0.0321", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9891", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9816", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9995", "max mem": 12643.0, "experiment": "run", "epoch": 58, "num_updates": 15200, "iterations": 15200, "max_updates": 22000, "lr": "0.00002", "ups": "0.54", "time": "03m 05s 769ms", "time_since_start": "08h 04m 30s 423ms", "eta": "03h 30m 32s 344ms"}
2020-06-09T05:55:02 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T05:58:06 INFO: {"progress": "15300/22000", "train/total_loss": "0.0007", "train/total_loss/avg": "0.0319", "train/hateful_memes/cross_entropy": "0.0007", "train/hateful_memes/cross_entropy/avg": "0.0319", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9891", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9817", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9995", "max mem": 12643.0, "experiment": "run", "epoch": 58, "num_updates": 15300, "iterations": 15300, "max_updates": 22000, "lr": "0.00002", "ups": "0.54", "time": "03m 05s 782ms", "time_since_start": "08h 07m 36s 206ms", "eta": "03h 27m 27s 430ms"}
2020-06-09T05:58:07 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T06:01:11 INFO: {"progress": "15400/22000", "train/total_loss": "0.0007", "train/total_loss/avg": "0.0317", "train/hateful_memes/cross_entropy": "0.0007", "train/hateful_memes/cross_entropy/avg": "0.0317", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9892", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9818", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9995", "max mem": 12643.0, "experiment": "run", "epoch": 58, "num_updates": 15400, "iterations": 15400, "max_updates": 22000, "lr": "0.00002", "ups": "0.54", "time": "03m 05s 833ms", "time_since_start": "08h 10m 42s 039ms", "eta": "03h 24m 25s 011ms"}
2020-06-09T06:01:13 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T06:04:17 INFO: {"progress": "15500/22000", "train/total_loss": "0.0007", "train/total_loss/avg": "0.0315", "train/hateful_memes/cross_entropy": "0.0007", "train/hateful_memes/cross_entropy/avg": "0.0315", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9893", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9819", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9995", "max mem": 12643.0, "experiment": "run", "epoch": 59, "num_updates": 15500, "iterations": 15500, "max_updates": 22000, "lr": "0.00002", "ups": "0.54", "time": "03m 06s 036ms", "time_since_start": "08h 13m 48s 076ms", "eta": "03h 21m 32s 403ms"}
2020-06-09T06:04:19 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T06:07:23 INFO: {"progress": "15600/22000", "train/total_loss": "0.0005", "train/total_loss/avg": "0.0313", "train/hateful_memes/cross_entropy": "0.0005", "train/hateful_memes/cross_entropy/avg": "0.0313", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9894", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9820", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9995", "max mem": 12643.0, "experiment": "run", "epoch": 59, "num_updates": 15600, "iterations": 15600, "max_updates": 22000, "lr": "0.00002", "ups": "0.54", "time": "03m 05s 739ms", "time_since_start": "08h 16m 53s 815ms", "eta": "03h 18m 07s 304ms"}
2020-06-09T06:07:25 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T06:10:29 INFO: {"progress": "15700/22000", "train/total_loss": "0.0003", "train/total_loss/avg": "0.0311", "train/hateful_memes/cross_entropy": "0.0003", "train/hateful_memes/cross_entropy/avg": "0.0311", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9894", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9821", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9995", "max mem": 12643.0, "experiment": "run", "epoch": 60, "num_updates": 15700, "iterations": 15700, "max_updates": 22000, "lr": "0.00002", "ups": "0.54", "time": "03m 05s 853ms", "time_since_start": "08h 19m 59s 669ms", "eta": "03h 15m 08s 770ms"}
2020-06-09T06:10:31 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T06:13:35 INFO: {"progress": "15800/22000", "train/total_loss": "0.0003", "train/total_loss/avg": "0.0309", "train/hateful_memes/cross_entropy": "0.0003", "train/hateful_memes/cross_entropy/avg": "0.0309", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9895", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9823", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9995", "max mem": 12643.0, "experiment": "run", "epoch": 60, "num_updates": 15800, "iterations": 15800, "max_updates": 22000, "lr": "0.00002", "ups": "0.54", "time": "03m 06s 053ms", "time_since_start": "08h 23m 05s 722ms", "eta": "03h 12m 15s 321ms"}
2020-06-09T06:13:37 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T06:16:41 INFO: {"progress": "15900/22000", "train/total_loss": "0.0003", "train/total_loss/avg": "0.0307", "train/hateful_memes/cross_entropy": "0.0003", "train/hateful_memes/cross_entropy/avg": "0.0307", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9896", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9824", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9995", "max mem": 12643.0, "experiment": "run", "epoch": 60, "num_updates": 15900, "iterations": 15900, "max_updates": 22000, "lr": "0.00002", "ups": "0.54", "time": "03m 05s 687ms", "time_since_start": "08h 26m 11s 410ms", "eta": "03h 08m 46s 941ms"}
2020-06-09T06:16:43 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T06:19:47 INFO: {"progress": "16000/22000", "train/total_loss": "0.0003", "train/total_loss/avg": "0.0305", "train/hateful_memes/cross_entropy": "0.0003", "train/hateful_memes/cross_entropy/avg": "0.0305", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9896", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9825", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9995", "max mem": 12643.0, "experiment": "run", "epoch": 61, "num_updates": 16000, "iterations": 16000, "max_updates": 22000, "lr": "0.00002", "ups": "0.54", "time": "03m 05s 796ms", "time_since_start": "08h 29m 17s 207ms", "eta": "03h 05m 47s 804ms"}
2020-06-09T06:19:47 INFO: Checkpoint time. Saving a checkpoint.
2020-06-09T06:20:07 INFO: Evaluation time. Running on full validation set...
2020-06-09T06:20:16 INFO: {"progress": "16000/22000", "val/total_loss": "4.8441", "val/hateful_memes/cross_entropy": "4.8441", "val/hateful_memes/accuracy": "0.5840", "val/hateful_memes/binary_f1": "0.4378", "val/hateful_memes/roc_auc": "0.6232", "num_updates": 16000, "epoch": 61, "iterations": 16000, "max_updates": 22000, "val_time": "08s 890ms", "best_update": 4000, "best_iteration": 4000, "best_val/hateful_memes/roc_auc": "0.648812"}
2020-06-09T06:20:19 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T06:23:23 INFO: {"progress": "16100/22000", "train/total_loss": "0.0003", "train/total_loss/avg": "0.0304", "train/hateful_memes/cross_entropy": "0.0003", "train/hateful_memes/cross_entropy/avg": "0.0304", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9897", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9826", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9995", "max mem": 12643.0, "experiment": "run", "epoch": 61, "num_updates": 16100, "iterations": 16100, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 147ms", "time_since_start": "08h 32m 53s 517ms", "eta": "03h 03m 02s 677ms"}
2020-06-09T06:23:25 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T06:26:28 INFO: {"progress": "16200/22000", "train/total_loss": "0.0003", "train/total_loss/avg": "0.0302", "train/hateful_memes/cross_entropy": "0.0003", "train/hateful_memes/cross_entropy/avg": "0.0302", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9898", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9827", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9995", "max mem": 12643.0, "experiment": "run", "epoch": 61, "num_updates": 16200, "iterations": 16200, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 05s 514ms", "time_since_start": "08h 35m 59s 031ms", "eta": "02h 59m 19s 842ms"}
2020-06-09T06:26:30 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T06:29:34 INFO: {"progress": "16300/22000", "train/total_loss": "0.0003", "train/total_loss/avg": "0.0300", "train/hateful_memes/cross_entropy": "0.0003", "train/hateful_memes/cross_entropy/avg": "0.0300", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9898", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9828", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9995", "max mem": 12643.0, "experiment": "run", "epoch": 62, "num_updates": 16300, "iterations": 16300, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 05s 788ms", "time_since_start": "08h 39m 04s 820ms", "eta": "02h 56m 29s 964ms"}
2020-06-09T06:29:36 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T06:32:40 INFO: {"progress": "16400/22000", "train/total_loss": "0.0003", "train/total_loss/avg": "0.0298", "train/hateful_memes/cross_entropy": "0.0003", "train/hateful_memes/cross_entropy/avg": "0.0298", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9899", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9829", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9995", "max mem": 12643.0, "experiment": "run", "epoch": 62, "num_updates": 16400, "iterations": 16400, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 05s 570ms", "time_since_start": "08h 42m 10s 390ms", "eta": "02h 53m 11s 925ms"}
2020-06-09T06:32:42 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T06:35:46 INFO: {"progress": "16500/22000", "train/total_loss": "0.0003", "train/total_loss/avg": "0.0296", "train/hateful_memes/cross_entropy": "0.0003", "train/hateful_memes/cross_entropy/avg": "0.0296", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9899", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9830", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9995", "max mem": 12643.0, "experiment": "run", "epoch": 63, "num_updates": 16500, "iterations": 16500, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 05s 954ms", "time_since_start": "08h 45m 16s 345ms", "eta": "02h 50m 27s 525ms"}
2020-06-09T06:35:48 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T06:38:51 INFO: {"progress": "16600/22000", "train/total_loss": "0.0002", "train/total_loss/avg": "0.0294", "train/hateful_memes/cross_entropy": "0.0002", "train/hateful_memes/cross_entropy/avg": "0.0294", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9900", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9831", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9995", "max mem": 12643.0, "experiment": "run", "epoch": 63, "num_updates": 16600, "iterations": 16600, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 05s 745ms", "time_since_start": "08h 48m 22s 091ms", "eta": "02h 47m 10s 250ms"}
2020-06-09T06:38:53 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T06:41:57 INFO: {"progress": "16700/22000", "train/total_loss": "0.0002", "train/total_loss/avg": "0.0293", "train/hateful_memes/cross_entropy": "0.0002", "train/hateful_memes/cross_entropy/avg": "0.0293", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9901", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9832", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9995", "max mem": 12643.0, "experiment": "run", "epoch": 63, "num_updates": 16700, "iterations": 16700, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 05s 589ms", "time_since_start": "08h 51m 27s 680ms", "eta": "02h 43m 56s 236ms"}
2020-06-09T06:41:59 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T06:45:03 INFO: {"progress": "16800/22000", "train/total_loss": "0.0002", "train/total_loss/avg": "0.0291", "train/hateful_memes/cross_entropy": "0.0002", "train/hateful_memes/cross_entropy/avg": "0.0291", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9901", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9833", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9995", "max mem": 12643.0, "experiment": "run", "epoch": 64, "num_updates": 16800, "iterations": 16800, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 05s 837ms", "time_since_start": "08h 54m 33s 518ms", "eta": "02h 41m 03s 559ms"}
2020-06-09T06:45:05 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T06:48:08 INFO: {"progress": "16900/22000", "train/total_loss": "0.0003", "train/total_loss/avg": "0.0289", "train/hateful_memes/cross_entropy": "0.0003", "train/hateful_memes/cross_entropy/avg": "0.0289", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9902", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9834", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9995", "max mem": 12643.0, "experiment": "run", "epoch": 64, "num_updates": 16900, "iterations": 16900, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 05s 584ms", "time_since_start": "08h 57m 39s 103ms", "eta": "02h 37m 44s 824ms"}
2020-06-09T06:48:10 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T06:51:14 INFO: {"progress": "17000/22000", "train/total_loss": "0.0003", "train/total_loss/avg": "0.0288", "train/hateful_memes/cross_entropy": "0.0003", "train/hateful_memes/cross_entropy/avg": "0.0288", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9902", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9835", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9995", "max mem": 12643.0, "experiment": "run", "epoch": 64, "num_updates": 17000, "iterations": 17000, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 05s 815ms", "time_since_start": "09h 44s 918ms", "eta": "02h 34m 50s 789ms"}
2020-06-09T06:51:14 INFO: Checkpoint time. Saving a checkpoint.
2020-06-09T06:51:36 INFO: Evaluation time. Running on full validation set...
2020-06-09T06:51:47 INFO: {"progress": "17000/22000", "val/total_loss": "4.9556", "val/hateful_memes/cross_entropy": "4.9556", "val/hateful_memes/accuracy": "0.5740", "val/hateful_memes/binary_f1": "0.4164", "val/hateful_memes/roc_auc": "0.6258", "num_updates": 17000, "epoch": 64, "iterations": 17000, "max_updates": 22000, "val_time": "10s 624ms", "best_update": 4000, "best_iteration": 4000, "best_val/hateful_memes/roc_auc": "0.648812"}
2020-06-09T06:51:49 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T06:54:54 INFO: {"progress": "17100/22000", "train/total_loss": "0.0003", "train/total_loss/avg": "0.0286", "train/hateful_memes/cross_entropy": "0.0003", "train/hateful_memes/cross_entropy/avg": "0.0286", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9903", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9836", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9995", "max mem": 12643.0, "experiment": "run", "epoch": 65, "num_updates": 17100, "iterations": 17100, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 445ms", "time_since_start": "09h 04m 24s 420ms", "eta": "02h 32m 15s 808ms"}
2020-06-09T06:54:56 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T06:57:59 INFO: {"progress": "17200/22000", "train/total_loss": "0.0003", "train/total_loss/avg": "0.0285", "train/hateful_memes/cross_entropy": "0.0003", "train/hateful_memes/cross_entropy/avg": "0.0285", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9903", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9837", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9996", "max mem": 12643.0, "experiment": "run", "epoch": 65, "num_updates": 17200, "iterations": 17200, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 05s 652ms", "time_since_start": "09h 07m 30s 073ms", "eta": "02h 28m 31s 327ms"}
2020-06-09T06:58:01 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T07:01:05 INFO: {"progress": "17300/22000", "train/total_loss": "0.0003", "train/total_loss/avg": "0.0283", "train/hateful_memes/cross_entropy": "0.0003", "train/hateful_memes/cross_entropy/avg": "0.0283", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9904", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9838", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9996", "max mem": 12643.0, "experiment": "run", "epoch": 66, "num_updates": 17300, "iterations": 17300, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 05s 506ms", "time_since_start": "09h 10m 35s 580ms", "eta": "02h 25m 18s 811ms"}
2020-06-09T07:01:07 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T07:04:11 INFO: {"progress": "17400/22000", "train/total_loss": "0.0003", "train/total_loss/avg": "0.0281", "train/hateful_memes/cross_entropy": "0.0003", "train/hateful_memes/cross_entropy/avg": "0.0281", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9905", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9839", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9996", "max mem": 12643.0, "experiment": "run", "epoch": 66, "num_updates": 17400, "iterations": 17400, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 05s 764ms", "time_since_start": "09h 13m 41s 344ms", "eta": "02h 22m 25s 153ms"}
2020-06-09T07:04:13 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T07:07:17 INFO: {"progress": "17500/22000", "train/total_loss": "0.0003", "train/total_loss/avg": "0.0280", "train/hateful_memes/cross_entropy": "0.0003", "train/hateful_memes/cross_entropy/avg": "0.0280", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9905", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9840", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9996", "max mem": 12643.0, "experiment": "run", "epoch": 66, "num_updates": 17500, "iterations": 17500, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 05s 823ms", "time_since_start": "09h 16m 47s 167ms", "eta": "02h 19m 22s 057ms"}
2020-06-09T07:07:18 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T07:10:22 INFO: {"progress": "17600/22000", "train/total_loss": "0.0003", "train/total_loss/avg": "0.0278", "train/hateful_memes/cross_entropy": "0.0003", "train/hateful_memes/cross_entropy/avg": "0.0278", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9906", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9841", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9996", "max mem": 12643.0, "experiment": "run", "epoch": 67, "num_updates": 17600, "iterations": 17600, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 05s 795ms", "time_since_start": "09h 19m 52s 963ms", "eta": "02h 16m 14s 987ms"}
2020-06-09T07:10:24 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T07:13:28 INFO: {"progress": "17700/22000", "train/total_loss": "0.0003", "train/total_loss/avg": "0.0277", "train/hateful_memes/cross_entropy": "0.0003", "train/hateful_memes/cross_entropy/avg": "0.0277", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9906", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9842", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9996", "max mem": 12643.0, "experiment": "run", "epoch": 67, "num_updates": 17700, "iterations": 17700, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 05s 931ms", "time_since_start": "09h 22m 58s 895ms", "eta": "02h 13m 15s 076ms"}
2020-06-09T07:13:30 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T07:16:34 INFO: {"progress": "17800/22000", "train/total_loss": "0.0003", "train/total_loss/avg": "0.0275", "train/hateful_memes/cross_entropy": "0.0003", "train/hateful_memes/cross_entropy/avg": "0.0275", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9907", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9843", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9996", "max mem": 12643.0, "experiment": "run", "epoch": 67, "num_updates": 17800, "iterations": 17800, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 05s 575ms", "time_since_start": "09h 26m 04s 470ms", "eta": "02h 09m 54s 179ms"}
2020-06-09T07:16:36 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T07:19:40 INFO: {"progress": "17900/22000", "train/total_loss": "0.0003", "train/total_loss/avg": "0.0274", "train/hateful_memes/cross_entropy": "0.0003", "train/hateful_memes/cross_entropy/avg": "0.0274", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9907", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9843", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9996", "max mem": 12643.0, "experiment": "run", "epoch": 68, "num_updates": 17900, "iterations": 17900, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 05s 858ms", "time_since_start": "09h 29m 10s 329ms", "eta": "02h 07m 208ms"}
2020-06-09T07:19:42 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T07:22:45 INFO: {"progress": "18000/22000", "train/total_loss": "0.0003", "train/total_loss/avg": "0.0272", "train/hateful_memes/cross_entropy": "0.0003", "train/hateful_memes/cross_entropy/avg": "0.0272", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9908", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9844", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9996", "max mem": 12643.0, "experiment": "run", "epoch": 68, "num_updates": 18000, "iterations": 18000, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 05s 662ms", "time_since_start": "09h 32m 15s 991ms", "eta": "02h 03m 46s 490ms"}
2020-06-09T07:22:45 INFO: Checkpoint time. Saving a checkpoint.
2020-06-09T07:23:06 INFO: Evaluation time. Running on full validation set...
2020-06-09T07:23:14 INFO: {"progress": "18000/22000", "val/total_loss": "4.9807", "val/hateful_memes/cross_entropy": "4.9807", "val/hateful_memes/accuracy": "0.5700", "val/hateful_memes/binary_f1": "0.3944", "val/hateful_memes/roc_auc": "0.6248", "num_updates": 18000, "epoch": 68, "iterations": 18000, "max_updates": 22000, "val_time": "08s 909ms", "best_update": 4000, "best_iteration": 4000, "best_val/hateful_memes/roc_auc": "0.648812"}
2020-06-09T07:23:17 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T07:26:22 INFO: {"progress": "18100/22000", "train/total_loss": "0.0002", "train/total_loss/avg": "0.0271", "train/hateful_memes/cross_entropy": "0.0002", "train/hateful_memes/cross_entropy/avg": "0.0271", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9908", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9845", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9996", "max mem": 12643.0, "experiment": "run", "epoch": 69, "num_updates": 18100, "iterations": 18100, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 693ms", "time_since_start": "09h 35m 52s 185ms", "eta": "02h 01m 21s 060ms"}
2020-06-09T07:26:23 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T07:29:28 INFO: {"progress": "18200/22000", "train/total_loss": "0.0003", "train/total_loss/avg": "0.0269", "train/hateful_memes/cross_entropy": "0.0003", "train/hateful_memes/cross_entropy/avg": "0.0269", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9909", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9846", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9996", "max mem": 12643.0, "experiment": "run", "epoch": 69, "num_updates": 18200, "iterations": 18200, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 046ms", "time_since_start": "09h 38m 58s 231ms", "eta": "01h 57m 49s 758ms"}
2020-06-09T07:29:29 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T07:32:33 INFO: {"progress": "18300/22000", "train/total_loss": "0.0003", "train/total_loss/avg": "0.0268", "train/hateful_memes/cross_entropy": "0.0003", "train/hateful_memes/cross_entropy/avg": "0.0268", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9909", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9847", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9996", "max mem": 12643.0, "experiment": "run", "epoch": 69, "num_updates": 18300, "iterations": 18300, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 05s 511ms", "time_since_start": "09h 42m 03s 742ms", "eta": "01h 54m 23s 914ms"}
2020-06-09T07:32:35 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T07:35:39 INFO: {"progress": "18400/22000", "train/total_loss": "0.0002", "train/total_loss/avg": "0.0266", "train/hateful_memes/cross_entropy": "0.0002", "train/hateful_memes/cross_entropy/avg": "0.0266", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9910", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9848", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9996", "max mem": 12643.0, "experiment": "run", "epoch": 70, "num_updates": 18400, "iterations": 18400, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 039ms", "time_since_start": "09h 45m 09s 782ms", "eta": "01h 51m 37s 418ms"}
2020-06-09T07:35:41 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T07:38:45 INFO: {"progress": "18500/22000", "train/total_loss": "0.0002", "train/total_loss/avg": "0.0265", "train/hateful_memes/cross_entropy": "0.0002", "train/hateful_memes/cross_entropy/avg": "0.0265", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9910", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9849", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9996", "max mem": 12643.0, "experiment": "run", "epoch": 70, "num_updates": 18500, "iterations": 18500, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 05s 606ms", "time_since_start": "09h 48m 15s 389ms", "eta": "01h 48m 16s 240ms"}
2020-06-09T07:38:47 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T07:41:50 INFO: {"progress": "18600/22000", "train/total_loss": "0.0003", "train/total_loss/avg": "0.0263", "train/hateful_memes/cross_entropy": "0.0003", "train/hateful_memes/cross_entropy/avg": "0.0263", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9911", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9849", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9996", "max mem": 12643.0, "experiment": "run", "epoch": 70, "num_updates": 18600, "iterations": 18600, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 05s 626ms", "time_since_start": "09h 51m 21s 015ms", "eta": "01h 45m 11s 285ms"}
2020-06-09T07:41:52 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T07:44:56 INFO: {"progress": "18700/22000", "train/total_loss": "0.0003", "train/total_loss/avg": "0.0262", "train/hateful_memes/cross_entropy": "0.0003", "train/hateful_memes/cross_entropy/avg": "0.0262", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9911", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9850", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9996", "max mem": 12643.0, "experiment": "run", "epoch": 71, "num_updates": 18700, "iterations": 18700, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 05s 851ms", "time_since_start": "09h 54m 26s 866ms", "eta": "01h 42m 13s 095ms"}
2020-06-09T07:44:58 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T07:48:02 INFO: {"progress": "18800/22000", "train/total_loss": "0.0002", "train/total_loss/avg": "0.0261", "train/hateful_memes/cross_entropy": "0.0002", "train/hateful_memes/cross_entropy/avg": "0.0261", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9912", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9851", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9996", "max mem": 12643.0, "experiment": "run", "epoch": 71, "num_updates": 18800, "iterations": 18800, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 05s 386ms", "time_since_start": "09h 57m 32s 252ms", "eta": "01h 38m 52s 356ms"}
2020-06-09T07:48:03 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T07:51:07 INFO: {"progress": "18900/22000", "train/total_loss": "0.0002", "train/total_loss/avg": "0.0259", "train/hateful_memes/cross_entropy": "0.0002", "train/hateful_memes/cross_entropy/avg": "0.0259", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9912", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9852", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9996", "max mem": 12643.0, "experiment": "run", "epoch": 72, "num_updates": 18900, "iterations": 18900, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 05s 860ms", "time_since_start": "10h 38s 112ms", "eta": "01h 36m 01s 663ms"}
2020-06-09T07:51:09 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T07:54:13 INFO: {"progress": "19000/22000", "train/total_loss": "0.0002", "train/total_loss/avg": "0.0258", "train/hateful_memes/cross_entropy": "0.0002", "train/hateful_memes/cross_entropy/avg": "0.0258", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9913", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9852", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9996", "max mem": 12643.0, "experiment": "run", "epoch": 72, "num_updates": 19000, "iterations": 19000, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 05s 756ms", "time_since_start": "10h 03m 43s 869ms", "eta": "01h 32m 52s 709ms"}
2020-06-09T07:54:13 INFO: Checkpoint time. Saving a checkpoint.
2020-06-09T07:54:34 INFO: Evaluation time. Running on full validation set...
2020-06-09T07:54:43 INFO: {"progress": "19000/22000", "val/total_loss": "4.5737", "val/hateful_memes/cross_entropy": "4.5737", "val/hateful_memes/accuracy": "0.5900", "val/hateful_memes/binary_f1": "0.4562", "val/hateful_memes/roc_auc": "0.6212", "num_updates": 19000, "epoch": 72, "iterations": 19000, "max_updates": 22000, "val_time": "09s 404ms", "best_update": 4000, "best_iteration": 4000, "best_val/hateful_memes/roc_auc": "0.648812"}
2020-06-09T07:54:45 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T07:57:50 INFO: {"progress": "19100/22000", "train/total_loss": "0.0001", "train/total_loss/avg": "0.0257", "train/hateful_memes/cross_entropy": "0.0001", "train/hateful_memes/cross_entropy/avg": "0.0257", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9913", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9853", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9996", "max mem": 12643.0, "experiment": "run", "epoch": 72, "num_updates": 19100, "iterations": 19100, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 430ms", "time_since_start": "10h 07m 20s 526ms", "eta": "01h 30m 06s 471ms"}
2020-06-09T07:57:52 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T08:00:56 INFO: {"progress": "19200/22000", "train/total_loss": "0.0001", "train/total_loss/avg": "0.0255", "train/hateful_memes/cross_entropy": "0.0001", "train/hateful_memes/cross_entropy/avg": "0.0255", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9914", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9854", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9996", "max mem": 12643.0, "experiment": "run", "epoch": 73, "num_updates": 19200, "iterations": 19200, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 229ms", "time_since_start": "10h 10m 26s 756ms", "eta": "01h 26m 54s 425ms"}
2020-06-09T08:00:58 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T08:04:02 INFO: {"progress": "19300/22000", "train/total_loss": "0.0001", "train/total_loss/avg": "0.0254", "train/hateful_memes/cross_entropy": "0.0001", "train/hateful_memes/cross_entropy/avg": "0.0254", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9914", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9855", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9996", "max mem": 12643.0, "experiment": "run", "epoch": 73, "num_updates": 19300, "iterations": 19300, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 05s 525ms", "time_since_start": "10h 13m 32s 281ms", "eta": "01h 23m 29s 179ms"}
2020-06-09T08:04:04 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T08:07:08 INFO: {"progress": "19400/22000", "train/total_loss": "0.0001", "train/total_loss/avg": "0.0253", "train/hateful_memes/cross_entropy": "0.0001", "train/hateful_memes/cross_entropy/avg": "0.0253", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9914", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9856", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9996", "max mem": 12643.0, "experiment": "run", "epoch": 73, "num_updates": 19400, "iterations": 19400, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 05s 895ms", "time_since_start": "10h 16m 38s 176ms", "eta": "01h 20m 33s 286ms"}
2020-06-09T08:07:09 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T08:10:14 INFO: {"progress": "19500/22000", "train/total_loss": "0.0001", "train/total_loss/avg": "0.0251", "train/hateful_memes/cross_entropy": "0.0001", "train/hateful_memes/cross_entropy/avg": "0.0251", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9915", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9856", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9996", "max mem": 12643.0, "experiment": "run", "epoch": 74, "num_updates": 19500, "iterations": 19500, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 057ms", "time_since_start": "10h 19m 44s 234ms", "eta": "01h 17m 31s 434ms"}
2020-06-09T08:10:15 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T08:13:19 INFO: {"progress": "19600/22000", "train/total_loss": "0.0001", "train/total_loss/avg": "0.0250", "train/hateful_memes/cross_entropy": "0.0001", "train/hateful_memes/cross_entropy/avg": "0.0250", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9915", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9857", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9996", "max mem": 12643.0, "experiment": "run", "epoch": 74, "num_updates": 19600, "iterations": 19600, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 05s 703ms", "time_since_start": "10h 22m 49s 937ms", "eta": "01h 14m 16s 885ms"}
2020-06-09T08:13:21 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T08:16:26 INFO: {"progress": "19700/22000", "train/total_loss": "0.0001", "train/total_loss/avg": "0.0249", "train/hateful_memes/cross_entropy": "0.0001", "train/hateful_memes/cross_entropy/avg": "0.0249", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9916", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9858", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9996", "max mem": 12643.0, "experiment": "run", "epoch": 75, "num_updates": 19700, "iterations": 19700, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 311ms", "time_since_start": "10h 25m 56s 249ms", "eta": "01h 11m 25s 164ms"}
2020-06-09T08:16:27 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

