2020-06-09T08:33:28 INFO: =====  Training Parameters    =====
2020-06-09T08:33:28 INFO: {
    "batch_size": 32,
    "checkpoint_interval": 1000,
    "clip_gradients": false,
    "clip_norm_mode": "all",
    "dataset_size_proportional_sampling": true,
    "device": "cuda",
    "early_stop": {
        "criteria": "hateful_memes/roc_auc",
        "enabled": false,
        "minimize": false,
        "patience": 4000
    },
    "evaluate_metrics": true,
    "evaluation_interval": 1000,
    "experiment_name": "run",
    "fast_read": false,
    "find_unused_parameters": false,
    "local_rank": null,
    "log_detailed_config": true,
    "log_format": "json",
    "log_interval": 100,
    "logger_level": "info",
    "lr_ratio": 0.1,
    "lr_scheduler": true,
    "lr_steps": [],
    "max_epochs": null,
    "max_updates": 22000,
    "num_workers": 4,
    "pin_memory": false,
    "seed": 28702595,
    "should_not_log": false,
    "tensorboard": true,
    "trainer": "base_trainer",
    "use_warmup": false,
    "verbose_dump": true,
    "warmup_factor": 0.2,
    "warmup_iterations": 1000
}
2020-06-09T08:33:28 INFO: ======  Dataset Attributes  ======
2020-06-09T08:33:28 INFO: ======== hateful_memes =======
2020-06-09T08:33:28 INFO: {
    "annotations": {
        "test": [
            "hateful_memes/defaults/annotations/test.jsonl"
        ],
        "train": [
            "hateful_memes/defaults/annotations/train.jsonl"
        ],
        "val": [
            "hateful_memes/defaults/annotations/dev.jsonl"
        ]
    },
    "data_dir": "/home/jupyter/meme_hateful_detection/data/raw/datasets",
    "depth_first": false,
    "fast_read": false,
    "features": {
        "test": [
            "hateful_memes/defaults/features/detectron.lmdb"
        ],
        "train": [
            "hateful_memes/defaults/features/detectron.lmdb"
        ],
        "val": [
            "hateful_memes/defaults/features/detectron.lmdb"
        ]
    },
    "images": {
        "test": [
            "hateful_memes/defaults/images/"
        ],
        "train": [
            "hateful_memes/defaults/images/"
        ],
        "val": [
            "hateful_memes/defaults/images/"
        ]
    },
    "max_features": 100,
    "processors": {
        "bbox_processor": {
            "params": {
                "max_length": 50
            },
            "type": "bbox"
        },
        "image_processor": {
            "params": {
                "transforms": [
                    {
                        "params": {
                            "size": [
                                256,
                                256
                            ]
                        },
                        "type": "Resize"
                    },
                    {
                        "params": {
                            "size": [
                                224,
                                224
                            ]
                        },
                        "type": "CenterCrop"
                    },
                    "ToTensor",
                    "GrayScaleTo3Channels",
                    {
                        "params": {
                            "mean": [
                                0.46777044,
                                0.44531429,
                                0.40661017
                            ],
                            "std": [
                                0.12221994,
                                0.12145835,
                                0.14380469
                            ]
                        },
                        "type": "Normalize"
                    }
                ]
            },
            "type": "torchvision_transforms"
        },
        "text_processor": {
            "params": {
                "mask_probability": 0,
                "max_length": 14,
                "max_seq_length": 128,
                "preprocessor": {
                    "params": {},
                    "type": "simple_sentence"
                },
                "tokenizer_config": {
                    "params": {
                        "do_lower_case": true
                    },
                    "type": "bert-base-uncased"
                },
                "vocab": {
                    "embedding_name": "glove.6B.300d",
                    "type": "intersected",
                    "vocab_file": "hateful_memes/defaults/extras/vocabs/vocabulary_100k.txt"
                }
            },
            "type": "bert_tokenizer"
        }
    },
    "return_features_info": false,
    "use_features": false,
    "use_images": true
}
2020-06-09T08:33:28 INFO: ======  Optimizer Attributes  ======
2020-06-09T08:33:28 INFO: {
    "params": {
        "eps": 1e-08,
        "lr": 1e-05
    },
    "type": "adam_w"
}
2020-06-09T08:33:28 INFO: ======  Model (concat_bert) Attributes  ======
2020-06-09T08:33:28 INFO: {
    "bert_model_name": "bert-base-uncased",
    "classifier": {
        "params": {
            "hidden_dim": 768,
            "in_dim": 205568,
            "num_layers": 2,
            "out_dim": 2
        },
        "type": "mlp"
    },
    "direct_features_input": false,
    "finetune_lr_multiplier": 1,
    "freeze_complete_base": false,
    "freeze_modal": false,
    "freeze_text": false,
    "losses": [
        {
            "type": "cross_entropy"
        }
    ],
    "modal_encoder": {
        "params": {
            "num_output_features": 1,
            "pool_type": "avg",
            "pretrained": true
        },
        "type": "resnet152"
    },
    "modal_hidden_size": 2048,
    "num_features": 100,
    "num_labels": 2,
    "text_encoder": {
        "params": {
            "bert_model_name": "bert-base-uncased",
            "hidden_size": 768,
            "num_attention_heads": 12,
            "num_hidden_layers": 12,
            "output_attentions": false,
            "output_hidden_states": false
        },
        "type": "transformer"
    },
    "text_hidden_size": 768
}
2020-06-09T08:33:28 INFO: Loading datasets
2020-06-09T08:33:33 INFO: CUDA Device 0 is: Tesla T4
2020-06-09T08:33:37 INFO: Torch version is: 1.5.0+cu101
2020-06-09T08:33:37 INFO: Loading checkpoint
2020-06-09T08:33:39 WARNING: /home/jupyter/mmf/mmf/utils/checkpoint.py:224: UserWarning: 'optimizer' key is not present in the checkpoint asked to be loaded. Skipping.
  "'optimizer' key is not present in the "

2020-06-09T08:33:39 INFO: Checkpoint loaded
2020-06-09T08:33:39 INFO: ===== Model =====
2020-06-09T08:33:39 INFO: ConcatBERT(
  (base): FusionBase(
    (text): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(30522, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
    (modal): ResNet152ImageEncoder(
      (model): Sequential(
        (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
        (4): Sequential(
          (0): Bottleneck(
            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (downsample): Sequential(
              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): Bottleneck(
            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (2): Bottleneck(
            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
        (5): Sequential(
          (0): Bottleneck(
            (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (downsample): Sequential(
              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): Bottleneck(
            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (2): Bottleneck(
            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (3): Bottleneck(
            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (4): Bottleneck(
            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (5): Bottleneck(
            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (6): Bottleneck(
            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (7): Bottleneck(
            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
        (6): Sequential(
          (0): Bottleneck(
            (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (downsample): Sequential(
              (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (2): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (3): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (4): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (5): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (6): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (7): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (8): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (9): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (10): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (11): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (12): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (13): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (14): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (15): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (16): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (17): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (18): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (19): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (20): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (21): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (22): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (23): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (24): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (25): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (26): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (27): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (28): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (29): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (30): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (31): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (32): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (33): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (34): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (35): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
        (7): Sequential(
          (0): Bottleneck(
            (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (downsample): Sequential(
              (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
              (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): Bottleneck(
            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (2): Bottleneck(
            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
      )
      (pool): AdaptiveAvgPool2d(output_size=(1, 1))
    )
  )
  (classifier): MLPClassifer(
    (layers): ModuleList(
      (0): Linear(in_features=2816, out_features=768, bias=True)
      (1): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.5, inplace=False)
      (4): Linear(in_features=768, out_features=768, bias=True)
      (5): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Dropout(p=0.5, inplace=False)
      (8): Linear(in_features=768, out_features=2, bias=True)
    )
  )
  (losses): Losses()
)
2020-06-09T08:33:39 INFO: Total Parameters: 170384706. Trained Parameters: 170384706
2020-06-09T08:33:39 INFO: Starting training...
2020-06-09T08:33:42 WARNING: /pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha)

2020-06-09T08:33:42 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T08:36:43 INFO: {"progress": "100/22000", "train/total_loss": "0.5936", "train/total_loss/avg": "0.5936", "train/hateful_memes/cross_entropy": "0.5936", "train/hateful_memes/cross_entropy/avg": "0.5936", "train/hateful_memes/accuracy": "0.7500", "train/hateful_memes/accuracy/avg": "0.7500", "train/hateful_memes/binary_f1": "0.7143", "train/hateful_memes/binary_f1/avg": "0.7143", "train/hateful_memes/roc_auc": "0.8157", "train/hateful_memes/roc_auc/avg": "0.8157", "max mem": 12643.0, "experiment": "run", "epoch": 1, "num_updates": 100, "iterations": 100, "max_updates": 22000, "lr": "0.", "ups": "0.55", "time": "03m 03s 644ms", "time_since_start": "03m 14s 738ms", "eta": "11h 10m 18s 121ms"}
2020-06-09T08:36:45 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T08:39:50 INFO: {"progress": "200/22000", "train/total_loss": "0.4071", "train/total_loss/avg": "0.5003", "train/hateful_memes/cross_entropy": "0.4071", "train/hateful_memes/cross_entropy/avg": "0.5003", "train/hateful_memes/accuracy": "0.7500", "train/hateful_memes/accuracy/avg": "0.7656", "train/hateful_memes/binary_f1": "0.7143", "train/hateful_memes/binary_f1/avg": "0.7275", "train/hateful_memes/roc_auc": "0.8157", "train/hateful_memes/roc_auc/avg": "0.8707", "max mem": 12643.0, "experiment": "run", "epoch": 1, "num_updates": 200, "iterations": 200, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 911ms", "time_since_start": "06m 21s 649ms", "eta": "11h 19m 06s 654ms"}
2020-06-09T08:39:52 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T08:42:56 INFO: {"progress": "300/22000", "train/total_loss": "0.4071", "train/total_loss/avg": "0.4576", "train/hateful_memes/cross_entropy": "0.4071", "train/hateful_memes/cross_entropy/avg": "0.4576", "train/hateful_memes/accuracy": "0.7812", "train/hateful_memes/accuracy/avg": "0.7812", "train/hateful_memes/binary_f1": "0.7143", "train/hateful_memes/binary_f1/avg": "0.7072", "train/hateful_memes/roc_auc": "0.8961", "train/hateful_memes/roc_auc/avg": "0.8792", "max mem": 12643.0, "experiment": "run", "epoch": 2, "num_updates": 300, "iterations": 300, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 429ms", "time_since_start": "09m 28s 079ms", "eta": "11h 14m 15s 111ms"}
2020-06-09T08:42:58 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T08:46:03 INFO: {"progress": "400/22000", "train/total_loss": "0.4071", "train/total_loss/avg": "0.4838", "train/hateful_memes/cross_entropy": "0.4071", "train/hateful_memes/cross_entropy/avg": "0.4838", "train/hateful_memes/accuracy": "0.7500", "train/hateful_memes/accuracy/avg": "0.7734", "train/hateful_memes/binary_f1": "0.6667", "train/hateful_memes/binary_f1/avg": "0.6804", "train/hateful_memes/roc_auc": "0.8157", "train/hateful_memes/roc_auc/avg": "0.8502", "max mem": 12643.0, "experiment": "run", "epoch": 2, "num_updates": 400, "iterations": 400, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 588ms", "time_since_start": "12m 34s 667ms", "eta": "11h 11m 43s 172ms"}
2020-06-09T08:46:05 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T08:49:09 INFO: {"progress": "500/22000", "train/total_loss": "0.4789", "train/total_loss/avg": "0.4828", "train/hateful_memes/cross_entropy": "0.4789", "train/hateful_memes/cross_entropy/avg": "0.4828", "train/hateful_memes/accuracy": "0.7812", "train/hateful_memes/accuracy/avg": "0.7750", "train/hateful_memes/binary_f1": "0.7143", "train/hateful_memes/binary_f1/avg": "0.6883", "train/hateful_memes/roc_auc": "0.8867", "train/hateful_memes/roc_auc/avg": "0.8575", "max mem": 12643.0, "experiment": "run", "epoch": 2, "num_updates": 500, "iterations": 500, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 540ms", "time_since_start": "15m 41s 208ms", "eta": "11h 08m 26s 222ms"}
2020-06-09T08:49:11 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T08:52:16 INFO: {"progress": "600/22000", "train/total_loss": "0.4071", "train/total_loss/avg": "0.4453", "train/hateful_memes/cross_entropy": "0.4071", "train/hateful_memes/cross_entropy/avg": "0.4453", "train/hateful_memes/accuracy": "0.7812", "train/hateful_memes/accuracy/avg": "0.8073", "train/hateful_memes/binary_f1": "0.7143", "train/hateful_memes/binary_f1/avg": "0.7292", "train/hateful_memes/roc_auc": "0.8867", "train/hateful_memes/roc_auc/avg": "0.8813", "max mem": 12643.0, "experiment": "run", "epoch": 3, "num_updates": 600, "iterations": 600, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 959ms", "time_since_start": "18m 48s 168ms", "eta": "11h 06m 49s 363ms"}
2020-06-09T08:52:18 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T08:55:23 INFO: {"progress": "700/22000", "train/total_loss": "0.4071", "train/total_loss/avg": "0.4384", "train/hateful_memes/cross_entropy": "0.4071", "train/hateful_memes/cross_entropy/avg": "0.4384", "train/hateful_memes/accuracy": "0.7812", "train/hateful_memes/accuracy/avg": "0.8080", "train/hateful_memes/binary_f1": "0.7143", "train/hateful_memes/binary_f1/avg": "0.7250", "train/hateful_memes/roc_auc": "0.8961", "train/hateful_memes/roc_auc/avg": "0.8840", "max mem": 12643.0, "experiment": "run", "epoch": 3, "num_updates": 700, "iterations": 700, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 510ms", "time_since_start": "21m 54s 678ms", "eta": "11h 02m 06s 734ms"}
2020-06-09T08:55:25 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T08:58:29 INFO: {"progress": "800/22000", "train/total_loss": "0.4071", "train/total_loss/avg": "0.4424", "train/hateful_memes/cross_entropy": "0.4071", "train/hateful_memes/cross_entropy/avg": "0.4424", "train/hateful_memes/accuracy": "0.7812", "train/hateful_memes/accuracy/avg": "0.7969", "train/hateful_memes/binary_f1": "0.7000", "train/hateful_memes/binary_f1/avg": "0.7058", "train/hateful_memes/roc_auc": "0.8867", "train/hateful_memes/roc_auc/avg": "0.8792", "max mem": 12643.0, "experiment": "run", "epoch": 4, "num_updates": 800, "iterations": 800, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 606ms", "time_since_start": "25m 01s 285ms", "eta": "10h 59m 20s 683ms"}
2020-06-09T08:58:31 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T09:01:36 INFO: {"progress": "900/22000", "train/total_loss": "0.4071", "train/total_loss/avg": "0.4279", "train/hateful_memes/cross_entropy": "0.4071", "train/hateful_memes/cross_entropy/avg": "0.4279", "train/hateful_memes/accuracy": "0.7812", "train/hateful_memes/accuracy/avg": "0.7986", "train/hateful_memes/binary_f1": "0.7143", "train/hateful_memes/binary_f1/avg": "0.7129", "train/hateful_memes/roc_auc": "0.8961", "train/hateful_memes/roc_auc/avg": "0.8882", "max mem": 12643.0, "experiment": "run", "epoch": 4, "num_updates": 900, "iterations": 900, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 483ms", "time_since_start": "28m 07s 769ms", "eta": "10h 55m 48s 023ms"}
2020-06-09T09:01:38 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T09:04:42 INFO: {"progress": "1000/22000", "train/total_loss": "0.3966", "train/total_loss/avg": "0.4142", "train/hateful_memes/cross_entropy": "0.3966", "train/hateful_memes/cross_entropy/avg": "0.4142", "train/hateful_memes/accuracy": "0.7812", "train/hateful_memes/accuracy/avg": "0.8094", "train/hateful_memes/binary_f1": "0.7143", "train/hateful_memes/binary_f1/avg": "0.7285", "train/hateful_memes/roc_auc": "0.8961", "train/hateful_memes/roc_auc/avg": "0.8944", "max mem": 12643.0, "experiment": "run", "epoch": 4, "num_updates": 1000, "iterations": 1000, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 276ms", "time_since_start": "31m 14s 045ms", "eta": "10h 51m 57s 996ms"}
2020-06-09T09:04:42 INFO: Checkpoint time. Saving a checkpoint.
2020-06-09T09:04:47 INFO: Evaluation time. Running on full validation set...
2020-06-09T09:06:06 INFO: {"progress": "1000/22000", "val/total_loss": "0.9417", "val/hateful_memes/cross_entropy": "0.9417", "val/hateful_memes/accuracy": "0.5680", "val/hateful_memes/binary_f1": "0.3864", "val/hateful_memes/roc_auc": "0.6310", "num_updates": 1000, "epoch": 4, "iterations": 1000, "max_updates": 22000, "val_time": "40s 490ms", "best_update": 1000, "best_iteration": 1000, "best_val/hateful_memes/roc_auc": "0.630992"}
2020-06-09T09:06:08 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T09:09:13 INFO: {"progress": "1100/22000", "train/total_loss": "0.3966", "train/total_loss/avg": "0.4098", "train/hateful_memes/cross_entropy": "0.3966", "train/hateful_memes/cross_entropy/avg": "0.4098", "train/hateful_memes/accuracy": "0.8125", "train/hateful_memes/accuracy/avg": "0.8097", "train/hateful_memes/binary_f1": "0.7143", "train/hateful_memes/binary_f1/avg": "0.7259", "train/hateful_memes/roc_auc": "0.9004", "train/hateful_memes/roc_auc/avg": "0.8983", "max mem": 12643.0, "experiment": "run", "epoch": 5, "num_updates": 1100, "iterations": 1100, "max_updates": 22000, "lr": "0.00001", "ups": "0.53", "time": "03m 07s 086ms", "time_since_start": "35m 45s 072ms", "eta": "10h 51m 40s 998ms"}
2020-06-09T09:09:15 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T09:12:19 INFO: {"progress": "1200/22000", "train/total_loss": "0.3722", "train/total_loss/avg": "0.4019", "train/hateful_memes/cross_entropy": "0.3722", "train/hateful_memes/cross_entropy/avg": "0.4019", "train/hateful_memes/accuracy": "0.8125", "train/hateful_memes/accuracy/avg": "0.8125", "train/hateful_memes/binary_f1": "0.7143", "train/hateful_memes/binary_f1/avg": "0.7289", "train/hateful_memes/roc_auc": "0.9004", "train/hateful_memes/roc_auc/avg": "0.9023", "max mem": 12643.0, "experiment": "run", "epoch": 5, "num_updates": 1200, "iterations": 1200, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 229ms", "time_since_start": "38m 51s 301ms", "eta": "10h 45m 35s 663ms"}
2020-06-09T09:12:21 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T09:15:26 INFO: {"progress": "1300/22000", "train/total_loss": "0.3722", "train/total_loss/avg": "0.3989", "train/hateful_memes/cross_entropy": "0.3722", "train/hateful_memes/cross_entropy/avg": "0.3989", "train/hateful_memes/accuracy": "0.8125", "train/hateful_memes/accuracy/avg": "0.8197", "train/hateful_memes/binary_f1": "0.7200", "train/hateful_memes/binary_f1/avg": "0.7388", "train/hateful_memes/roc_auc": "0.9091", "train/hateful_memes/roc_auc/avg": "0.9029", "max mem": 12643.0, "experiment": "run", "epoch": 5, "num_updates": 1300, "iterations": 1300, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 655ms", "time_since_start": "41m 57s 957ms", "eta": "10h 43m 57s 750ms"}
2020-06-09T09:15:28 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T09:18:33 INFO: {"progress": "1400/22000", "train/total_loss": "0.3663", "train/total_loss/avg": "0.3868", "train/hateful_memes/cross_entropy": "0.3663", "train/hateful_memes/cross_entropy/avg": "0.3868", "train/hateful_memes/accuracy": "0.8125", "train/hateful_memes/accuracy/avg": "0.8259", "train/hateful_memes/binary_f1": "0.7200", "train/hateful_memes/binary_f1/avg": "0.7489", "train/hateful_memes/roc_auc": "0.9091", "train/hateful_memes/roc_auc/avg": "0.9086", "max mem": 12643.0, "experiment": "run", "epoch": 6, "num_updates": 1400, "iterations": 1400, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 685ms", "time_since_start": "45m 04s 642ms", "eta": "10h 40m 57s 119ms"}
2020-06-09T09:18:35 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T09:21:39 INFO: {"progress": "1500/22000", "train/total_loss": "0.3663", "train/total_loss/avg": "0.3826", "train/hateful_memes/cross_entropy": "0.3663", "train/hateful_memes/cross_entropy/avg": "0.3826", "train/hateful_memes/accuracy": "0.8125", "train/hateful_memes/accuracy/avg": "0.8292", "train/hateful_memes/binary_f1": "0.7407", "train/hateful_memes/binary_f1/avg": "0.7561", "train/hateful_memes/roc_auc": "0.9258", "train/hateful_memes/roc_auc/avg": "0.9114", "max mem": 12643.0, "experiment": "run", "epoch": 6, "num_updates": 1500, "iterations": 1500, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 566ms", "time_since_start": "48m 11s 209ms", "eta": "10h 37m 26s 210ms"}
2020-06-09T09:21:41 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T09:24:46 INFO: {"progress": "1600/22000", "train/total_loss": "0.3627", "train/total_loss/avg": "0.3663", "train/hateful_memes/cross_entropy": "0.3627", "train/hateful_memes/cross_entropy/avg": "0.3663", "train/hateful_memes/accuracy": "0.8125", "train/hateful_memes/accuracy/avg": "0.8379", "train/hateful_memes/binary_f1": "0.7407", "train/hateful_memes/binary_f1/avg": "0.7688", "train/hateful_memes/roc_auc": "0.9258", "train/hateful_memes/roc_auc/avg": "0.9169", "max mem": 12643.0, "experiment": "run", "epoch": 7, "num_updates": 1600, "iterations": 1600, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 618ms", "time_since_start": "51m 17s 828ms", "eta": "10h 34m 30s 250ms"}
2020-06-09T09:24:48 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T09:27:53 INFO: {"progress": "1700/22000", "train/total_loss": "0.3627", "train/total_loss/avg": "0.3513", "train/hateful_memes/cross_entropy": "0.3627", "train/hateful_memes/cross_entropy/avg": "0.3513", "train/hateful_memes/accuracy": "0.8125", "train/hateful_memes/accuracy/avg": "0.8456", "train/hateful_memes/binary_f1": "0.7619", "train/hateful_memes/binary_f1/avg": "0.7803", "train/hateful_memes/roc_auc": "0.9375", "train/hateful_memes/roc_auc/avg": "0.9218", "max mem": 12643.0, "experiment": "run", "epoch": 7, "num_updates": 1700, "iterations": 1700, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 635ms", "time_since_start": "54m 24s 464ms", "eta": "10h 31m 27s 080ms"}
2020-06-09T09:27:54 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T09:30:59 INFO: {"progress": "1800/22000", "train/total_loss": "0.3235", "train/total_loss/avg": "0.3382", "train/hateful_memes/cross_entropy": "0.3235", "train/hateful_memes/cross_entropy/avg": "0.3382", "train/hateful_memes/accuracy": "0.8125", "train/hateful_memes/accuracy/avg": "0.8524", "train/hateful_memes/binary_f1": "0.7619", "train/hateful_memes/binary_f1/avg": "0.7904", "train/hateful_memes/roc_auc": "0.9375", "train/hateful_memes/roc_auc/avg": "0.9261", "max mem": 12643.0, "experiment": "run", "epoch": 7, "num_updates": 1800, "iterations": 1800, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 443ms", "time_since_start": "57m 30s 907ms", "eta": "10h 27m 41s 514ms"}
2020-06-09T09:31:01 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T09:34:06 INFO: {"progress": "1900/22000", "train/total_loss": "0.3235", "train/total_loss/avg": "0.3232", "train/hateful_memes/cross_entropy": "0.3235", "train/hateful_memes/cross_entropy/avg": "0.3232", "train/hateful_memes/accuracy": "0.8438", "train/hateful_memes/accuracy/avg": "0.8602", "train/hateful_memes/binary_f1": "0.7692", "train/hateful_memes/binary_f1/avg": "0.8014", "train/hateful_memes/roc_auc": "0.9469", "train/hateful_memes/roc_auc/avg": "0.9300", "max mem": 12643.0, "experiment": "run", "epoch": 8, "num_updates": 1900, "iterations": 1900, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 785ms", "time_since_start": "01h 37s 692ms", "eta": "10h 25m 43s 819ms"}
2020-06-09T09:34:08 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T09:37:12 INFO: {"progress": "2000/22000", "train/total_loss": "0.3150", "train/total_loss/avg": "0.3121", "train/hateful_memes/cross_entropy": "0.3150", "train/hateful_memes/cross_entropy/avg": "0.3121", "train/hateful_memes/accuracy": "0.8438", "train/hateful_memes/accuracy/avg": "0.8641", "train/hateful_memes/binary_f1": "0.7692", "train/hateful_memes/binary_f1/avg": "0.8078", "train/hateful_memes/roc_auc": "0.9469", "train/hateful_memes/roc_auc/avg": "0.9333", "max mem": 12643.0, "experiment": "run", "epoch": 8, "num_updates": 2000, "iterations": 2000, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 635ms", "time_since_start": "01h 03m 44s 328ms", "eta": "10h 22m 07s 179ms"}
2020-06-09T09:37:12 INFO: Checkpoint time. Saving a checkpoint.
2020-06-09T09:37:32 INFO: Evaluation time. Running on full validation set...
2020-06-09T09:38:20 INFO: {"progress": "2000/22000", "val/total_loss": "1.4182", "val/hateful_memes/cross_entropy": "1.4182", "val/hateful_memes/accuracy": "0.5540", "val/hateful_memes/binary_f1": "0.3754", "val/hateful_memes/roc_auc": "0.6013", "num_updates": 2000, "epoch": 8, "iterations": 2000, "max_updates": 22000, "val_time": "11s 004ms", "best_update": 1000, "best_iteration": 1000, "best_val/hateful_memes/roc_auc": "0.630992"}
2020-06-09T09:38:22 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T09:41:27 INFO: {"progress": "2100/22000", "train/total_loss": "0.3114", "train/total_loss/avg": "0.3016", "train/hateful_memes/cross_entropy": "0.3114", "train/hateful_memes/cross_entropy/avg": "0.3016", "train/hateful_memes/accuracy": "0.8750", "train/hateful_memes/accuracy/avg": "0.8690", "train/hateful_memes/binary_f1": "0.8571", "train/hateful_memes/binary_f1/avg": "0.8141", "train/hateful_memes/roc_auc": "0.9492", "train/hateful_memes/roc_auc/avg": "0.9365", "max mem": 12643.0, "experiment": "run", "epoch": 8, "num_updates": 2100, "iterations": 2100, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 727ms", "time_since_start": "01h 07m 59s 100ms", "eta": "10h 19m 18s 843ms"}
2020-06-09T09:41:29 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T09:44:34 INFO: {"progress": "2200/22000", "train/total_loss": "0.2912", "train/total_loss/avg": "0.2901", "train/hateful_memes/cross_entropy": "0.2912", "train/hateful_memes/cross_entropy/avg": "0.2901", "train/hateful_memes/accuracy": "0.9062", "train/hateful_memes/accuracy/avg": "0.8750", "train/hateful_memes/binary_f1": "0.8571", "train/hateful_memes/binary_f1/avg": "0.8226", "train/hateful_memes/roc_auc": "0.9500", "train/hateful_memes/roc_auc/avg": "0.9394", "max mem": 12643.0, "experiment": "run", "epoch": 9, "num_updates": 2200, "iterations": 2200, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 771ms", "time_since_start": "01h 11m 05s 871ms", "eta": "10h 16m 20s 806ms"}
2020-06-09T09:44:36 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T09:47:41 INFO: {"progress": "2300/22000", "train/total_loss": "0.2579", "train/total_loss/avg": "0.2788", "train/hateful_memes/cross_entropy": "0.2579", "train/hateful_memes/cross_entropy/avg": "0.2788", "train/hateful_memes/accuracy": "0.9062", "train/hateful_memes/accuracy/avg": "0.8804", "train/hateful_memes/binary_f1": "0.8696", "train/hateful_memes/binary_f1/avg": "0.8303", "train/hateful_memes/roc_auc": "0.9603", "train/hateful_memes/roc_auc/avg": "0.9420", "max mem": 12643.0, "experiment": "run", "epoch": 9, "num_updates": 2300, "iterations": 2300, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 624ms", "time_since_start": "01h 14m 12s 496ms", "eta": "10h 12m 45s 000ms"}
2020-06-09T09:47:43 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T09:50:47 INFO: {"progress": "2400/22000", "train/total_loss": "0.2292", "train/total_loss/avg": "0.2687", "train/hateful_memes/cross_entropy": "0.2292", "train/hateful_memes/cross_entropy/avg": "0.2687", "train/hateful_memes/accuracy": "0.9062", "train/hateful_memes/accuracy/avg": "0.8854", "train/hateful_memes/binary_f1": "0.8800", "train/hateful_memes/binary_f1/avg": "0.8374", "train/hateful_memes/roc_auc": "0.9838", "train/hateful_memes/roc_auc/avg": "0.9444", "max mem": 12643.0, "experiment": "run", "epoch": 10, "num_updates": 2400, "iterations": 2400, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 684ms", "time_since_start": "01h 17m 19s 180ms", "eta": "10h 09m 50s 133ms"}
2020-06-09T09:50:49 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T09:53:54 INFO: {"progress": "2500/22000", "train/total_loss": "0.1219", "train/total_loss/avg": "0.2586", "train/hateful_memes/cross_entropy": "0.1219", "train/hateful_memes/cross_entropy/avg": "0.2586", "train/hateful_memes/accuracy": "0.9375", "train/hateful_memes/accuracy/avg": "0.8900", "train/hateful_memes/binary_f1": "0.9286", "train/hateful_memes/binary_f1/avg": "0.8439", "train/hateful_memes/roc_auc": "0.9960", "train/hateful_memes/roc_auc/avg": "0.9467", "max mem": 12643.0, "experiment": "run", "epoch": 10, "num_updates": 2500, "iterations": 2500, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 567ms", "time_since_start": "01h 20m 25s 748ms", "eta": "10h 06m 20s 685ms"}
2020-06-09T09:53:56 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T09:57:00 INFO: {"progress": "2600/22000", "train/total_loss": "0.1147", "train/total_loss/avg": "0.2498", "train/hateful_memes/cross_entropy": "0.1147", "train/hateful_memes/cross_entropy/avg": "0.2498", "train/hateful_memes/accuracy": "0.9375", "train/hateful_memes/accuracy/avg": "0.8942", "train/hateful_memes/binary_f1": "0.9286", "train/hateful_memes/binary_f1/avg": "0.8499", "train/hateful_memes/roc_auc": "0.9960", "train/hateful_memes/roc_auc/avg": "0.9487", "max mem": 12643.0, "experiment": "run", "epoch": 10, "num_updates": 2600, "iterations": 2600, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 465ms", "time_since_start": "01h 23m 32s 214ms", "eta": "10h 02m 54s 336ms"}
2020-06-09T09:57:02 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T10:00:07 INFO: {"progress": "2700/22000", "train/total_loss": "0.1117", "train/total_loss/avg": "0.2427", "train/hateful_memes/cross_entropy": "0.1117", "train/hateful_memes/cross_entropy/avg": "0.2427", "train/hateful_memes/accuracy": "0.9688", "train/hateful_memes/accuracy/avg": "0.8970", "train/hateful_memes/binary_f1": "0.9412", "train/hateful_memes/binary_f1/avg": "0.8541", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9506", "max mem": 12643.0, "experiment": "run", "epoch": 11, "num_updates": 2700, "iterations": 2700, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 584ms", "time_since_start": "01h 26m 38s 798ms", "eta": "10h 10s 841ms"}
2020-06-09T10:00:09 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T10:03:13 INFO: {"progress": "2800/22000", "train/total_loss": "0.1011", "train/total_loss/avg": "0.2349", "train/hateful_memes/cross_entropy": "0.1011", "train/hateful_memes/cross_entropy/avg": "0.2349", "train/hateful_memes/accuracy": "0.9688", "train/hateful_memes/accuracy/avg": "0.9007", "train/hateful_memes/binary_f1": "0.9600", "train/hateful_memes/binary_f1/avg": "0.8593", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9524", "max mem": 12643.0, "experiment": "run", "epoch": 11, "num_updates": 2800, "iterations": 2800, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 477ms", "time_since_start": "01h 29m 45s 276ms", "eta": "09h 56m 43s 744ms"}
2020-06-09T10:03:15 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T10:06:20 INFO: {"progress": "2900/22000", "train/total_loss": "0.0910", "train/total_loss/avg": "0.2278", "train/hateful_memes/cross_entropy": "0.0910", "train/hateful_memes/cross_entropy/avg": "0.2278", "train/hateful_memes/accuracy": "0.9688", "train/hateful_memes/accuracy/avg": "0.9041", "train/hateful_memes/binary_f1": "0.9630", "train/hateful_memes/binary_f1/avg": "0.8641", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9540", "max mem": 12643.0, "experiment": "run", "epoch": 11, "num_updates": 2900, "iterations": 2900, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 541ms", "time_since_start": "01h 32m 51s 818ms", "eta": "09h 53m 49s 511ms"}
2020-06-09T10:06:22 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T10:09:27 INFO: {"progress": "3000/22000", "train/total_loss": "0.0578", "train/total_loss/avg": "0.2220", "train/hateful_memes/cross_entropy": "0.0578", "train/hateful_memes/cross_entropy/avg": "0.2220", "train/hateful_memes/accuracy": "0.9688", "train/hateful_memes/accuracy/avg": "0.9062", "train/hateful_memes/binary_f1": "0.9630", "train/hateful_memes/binary_f1/avg": "0.8667", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9555", "max mem": 12643.0, "experiment": "run", "epoch": 12, "num_updates": 3000, "iterations": 3000, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 854ms", "time_since_start": "01h 35m 58s 672ms", "eta": "09h 51m 42s 308ms"}
2020-06-09T10:09:27 INFO: Checkpoint time. Saving a checkpoint.
2020-06-09T10:09:46 INFO: Evaluation time. Running on full validation set...
2020-06-09T10:10:49 INFO: {"progress": "3000/22000", "val/total_loss": "1.4681", "val/hateful_memes/cross_entropy": "1.4681", "val/hateful_memes/accuracy": "0.5700", "val/hateful_memes/binary_f1": "0.4044", "val/hateful_memes/roc_auc": "0.6356", "num_updates": 3000, "epoch": 12, "iterations": 3000, "max_updates": 22000, "val_time": "11s 038ms", "best_update": 3000, "best_iteration": 3000, "best_val/hateful_memes/roc_auc": "0.635632"}
2020-06-09T10:10:52 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T10:13:57 INFO: {"progress": "3100/22000", "train/total_loss": "0.0560", "train/total_loss/avg": "0.2151", "train/hateful_memes/cross_entropy": "0.0560", "train/hateful_memes/cross_entropy/avg": "0.2151", "train/hateful_memes/accuracy": "0.9688", "train/hateful_memes/accuracy/avg": "0.9093", "train/hateful_memes/binary_f1": "0.9630", "train/hateful_memes/binary_f1/avg": "0.8710", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9570", "max mem": 12643.0, "experiment": "run", "epoch": 12, "num_updates": 3100, "iterations": 3100, "max_updates": 22000, "lr": "0.00001", "ups": "0.53", "time": "03m 07s 017ms", "time_since_start": "01h 40m 28s 524ms", "eta": "09h 49m 06s 265ms"}
2020-06-09T10:13:59 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T10:17:03 INFO: {"progress": "3200/22000", "train/total_loss": "0.0538", "train/total_loss/avg": "0.2092", "train/hateful_memes/cross_entropy": "0.0538", "train/hateful_memes/cross_entropy/avg": "0.2092", "train/hateful_memes/accuracy": "0.9688", "train/hateful_memes/accuracy/avg": "0.9121", "train/hateful_memes/binary_f1": "0.9630", "train/hateful_memes/binary_f1/avg": "0.8750", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9583", "max mem": 12643.0, "experiment": "run", "epoch": 13, "num_updates": 3200, "iterations": 3200, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 403ms", "time_since_start": "01h 43m 34s 928ms", "eta": "09h 44m 03s 915ms"}
2020-06-09T10:17:05 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T10:20:10 INFO: {"progress": "3300/22000", "train/total_loss": "0.0491", "train/total_loss/avg": "0.2043", "train/hateful_memes/cross_entropy": "0.0491", "train/hateful_memes/cross_entropy/avg": "0.2043", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9148", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.8788", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9596", "max mem": 12643.0, "experiment": "run", "epoch": 13, "num_updates": 3300, "iterations": 3300, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 674ms", "time_since_start": "01h 46m 41s 602ms", "eta": "09h 41m 48s 164ms"}
2020-06-09T10:20:12 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T10:23:16 INFO: {"progress": "3400/22000", "train/total_loss": "0.0475", "train/total_loss/avg": "0.1993", "train/hateful_memes/cross_entropy": "0.0475", "train/hateful_memes/cross_entropy/avg": "0.1993", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9173", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.8824", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9608", "max mem": 12643.0, "experiment": "run", "epoch": 13, "num_updates": 3400, "iterations": 3400, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 569ms", "time_since_start": "01h 49m 48s 172ms", "eta": "09h 38m 22s 016ms"}
2020-06-09T10:23:18 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T10:26:23 INFO: {"progress": "3500/22000", "train/total_loss": "0.0371", "train/total_loss/avg": "0.1943", "train/hateful_memes/cross_entropy": "0.0371", "train/hateful_memes/cross_entropy/avg": "0.1943", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9196", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.8858", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9619", "max mem": 12643.0, "experiment": "run", "epoch": 14, "num_updates": 3500, "iterations": 3500, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 436ms", "time_since_start": "01h 52m 54s 609ms", "eta": "09h 34m 50s 743ms"}
2020-06-09T10:26:25 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T10:29:29 INFO: {"progress": "3600/22000", "train/total_loss": "0.0363", "train/total_loss/avg": "0.1892", "train/hateful_memes/cross_entropy": "0.0363", "train/hateful_memes/cross_entropy/avg": "0.1892", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9219", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.8889", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9630", "max mem": 12643.0, "experiment": "run", "epoch": 14, "num_updates": 3600, "iterations": 3600, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 427ms", "time_since_start": "01h 56m 01s 036ms", "eta": "09h 31m 42s 579ms"}
2020-06-09T10:29:31 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T10:32:35 INFO: {"progress": "3700/22000", "train/total_loss": "0.0300", "train/total_loss/avg": "0.1846", "train/hateful_memes/cross_entropy": "0.0300", "train/hateful_memes/cross_entropy/avg": "0.1846", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9240", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.8919", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9640", "max mem": 12643.0, "experiment": "run", "epoch": 14, "num_updates": 3700, "iterations": 3700, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 285ms", "time_since_start": "01h 59m 07s 321ms", "eta": "09h 28m 10s 176ms"}
2020-06-09T10:32:37 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T10:35:42 INFO: {"progress": "3800/22000", "train/total_loss": "0.0292", "train/total_loss/avg": "0.1801", "train/hateful_memes/cross_entropy": "0.0292", "train/hateful_memes/cross_entropy/avg": "0.1801", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9260", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.8948", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9649", "max mem": 12643.0, "experiment": "run", "epoch": 15, "num_updates": 3800, "iterations": 3800, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 825ms", "time_since_start": "02h 02m 14s 147ms", "eta": "09h 26m 42s 222ms"}
2020-06-09T10:35:44 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T10:38:49 INFO: {"progress": "3900/22000", "train/total_loss": "0.0292", "train/total_loss/avg": "0.1788", "train/hateful_memes/cross_entropy": "0.0292", "train/hateful_memes/cross_entropy/avg": "0.1788", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9255", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.8916", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9658", "max mem": 12643.0, "experiment": "run", "epoch": 15, "num_updates": 3900, "iterations": 3900, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 348ms", "time_since_start": "02h 05m 20s 495ms", "eta": "09h 22m 09s 102ms"}
2020-06-09T10:38:51 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T10:41:55 INFO: {"progress": "4000/22000", "train/total_loss": "0.0287", "train/total_loss/avg": "0.1745", "train/hateful_memes/cross_entropy": "0.0287", "train/hateful_memes/cross_entropy/avg": "0.1745", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9273", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.8943", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9667", "max mem": 12643.0, "experiment": "run", "epoch": 16, "num_updates": 4000, "iterations": 4000, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 577ms", "time_since_start": "02h 08m 27s 073ms", "eta": "09h 19m 43s 952ms"}
2020-06-09T10:41:55 INFO: Checkpoint time. Saving a checkpoint.
2020-06-09T10:42:15 INFO: Evaluation time. Running on full validation set...
2020-06-09T10:43:00 INFO: {"progress": "4000/22000", "val/total_loss": "1.9630", "val/hateful_memes/cross_entropy": "1.9630", "val/hateful_memes/accuracy": "0.5800", "val/hateful_memes/binary_f1": "0.3824", "val/hateful_memes/roc_auc": "0.6311", "num_updates": 4000, "epoch": 16, "iterations": 4000, "max_updates": 22000, "val_time": "10s 718ms", "best_update": 3000, "best_iteration": 3000, "best_val/hateful_memes/roc_auc": "0.635632"}
2020-06-09T10:43:02 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T10:46:08 INFO: {"progress": "4100/22000", "train/total_loss": "0.0239", "train/total_loss/avg": "0.1703", "train/hateful_memes/cross_entropy": "0.0239", "train/hateful_memes/cross_entropy/avg": "0.1703", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9291", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.8968", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9675", "max mem": 12643.0, "experiment": "run", "epoch": 16, "num_updates": 4100, "iterations": 4100, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 976ms", "time_since_start": "02h 12m 39s 430ms", "eta": "09h 17m 48s 877ms"}
2020-06-09T10:46:09 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T10:49:14 INFO: {"progress": "4200/22000", "train/total_loss": "0.0235", "train/total_loss/avg": "0.1667", "train/hateful_memes/cross_entropy": "0.0235", "train/hateful_memes/cross_entropy/avg": "0.1667", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9308", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.8993", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9682", "max mem": 12643.0, "experiment": "run", "epoch": 16, "num_updates": 4200, "iterations": 4200, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 150ms", "time_since_start": "02h 15m 45s 580ms", "eta": "09h 12m 14s 772ms"}
2020-06-09T10:49:16 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T10:52:20 INFO: {"progress": "4300/22000", "train/total_loss": "0.0235", "train/total_loss/avg": "0.1638", "train/hateful_memes/cross_entropy": "0.0235", "train/hateful_memes/cross_entropy/avg": "0.1638", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9317", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9009", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9690", "max mem": 12643.0, "experiment": "run", "epoch": 17, "num_updates": 4300, "iterations": 4300, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 758ms", "time_since_start": "02h 18m 52s 339ms", "eta": "09h 10m 56s 210ms"}
2020-06-09T10:52:22 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T10:55:27 INFO: {"progress": "4400/22000", "train/total_loss": "0.0228", "train/total_loss/avg": "0.1603", "train/hateful_memes/cross_entropy": "0.0228", "train/hateful_memes/cross_entropy/avg": "0.1603", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9332", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9031", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9697", "max mem": 12643.0, "experiment": "run", "epoch": 17, "num_updates": 4400, "iterations": 4400, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 406ms", "time_since_start": "02h 21m 58s 745ms", "eta": "09h 06m 47s 580ms"}
2020-06-09T10:55:29 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T10:58:33 INFO: {"progress": "4500/22000", "train/total_loss": "0.0235", "train/total_loss/avg": "0.1578", "train/hateful_memes/cross_entropy": "0.0235", "train/hateful_memes/cross_entropy/avg": "0.1578", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9340", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9040", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9704", "max mem": 12643.0, "experiment": "run", "epoch": 17, "num_updates": 4500, "iterations": 4500, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 382ms", "time_since_start": "02h 25m 05s 128ms", "eta": "09h 03m 37s 027ms"}
2020-06-09T10:58:35 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T11:01:40 INFO: {"progress": "4600/22000", "train/total_loss": "0.0235", "train/total_loss/avg": "0.1553", "train/hateful_memes/cross_entropy": "0.0235", "train/hateful_memes/cross_entropy/avg": "0.1553", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9348", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9053", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9710", "max mem": 12643.0, "experiment": "run", "epoch": 18, "num_updates": 4600, "iterations": 4600, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 600ms", "time_since_start": "02h 28m 11s 729ms", "eta": "09h 01m 08s 492ms"}
2020-06-09T11:01:42 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T11:04:46 INFO: {"progress": "4700/22000", "train/total_loss": "0.0228", "train/total_loss/avg": "0.1522", "train/hateful_memes/cross_entropy": "0.0228", "train/hateful_memes/cross_entropy/avg": "0.1522", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9362", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9073", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9716", "max mem": 12643.0, "experiment": "run", "epoch": 18, "num_updates": 4700, "iterations": 4700, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 328ms", "time_since_start": "02h 31m 18s 057ms", "eta": "08h 57m 14s 833ms"}
2020-06-09T11:04:48 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T11:07:53 INFO: {"progress": "4800/22000", "train/total_loss": "0.0186", "train/total_loss/avg": "0.1492", "train/hateful_memes/cross_entropy": "0.0186", "train/hateful_memes/cross_entropy/avg": "0.1492", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9375", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9093", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9722", "max mem": 12643.0, "experiment": "run", "epoch": 19, "num_updates": 4800, "iterations": 4800, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 454ms", "time_since_start": "02h 34m 24s 511ms", "eta": "08h 54m 30s 107ms"}
2020-06-09T11:07:55 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T11:10:59 INFO: {"progress": "4900/22000", "train/total_loss": "0.0171", "train/total_loss/avg": "0.1464", "train/hateful_memes/cross_entropy": "0.0171", "train/hateful_memes/cross_entropy/avg": "0.1464", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9388", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9111", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9728", "max mem": 12643.0, "experiment": "run", "epoch": 19, "num_updates": 4900, "iterations": 4900, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 601ms", "time_since_start": "02h 37m 31s 113ms", "eta": "08h 51m 48s 821ms"}
2020-06-09T11:11:01 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T11:14:06 INFO: {"progress": "5000/22000", "train/total_loss": "0.0136", "train/total_loss/avg": "0.1435", "train/hateful_memes/cross_entropy": "0.0136", "train/hateful_memes/cross_entropy/avg": "0.1435", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9400", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9129", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9733", "max mem": 12643.0, "experiment": "run", "epoch": 19, "num_updates": 5000, "iterations": 5000, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 320ms", "time_since_start": "02h 40m 37s 434ms", "eta": "08h 47m 54s 529ms"}
2020-06-09T11:14:06 INFO: Checkpoint time. Saving a checkpoint.
2020-06-09T11:14:25 INFO: Evaluation time. Running on full validation set...
2020-06-09T11:15:26 INFO: {"progress": "5000/22000", "val/total_loss": "1.8092", "val/hateful_memes/cross_entropy": "1.8092", "val/hateful_memes/accuracy": "0.5700", "val/hateful_memes/binary_f1": "0.4386", "val/hateful_memes/roc_auc": "0.6380", "num_updates": 5000, "epoch": 19, "iterations": 5000, "max_updates": 22000, "val_time": "09s 414ms", "best_update": 5000, "best_iteration": 5000, "best_val/hateful_memes/roc_auc": "0.637968"}
2020-06-09T11:15:28 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T11:18:33 INFO: {"progress": "5100/22000", "train/total_loss": "0.0136", "train/total_loss/avg": "0.1409", "train/hateful_memes/cross_entropy": "0.0136", "train/hateful_memes/cross_entropy/avg": "0.1409", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9412", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9146", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9738", "max mem": 12643.0, "experiment": "run", "epoch": 20, "num_updates": 5100, "iterations": 5100, "max_updates": 22000, "lr": "0.00001", "ups": "0.53", "time": "03m 07s 093ms", "time_since_start": "02h 45m 05s 069ms", "eta": "08h 46m 58s 836ms"}
2020-06-09T11:18:35 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T11:21:40 INFO: {"progress": "5200/22000", "train/total_loss": "0.0121", "train/total_loss/avg": "0.1383", "train/hateful_memes/cross_entropy": "0.0121", "train/hateful_memes/cross_entropy/avg": "0.1383", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9423", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9162", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9744", "max mem": 12643.0, "experiment": "run", "epoch": 20, "num_updates": 5200, "iterations": 5200, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 797ms", "time_since_start": "02h 48m 11s 867ms", "eta": "08h 43m 01s 960ms"}
2020-06-09T11:21:42 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T11:24:47 INFO: {"progress": "5300/22000", "train/total_loss": "0.0111", "train/total_loss/avg": "0.1359", "train/hateful_memes/cross_entropy": "0.0111", "train/hateful_memes/cross_entropy/avg": "0.1359", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9434", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9178", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9748", "max mem": 12643.0, "experiment": "run", "epoch": 20, "num_updates": 5300, "iterations": 5300, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 529ms", "time_since_start": "02h 51m 18s 397ms", "eta": "08h 39m 10s 505ms"}
2020-06-09T11:24:48 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T11:27:53 INFO: {"progress": "5400/22000", "train/total_loss": "0.0109", "train/total_loss/avg": "0.1334", "train/hateful_memes/cross_entropy": "0.0109", "train/hateful_memes/cross_entropy/avg": "0.1334", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9444", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9194", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9753", "max mem": 12643.0, "experiment": "run", "epoch": 21, "num_updates": 5400, "iterations": 5400, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 654ms", "time_since_start": "02h 54m 25s 052ms", "eta": "08h 36m 24s 720ms"}
2020-06-09T11:27:55 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T11:31:00 INFO: {"progress": "5500/22000", "train/total_loss": "0.0102", "train/total_loss/avg": "0.1311", "train/hateful_memes/cross_entropy": "0.0102", "train/hateful_memes/cross_entropy/avg": "0.1311", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9455", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9208", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9758", "max mem": 12643.0, "experiment": "run", "epoch": 21, "num_updates": 5500, "iterations": 5500, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 470ms", "time_since_start": "02h 57m 31s 523ms", "eta": "08h 32m 47s 676ms"}
2020-06-09T11:31:02 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T11:34:06 INFO: {"progress": "5600/22000", "train/total_loss": "0.0101", "train/total_loss/avg": "0.1289", "train/hateful_memes/cross_entropy": "0.0101", "train/hateful_memes/cross_entropy/avg": "0.1289", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9464", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9222", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9762", "max mem": 12643.0, "experiment": "run", "epoch": 22, "num_updates": 5600, "iterations": 5600, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 732ms", "time_since_start": "03h 38s 255ms", "eta": "08h 30m 24s 200ms"}
2020-06-09T11:34:08 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T11:37:13 INFO: {"progress": "5700/22000", "train/total_loss": "0.0084", "train/total_loss/avg": "0.1267", "train/hateful_memes/cross_entropy": "0.0084", "train/hateful_memes/cross_entropy/avg": "0.1267", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9474", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9236", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9766", "max mem": 12643.0, "experiment": "run", "epoch": 22, "num_updates": 5700, "iterations": 5700, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 624ms", "time_since_start": "03h 03m 44s 880ms", "eta": "08h 26m 59s 815ms"}
2020-06-09T11:37:15 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T11:40:20 INFO: {"progress": "5800/22000", "train/total_loss": "0.0084", "train/total_loss/avg": "0.1252", "train/hateful_memes/cross_entropy": "0.0084", "train/hateful_memes/cross_entropy/avg": "0.1252", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9483", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9249", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9770", "max mem": 12643.0, "experiment": "run", "epoch": 22, "num_updates": 5800, "iterations": 5800, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 500ms", "time_since_start": "03h 06m 51s 381ms", "eta": "08h 23m 33s 068ms"}
2020-06-09T11:40:21 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T11:43:26 INFO: {"progress": "5900/22000", "train/total_loss": "0.0080", "train/total_loss/avg": "0.1231", "train/hateful_memes/cross_entropy": "0.0080", "train/hateful_memes/cross_entropy/avg": "0.1231", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9492", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9262", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9774", "max mem": 12643.0, "experiment": "run", "epoch": 23, "num_updates": 5900, "iterations": 5900, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 542ms", "time_since_start": "03h 09m 57s 924ms", "eta": "08h 20m 33s 426ms"}
2020-06-09T11:43:28 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T11:46:33 INFO: {"progress": "6000/22000", "train/total_loss": "0.0084", "train/total_loss/avg": "0.1217", "train/hateful_memes/cross_entropy": "0.0084", "train/hateful_memes/cross_entropy/avg": "0.1217", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9495", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9263", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9778", "max mem": 12643.0, "experiment": "run", "epoch": 23, "num_updates": 6000, "iterations": 6000, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 707ms", "time_since_start": "03h 13m 04s 631ms", "eta": "08h 17m 53s 155ms"}
2020-06-09T11:46:33 INFO: Checkpoint time. Saving a checkpoint.
2020-06-09T11:46:53 INFO: Evaluation time. Running on full validation set...
2020-06-09T11:47:42 INFO: {"progress": "6000/22000", "val/total_loss": "2.0965", "val/hateful_memes/cross_entropy": "2.0965", "val/hateful_memes/accuracy": "0.5680", "val/hateful_memes/binary_f1": "0.4130", "val/hateful_memes/roc_auc": "0.6152", "num_updates": 6000, "epoch": 23, "iterations": 6000, "max_updates": 22000, "val_time": "08s 877ms", "best_update": 5000, "best_iteration": 5000, "best_val/hateful_memes/roc_auc": "0.637968"}
2020-06-09T11:47:44 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T11:50:49 INFO: {"progress": "6100/22000", "train/total_loss": "0.0084", "train/total_loss/avg": "0.1197", "train/hateful_memes/cross_entropy": "0.0084", "train/hateful_memes/cross_entropy/avg": "0.1197", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9503", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9275", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9781", "max mem": 12643.0, "experiment": "run", "epoch": 23, "num_updates": 6100, "iterations": 6100, "max_updates": 22000, "lr": "0.00001", "ups": "0.53", "time": "03m 07s 055ms", "time_since_start": "03h 17m 21s 077ms", "eta": "08h 15m 41s 896ms"}
2020-06-09T11:50:51 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T11:53:56 INFO: {"progress": "6200/22000", "train/total_loss": "0.0084", "train/total_loss/avg": "0.1187", "train/hateful_memes/cross_entropy": "0.0084", "train/hateful_memes/cross_entropy/avg": "0.1187", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9506", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9278", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9785", "max mem": 12643.0, "experiment": "run", "epoch": 24, "num_updates": 6200, "iterations": 6200, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 733ms", "time_since_start": "03h 20m 27s 811ms", "eta": "08h 11m 43s 850ms"}
2020-06-09T11:53:58 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T11:57:02 INFO: {"progress": "6300/22000", "train/total_loss": "0.0084", "train/total_loss/avg": "0.1170", "train/hateful_memes/cross_entropy": "0.0084", "train/hateful_memes/cross_entropy/avg": "0.1170", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9514", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9290", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9788", "max mem": 12643.0, "experiment": "run", "epoch": 24, "num_updates": 6300, "iterations": 6300, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 489ms", "time_since_start": "03h 23m 34s 300ms", "eta": "08h 07m 58s 845ms"}
2020-06-09T11:57:04 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T12:00:09 INFO: {"progress": "6400/22000", "train/total_loss": "0.0080", "train/total_loss/avg": "0.1152", "train/hateful_memes/cross_entropy": "0.0080", "train/hateful_memes/cross_entropy/avg": "0.1152", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9521", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9301", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9792", "max mem": 12643.0, "experiment": "run", "epoch": 25, "num_updates": 6400, "iterations": 6400, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 414ms", "time_since_start": "03h 26m 40s 715ms", "eta": "08h 04m 40s 672ms"}
2020-06-09T12:00:11 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T12:03:16 INFO: {"progress": "6500/22000", "train/total_loss": "0.0080", "train/total_loss/avg": "0.1136", "train/hateful_memes/cross_entropy": "0.0080", "train/hateful_memes/cross_entropy/avg": "0.1136", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9529", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9312", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9795", "max mem": 12643.0, "experiment": "run", "epoch": 25, "num_updates": 6500, "iterations": 6500, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 746ms", "time_since_start": "03h 29m 47s 461ms", "eta": "08h 02m 25s 733ms"}
2020-06-09T12:03:17 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T12:06:22 INFO: {"progress": "6600/22000", "train/total_loss": "0.0080", "train/total_loss/avg": "0.1121", "train/hateful_memes/cross_entropy": "0.0080", "train/hateful_memes/cross_entropy/avg": "0.1121", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9536", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9322", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9798", "max mem": 12643.0, "experiment": "run", "epoch": 25, "num_updates": 6600, "iterations": 6600, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 461ms", "time_since_start": "03h 32m 53s 923ms", "eta": "07h 58m 35s 105ms"}
2020-06-09T12:06:24 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T12:09:29 INFO: {"progress": "6700/22000", "train/total_loss": "0.0084", "train/total_loss/avg": "0.1110", "train/hateful_memes/cross_entropy": "0.0084", "train/hateful_memes/cross_entropy/avg": "0.1110", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9538", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9326", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9801", "max mem": 12643.0, "experiment": "run", "epoch": 26, "num_updates": 6700, "iterations": 6700, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 613ms", "time_since_start": "03h 36m 537ms", "eta": "07h 55m 51s 847ms"}
2020-06-09T12:09:31 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T12:12:35 INFO: {"progress": "6800/22000", "train/total_loss": "0.0080", "train/total_loss/avg": "0.1094", "train/hateful_memes/cross_entropy": "0.0080", "train/hateful_memes/cross_entropy/avg": "0.1094", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9545", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9336", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9804", "max mem": 12643.0, "experiment": "run", "epoch": 26, "num_updates": 6800, "iterations": 6800, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 456ms", "time_since_start": "03h 39m 06s 993ms", "eta": "07h 52m 21s 361ms"}
2020-06-09T12:12:37 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T12:15:42 INFO: {"progress": "6900/22000", "train/total_loss": "0.0059", "train/total_loss/avg": "0.1078", "train/hateful_memes/cross_entropy": "0.0059", "train/hateful_memes/cross_entropy/avg": "0.1078", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9552", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9345", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9807", "max mem": 12643.0, "experiment": "run", "epoch": 26, "num_updates": 6900, "iterations": 6900, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 417ms", "time_since_start": "03h 42m 13s 410ms", "eta": "07h 49m 09s 024ms"}
2020-06-09T12:15:43 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T12:18:48 INFO: {"progress": "7000/22000", "train/total_loss": "0.0059", "train/total_loss/avg": "0.1063", "train/hateful_memes/cross_entropy": "0.0059", "train/hateful_memes/cross_entropy/avg": "0.1063", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9558", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9355", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9809", "max mem": 12643.0, "experiment": "run", "epoch": 27, "num_updates": 7000, "iterations": 7000, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 599ms", "time_since_start": "03h 45m 20s 010ms", "eta": "07h 46m 29s 889ms"}
2020-06-09T12:18:48 INFO: Checkpoint time. Saving a checkpoint.
2020-06-09T12:19:08 INFO: Evaluation time. Running on full validation set...
2020-06-09T12:20:17 INFO: {"progress": "7000/22000", "val/total_loss": "2.0553", "val/hateful_memes/cross_entropy": "2.0553", "val/hateful_memes/accuracy": "0.5840", "val/hateful_memes/binary_f1": "0.4091", "val/hateful_memes/roc_auc": "0.6517", "num_updates": 7000, "epoch": 27, "iterations": 7000, "max_updates": 22000, "val_time": "08s 884ms", "best_update": 7000, "best_iteration": 7000, "best_val/hateful_memes/roc_auc": "0.651700"}
2020-06-09T12:20:19 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T12:23:24 INFO: {"progress": "7100/22000", "train/total_loss": "0.0046", "train/total_loss/avg": "0.1048", "train/hateful_memes/cross_entropy": "0.0046", "train/hateful_memes/cross_entropy/avg": "0.1048", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9564", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9364", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9812", "max mem": 12643.0, "experiment": "run", "epoch": 27, "num_updates": 7100, "iterations": 7100, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 876ms", "time_since_start": "03h 49m 55s 722ms", "eta": "07h 44m 04s 537ms"}
2020-06-09T12:23:26 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T12:26:31 INFO: {"progress": "7200/22000", "train/total_loss": "0.0045", "train/total_loss/avg": "0.1034", "train/hateful_memes/cross_entropy": "0.0045", "train/hateful_memes/cross_entropy/avg": "0.1034", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9570", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9373", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9815", "max mem": 12643.0, "experiment": "run", "epoch": 28, "num_updates": 7200, "iterations": 7200, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 773ms", "time_since_start": "03h 53m 02s 495ms", "eta": "07h 40m 42s 504ms"}
2020-06-09T12:26:33 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T12:29:37 INFO: {"progress": "7300/22000", "train/total_loss": "0.0045", "train/total_loss/avg": "0.1023", "train/hateful_memes/cross_entropy": "0.0045", "train/hateful_memes/cross_entropy/avg": "0.1023", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9576", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9381", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9817", "max mem": 12643.0, "experiment": "run", "epoch": 28, "num_updates": 7300, "iterations": 7300, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 322ms", "time_since_start": "03h 56m 08s 818ms", "eta": "07h 36m 29s 475ms"}
2020-06-09T12:29:39 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T12:32:43 INFO: {"progress": "7400/22000", "train/total_loss": "0.0045", "train/total_loss/avg": "0.1009", "train/hateful_memes/cross_entropy": "0.0045", "train/hateful_memes/cross_entropy/avg": "0.1009", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9582", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9389", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9820", "max mem": 12643.0, "experiment": "run", "epoch": 28, "num_updates": 7400, "iterations": 7400, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 390ms", "time_since_start": "03h 59m 15s 209ms", "eta": "07h 33m 33s 042ms"}
2020-06-09T12:32:45 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T12:35:50 INFO: {"progress": "7500/22000", "train/total_loss": "0.0041", "train/total_loss/avg": "0.0996", "train/hateful_memes/cross_entropy": "0.0041", "train/hateful_memes/cross_entropy/avg": "0.0996", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9587", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9398", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9822", "max mem": 12643.0, "experiment": "run", "epoch": 29, "num_updates": 7500, "iterations": 7500, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 573ms", "time_since_start": "04h 02m 21s 783ms", "eta": "07h 30m 53s 224ms"}
2020-06-09T12:35:52 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T12:38:56 INFO: {"progress": "7600/22000", "train/total_loss": "0.0033", "train/total_loss/avg": "0.0983", "train/hateful_memes/cross_entropy": "0.0033", "train/hateful_memes/cross_entropy/avg": "0.0983", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9593", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9406", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9825", "max mem": 12643.0, "experiment": "run", "epoch": 29, "num_updates": 7600, "iterations": 7600, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 412ms", "time_since_start": "04h 05m 28s 196ms", "eta": "07h 27m 23s 473ms"}
2020-06-09T12:38:58 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T12:42:03 INFO: {"progress": "7700/22000", "train/total_loss": "0.0031", "train/total_loss/avg": "0.0971", "train/hateful_memes/cross_entropy": "0.0031", "train/hateful_memes/cross_entropy/avg": "0.0971", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9598", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9413", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9827", "max mem": 12643.0, "experiment": "run", "epoch": 29, "num_updates": 7700, "iterations": 7700, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 364ms", "time_since_start": "04h 08m 34s 560ms", "eta": "07h 24m 10s 073ms"}
2020-06-09T12:42:05 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T12:45:09 INFO: {"progress": "7800/22000", "train/total_loss": "0.0026", "train/total_loss/avg": "0.0958", "train/hateful_memes/cross_entropy": "0.0026", "train/hateful_memes/cross_entropy/avg": "0.0958", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9603", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9421", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9829", "max mem": 12643.0, "experiment": "run", "epoch": 30, "num_updates": 7800, "iterations": 7800, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 703ms", "time_since_start": "04h 11m 41s 264ms", "eta": "07h 21m 51s 950ms"}
2020-06-09T12:45:11 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T12:48:16 INFO: {"progress": "7900/22000", "train/total_loss": "0.0026", "train/total_loss/avg": "0.0946", "train/hateful_memes/cross_entropy": "0.0026", "train/hateful_memes/cross_entropy/avg": "0.0946", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9608", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9428", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9831", "max mem": 12643.0, "experiment": "run", "epoch": 30, "num_updates": 7900, "iterations": 7900, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 535ms", "time_since_start": "04h 14m 47s 800ms", "eta": "07h 18m 21s 547ms"}
2020-06-09T12:48:18 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T12:51:23 INFO: {"progress": "8000/22000", "train/total_loss": "0.0026", "train/total_loss/avg": "0.0935", "train/hateful_memes/cross_entropy": "0.0026", "train/hateful_memes/cross_entropy/avg": "0.0935", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9613", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9435", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9833", "max mem": 12643.0, "experiment": "run", "epoch": 31, "num_updates": 8000, "iterations": 8000, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 550ms", "time_since_start": "04h 17m 54s 350ms", "eta": "07h 15m 17s 023ms"}
2020-06-09T12:51:23 INFO: Checkpoint time. Saving a checkpoint.
2020-06-09T12:51:43 INFO: Evaluation time. Running on full validation set...
2020-06-09T12:52:31 INFO: {"progress": "8000/22000", "val/total_loss": "2.1901", "val/hateful_memes/cross_entropy": "2.1901", "val/hateful_memes/accuracy": "0.5580", "val/hateful_memes/binary_f1": "0.3739", "val/hateful_memes/roc_auc": "0.6319", "num_updates": 8000, "epoch": 31, "iterations": 8000, "max_updates": 22000, "val_time": "08s 838ms", "best_update": 7000, "best_iteration": 7000, "best_val/hateful_memes/roc_auc": "0.651700"}
2020-06-09T12:52:34 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T12:55:39 INFO: {"progress": "8100/22000", "train/total_loss": "0.0031", "train/total_loss/avg": "0.0924", "train/hateful_memes/cross_entropy": "0.0031", "train/hateful_memes/cross_entropy/avg": "0.0924", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9618", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9442", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9835", "max mem": 12643.0, "experiment": "run", "epoch": 31, "num_updates": 8100, "iterations": 8100, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 895ms", "time_since_start": "04h 22m 10s 647ms", "eta": "07h 12m 58s 436ms"}
2020-06-09T12:55:41 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T12:58:45 INFO: {"progress": "8200/22000", "train/total_loss": "0.0026", "train/total_loss/avg": "0.0913", "train/hateful_memes/cross_entropy": "0.0026", "train/hateful_memes/cross_entropy/avg": "0.0913", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9623", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9449", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9837", "max mem": 12643.0, "experiment": "run", "epoch": 31, "num_updates": 8200, "iterations": 8200, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 328ms", "time_since_start": "04h 25m 16s 975ms", "eta": "07h 08m 33s 300ms"}
2020-06-09T12:58:47 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T13:01:52 INFO: {"progress": "8300/22000", "train/total_loss": "0.0026", "train/total_loss/avg": "0.0903", "train/hateful_memes/cross_entropy": "0.0026", "train/hateful_memes/cross_entropy/avg": "0.0903", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9627", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9456", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9839", "max mem": 12643.0, "experiment": "run", "epoch": 32, "num_updates": 8300, "iterations": 8300, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 801ms", "time_since_start": "04h 28m 23s 776ms", "eta": "07h 06m 31s 761ms"}
2020-06-09T13:01:54 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T13:04:58 INFO: {"progress": "8400/22000", "train/total_loss": "0.0026", "train/total_loss/avg": "0.0892", "train/hateful_memes/cross_entropy": "0.0026", "train/hateful_memes/cross_entropy/avg": "0.0892", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9632", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9462", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9841", "max mem": 12643.0, "experiment": "run", "epoch": 32, "num_updates": 8400, "iterations": 8400, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 447ms", "time_since_start": "04h 31m 30s 224ms", "eta": "07h 02m 36s 891ms"}
2020-06-09T13:05:00 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T13:08:05 INFO: {"progress": "8500/22000", "train/total_loss": "0.0024", "train/total_loss/avg": "0.0882", "train/hateful_memes/cross_entropy": "0.0024", "train/hateful_memes/cross_entropy/avg": "0.0882", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9636", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9468", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9843", "max mem": 12643.0, "experiment": "run", "epoch": 32, "num_updates": 8500, "iterations": 8500, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 312ms", "time_since_start": "04h 34m 36s 537ms", "eta": "06h 59m 12s 225ms"}
2020-06-09T13:08:07 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T13:11:12 INFO: {"progress": "8600/22000", "train/total_loss": "0.0024", "train/total_loss/avg": "0.0874", "train/hateful_memes/cross_entropy": "0.0024", "train/hateful_memes/cross_entropy/avg": "0.0874", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9640", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9475", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9845", "max mem": 12643.0, "experiment": "run", "epoch": 33, "num_updates": 8600, "iterations": 8600, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 831ms", "time_since_start": "04h 37m 43s 369ms", "eta": "06h 57m 15s 443ms"}
2020-06-09T13:11:13 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T13:14:18 INFO: {"progress": "8700/22000", "train/total_loss": "0.0017", "train/total_loss/avg": "0.0864", "train/hateful_memes/cross_entropy": "0.0017", "train/hateful_memes/cross_entropy/avg": "0.0864", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9644", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9481", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9847", "max mem": 12643.0, "experiment": "run", "epoch": 33, "num_updates": 8700, "iterations": 8700, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 391ms", "time_since_start": "04h 40m 49s 760ms", "eta": "06h 53m 10s 060ms"}
2020-06-09T13:14:20 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T13:17:25 INFO: {"progress": "8800/22000", "train/total_loss": "0.0017", "train/total_loss/avg": "0.0854", "train/hateful_memes/cross_entropy": "0.0017", "train/hateful_memes/cross_entropy/avg": "0.0854", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9648", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9487", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9848", "max mem": 12643.0, "experiment": "run", "epoch": 34, "num_updates": 8800, "iterations": 8800, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 817ms", "time_since_start": "04h 43m 56s 577ms", "eta": "06h 50m 59s 874ms"}
2020-06-09T13:17:27 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T13:20:31 INFO: {"progress": "8900/22000", "train/total_loss": "0.0017", "train/total_loss/avg": "0.0845", "train/hateful_memes/cross_entropy": "0.0017", "train/hateful_memes/cross_entropy/avg": "0.0845", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9652", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9492", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9850", "max mem": 12643.0, "experiment": "run", "epoch": 34, "num_updates": 8900, "iterations": 8900, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 466ms", "time_since_start": "04h 47m 03s 044ms", "eta": "06h 47m 07s 115ms"}
2020-06-09T13:20:33 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T13:23:38 INFO: {"progress": "9000/22000", "train/total_loss": "0.0017", "train/total_loss/avg": "0.0836", "train/hateful_memes/cross_entropy": "0.0017", "train/hateful_memes/cross_entropy/avg": "0.0836", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9656", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9498", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9852", "max mem": 12643.0, "experiment": "run", "epoch": 34, "num_updates": 9000, "iterations": 9000, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 322ms", "time_since_start": "04h 50m 09s 366ms", "eta": "06h 43m 41s 928ms"}
2020-06-09T13:23:38 INFO: Checkpoint time. Saving a checkpoint.
2020-06-09T13:23:58 INFO: Evaluation time. Running on full validation set...
2020-06-09T13:24:45 INFO: {"progress": "9000/22000", "val/total_loss": "2.4483", "val/hateful_memes/cross_entropy": "2.4483", "val/hateful_memes/accuracy": "0.5700", "val/hateful_memes/binary_f1": "0.3804", "val/hateful_memes/roc_auc": "0.6151", "num_updates": 9000, "epoch": 34, "iterations": 9000, "max_updates": 22000, "val_time": "10s 184ms", "best_update": 7000, "best_iteration": 7000, "best_val/hateful_memes/roc_auc": "0.651700"}
2020-06-09T13:24:47 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T13:27:53 INFO: {"progress": "9100/22000", "train/total_loss": "0.0017", "train/total_loss/avg": "0.0827", "train/hateful_memes/cross_entropy": "0.0017", "train/hateful_memes/cross_entropy/avg": "0.0827", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9660", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9504", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9853", "max mem": 12643.0, "experiment": "run", "epoch": 35, "num_updates": 9100, "iterations": 9100, "max_updates": 22000, "lr": "0.00001", "ups": "0.53", "time": "03m 07s 076ms", "time_since_start": "04h 54m 24s 382ms", "eta": "06h 42m 12s 870ms"}
2020-06-09T13:27:54 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T13:30:59 INFO: {"progress": "9200/22000", "train/total_loss": "0.0017", "train/total_loss/avg": "0.0822", "train/hateful_memes/cross_entropy": "0.0017", "train/hateful_memes/cross_entropy/avg": "0.0822", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9664", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9509", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9855", "max mem": 12643.0, "experiment": "run", "epoch": 35, "num_updates": 9200, "iterations": 9200, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 480ms", "time_since_start": "04h 57m 30s 862ms", "eta": "06h 37m 49s 449ms"}
2020-06-09T13:31:01 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T13:34:05 INFO: {"progress": "9300/22000", "train/total_loss": "0.0017", "train/total_loss/avg": "0.0814", "train/hateful_memes/cross_entropy": "0.0017", "train/hateful_memes/cross_entropy/avg": "0.0814", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9667", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9514", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9857", "max mem": 12643.0, "experiment": "run", "epoch": 35, "num_updates": 9300, "iterations": 9300, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 435ms", "time_since_start": "05h 37s 298ms", "eta": "06h 34m 37s 298ms"}
2020-06-09T13:34:07 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T13:37:12 INFO: {"progress": "9400/22000", "train/total_loss": "0.0017", "train/total_loss/avg": "0.0805", "train/hateful_memes/cross_entropy": "0.0017", "train/hateful_memes/cross_entropy/avg": "0.0805", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9671", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9519", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9858", "max mem": 12643.0, "experiment": "run", "epoch": 36, "num_updates": 9400, "iterations": 9400, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 551ms", "time_since_start": "05h 03m 43s 849ms", "eta": "06h 31m 45s 463ms"}
2020-06-09T13:37:14 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T13:40:18 INFO: {"progress": "9500/22000", "train/total_loss": "0.0017", "train/total_loss/avg": "0.0797", "train/hateful_memes/cross_entropy": "0.0017", "train/hateful_memes/cross_entropy/avg": "0.0797", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9674", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9524", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9860", "max mem": 12643.0, "experiment": "run", "epoch": 36, "num_updates": 9500, "iterations": 9500, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 390ms", "time_since_start": "05h 06m 50s 239ms", "eta": "06h 28m 18s 765ms"}
2020-06-09T13:40:20 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T13:43:25 INFO: {"progress": "9600/22000", "train/total_loss": "0.0017", "train/total_loss/avg": "0.0809", "train/hateful_memes/cross_entropy": "0.0017", "train/hateful_memes/cross_entropy/avg": "0.0809", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9671", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9512", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9861", "max mem": 12643.0, "experiment": "run", "epoch": 37, "num_updates": 9600, "iterations": 9600, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 809ms", "time_since_start": "05h 09m 57s 048ms", "eta": "06h 26m 04s 370ms"}
2020-06-09T13:43:27 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T13:46:32 INFO: {"progress": "9700/22000", "train/total_loss": "0.0017", "train/total_loss/avg": "0.0801", "train/hateful_memes/cross_entropy": "0.0017", "train/hateful_memes/cross_entropy/avg": "0.0801", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9675", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9517", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9863", "max mem": 12643.0, "experiment": "run", "epoch": 37, "num_updates": 9700, "iterations": 9700, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 564ms", "time_since_start": "05h 13m 03s 613ms", "eta": "06h 22m 27s 447ms"}
2020-06-09T13:46:34 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T13:49:38 INFO: {"progress": "9800/22000", "train/total_loss": "0.0018", "train/total_loss/avg": "0.0793", "train/hateful_memes/cross_entropy": "0.0018", "train/hateful_memes/cross_entropy/avg": "0.0793", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9678", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9522", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9864", "max mem": 12643.0, "experiment": "run", "epoch": 37, "num_updates": 9800, "iterations": 9800, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 560ms", "time_since_start": "05h 16m 10s 174ms", "eta": "06h 19m 20s 424ms"}
2020-06-09T13:49:40 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T13:52:45 INFO: {"progress": "9900/22000", "train/total_loss": "0.0018", "train/total_loss/avg": "0.0785", "train/hateful_memes/cross_entropy": "0.0018", "train/hateful_memes/cross_entropy/avg": "0.0785", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9681", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9527", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9865", "max mem": 12643.0, "experiment": "run", "epoch": 38, "num_updates": 9900, "iterations": 9900, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 708ms", "time_since_start": "05h 19m 16s 882ms", "eta": "06h 16m 31s 725ms"}
2020-06-09T13:52:47 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T13:55:52 INFO: {"progress": "10000/22000", "train/total_loss": "0.0018", "train/total_loss/avg": "0.0778", "train/hateful_memes/cross_entropy": "0.0018", "train/hateful_memes/cross_entropy/avg": "0.0778", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9684", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9532", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9867", "max mem": 12643.0, "experiment": "run", "epoch": 38, "num_updates": 10000, "iterations": 10000, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 491ms", "time_since_start": "05h 22m 23s 374ms", "eta": "06h 12m 58s 941ms"}
2020-06-09T13:55:52 INFO: Checkpoint time. Saving a checkpoint.
2020-06-09T13:56:12 INFO: Evaluation time. Running on full validation set...
2020-06-09T13:56:59 INFO: {"progress": "10000/22000", "val/total_loss": "2.2491", "val/hateful_memes/cross_entropy": "2.2491", "val/hateful_memes/accuracy": "0.5760", "val/hateful_memes/binary_f1": "0.4270", "val/hateful_memes/roc_auc": "0.6336", "num_updates": 10000, "epoch": 38, "iterations": 10000, "max_updates": 22000, "val_time": "08s 925ms", "best_update": 7000, "best_iteration": 7000, "best_val/hateful_memes/roc_auc": "0.651700"}
2020-06-09T13:57:02 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T14:00:07 INFO: {"progress": "10100/22000", "train/total_loss": "0.0018", "train/total_loss/avg": "0.0770", "train/hateful_memes/cross_entropy": "0.0018", "train/hateful_memes/cross_entropy/avg": "0.0770", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9688", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9536", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9868", "max mem": 12643.0, "experiment": "run", "epoch": 38, "num_updates": 10100, "iterations": 10100, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 872ms", "time_since_start": "05h 26m 38s 427ms", "eta": "06h 10m 37s 774ms"}
2020-06-09T14:00:08 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T14:03:13 INFO: {"progress": "10200/22000", "train/total_loss": "0.0017", "train/total_loss/avg": "0.0763", "train/hateful_memes/cross_entropy": "0.0017", "train/hateful_memes/cross_entropy/avg": "0.0763", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9691", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9541", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9869", "max mem": 12643.0, "experiment": "run", "epoch": 39, "num_updates": 10200, "iterations": 10200, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 526ms", "time_since_start": "05h 29m 44s 953ms", "eta": "06h 06m 50s 146ms"}
2020-06-09T14:03:15 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T14:06:19 INFO: {"progress": "10300/22000", "train/total_loss": "0.0017", "train/total_loss/avg": "0.0755", "train/hateful_memes/cross_entropy": "0.0017", "train/hateful_memes/cross_entropy/avg": "0.0755", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9694", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9545", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9871", "max mem": 12643.0, "experiment": "run", "epoch": 39, "num_updates": 10300, "iterations": 10300, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 304ms", "time_since_start": "05h 32m 51s 257ms", "eta": "06h 03m 17s 582ms"}
2020-06-09T14:06:21 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T14:09:26 INFO: {"progress": "10400/22000", "train/total_loss": "0.0017", "train/total_loss/avg": "0.0748", "train/hateful_memes/cross_entropy": "0.0017", "train/hateful_memes/cross_entropy/avg": "0.0748", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9697", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9550", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9872", "max mem": 12643.0, "experiment": "run", "epoch": 40, "num_updates": 10400, "iterations": 10400, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 657ms", "time_since_start": "05h 35m 57s 915ms", "eta": "06h 52s 314ms"}
2020-06-09T14:09:28 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T14:12:33 INFO: {"progress": "10500/22000", "train/total_loss": "0.0016", "train/total_loss/avg": "0.0741", "train/hateful_memes/cross_entropy": "0.0016", "train/hateful_memes/cross_entropy/avg": "0.0741", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9699", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9554", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9873", "max mem": 12643.0, "experiment": "run", "epoch": 40, "num_updates": 10500, "iterations": 10500, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 777ms", "time_since_start": "05h 39m 04s 693ms", "eta": "05h 57m 59s 456ms"}
2020-06-09T14:12:35 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T14:15:39 INFO: {"progress": "10600/22000", "train/total_loss": "0.0016", "train/total_loss/avg": "0.0734", "train/hateful_memes/cross_entropy": "0.0016", "train/hateful_memes/cross_entropy/avg": "0.0734", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9702", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9558", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9874", "max mem": 12643.0, "experiment": "run", "epoch": 40, "num_updates": 10600, "iterations": 10600, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 386ms", "time_since_start": "05h 42m 11s 080ms", "eta": "05h 54m 08s 047ms"}
2020-06-09T14:15:41 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T14:18:46 INFO: {"progress": "10700/22000", "train/total_loss": "0.0016", "train/total_loss/avg": "0.0727", "train/hateful_memes/cross_entropy": "0.0016", "train/hateful_memes/cross_entropy/avg": "0.0727", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9705", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9562", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9875", "max mem": 12643.0, "experiment": "run", "epoch": 41, "num_updates": 10700, "iterations": 10700, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 617ms", "time_since_start": "05h 45m 17s 697ms", "eta": "05h 51m 27s 765ms"}
2020-06-09T14:18:48 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T14:21:52 INFO: {"progress": "10800/22000", "train/total_loss": "0.0014", "train/total_loss/avg": "0.0721", "train/hateful_memes/cross_entropy": "0.0014", "train/hateful_memes/cross_entropy/avg": "0.0721", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9708", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9566", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9877", "max mem": 12643.0, "experiment": "run", "epoch": 41, "num_updates": 10800, "iterations": 10800, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 589ms", "time_since_start": "05h 48m 24s 286ms", "eta": "05h 48m 18s 020ms"}
2020-06-09T14:21:54 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T14:24:59 INFO: {"progress": "10900/22000", "train/total_loss": "0.0009", "train/total_loss/avg": "0.0714", "train/hateful_memes/cross_entropy": "0.0009", "train/hateful_memes/cross_entropy/avg": "0.0714", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9710", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9570", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9878", "max mem": 12643.0, "experiment": "run", "epoch": 41, "num_updates": 10900, "iterations": 10900, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 341ms", "time_since_start": "05h 51m 30s 628ms", "eta": "05h 44m 43s 854ms"}
2020-06-09T14:25:01 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T14:28:05 INFO: {"progress": "11000/22000", "train/total_loss": "0.0009", "train/total_loss/avg": "0.0708", "train/hateful_memes/cross_entropy": "0.0009", "train/hateful_memes/cross_entropy/avg": "0.0708", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9713", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9574", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9879", "max mem": 12643.0, "experiment": "run", "epoch": 42, "num_updates": 11000, "iterations": 11000, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 653ms", "time_since_start": "05h 54m 37s 281ms", "eta": "05h 42m 11s 857ms"}
2020-06-09T14:28:05 INFO: Checkpoint time. Saving a checkpoint.
2020-06-09T14:28:26 INFO: Evaluation time. Running on full validation set...
2020-06-09T14:29:09 INFO: {"progress": "11000/22000", "val/total_loss": "2.6091", "val/hateful_memes/cross_entropy": "2.6091", "val/hateful_memes/accuracy": "0.5620", "val/hateful_memes/binary_f1": "0.3578", "val/hateful_memes/roc_auc": "0.6246", "num_updates": 11000, "epoch": 42, "iterations": 11000, "max_updates": 22000, "val_time": "08s 856ms", "best_update": 7000, "best_iteration": 7000, "best_val/hateful_memes/roc_auc": "0.651700"}
2020-06-09T14:29:12 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T14:32:17 INFO: {"progress": "11100/22000", "train/total_loss": "0.0009", "train/total_loss/avg": "0.0702", "train/hateful_memes/cross_entropy": "0.0009", "train/hateful_memes/cross_entropy/avg": "0.0702", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9716", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9578", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9880", "max mem": 12643.0, "experiment": "run", "epoch": 42, "num_updates": 11100, "iterations": 11100, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 930ms", "time_since_start": "05h 58m 48s 486ms", "eta": "05h 39m 35s 481ms"}
2020-06-09T14:32:19 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T14:35:23 INFO: {"progress": "11200/22000", "train/total_loss": "0.0009", "train/total_loss/avg": "0.0695", "train/hateful_memes/cross_entropy": "0.0009", "train/hateful_memes/cross_entropy/avg": "0.0695", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9718", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9582", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9881", "max mem": 12643.0, "experiment": "run", "epoch": 43, "num_updates": 11200, "iterations": 11200, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 508ms", "time_since_start": "06h 01m 54s 994ms", "eta": "05h 35m 42s 956ms"}
2020-06-09T14:35:25 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T14:38:30 INFO: {"progress": "11300/22000", "train/total_loss": "0.0009", "train/total_loss/avg": "0.0689", "train/hateful_memes/cross_entropy": "0.0009", "train/hateful_memes/cross_entropy/avg": "0.0689", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9721", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9585", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9882", "max mem": 12643.0, "experiment": "run", "epoch": 43, "num_updates": 11300, "iterations": 11300, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 654ms", "time_since_start": "06h 05m 01s 649ms", "eta": "05h 32m 52s 071ms"}
2020-06-09T14:38:32 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T14:41:36 INFO: {"progress": "11400/22000", "train/total_loss": "0.0009", "train/total_loss/avg": "0.0684", "train/hateful_memes/cross_entropy": "0.0009", "train/hateful_memes/cross_entropy/avg": "0.0684", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9723", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9589", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9883", "max mem": 12643.0, "experiment": "run", "epoch": 43, "num_updates": 11400, "iterations": 11400, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 416ms", "time_since_start": "06h 08m 08s 066ms", "eta": "05h 29m 20s 153ms"}
2020-06-09T14:41:38 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T14:44:43 INFO: {"progress": "11500/22000", "train/total_loss": "0.0014", "train/total_loss/avg": "0.0678", "train/hateful_memes/cross_entropy": "0.0014", "train/hateful_memes/cross_entropy/avg": "0.0678", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9726", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9593", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9884", "max mem": 12643.0, "experiment": "run", "epoch": 44, "num_updates": 11500, "iterations": 11500, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 554ms", "time_since_start": "06h 11m 14s 621ms", "eta": "05h 26m 28s 254ms"}
2020-06-09T14:44:45 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T14:47:49 INFO: {"progress": "11600/22000", "train/total_loss": "0.0009", "train/total_loss/avg": "0.0672", "train/hateful_memes/cross_entropy": "0.0009", "train/hateful_memes/cross_entropy/avg": "0.0672", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9728", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9596", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9885", "max mem": 12643.0, "experiment": "run", "epoch": 44, "num_updates": 11600, "iterations": 11600, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 593ms", "time_since_start": "06h 14m 21s 214ms", "eta": "05h 23m 25s 733ms"}
2020-06-09T14:47:51 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T14:50:56 INFO: {"progress": "11700/22000", "train/total_loss": "0.0009", "train/total_loss/avg": "0.0666", "train/hateful_memes/cross_entropy": "0.0009", "train/hateful_memes/cross_entropy/avg": "0.0666", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9730", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9600", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9886", "max mem": 12643.0, "experiment": "run", "epoch": 44, "num_updates": 11700, "iterations": 11700, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 553ms", "time_since_start": "06h 17m 27s 768ms", "eta": "05h 20m 15s 030ms"}
2020-06-09T14:50:58 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T14:54:03 INFO: {"progress": "11800/22000", "train/total_loss": "0.0009", "train/total_loss/avg": "0.0661", "train/hateful_memes/cross_entropy": "0.0009", "train/hateful_memes/cross_entropy/avg": "0.0661", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9733", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9603", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9887", "max mem": 12643.0, "experiment": "run", "epoch": 45, "num_updates": 11800, "iterations": 11800, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 668ms", "time_since_start": "06h 20m 34s 436ms", "eta": "05h 17m 20s 153ms"}
2020-06-09T14:54:04 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T14:57:09 INFO: {"progress": "11900/22000", "train/total_loss": "0.0009", "train/total_loss/avg": "0.0655", "train/hateful_memes/cross_entropy": "0.0009", "train/hateful_memes/cross_entropy/avg": "0.0655", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9735", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9606", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9888", "max mem": 12643.0, "experiment": "run", "epoch": 45, "num_updates": 11900, "iterations": 11900, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 595ms", "time_since_start": "06h 23m 41s 031ms", "eta": "05h 14m 06s 100ms"}
2020-06-09T14:57:11 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T15:00:16 INFO: {"progress": "12000/22000", "train/total_loss": "0.0009", "train/total_loss/avg": "0.0650", "train/hateful_memes/cross_entropy": "0.0009", "train/hateful_memes/cross_entropy/avg": "0.0650", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9737", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9610", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9889", "max mem": 12643.0, "experiment": "run", "epoch": 46, "num_updates": 12000, "iterations": 12000, "max_updates": 22000, "lr": "0.00001", "ups": "0.54", "time": "03m 06s 862ms", "time_since_start": "06h 26m 47s 894ms", "eta": "05h 11m 26s 286ms"}
2020-06-09T15:00:16 INFO: Checkpoint time. Saving a checkpoint.
2020-06-09T15:00:37 INFO: Evaluation time. Running on full validation set...
2020-06-09T15:00:47 INFO: {"progress": "12000/22000", "val/total_loss": "2.4477", "val/hateful_memes/cross_entropy": "2.4477", "val/hateful_memes/accuracy": "0.5720", "val/hateful_memes/binary_f1": "0.3920", "val/hateful_memes/roc_auc": "0.6355", "num_updates": 12000, "epoch": 46, "iterations": 12000, "max_updates": 22000, "val_time": "10s 124ms", "best_update": 7000, "best_iteration": 7000, "best_val/hateful_memes/roc_auc": "0.651700"}
2020-06-09T15:00:49 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T15:03:54 INFO: {"progress": "12100/22000", "train/total_loss": "0.0009", "train/total_loss/avg": "0.0645", "train/hateful_memes/cross_entropy": "0.0009", "train/hateful_memes/cross_entropy/avg": "0.0645", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9739", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9613", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9890", "max mem": 12643.0, "experiment": "run", "epoch": 46, "num_updates": 12100, "iterations": 12100, "max_updates": 22000, "lr": "0.", "ups": "0.53", "time": "03m 07s 035ms", "time_since_start": "06h 30m 25s 917ms", "eta": "05h 08m 36s 554ms"}
2020-06-09T15:03:56 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T15:07:01 INFO: {"progress": "12200/22000", "train/total_loss": "0.0009", "train/total_loss/avg": "0.0640", "train/hateful_memes/cross_entropy": "0.0009", "train/hateful_memes/cross_entropy/avg": "0.0640", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9741", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9616", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9891", "max mem": 12643.0, "experiment": "run", "epoch": 46, "num_updates": 12200, "iterations": 12200, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 487ms", "time_since_start": "06h 33m 32s 404ms", "eta": "05h 04m 35s 736ms"}
2020-06-09T15:07:02 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T15:10:07 INFO: {"progress": "12300/22000", "train/total_loss": "0.0009", "train/total_loss/avg": "0.0636", "train/hateful_memes/cross_entropy": "0.0009", "train/hateful_memes/cross_entropy/avg": "0.0636", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9743", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9619", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9892", "max mem": 12643.0, "experiment": "run", "epoch": 47, "num_updates": 12300, "iterations": 12300, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 762ms", "time_since_start": "06h 36m 39s 167ms", "eta": "05h 01m 55s 961ms"}
2020-06-09T15:10:09 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T15:13:14 INFO: {"progress": "12400/22000", "train/total_loss": "0.0009", "train/total_loss/avg": "0.0631", "train/hateful_memes/cross_entropy": "0.0009", "train/hateful_memes/cross_entropy/avg": "0.0631", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9745", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9622", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9892", "max mem": 12643.0, "experiment": "run", "epoch": 47, "num_updates": 12400, "iterations": 12400, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 464ms", "time_since_start": "06h 39m 45s 631ms", "eta": "04h 58m 20s 550ms"}
2020-06-09T15:13:16 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T15:16:20 INFO: {"progress": "12500/22000", "train/total_loss": "0.0012", "train/total_loss/avg": "0.0627", "train/hateful_memes/cross_entropy": "0.0012", "train/hateful_memes/cross_entropy/avg": "0.0627", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9748", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9625", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9893", "max mem": 12643.0, "experiment": "run", "epoch": 47, "num_updates": 12500, "iterations": 12500, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 425ms", "time_since_start": "06h 42m 52s 057ms", "eta": "04h 55m 10s 458ms"}
2020-06-09T15:16:22 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T15:19:27 INFO: {"progress": "12600/22000", "train/total_loss": "0.0012", "train/total_loss/avg": "0.0622", "train/hateful_memes/cross_entropy": "0.0012", "train/hateful_memes/cross_entropy/avg": "0.0622", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9750", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9628", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9894", "max mem": 12643.0, "experiment": "run", "epoch": 48, "num_updates": 12600, "iterations": 12600, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 786ms", "time_since_start": "06h 45m 58s 843ms", "eta": "04h 52m 37s 958ms"}
2020-06-09T15:19:29 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T15:22:33 INFO: {"progress": "12700/22000", "train/total_loss": "0.0012", "train/total_loss/avg": "0.0617", "train/hateful_memes/cross_entropy": "0.0012", "train/hateful_memes/cross_entropy/avg": "0.0617", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9751", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9631", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9895", "max mem": 12643.0, "experiment": "run", "epoch": 48, "num_updates": 12700, "iterations": 12700, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 477ms", "time_since_start": "06h 49m 05s 321ms", "eta": "04h 49m 02s 402ms"}
2020-06-09T15:22:35 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T15:25:41 INFO: {"progress": "12800/22000", "train/total_loss": "0.0018", "train/total_loss/avg": "0.0613", "train/hateful_memes/cross_entropy": "0.0018", "train/hateful_memes/cross_entropy/avg": "0.0613", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9753", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9634", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9896", "max mem": 12643.0, "experiment": "run", "epoch": 49, "num_updates": 12800, "iterations": 12800, "max_updates": 22000, "lr": "0.", "ups": "0.53", "time": "03m 07s 151ms", "time_since_start": "06h 52m 12s 472ms", "eta": "04h 46m 57s 926ms"}
2020-06-09T15:25:42 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T15:28:47 INFO: {"progress": "12900/22000", "train/total_loss": "0.0018", "train/total_loss/avg": "0.0609", "train/hateful_memes/cross_entropy": "0.0018", "train/hateful_memes/cross_entropy/avg": "0.0609", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9755", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9637", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9897", "max mem": 12643.0, "experiment": "run", "epoch": 49, "num_updates": 12900, "iterations": 12900, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 566ms", "time_since_start": "06h 55m 19s 038ms", "eta": "04h 42m 57s 521ms"}
2020-06-09T15:28:49 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T15:31:54 INFO: {"progress": "13000/22000", "train/total_loss": "0.0018", "train/total_loss/avg": "0.0604", "train/hateful_memes/cross_entropy": "0.0018", "train/hateful_memes/cross_entropy/avg": "0.0604", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9757", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9640", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9897", "max mem": 12643.0, "experiment": "run", "epoch": 49, "num_updates": 13000, "iterations": 13000, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 530ms", "time_since_start": "06h 58m 25s 569ms", "eta": "04h 39m 47s 735ms"}
2020-06-09T15:31:54 INFO: Checkpoint time. Saving a checkpoint.
2020-06-09T15:32:14 INFO: Evaluation time. Running on full validation set...
2020-06-09T15:32:23 INFO: {"progress": "13000/22000", "val/total_loss": "2.5922", "val/hateful_memes/cross_entropy": "2.5922", "val/hateful_memes/accuracy": "0.5720", "val/hateful_memes/binary_f1": "0.3779", "val/hateful_memes/roc_auc": "0.6351", "num_updates": 13000, "epoch": 49, "iterations": 13000, "max_updates": 22000, "val_time": "08s 865ms", "best_update": 7000, "best_iteration": 7000, "best_val/hateful_memes/roc_auc": "0.651700"}
2020-06-09T15:32:25 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T15:35:32 INFO: {"progress": "13100/22000", "train/total_loss": "0.0016", "train/total_loss/avg": "0.0600", "train/hateful_memes/cross_entropy": "0.0016", "train/hateful_memes/cross_entropy/avg": "0.0600", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9759", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9642", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9898", "max mem": 12643.0, "experiment": "run", "epoch": 50, "num_updates": 13100, "iterations": 13100, "max_updates": 22000, "lr": "0.", "ups": "0.53", "time": "03m 08s 555ms", "time_since_start": "07h 02m 03s 865ms", "eta": "04h 39m 41s 398ms"}
2020-06-09T15:35:34 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T15:38:39 INFO: {"progress": "13200/22000", "train/total_loss": "0.0016", "train/total_loss/avg": "0.0595", "train/hateful_memes/cross_entropy": "0.0016", "train/hateful_memes/cross_entropy/avg": "0.0595", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9761", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9645", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9899", "max mem": 12643.0, "experiment": "run", "epoch": 50, "num_updates": 13200, "iterations": 13200, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 678ms", "time_since_start": "07h 05m 10s 543ms", "eta": "04h 33m 47s 684ms"}
2020-06-09T15:38:41 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T15:41:44 INFO: {"progress": "13300/22000", "train/total_loss": "0.0016", "train/total_loss/avg": "0.0592", "train/hateful_memes/cross_entropy": "0.0016", "train/hateful_memes/cross_entropy/avg": "0.0592", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9762", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9647", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9899", "max mem": 12643.0, "experiment": "run", "epoch": 50, "num_updates": 13300, "iterations": 13300, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 05s 788ms", "time_since_start": "07h 08m 16s 332ms", "eta": "04h 29m 23s 581ms"}
2020-06-09T15:41:47 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T15:44:52 INFO: {"progress": "13400/22000", "train/total_loss": "0.0012", "train/total_loss/avg": "0.0588", "train/hateful_memes/cross_entropy": "0.0012", "train/hateful_memes/cross_entropy/avg": "0.0588", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9764", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9649", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9900", "max mem": 12643.0, "experiment": "run", "epoch": 51, "num_updates": 13400, "iterations": 13400, "max_updates": 22000, "lr": "0.", "ups": "0.53", "time": "03m 07s 400ms", "time_since_start": "07h 11m 23s 732ms", "eta": "04h 28m 36s 442ms"}
2020-06-09T15:44:54 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T15:47:58 INFO: {"progress": "13500/22000", "train/total_loss": "0.0012", "train/total_loss/avg": "0.0584", "train/hateful_memes/cross_entropy": "0.0012", "train/hateful_memes/cross_entropy/avg": "0.0584", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9766", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9652", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9901", "max mem": 12643.0, "experiment": "run", "epoch": 51, "num_updates": 13500, "iterations": 13500, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 382ms", "time_since_start": "07h 14m 30s 115ms", "eta": "04h 24m 02s 489ms"}
2020-06-09T15:48:00 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T15:51:05 INFO: {"progress": "13600/22000", "train/total_loss": "0.0012", "train/total_loss/avg": "0.0579", "train/hateful_memes/cross_entropy": "0.0012", "train/hateful_memes/cross_entropy/avg": "0.0579", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9767", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9655", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9902", "max mem": 12643.0, "experiment": "run", "epoch": 52, "num_updates": 13600, "iterations": 13600, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 683ms", "time_since_start": "07h 17m 36s 798ms", "eta": "04h 21m 21s 453ms"}
2020-06-09T15:51:07 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T15:54:11 INFO: {"progress": "13700/22000", "train/total_loss": "0.0016", "train/total_loss/avg": "0.0575", "train/hateful_memes/cross_entropy": "0.0016", "train/hateful_memes/cross_entropy/avg": "0.0575", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9769", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9657", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9902", "max mem": 12643.0, "experiment": "run", "epoch": 52, "num_updates": 13700, "iterations": 13700, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 422ms", "time_since_start": "07h 20m 43s 221ms", "eta": "04h 17m 53s 071ms"}
2020-06-09T15:54:13 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T15:57:18 INFO: {"progress": "13800/22000", "train/total_loss": "0.0016", "train/total_loss/avg": "0.0571", "train/hateful_memes/cross_entropy": "0.0016", "train/hateful_memes/cross_entropy/avg": "0.0571", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9771", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9660", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9903", "max mem": 12643.0, "experiment": "run", "epoch": 52, "num_updates": 13800, "iterations": 13800, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 543ms", "time_since_start": "07h 23m 49s 765ms", "eta": "04h 14m 56s 566ms"}
2020-06-09T15:57:20 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T16:00:25 INFO: {"progress": "13900/22000", "train/total_loss": "0.0011", "train/total_loss/avg": "0.0567", "train/hateful_memes/cross_entropy": "0.0011", "train/hateful_memes/cross_entropy/avg": "0.0567", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9772", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9662", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9904", "max mem": 12643.0, "experiment": "run", "epoch": 53, "num_updates": 13900, "iterations": 13900, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 707ms", "time_since_start": "07h 26m 56s 472ms", "eta": "04h 12m 03s 300ms"}
2020-06-09T16:00:27 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T16:03:31 INFO: {"progress": "14000/22000", "train/total_loss": "0.0011", "train/total_loss/avg": "0.0563", "train/hateful_memes/cross_entropy": "0.0011", "train/hateful_memes/cross_entropy/avg": "0.0563", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9774", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9664", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9904", "max mem": 12643.0, "experiment": "run", "epoch": 53, "num_updates": 14000, "iterations": 14000, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 569ms", "time_since_start": "07h 30m 03s 041ms", "eta": "04h 08m 45s 531ms"}
2020-06-09T16:03:31 INFO: Checkpoint time. Saving a checkpoint.
2020-06-09T16:03:52 INFO: Evaluation time. Running on full validation set...
2020-06-09T16:04:02 INFO: {"progress": "14000/22000", "val/total_loss": "2.5669", "val/hateful_memes/cross_entropy": "2.5669", "val/hateful_memes/accuracy": "0.5740", "val/hateful_memes/binary_f1": "0.4000", "val/hateful_memes/roc_auc": "0.6468", "num_updates": 14000, "epoch": 53, "iterations": 14000, "max_updates": 22000, "val_time": "10s 176ms", "best_update": 7000, "best_iteration": 7000, "best_val/hateful_memes/roc_auc": "0.651700"}
2020-06-09T16:04:04 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T16:07:09 INFO: {"progress": "14100/22000", "train/total_loss": "0.0011", "train/total_loss/avg": "0.0559", "train/hateful_memes/cross_entropy": "0.0011", "train/hateful_memes/cross_entropy/avg": "0.0559", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9776", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9667", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9905", "max mem": 12643.0, "experiment": "run", "epoch": 54, "num_updates": 14100, "iterations": 14100, "max_updates": 22000, "lr": "0.", "ups": "0.53", "time": "03m 07s 124ms", "time_since_start": "07h 33m 41s 114ms", "eta": "04h 06m 22s 804ms"}
2020-06-09T16:07:11 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T16:10:16 INFO: {"progress": "14200/22000", "train/total_loss": "0.0011", "train/total_loss/avg": "0.0555", "train/hateful_memes/cross_entropy": "0.0011", "train/hateful_memes/cross_entropy/avg": "0.0555", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9777", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9669", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9906", "max mem": 12643.0, "experiment": "run", "epoch": 54, "num_updates": 14200, "iterations": 14200, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 612ms", "time_since_start": "07h 36m 47s 727ms", "eta": "04h 02m 35s 814ms"}
2020-06-09T16:10:18 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T16:13:23 INFO: {"progress": "14300/22000", "train/total_loss": "0.0011", "train/total_loss/avg": "0.0552", "train/hateful_memes/cross_entropy": "0.0011", "train/hateful_memes/cross_entropy/avg": "0.0552", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9779", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9672", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9906", "max mem": 12643.0, "experiment": "run", "epoch": 54, "num_updates": 14300, "iterations": 14300, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 760ms", "time_since_start": "07h 39m 54s 487ms", "eta": "03h 59m 40s 535ms"}
2020-06-09T16:13:25 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T16:16:29 INFO: {"progress": "14400/22000", "train/total_loss": "0.0007", "train/total_loss/avg": "0.0548", "train/hateful_memes/cross_entropy": "0.0007", "train/hateful_memes/cross_entropy/avg": "0.0548", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9780", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9674", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9907", "max mem": 12643.0, "experiment": "run", "epoch": 55, "num_updates": 14400, "iterations": 14400, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 674ms", "time_since_start": "07h 43m 01s 162ms", "eta": "03h 56m 27s 296ms"}
2020-06-09T16:16:31 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T16:19:36 INFO: {"progress": "14500/22000", "train/total_loss": "0.0007", "train/total_loss/avg": "0.0544", "train/hateful_memes/cross_entropy": "0.0007", "train/hateful_memes/cross_entropy/avg": "0.0544", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9782", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9676", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9908", "max mem": 12643.0, "experiment": "run", "epoch": 55, "num_updates": 14500, "iterations": 14500, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 777ms", "time_since_start": "07h 46m 07s 939ms", "eta": "03h 53m 28s 277ms"}
2020-06-09T16:19:38 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T16:22:43 INFO: {"progress": "14600/22000", "train/total_loss": "0.0007", "train/total_loss/avg": "0.0541", "train/hateful_memes/cross_entropy": "0.0007", "train/hateful_memes/cross_entropy/avg": "0.0541", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9783", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9678", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9908", "max mem": 12643.0, "experiment": "run", "epoch": 55, "num_updates": 14600, "iterations": 14600, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 549ms", "time_since_start": "07h 49m 14s 489ms", "eta": "03h 50m 04s 662ms"}
2020-06-09T16:22:45 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T16:25:49 INFO: {"progress": "14700/22000", "train/total_loss": "0.0006", "train/total_loss/avg": "0.0537", "train/hateful_memes/cross_entropy": "0.0006", "train/hateful_memes/cross_entropy/avg": "0.0537", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9785", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9681", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9909", "max mem": 12643.0, "experiment": "run", "epoch": 56, "num_updates": 14700, "iterations": 14700, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 725ms", "time_since_start": "07h 52m 21s 214ms", "eta": "03h 47m 10s 961ms"}
2020-06-09T16:25:51 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T16:28:56 INFO: {"progress": "14800/22000", "train/total_loss": "0.0006", "train/total_loss/avg": "0.0533", "train/hateful_memes/cross_entropy": "0.0006", "train/hateful_memes/cross_entropy/avg": "0.0533", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9786", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9683", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9910", "max mem": 12643.0, "experiment": "run", "epoch": 56, "num_updates": 14800, "iterations": 14800, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 467ms", "time_since_start": "07h 55m 27s 682ms", "eta": "03h 43m 45s 664ms"}
2020-06-09T16:28:58 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T16:32:03 INFO: {"progress": "14900/22000", "train/total_loss": "0.0004", "train/total_loss/avg": "0.0530", "train/hateful_memes/cross_entropy": "0.0004", "train/hateful_memes/cross_entropy/avg": "0.0530", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9788", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9685", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9910", "max mem": 12643.0, "experiment": "run", "epoch": 57, "num_updates": 14900, "iterations": 14900, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 721ms", "time_since_start": "07h 58m 34s 403ms", "eta": "03h 40m 57s 207ms"}
2020-06-09T16:32:04 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T16:35:09 INFO: {"progress": "15000/22000", "train/total_loss": "0.0006", "train/total_loss/avg": "0.0526", "train/hateful_memes/cross_entropy": "0.0006", "train/hateful_memes/cross_entropy/avg": "0.0526", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9789", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9687", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9911", "max mem": 12643.0, "experiment": "run", "epoch": 57, "num_updates": 15000, "iterations": 15000, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 849ms", "time_since_start": "08h 01m 41s 253ms", "eta": "03h 37m 59s 473ms"}
2020-06-09T16:35:09 INFO: Checkpoint time. Saving a checkpoint.
2020-06-09T16:35:32 INFO: Evaluation time. Running on full validation set...
2020-06-09T16:35:41 INFO: {"progress": "15000/22000", "val/total_loss": "2.3636", "val/hateful_memes/cross_entropy": "2.3636", "val/hateful_memes/accuracy": "0.5860", "val/hateful_memes/binary_f1": "0.4538", "val/hateful_memes/roc_auc": "0.6404", "num_updates": 15000, "epoch": 57, "iterations": 15000, "max_updates": 22000, "val_time": "08s 828ms", "best_update": 7000, "best_iteration": 7000, "best_val/hateful_memes/roc_auc": "0.651700"}
2020-06-09T16:35:43 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T16:38:48 INFO: {"progress": "15100/22000", "train/total_loss": "0.0007", "train/total_loss/avg": "0.0523", "train/hateful_memes/cross_entropy": "0.0007", "train/hateful_memes/cross_entropy/avg": "0.0523", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9790", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9689", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9911", "max mem": 12643.0, "experiment": "run", "epoch": 57, "num_updates": 15100, "iterations": 15100, "max_updates": 22000, "lr": "0.", "ups": "0.53", "time": "03m 07s 163ms", "time_since_start": "08h 05m 20s 159ms", "eta": "03h 35m 14s 289ms"}
2020-06-09T16:38:50 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T16:41:55 INFO: {"progress": "15200/22000", "train/total_loss": "0.0007", "train/total_loss/avg": "0.0520", "train/hateful_memes/cross_entropy": "0.0007", "train/hateful_memes/cross_entropy/avg": "0.0520", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9792", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9691", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9912", "max mem": 12643.0, "experiment": "run", "epoch": 58, "num_updates": 15200, "iterations": 15200, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 743ms", "time_since_start": "08h 08m 26s 903ms", "eta": "03h 31m 38s 546ms"}
2020-06-09T16:41:57 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T16:45:02 INFO: {"progress": "15300/22000", "train/total_loss": "0.0007", "train/total_loss/avg": "0.0517", "train/hateful_memes/cross_entropy": "0.0007", "train/hateful_memes/cross_entropy/avg": "0.0517", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9793", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9693", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9913", "max mem": 12643.0, "experiment": "run", "epoch": 58, "num_updates": 15300, "iterations": 15300, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 885ms", "time_since_start": "08h 11m 33s 788ms", "eta": "03h 28m 41s 316ms"}
2020-06-09T16:45:04 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T16:48:09 INFO: {"progress": "15400/22000", "train/total_loss": "0.0008", "train/total_loss/avg": "0.0513", "train/hateful_memes/cross_entropy": "0.0008", "train/hateful_memes/cross_entropy/avg": "0.0513", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9795", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9695", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9913", "max mem": 12643.0, "experiment": "run", "epoch": 58, "num_updates": 15400, "iterations": 15400, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 642ms", "time_since_start": "08h 14m 40s 431ms", "eta": "03h 25m 18s 405ms"}
2020-06-09T16:48:10 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T16:51:15 INFO: {"progress": "15500/22000", "train/total_loss": "0.0008", "train/total_loss/avg": "0.0510", "train/hateful_memes/cross_entropy": "0.0008", "train/hateful_memes/cross_entropy/avg": "0.0510", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9796", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9697", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9914", "max mem": 12643.0, "experiment": "run", "epoch": 59, "num_updates": 15500, "iterations": 15500, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 865ms", "time_since_start": "08h 17m 47s 297ms", "eta": "03h 22m 26s 291ms"}
2020-06-09T16:51:17 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T16:54:22 INFO: {"progress": "15600/22000", "train/total_loss": "0.0008", "train/total_loss/avg": "0.0507", "train/hateful_memes/cross_entropy": "0.0008", "train/hateful_memes/cross_entropy/avg": "0.0507", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9797", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9699", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9914", "max mem": 12643.0, "experiment": "run", "epoch": 59, "num_updates": 15600, "iterations": 15600, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 536ms", "time_since_start": "08h 20m 53s 833ms", "eta": "03h 18m 58s 349ms"}
2020-06-09T16:54:24 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T16:57:29 INFO: {"progress": "15700/22000", "train/total_loss": "0.0007", "train/total_loss/avg": "0.0504", "train/hateful_memes/cross_entropy": "0.0007", "train/hateful_memes/cross_entropy/avg": "0.0504", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9798", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9701", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9915", "max mem": 12643.0, "experiment": "run", "epoch": 60, "num_updates": 15700, "iterations": 15700, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 579ms", "time_since_start": "08h 24m 413ms", "eta": "03h 15m 54s 492ms"}
2020-06-09T16:57:30 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T17:00:35 INFO: {"progress": "15800/22000", "train/total_loss": "0.0007", "train/total_loss/avg": "0.0500", "train/hateful_memes/cross_entropy": "0.0007", "train/hateful_memes/cross_entropy/avg": "0.0500", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9800", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9703", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9915", "max mem": 12643.0, "experiment": "run", "epoch": 60, "num_updates": 15800, "iterations": 15800, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 829ms", "time_since_start": "08h 27m 07s 242ms", "eta": "03h 13m 03s 410ms"}
2020-06-09T17:00:37 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T17:03:42 INFO: {"progress": "15900/22000", "train/total_loss": "0.0007", "train/total_loss/avg": "0.0497", "train/hateful_memes/cross_entropy": "0.0007", "train/hateful_memes/cross_entropy/avg": "0.0497", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9801", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9705", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9916", "max mem": 12643.0, "experiment": "run", "epoch": 60, "num_updates": 15900, "iterations": 15900, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 590ms", "time_since_start": "08h 30m 13s 832ms", "eta": "03h 09m 42s 015ms"}
2020-06-09T17:03:44 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T17:06:49 INFO: {"progress": "16000/22000", "train/total_loss": "0.0007", "train/total_loss/avg": "0.0494", "train/hateful_memes/cross_entropy": "0.0007", "train/hateful_memes/cross_entropy/avg": "0.0494", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9802", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9707", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9916", "max mem": 12643.0, "experiment": "run", "epoch": 61, "num_updates": 16000, "iterations": 16000, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 679ms", "time_since_start": "08h 33m 20s 512ms", "eta": "03h 06m 40s 792ms"}
2020-06-09T17:06:49 INFO: Checkpoint time. Saving a checkpoint.
2020-06-09T17:07:09 INFO: Evaluation time. Running on full validation set...
2020-06-09T17:08:10 INFO: {"progress": "16000/22000", "val/total_loss": "2.6439", "val/hateful_memes/cross_entropy": "2.6439", "val/hateful_memes/accuracy": "0.5680", "val/hateful_memes/binary_f1": "0.3721", "val/hateful_memes/roc_auc": "0.6594", "num_updates": 16000, "epoch": 61, "iterations": 16000, "max_updates": 22000, "val_time": "08s 822ms", "best_update": 16000, "best_iteration": 16000, "best_val/hateful_memes/roc_auc": "0.659360"}
2020-06-09T17:08:12 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T17:11:18 INFO: {"progress": "16100/22000", "train/total_loss": "0.0003", "train/total_loss/avg": "0.0491", "train/hateful_memes/cross_entropy": "0.0003", "train/hateful_memes/cross_entropy/avg": "0.0491", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9804", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9708", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9917", "max mem": 12643.0, "experiment": "run", "epoch": 61, "num_updates": 16100, "iterations": 16100, "max_updates": 22000, "lr": "0.", "ups": "0.53", "time": "03m 07s 057ms", "time_since_start": "08h 37m 49s 387ms", "eta": "03h 03m 56s 386ms"}
2020-06-09T17:11:19 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T17:14:24 INFO: {"progress": "16200/22000", "train/total_loss": "0.0007", "train/total_loss/avg": "0.0488", "train/hateful_memes/cross_entropy": "0.0007", "train/hateful_memes/cross_entropy/avg": "0.0488", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9805", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9710", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9917", "max mem": 12643.0, "experiment": "run", "epoch": 61, "num_updates": 16200, "iterations": 16200, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 352ms", "time_since_start": "08h 40m 55s 739ms", "eta": "03h 08s 440ms"}
2020-06-09T17:14:26 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T17:17:31 INFO: {"progress": "16300/22000", "train/total_loss": "0.0004", "train/total_loss/avg": "0.0485", "train/hateful_memes/cross_entropy": "0.0004", "train/hateful_memes/cross_entropy/avg": "0.0485", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9806", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9712", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9918", "max mem": 12643.0, "experiment": "run", "epoch": 62, "num_updates": 16300, "iterations": 16300, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 840ms", "time_since_start": "08h 44m 02s 579ms", "eta": "02h 57m 29s 889ms"}
2020-06-09T17:17:33 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T17:20:37 INFO: {"progress": "16400/22000", "train/total_loss": "0.0004", "train/total_loss/avg": "0.0482", "train/hateful_memes/cross_entropy": "0.0004", "train/hateful_memes/cross_entropy/avg": "0.0482", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9807", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9714", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9918", "max mem": 12643.0, "experiment": "run", "epoch": 62, "num_updates": 16400, "iterations": 16400, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 550ms", "time_since_start": "08h 47m 09s 130ms", "eta": "02h 54m 06s 846ms"}
2020-06-09T17:20:39 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T17:23:44 INFO: {"progress": "16500/22000", "train/total_loss": "0.0003", "train/total_loss/avg": "0.0479", "train/hateful_memes/cross_entropy": "0.0003", "train/hateful_memes/cross_entropy/avg": "0.0479", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9808", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9715", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9919", "max mem": 12643.0, "experiment": "run", "epoch": 63, "num_updates": 16500, "iterations": 16500, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 619ms", "time_since_start": "08h 50m 15s 750ms", "eta": "02h 51m 04s 071ms"}
2020-06-09T17:23:46 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T17:26:50 INFO: {"progress": "16600/22000", "train/total_loss": "0.0003", "train/total_loss/avg": "0.0477", "train/hateful_memes/cross_entropy": "0.0003", "train/hateful_memes/cross_entropy/avg": "0.0477", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9809", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9717", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9919", "max mem": 12643.0, "experiment": "run", "epoch": 63, "num_updates": 16600, "iterations": 16600, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 541ms", "time_since_start": "08h 53m 22s 291ms", "eta": "02h 47m 53s 225ms"}
2020-06-09T17:26:52 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T17:29:57 INFO: {"progress": "16700/22000", "train/total_loss": "0.0004", "train/total_loss/avg": "0.0474", "train/hateful_memes/cross_entropy": "0.0004", "train/hateful_memes/cross_entropy/avg": "0.0474", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9811", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9719", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9920", "max mem": 12643.0, "experiment": "run", "epoch": 63, "num_updates": 16700, "iterations": 16700, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 606ms", "time_since_start": "08h 56m 28s 897ms", "eta": "02h 44m 50s 140ms"}
2020-06-09T17:29:59 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T17:33:04 INFO: {"progress": "16800/22000", "train/total_loss": "0.0004", "train/total_loss/avg": "0.0471", "train/hateful_memes/cross_entropy": "0.0004", "train/hateful_memes/cross_entropy/avg": "0.0471", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9812", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9721", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9920", "max mem": 12643.0, "experiment": "run", "epoch": 64, "num_updates": 16800, "iterations": 16800, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 616ms", "time_since_start": "08h 59m 35s 514ms", "eta": "02h 41m 44s 073ms"}
2020-06-09T17:33:06 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T17:36:10 INFO: {"progress": "16900/22000", "train/total_loss": "0.0004", "train/total_loss/avg": "0.0469", "train/hateful_memes/cross_entropy": "0.0004", "train/hateful_memes/cross_entropy/avg": "0.0469", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9813", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9722", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9921", "max mem": 12643.0, "experiment": "run", "epoch": 64, "num_updates": 16900, "iterations": 16900, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 625ms", "time_since_start": "09h 02m 42s 140ms", "eta": "02h 38m 37s 919ms"}
2020-06-09T17:36:12 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T17:39:17 INFO: {"progress": "17000/22000", "train/total_loss": "0.0003", "train/total_loss/avg": "0.0466", "train/hateful_memes/cross_entropy": "0.0003", "train/hateful_memes/cross_entropy/avg": "0.0466", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9814", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9724", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9921", "max mem": 12643.0, "experiment": "run", "epoch": 64, "num_updates": 17000, "iterations": 17000, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 465ms", "time_since_start": "09h 05m 48s 605ms", "eta": "02h 35m 23s 254ms"}
2020-06-09T17:39:17 INFO: Checkpoint time. Saving a checkpoint.
2020-06-09T17:39:36 INFO: Evaluation time. Running on full validation set...
2020-06-09T17:40:34 INFO: {"progress": "17000/22000", "val/total_loss": "2.7015", "val/hateful_memes/cross_entropy": "2.7015", "val/hateful_memes/accuracy": "0.5820", "val/hateful_memes/binary_f1": "0.3871", "val/hateful_memes/roc_auc": "0.6424", "num_updates": 17000, "epoch": 64, "iterations": 17000, "max_updates": 22000, "val_time": "24s 381ms", "best_update": 16000, "best_iteration": 16000, "best_val/hateful_memes/roc_auc": "0.659360"}
2020-06-09T17:40:37 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T17:43:42 INFO: {"progress": "17100/22000", "train/total_loss": "0.0003", "train/total_loss/avg": "0.0463", "train/hateful_memes/cross_entropy": "0.0003", "train/hateful_memes/cross_entropy/avg": "0.0463", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9815", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9725", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9922", "max mem": 12643.0, "experiment": "run", "epoch": 65, "num_updates": 17100, "iterations": 17100, "max_updates": 22000, "lr": "0.", "ups": "0.53", "time": "03m 07s 327ms", "time_since_start": "09h 10m 13s 978ms", "eta": "02h 32m 59s 043ms"}
2020-06-09T17:43:44 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T17:46:49 INFO: {"progress": "17200/22000", "train/total_loss": "0.0003", "train/total_loss/avg": "0.0461", "train/hateful_memes/cross_entropy": "0.0003", "train/hateful_memes/cross_entropy/avg": "0.0461", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9816", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9727", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9922", "max mem": 12643.0, "experiment": "run", "epoch": 65, "num_updates": 17200, "iterations": 17200, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 672ms", "time_since_start": "09h 13m 20s 650ms", "eta": "02h 29m 20s 256ms"}
2020-06-09T17:46:51 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T17:49:56 INFO: {"progress": "17300/22000", "train/total_loss": "0.0003", "train/total_loss/avg": "0.0458", "train/hateful_memes/cross_entropy": "0.0003", "train/hateful_memes/cross_entropy/avg": "0.0458", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9817", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9729", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9923", "max mem": 12643.0, "experiment": "run", "epoch": 66, "num_updates": 17300, "iterations": 17300, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 708ms", "time_since_start": "09h 16m 27s 359ms", "eta": "02h 26m 15s 307ms"}
2020-06-09T17:49:57 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T17:53:02 INFO: {"progress": "17400/22000", "train/total_loss": "0.0003", "train/total_loss/avg": "0.0455", "train/hateful_memes/cross_entropy": "0.0003", "train/hateful_memes/cross_entropy/avg": "0.0455", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9818", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9730", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9923", "max mem": 12643.0, "experiment": "run", "epoch": 66, "num_updates": 17400, "iterations": 17400, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 770ms", "time_since_start": "09h 19m 34s 130ms", "eta": "02h 23m 11s 454ms"}
2020-06-09T17:53:04 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T17:56:09 INFO: {"progress": "17500/22000", "train/total_loss": "0.0003", "train/total_loss/avg": "0.0453", "train/hateful_memes/cross_entropy": "0.0003", "train/hateful_memes/cross_entropy/avg": "0.0453", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9819", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9732", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9924", "max mem": 12643.0, "experiment": "run", "epoch": 66, "num_updates": 17500, "iterations": 17500, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 504ms", "time_since_start": "09h 22m 40s 634ms", "eta": "02h 19m 52s 687ms"}
2020-06-09T17:56:11 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T17:59:16 INFO: {"progress": "17600/22000", "train/total_loss": "0.0002", "train/total_loss/avg": "0.0450", "train/hateful_memes/cross_entropy": "0.0002", "train/hateful_memes/cross_entropy/avg": "0.0450", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9820", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9733", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9924", "max mem": 12643.0, "experiment": "run", "epoch": 67, "num_updates": 17600, "iterations": 17600, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 822ms", "time_since_start": "09h 25m 47s 456ms", "eta": "02h 17m 178ms"}
2020-06-09T17:59:17 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T18:02:22 INFO: {"progress": "17700/22000", "train/total_loss": "0.0002", "train/total_loss/avg": "0.0448", "train/hateful_memes/cross_entropy": "0.0002", "train/hateful_memes/cross_entropy/avg": "0.0448", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9821", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9735", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9924", "max mem": 12643.0, "experiment": "run", "epoch": 67, "num_updates": 17700, "iterations": 17700, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 649ms", "time_since_start": "09h 28m 54s 105ms", "eta": "02h 13m 45s 923ms"}
2020-06-09T18:02:24 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T18:05:29 INFO: {"progress": "17800/22000", "train/total_loss": "0.0002", "train/total_loss/avg": "0.0445", "train/hateful_memes/cross_entropy": "0.0002", "train/hateful_memes/cross_entropy/avg": "0.0445", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9822", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9736", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9925", "max mem": 12643.0, "experiment": "run", "epoch": 67, "num_updates": 17800, "iterations": 17800, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 786ms", "time_since_start": "09h 32m 892ms", "eta": "02h 10m 45s 026ms"}
2020-06-09T18:05:31 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T18:08:36 INFO: {"progress": "17900/22000", "train/total_loss": "0.0002", "train/total_loss/avg": "0.0443", "train/hateful_memes/cross_entropy": "0.0002", "train/hateful_memes/cross_entropy/avg": "0.0443", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9823", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9738", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9925", "max mem": 12643.0, "experiment": "run", "epoch": 68, "num_updates": 17900, "iterations": 17900, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 746ms", "time_since_start": "09h 35m 07s 638ms", "eta": "02h 07m 36s 606ms"}
2020-06-09T18:08:38 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T18:11:43 INFO: {"progress": "18000/22000", "train/total_loss": "0.0002", "train/total_loss/avg": "0.0440", "train/hateful_memes/cross_entropy": "0.0002", "train/hateful_memes/cross_entropy/avg": "0.0440", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9824", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9739", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9926", "max mem": 12643.0, "experiment": "run", "epoch": 68, "num_updates": 18000, "iterations": 18000, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 788ms", "time_since_start": "09h 38m 14s 427ms", "eta": "02h 04m 31s 557ms"}
2020-06-09T18:11:43 INFO: Checkpoint time. Saving a checkpoint.
2020-06-09T18:12:03 INFO: Evaluation time. Running on full validation set...
2020-06-09T18:12:46 INFO: {"progress": "18000/22000", "val/total_loss": "2.7201", "val/hateful_memes/cross_entropy": "2.7201", "val/hateful_memes/accuracy": "0.5740", "val/hateful_memes/binary_f1": "0.3897", "val/hateful_memes/roc_auc": "0.6354", "num_updates": 18000, "epoch": 68, "iterations": 18000, "max_updates": 22000, "val_time": "08s 869ms", "best_update": 16000, "best_iteration": 16000, "best_val/hateful_memes/roc_auc": "0.659360"}
2020-06-09T18:12:49 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T18:15:54 INFO: {"progress": "18100/22000", "train/total_loss": "0.0002", "train/total_loss/avg": "0.0438", "train/hateful_memes/cross_entropy": "0.0002", "train/hateful_memes/cross_entropy/avg": "0.0438", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9825", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9741", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9926", "max mem": 12643.0, "experiment": "run", "epoch": 69, "num_updates": 18100, "iterations": 18100, "max_updates": 22000, "lr": "0.", "ups": "0.53", "time": "03m 07s 111ms", "time_since_start": "09h 42m 25s 897ms", "eta": "02h 01m 37s 330ms"}
2020-06-09T18:15:56 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T18:19:01 INFO: {"progress": "18200/22000", "train/total_loss": "0.0002", "train/total_loss/avg": "0.0435", "train/hateful_memes/cross_entropy": "0.0002", "train/hateful_memes/cross_entropy/avg": "0.0435", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9826", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9742", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9927", "max mem": 12643.0, "experiment": "run", "epoch": 69, "num_updates": 18200, "iterations": 18200, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 876ms", "time_since_start": "09h 45m 32s 774ms", "eta": "01h 58m 21s 314ms"}
2020-06-09T18:19:03 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T18:22:07 INFO: {"progress": "18300/22000", "train/total_loss": "0.0002", "train/total_loss/avg": "0.0433", "train/hateful_memes/cross_entropy": "0.0002", "train/hateful_memes/cross_entropy/avg": "0.0433", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9827", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9743", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9927", "max mem": 12643.0, "experiment": "run", "epoch": 69, "num_updates": 18300, "iterations": 18300, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 434ms", "time_since_start": "09h 48m 39s 208ms", "eta": "01h 54m 58s 068ms"}
2020-06-09T18:22:09 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T18:25:14 INFO: {"progress": "18400/22000", "train/total_loss": "0.0002", "train/total_loss/avg": "0.0431", "train/hateful_memes/cross_entropy": "0.0002", "train/hateful_memes/cross_entropy/avg": "0.0431", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9828", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9745", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9927", "max mem": 12643.0, "experiment": "run", "epoch": 70, "num_updates": 18400, "iterations": 18400, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 984ms", "time_since_start": "09h 51m 46s 193ms", "eta": "01h 52m 11s 446ms"}
2020-06-09T18:25:16 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T18:28:21 INFO: {"progress": "18500/22000", "train/total_loss": "0.0002", "train/total_loss/avg": "0.0428", "train/hateful_memes/cross_entropy": "0.0002", "train/hateful_memes/cross_entropy/avg": "0.0428", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9829", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9746", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9928", "max mem": 12643.0, "experiment": "run", "epoch": 70, "num_updates": 18500, "iterations": 18500, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 856ms", "time_since_start": "09h 54m 53s 049ms", "eta": "01h 48m 59s 969ms"}
2020-06-09T18:28:23 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T18:31:28 INFO: {"progress": "18600/22000", "train/total_loss": "0.0002", "train/total_loss/avg": "0.0426", "train/hateful_memes/cross_entropy": "0.0002", "train/hateful_memes/cross_entropy/avg": "0.0426", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9830", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9748", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9928", "max mem": 12643.0, "experiment": "run", "epoch": 70, "num_updates": 18600, "iterations": 18600, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 446ms", "time_since_start": "09h 57m 59s 496ms", "eta": "01h 45m 39s 196ms"}
2020-06-09T18:31:30 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T18:34:35 INFO: {"progress": "18700/22000", "train/total_loss": "0.0001", "train/total_loss/avg": "0.0424", "train/hateful_memes/cross_entropy": "0.0001", "train/hateful_memes/cross_entropy/avg": "0.0424", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9831", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9749", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9929", "max mem": 12643.0, "experiment": "run", "epoch": 71, "num_updates": 18700, "iterations": 18700, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 865ms", "time_since_start": "10h 01m 06s 362ms", "eta": "01h 42m 46s 561ms"}
2020-06-09T18:34:36 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T18:37:41 INFO: {"progress": "18800/22000", "train/total_loss": "0.0001", "train/total_loss/avg": "0.0421", "train/hateful_memes/cross_entropy": "0.0001", "train/hateful_memes/cross_entropy/avg": "0.0421", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9832", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9750", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9929", "max mem": 12643.0, "experiment": "run", "epoch": 71, "num_updates": 18800, "iterations": 18800, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 715ms", "time_since_start": "10h 04m 13s 077ms", "eta": "01h 39m 34s 892ms"}
2020-06-09T18:37:43 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T18:40:48 INFO: {"progress": "18900/22000", "train/total_loss": "0.0002", "train/total_loss/avg": "0.0419", "train/hateful_memes/cross_entropy": "0.0002", "train/hateful_memes/cross_entropy/avg": "0.0419", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9833", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9752", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9929", "max mem": 12643.0, "experiment": "run", "epoch": 72, "num_updates": 18900, "iterations": 18900, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 804ms", "time_since_start": "10h 07m 19s 882ms", "eta": "01h 36m 30s 955ms"}
2020-06-09T18:40:50 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T18:43:55 INFO: {"progress": "19000/22000", "train/total_loss": "0.0002", "train/total_loss/avg": "0.0417", "train/hateful_memes/cross_entropy": "0.0002", "train/hateful_memes/cross_entropy/avg": "0.0417", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9834", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9753", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9930", "max mem": 12643.0, "experiment": "run", "epoch": 72, "num_updates": 19000, "iterations": 19000, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 579ms", "time_since_start": "10h 10m 26s 461ms", "eta": "01h 33m 17s 384ms"}
2020-06-09T18:43:55 INFO: Checkpoint time. Saving a checkpoint.
2020-06-09T18:44:14 INFO: Evaluation time. Running on full validation set...
2020-06-09T18:45:03 INFO: {"progress": "19000/22000", "val/total_loss": "2.9128", "val/hateful_memes/cross_entropy": "2.9128", "val/hateful_memes/accuracy": "0.5620", "val/hateful_memes/binary_f1": "0.3615", "val/hateful_memes/roc_auc": "0.6326", "num_updates": 19000, "epoch": 72, "iterations": 19000, "max_updates": 22000, "val_time": "08s 791ms", "best_update": 16000, "best_iteration": 16000, "best_val/hateful_memes/roc_auc": "0.659360"}
2020-06-09T18:45:06 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T18:48:11 INFO: {"progress": "19100/22000", "train/total_loss": "0.0002", "train/total_loss/avg": "0.0415", "train/hateful_memes/cross_entropy": "0.0002", "train/hateful_memes/cross_entropy/avg": "0.0415", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9834", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9754", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9930", "max mem": 12643.0, "experiment": "run", "epoch": 72, "num_updates": 19100, "iterations": 19100, "max_updates": 22000, "lr": "0.", "ups": "0.53", "time": "03m 07s 174ms", "time_since_start": "10h 14m 42s 967ms", "eta": "01h 30m 28s 059ms"}
2020-06-09T18:48:13 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T18:51:18 INFO: {"progress": "19200/22000", "train/total_loss": "0.0002", "train/total_loss/avg": "0.0413", "train/hateful_memes/cross_entropy": "0.0002", "train/hateful_memes/cross_entropy/avg": "0.0413", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9835", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9756", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9930", "max mem": 12643.0, "experiment": "run", "epoch": 73, "num_updates": 19200, "iterations": 19200, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 697ms", "time_since_start": "10h 17m 49s 665ms", "eta": "01h 27m 07s 537ms"}
2020-06-09T18:51:20 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T18:54:24 INFO: {"progress": "19300/22000", "train/total_loss": "0.0002", "train/total_loss/avg": "0.0411", "train/hateful_memes/cross_entropy": "0.0002", "train/hateful_memes/cross_entropy/avg": "0.0411", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9836", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9757", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9931", "max mem": 12643.0, "experiment": "run", "epoch": 73, "num_updates": 19300, "iterations": 19300, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 609ms", "time_since_start": "10h 20m 56s 275ms", "eta": "01h 23m 58s 464ms"}
2020-06-09T18:54:26 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T18:57:31 INFO: {"progress": "19400/22000", "train/total_loss": "0.0002", "train/total_loss/avg": "0.0409", "train/hateful_memes/cross_entropy": "0.0002", "train/hateful_memes/cross_entropy/avg": "0.0409", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9837", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9758", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9931", "max mem": 12643.0, "experiment": "run", "epoch": 73, "num_updates": 19400, "iterations": 19400, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 547ms", "time_since_start": "10h 24m 02s 822ms", "eta": "01h 20m 50s 231ms"}
2020-06-09T18:57:33 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T19:00:38 INFO: {"progress": "19500/22000", "train/total_loss": "0.0002", "train/total_loss/avg": "0.0406", "train/hateful_memes/cross_entropy": "0.0002", "train/hateful_memes/cross_entropy/avg": "0.0406", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9838", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9759", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9931", "max mem": 12643.0, "experiment": "run", "epoch": 74, "num_updates": 19500, "iterations": 19500, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 860ms", "time_since_start": "10h 27m 09s 683ms", "eta": "01h 17m 51s 518ms"}
2020-06-09T19:00:40 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T19:03:45 INFO: {"progress": "19600/22000", "train/total_loss": "0.0002", "train/total_loss/avg": "0.0404", "train/hateful_memes/cross_entropy": "0.0002", "train/hateful_memes/cross_entropy/avg": "0.0404", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9839", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9761", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9932", "max mem": 12643.0, "experiment": "run", "epoch": 74, "num_updates": 19600, "iterations": 19600, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 667ms", "time_since_start": "10h 30m 16s 350ms", "eta": "01h 14m 40s 015ms"}
2020-06-09T19:03:46 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T19:06:51 INFO: {"progress": "19700/22000", "train/total_loss": "0.0002", "train/total_loss/avg": "0.0402", "train/hateful_memes/cross_entropy": "0.0002", "train/hateful_memes/cross_entropy/avg": "0.0402", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9839", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9762", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9932", "max mem": 12643.0, "experiment": "run", "epoch": 75, "num_updates": 19700, "iterations": 19700, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 710ms", "time_since_start": "10h 33m 23s 061ms", "eta": "01h 11m 34s 352ms"}
2020-06-09T19:06:53 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T19:09:58 INFO: {"progress": "19800/22000", "train/total_loss": "0.0002", "train/total_loss/avg": "0.0400", "train/hateful_memes/cross_entropy": "0.0002", "train/hateful_memes/cross_entropy/avg": "0.0400", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9840", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9763", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9933", "max mem": 12643.0, "experiment": "run", "epoch": 75, "num_updates": 19800, "iterations": 19800, "max_updates": 22000, "lr": "0.", "ups": "0.53", "time": "03m 07s 060ms", "time_since_start": "10h 36m 30s 122ms", "eta": "01h 08m 35s 338ms"}
2020-06-09T19:10:00 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T19:13:05 INFO: {"progress": "19900/22000", "train/total_loss": "0.0002", "train/total_loss/avg": "0.0398", "train/hateful_memes/cross_entropy": "0.0002", "train/hateful_memes/cross_entropy/avg": "0.0398", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9841", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9764", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9933", "max mem": 12643.0, "experiment": "run", "epoch": 75, "num_updates": 19900, "iterations": 19900, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 458ms", "time_since_start": "10h 39m 36s 580ms", "eta": "01h 05m 15s 628ms"}
2020-06-09T19:13:07 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T19:16:12 INFO: {"progress": "20000/22000", "train/total_loss": "0.0002", "train/total_loss/avg": "0.0396", "train/hateful_memes/cross_entropy": "0.0002", "train/hateful_memes/cross_entropy/avg": "0.0396", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9842", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9765", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9933", "max mem": 12643.0, "experiment": "run", "epoch": 76, "num_updates": 20000, "iterations": 20000, "max_updates": 22000, "lr": "0.", "ups": "0.53", "time": "03m 07s 038ms", "time_since_start": "10h 42m 43s 619ms", "eta": "01h 02m 20s 772ms"}
2020-06-09T19:16:12 INFO: Checkpoint time. Saving a checkpoint.
2020-06-09T19:16:34 INFO: Evaluation time. Running on full validation set...
2020-06-09T19:17:20 INFO: {"progress": "20000/22000", "val/total_loss": "2.7405", "val/hateful_memes/cross_entropy": "2.7405", "val/hateful_memes/accuracy": "0.5780", "val/hateful_memes/binary_f1": "0.4056", "val/hateful_memes/roc_auc": "0.6324", "num_updates": 20000, "epoch": 76, "iterations": 20000, "max_updates": 22000, "val_time": "10s 148ms", "best_update": 16000, "best_iteration": 16000, "best_val/hateful_memes/roc_auc": "0.659360"}
2020-06-09T19:17:22 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T19:20:28 INFO: {"progress": "20100/22000", "train/total_loss": "0.0002", "train/total_loss/avg": "0.0394", "train/hateful_memes/cross_entropy": "0.0002", "train/hateful_memes/cross_entropy/avg": "0.0394", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9843", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9767", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9934", "max mem": 12643.0, "experiment": "run", "epoch": 76, "num_updates": 20100, "iterations": 20100, "max_updates": 22000, "lr": "0.", "ups": "0.53", "time": "03m 07s 250ms", "time_since_start": "10h 46m 59s 355ms", "eta": "59m 17s 763ms"}
2020-06-09T19:20:29 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T19:23:34 INFO: {"progress": "20200/22000", "train/total_loss": "0.0002", "train/total_loss/avg": "0.0393", "train/hateful_memes/cross_entropy": "0.0002", "train/hateful_memes/cross_entropy/avg": "0.0393", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9843", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9768", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9934", "max mem": 12643.0, "experiment": "run", "epoch": 76, "num_updates": 20200, "iterations": 20200, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 929ms", "time_since_start": "10h 50m 06s 284ms", "eta": "56m 04s 722ms"}
2020-06-09T19:23:36 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T19:26:41 INFO: {"progress": "20300/22000", "train/total_loss": "0.0002", "train/total_loss/avg": "0.0391", "train/hateful_memes/cross_entropy": "0.0002", "train/hateful_memes/cross_entropy/avg": "0.0391", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9844", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9769", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9934", "max mem": 12643.0, "experiment": "run", "epoch": 77, "num_updates": 20300, "iterations": 20300, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 627ms", "time_since_start": "10h 53m 12s 912ms", "eta": "52m 52s 673ms"}
2020-06-09T19:26:43 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T19:29:48 INFO: {"progress": "20400/22000", "train/total_loss": "0.0002", "train/total_loss/avg": "0.0390", "train/hateful_memes/cross_entropy": "0.0002", "train/hateful_memes/cross_entropy/avg": "0.0390", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9845", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9770", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9935", "max mem": 12643.0, "experiment": "run", "epoch": 77, "num_updates": 20400, "iterations": 20400, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 861ms", "time_since_start": "10h 56m 19s 773ms", "eta": "49m 49s 781ms"}
2020-06-09T19:29:50 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T19:32:55 INFO: {"progress": "20500/22000", "train/total_loss": "0.0002", "train/total_loss/avg": "0.0388", "train/hateful_memes/cross_entropy": "0.0002", "train/hateful_memes/cross_entropy/avg": "0.0388", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9846", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9771", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9935", "max mem": 12643.0, "experiment": "run", "epoch": 78, "num_updates": 20500, "iterations": 20500, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 708ms", "time_since_start": "10h 59m 26s 482ms", "eta": "46m 40s 632ms"}
2020-06-09T19:32:56 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T19:36:01 INFO: {"progress": "20600/22000", "train/total_loss": "0.0002", "train/total_loss/avg": "0.0386", "train/hateful_memes/cross_entropy": "0.0002", "train/hateful_memes/cross_entropy/avg": "0.0386", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9847", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9772", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9935", "max mem": 12643.0, "experiment": "run", "epoch": 78, "num_updates": 20600, "iterations": 20600, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 684ms", "time_since_start": "11h 02m 33s 166ms", "eta": "43m 33s 578ms"}
2020-06-09T19:36:03 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T19:39:08 INFO: {"progress": "20700/22000", "train/total_loss": "0.0004", "train/total_loss/avg": "0.0384", "train/hateful_memes/cross_entropy": "0.0004", "train/hateful_memes/cross_entropy/avg": "0.0384", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9847", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9773", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9935", "max mem": 12643.0, "experiment": "run", "epoch": 78, "num_updates": 20700, "iterations": 20700, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 451ms", "time_since_start": "11h 05m 39s 618ms", "eta": "40m 23s 869ms"}
2020-06-09T19:39:10 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T19:42:15 INFO: {"progress": "20800/22000", "train/total_loss": "0.0004", "train/total_loss/avg": "0.0382", "train/hateful_memes/cross_entropy": "0.0004", "train/hateful_memes/cross_entropy/avg": "0.0382", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9848", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9774", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9936", "max mem": 12643.0, "experiment": "run", "epoch": 79, "num_updates": 20800, "iterations": 20800, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 852ms", "time_since_start": "11h 08m 46s 471ms", "eta": "37m 22s 230ms"}
2020-06-09T19:42:16 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T19:45:21 INFO: {"progress": "20900/22000", "train/total_loss": "0.0002", "train/total_loss/avg": "0.0380", "train/hateful_memes/cross_entropy": "0.0002", "train/hateful_memes/cross_entropy/avg": "0.0380", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9849", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9775", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9936", "max mem": 12643.0, "experiment": "run", "epoch": 79, "num_updates": 20900, "iterations": 20900, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 692ms", "time_since_start": "11h 11m 53s 163ms", "eta": "34m 13s 617ms"}
2020-06-09T19:45:23 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T19:48:28 INFO: {"progress": "21000/22000", "train/total_loss": "0.0002", "train/total_loss/avg": "0.0379", "train/hateful_memes/cross_entropy": "0.0002", "train/hateful_memes/cross_entropy/avg": "0.0379", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9849", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9777", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9936", "max mem": 12643.0, "experiment": "run", "epoch": 79, "num_updates": 21000, "iterations": 21000, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 651ms", "time_since_start": "11h 14m 59s 814ms", "eta": "31m 06s 510ms"}
2020-06-09T19:48:28 INFO: Checkpoint time. Saving a checkpoint.
2020-06-09T19:48:49 INFO: Evaluation time. Running on full validation set...
2020-06-09T19:48:59 INFO: {"progress": "21000/22000", "val/total_loss": "2.8061", "val/hateful_memes/cross_entropy": "2.8061", "val/hateful_memes/accuracy": "0.5700", "val/hateful_memes/binary_f1": "0.3944", "val/hateful_memes/roc_auc": "0.6358", "num_updates": 21000, "epoch": 79, "iterations": 21000, "max_updates": 22000, "val_time": "10s 152ms", "best_update": 16000, "best_iteration": 16000, "best_val/hateful_memes/roc_auc": "0.659360"}
2020-06-09T19:49:01 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T19:52:07 INFO: {"progress": "21100/22000", "train/total_loss": "0.0002", "train/total_loss/avg": "0.0377", "train/hateful_memes/cross_entropy": "0.0002", "train/hateful_memes/cross_entropy/avg": "0.0377", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9850", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9778", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9937", "max mem": 12643.0, "experiment": "run", "epoch": 80, "num_updates": 21100, "iterations": 21100, "max_updates": 22000, "lr": "0.", "ups": "0.53", "time": "03m 07s 451ms", "time_since_start": "11h 18m 38s 352ms", "eta": "28m 07s 061ms"}
2020-06-09T19:52:08 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T19:55:13 INFO: {"progress": "21200/22000", "train/total_loss": "0.0001", "train/total_loss/avg": "0.0375", "train/hateful_memes/cross_entropy": "0.0001", "train/hateful_memes/cross_entropy/avg": "0.0375", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9851", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9779", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9937", "max mem": 12643.0, "experiment": "run", "epoch": 80, "num_updates": 21200, "iterations": 21200, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 695ms", "time_since_start": "11h 21m 45s 048ms", "eta": "24m 53s 564ms"}
2020-06-09T19:55:15 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T19:58:20 INFO: {"progress": "21300/22000", "train/total_loss": "0.0001", "train/total_loss/avg": "0.0373", "train/hateful_memes/cross_entropy": "0.0001", "train/hateful_memes/cross_entropy/avg": "0.0373", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9852", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9780", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9937", "max mem": 12643.0, "experiment": "run", "epoch": 81, "num_updates": 21300, "iterations": 21300, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 644ms", "time_since_start": "11h 24m 51s 692ms", "eta": "21m 46s 511ms"}
2020-06-09T19:58:22 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T20:01:26 INFO: {"progress": "21400/22000", "train/total_loss": "0.0001", "train/total_loss/avg": "0.0371", "train/hateful_memes/cross_entropy": "0.0001", "train/hateful_memes/cross_entropy/avg": "0.0371", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9852", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9781", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9938", "max mem": 12643.0, "experiment": "run", "epoch": 81, "num_updates": 21400, "iterations": 21400, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 556ms", "time_since_start": "11h 27m 58s 249ms", "eta": "18m 39s 340ms"}
2020-06-09T20:01:28 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T20:04:33 INFO: {"progress": "21500/22000", "train/total_loss": "0.0001", "train/total_loss/avg": "0.0370", "train/hateful_memes/cross_entropy": "0.0001", "train/hateful_memes/cross_entropy/avg": "0.0370", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9853", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9782", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9938", "max mem": 12643.0, "experiment": "run", "epoch": 81, "num_updates": 21500, "iterations": 21500, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 310ms", "time_since_start": "11h 31m 04s 560ms", "eta": "15m 31s 553ms"}
2020-06-09T20:04:35 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T20:07:39 INFO: {"progress": "21600/22000", "train/total_loss": "0.0001", "train/total_loss/avg": "0.0368", "train/hateful_memes/cross_entropy": "0.0001", "train/hateful_memes/cross_entropy/avg": "0.0368", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9854", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9783", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9938", "max mem": 12643.0, "experiment": "run", "epoch": 82, "num_updates": 21600, "iterations": 21600, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 572ms", "time_since_start": "11h 34m 11s 132ms", "eta": "12m 26s 288ms"}
2020-06-09T20:07:41 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T20:10:46 INFO: {"progress": "21700/22000", "train/total_loss": "0.0001", "train/total_loss/avg": "0.0366", "train/hateful_memes/cross_entropy": "0.0001", "train/hateful_memes/cross_entropy/avg": "0.0366", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9854", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9784", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9938", "max mem": 12643.0, "experiment": "run", "epoch": 82, "num_updates": 21700, "iterations": 21700, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 727ms", "time_since_start": "11h 37m 17s 860ms", "eta": "09m 20s 182ms"}
2020-06-09T20:10:48 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T20:13:53 INFO: {"progress": "21800/22000", "train/total_loss": "0.0001", "train/total_loss/avg": "0.0365", "train/hateful_memes/cross_entropy": "0.0001", "train/hateful_memes/cross_entropy/avg": "0.0365", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9855", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9785", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9939", "max mem": 12643.0, "experiment": "run", "epoch": 82, "num_updates": 21800, "iterations": 21800, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 533ms", "time_since_start": "11h 40m 24s 393ms", "eta": "06m 13s 067ms"}
2020-06-09T20:13:54 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T20:16:59 INFO: {"progress": "21900/22000", "train/total_loss": "0.0001", "train/total_loss/avg": "0.0363", "train/hateful_memes/cross_entropy": "0.0001", "train/hateful_memes/cross_entropy/avg": "0.0363", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9856", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9786", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9939", "max mem": 12643.0, "experiment": "run", "epoch": 83, "num_updates": 21900, "iterations": 21900, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 840ms", "time_since_start": "11h 43m 31s 234ms", "eta": "03m 06s 840ms"}
2020-06-09T20:17:01 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T20:20:06 INFO: {"progress": "22000/22000", "train/total_loss": "0.0002", "train/total_loss/avg": "0.0361", "train/hateful_memes/cross_entropy": "0.0002", "train/hateful_memes/cross_entropy/avg": "0.0361", "train/hateful_memes/accuracy": "1.0000", "train/hateful_memes/accuracy/avg": "0.9856", "train/hateful_memes/binary_f1": "1.0000", "train/hateful_memes/binary_f1/avg": "0.9787", "train/hateful_memes/roc_auc": "1.0000", "train/hateful_memes/roc_auc/avg": "0.9939", "max mem": 12643.0, "experiment": "run", "epoch": 83, "num_updates": 22000, "iterations": 22000, "max_updates": 22000, "lr": "0.", "ups": "0.54", "time": "03m 06s 558ms", "time_since_start": "11h 46m 37s 792ms", "eta": "0ms"}
2020-06-09T20:20:06 INFO: Checkpoint time. Saving a checkpoint.
2020-06-09T20:20:26 INFO: Evaluation time. Running on full validation set...
2020-06-09T20:20:37 INFO: {"progress": "22000/22000", "val/total_loss": "2.8755", "val/hateful_memes/cross_entropy": "2.8755", "val/hateful_memes/accuracy": "0.5700", "val/hateful_memes/binary_f1": "0.3909", "val/hateful_memes/roc_auc": "0.6418", "num_updates": 22000, "epoch": 83, "iterations": 22000, "max_updates": 22000, "val_time": "10s 284ms", "best_update": 16000, "best_iteration": 16000, "best_val/hateful_memes/roc_auc": "0.659360"}
2020-06-09T20:20:39 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

2020-06-09T20:20:39 INFO: Stepping into final validation check
2020-06-09T20:20:39 INFO: Evaluation time. Running on full validation set...
2020-06-09T20:20:50 INFO: {"progress": "22001/22000", "val/total_loss": "2.7818", "val/hateful_memes/cross_entropy": "2.7818", "val/hateful_memes/accuracy": "0.5720", "val/hateful_memes/binary_f1": "0.4056", "val/hateful_memes/roc_auc": "0.6430", "num_updates": 22001, "epoch": 83, "iterations": 22001, "max_updates": 22000, "val_time": "11s 087ms", "best_update": 16000, "best_iteration": 16000, "best_val/hateful_memes/roc_auc": "0.659360"}
2020-06-09T20:20:50 INFO: Restoring checkpoint
2020-06-09T20:20:50 INFO: Loading checkpoint
