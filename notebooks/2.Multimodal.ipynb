{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "\n",
    "PATH_CURRENT = '/home/jupyter/meme_hateful_detection'\n",
    "PATH_MODEL = f'{PATH_CURRENT}/models'\n",
    "PATH_DATA = f'{PATH_CURRENT}/data/raw'\n",
    "PATH_SAVE = f'{PATH_CURRENT}/save'\n",
    "PATH_LOGS = f'{PATH_CURRENT}/logs'\n",
    "PATH_TENSOR = f'{PATH_CURRENT}/tensor_logs'\n",
    "PATH_REPO = f'{PATH_SAVE}/reports'\n",
    "\n",
    "\n",
    "os.environ\n",
    "os.environ['MMF_DATA_DIR'] = PATH_DATA\n",
    "os.environ['MMF_SAVE_DIR'] = PATH_SAVE\n",
    "os.environ['MMF_LOG_DIR']  = PATH_LOGS\n",
    "os.environ['MMF_REPORT_DIR']  = PATH_REPO\n",
    "os.environ['MMF_TENSORBOARD_LOGDIR']  = PATH_TENSOR\n",
    "os.environ['MMF_USER_DIR']  = PATH_CURRENT\n",
    "os.environ['OC_DISABLE_DOT_ACCESS_WARNING'] = '1'\n",
    "# print(os.environ)\n",
    "\n",
    "if PATH_CURRENT not in sys.path:\n",
    "    sys.path.append(PATH_CURRENT)\n",
    "if PATH_MODEL not in sys.path:\n",
    "    sys.path.append(PATH_MODEL)\n",
    "if PATH_DATA not in sys.path:\n",
    "    sys.path.append(PATH_DATA)\n",
    "# print(sys.path)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Baseline         | Model Key      | Pretrained Key                                   | Baseine Config                                                     |\n",
    "|------------------|----------------|--------------------------------------------------|------------------------------------------------------------|\n",
    "| Image-Grid       | unimodal_image | unimodal_image.hateful_memes.images              | projects/hateful_memes/configs/unimodal/image.yaml         |\n",
    "| Image-Region     | unimodal_image | unimodal_image.hateful_memes.features            | projects/hateful_memes/configs/unimodal/with_features.yaml |\n",
    "| Text BERT        | unimodal_text  | unimodal_text.hateful_memes.bert                 | projects/hateful_memes/configs/unimodal/bert.yaml          |\n",
    "| Late Fusion      | late_fusion    | late_fusion.hateful_memes                        | projects/hateful_memes/configs/late_fusion/defaults.yaml   |\n",
    "| ConcatBERT       | concat_bert    | concat_bert.hateful_memes                        | projects/hateful_memes/configs/concat_bert/defaults.yaml   |\n",
    "| MMBT-Grid        | mmbt           | mmbt.hateful_memes.images                        | projects/hateful_memes/configs/mmbt/defaults.yaml          |\n",
    "| MMBT-Region      | mmbt           | mmbt.hateful_memes.features                      | projects/hateful_memes/configs/mmbt/with_features.yaml     |\n",
    "| ViLBERT          | vilbert        | vilbert.finetuned.hateful_memes.direct           | projects/hateful_memes/configs/vilbert/defaults.yaml       |\n",
    "| Visual BERT      | visual_bert    | visual_bert.finetuned.hateful_memes.direct       | projects/hateful_memes/configs/visual_bert/direct.yaml     |\n",
    "| ViLBERT CC       | vilbert        | vilbert.finetuned.hateful_memes.from_cc_original | projects/hateful_memes/configs/vilbert/from_cc.yaml        |\n",
    "| Visual BERT COCO | visual_bert    | visual_bert.finetuned.hateful_memes.from_coco    | projects/hateful_memes/configs/visual_bert/from_coco.yaml  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cd ../data/raw/\n",
    "# !wget \"https://drivendata-competition-fb-hateful-memes-data.s3.amazonaws.com/Lnmwdnq3YcF7F3YsJncp.zip?AWSAccessKeyId=AKIAJYJLFLA7N3WRICBQ&Signature=Vc9g%2B2IZYWz%2B%2FOAv3Hum2akybC0%3D&Expires=1591925619\"\n",
    "# !mmf_convert_hm --zip_file={PATH_DATA}/facebook_memes.zip --password=KexZs4tn8hujn1nK --mmf_data_folder={PATH_DATA}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baseline</th>\n",
       "      <th>model_key</th>\n",
       "      <th>pretrained_key</th>\n",
       "      <th>save_dir</th>\n",
       "      <th>baseline_config</th>\n",
       "      <th>custom_config</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Image-Grid</td>\n",
       "      <td>unimodal_image</td>\n",
       "      <td>unimodal_image.hateful_memes.images</td>\n",
       "      <td>unimodal_image_grid</td>\n",
       "      <td>configs/unimodal/image.yaml</td>\n",
       "      <td>configs/unimodal/image_custom.yaml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Image-Region</td>\n",
       "      <td>unimodal_image</td>\n",
       "      <td>unimodal_image.hateful_memes.features</td>\n",
       "      <td>unimodal_image_region</td>\n",
       "      <td>configs/unimodal/with_features.yaml</td>\n",
       "      <td>configs/unimodal/with_features_custom.yaml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Text BERT</td>\n",
       "      <td>unimodal_text</td>\n",
       "      <td>unimodal_text.hateful_memes.bert</td>\n",
       "      <td>unimodal_text</td>\n",
       "      <td>configs/unimodal/bert.yaml</td>\n",
       "      <td>configs/unimodal/bert_custom.yaml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Late Fusion</td>\n",
       "      <td>late_fusion</td>\n",
       "      <td>late_fusion.hateful_memes</td>\n",
       "      <td>late_fusion</td>\n",
       "      <td>configs/late_fusion/defaults.yaml</td>\n",
       "      <td>configs/late_fusion/defaults_custom.yaml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ConcatBERT</td>\n",
       "      <td>concat_bert</td>\n",
       "      <td>concat_bert.hateful_memes</td>\n",
       "      <td>concat_bert</td>\n",
       "      <td>configs/concat_bert/defaults.yaml</td>\n",
       "      <td>configs/concat_bert/defaults_custom.yaml</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       baseline       model_key                         pretrained_key  \\\n",
       "0    Image-Grid  unimodal_image    unimodal_image.hateful_memes.images   \n",
       "1  Image-Region  unimodal_image  unimodal_image.hateful_memes.features   \n",
       "2     Text BERT   unimodal_text       unimodal_text.hateful_memes.bert   \n",
       "3   Late Fusion     late_fusion              late_fusion.hateful_memes   \n",
       "4    ConcatBERT     concat_bert              concat_bert.hateful_memes   \n",
       "\n",
       "                save_dir                      baseline_config  \\\n",
       "0    unimodal_image_grid          configs/unimodal/image.yaml   \n",
       "1  unimodal_image_region  configs/unimodal/with_features.yaml   \n",
       "2          unimodal_text           configs/unimodal/bert.yaml   \n",
       "3            late_fusion    configs/late_fusion/defaults.yaml   \n",
       "4            concat_bert    configs/concat_bert/defaults.yaml   \n",
       "\n",
       "                                custom_config  \n",
       "0          configs/unimodal/image_custom.yaml  \n",
       "1  configs/unimodal/with_features_custom.yaml  \n",
       "2           configs/unimodal/bert_custom.yaml  \n",
       "3    configs/late_fusion/defaults_custom.yaml  \n",
       "4    configs/concat_bert/defaults_custom.yaml  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model_config = pd.read_csv(f'{PATH_MODEL}/model_config.csv', sep = ',')\n",
    "df_model_config.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MMF_SAVE_DIR=\"/home/jupyter/meme_hateful_detection/save/unimodal_image_grid\" mmf_run config=configs/unimodal/image_custom.yaml model=unimodal_image dataset=hateful_memes run_type=train checkpoint.resume_zoo=unimodal_image.hateful_memes.images\n",
      "MMF_SAVE_DIR=\"/home/jupyter/meme_hateful_detection/save/unimodal_image_region\" mmf_run config=configs/unimodal/with_features_custom.yaml model=unimodal_image dataset=hateful_memes run_type=train checkpoint.resume_zoo=unimodal_image.hateful_memes.features\n",
      "MMF_SAVE_DIR=\"/home/jupyter/meme_hateful_detection/save/unimodal_text\" mmf_run config=configs/unimodal/bert_custom.yaml model=unimodal_text dataset=hateful_memes run_type=train checkpoint.resume_zoo=unimodal_text.hateful_memes.bert\n",
      "MMF_SAVE_DIR=\"/home/jupyter/meme_hateful_detection/save/late_fusion\" mmf_run config=configs/late_fusion/defaults_custom.yaml model=late_fusion dataset=hateful_memes run_type=train checkpoint.resume_zoo=late_fusion.hateful_memes\n",
      "MMF_SAVE_DIR=\"/home/jupyter/meme_hateful_detection/save/concat_bert\" mmf_run config=configs/concat_bert/defaults_custom.yaml model=concat_bert dataset=hateful_memes run_type=train checkpoint.resume_zoo=concat_bert.hateful_memes\n",
      "MMF_SAVE_DIR=\"/home/jupyter/meme_hateful_detection/save/mmbt_grid\" mmf_run config=configs/mmbt/defaults_custom.yaml model=mmbt dataset=hateful_memes run_type=train checkpoint.resume_zoo=mmbt.hateful_memes.images\n",
      "MMF_SAVE_DIR=\"/home/jupyter/meme_hateful_detection/save/mmbt_region\" mmf_run config=configs/mmbt/with_features_custom.yaml model=mmbt dataset=hateful_memes run_type=train checkpoint.resume_zoo=mmbt.hateful_memes.features\n",
      "MMF_SAVE_DIR=\"/home/jupyter/meme_hateful_detection/save/vilbert_direct\" mmf_run config=configs/vilbert/defaults_custom.yaml model=vilbert dataset=hateful_memes run_type=train checkpoint.resume_zoo=vilbert.finetuned.hateful_memes.direct\n",
      "MMF_SAVE_DIR=\"/home/jupyter/meme_hateful_detection/save/visual_bert_direct\" mmf_run config=configs/visual_bert/direct_custom.yaml model=visual_bert dataset=hateful_memes run_type=train checkpoint.resume_zoo=visual_bert.finetuned.hateful_memes.direct\n",
      "MMF_SAVE_DIR=\"/home/jupyter/meme_hateful_detection/save/vilbert_from_cc\" mmf_run config=configs/vilbert/from_cc_custom.yaml model=vilbert dataset=hateful_memes run_type=train checkpoint.resume_zoo=vilbert.finetuned.hateful_memes.from_cc_original\n",
      "MMF_SAVE_DIR=\"/home/jupyter/meme_hateful_detection/save/visual_bert_from_coco\" mmf_run config=configs/visual_bert/from_coco_custom.yaml model=visual_bert dataset=hateful_memes run_type=train checkpoint.resume_zoo=visual_bert.finetuned.hateful_memes.from_coco\n"
     ]
    }
   ],
   "source": [
    "#Training model \n",
    "for index, row in df_model_config.iterrows():\n",
    "    model_baseline = row['baseline']\n",
    "    model_key = row['model_key']\n",
    "    model_pretrained_key = row['pretrained_key']\n",
    "    baseline_config = row['baseline_config']\n",
    "    custom_config = row['custom_config']\n",
    "    save_dir = row['save_dir']\n",
    "#     str_run_train = f'MMF_SAVE_DIR=\"{PATH_SAVE}/{save_dir}\" mmf_run config={custom_config} model={model_key} dataset=hateful_memes'\n",
    "#     !{str_run_train}\n",
    "#     print(str_run_train)\n",
    "    str_pret_eval = f'MMF_SAVE_DIR=\"{PATH_SAVE}/{save_dir}\" mmf_run config={custom_config} model={model_key} dataset=hateful_memes run_type=train checkpoint.resume_zoo={model_pretrained_key}'\n",
    "    print(str_pret_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !MMF_SAVE_DIR=\"/home/jupyter/meme_hateful_detection/save/unimodal_image_grid\" mmf_run config=configs/unimodal/image_custom.yaml model=unimodal_image dataset=hateful_memes run_type=train checkpoint.resume_zoo=unimodal_image.hateful_memes.images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !MMF_SAVE_DIR=\"/home/jupyter/meme_hateful_detection/save/unimodal_image_region\" mmf_run config=configs/unimodal/with_features_custom.yaml model=unimodal_image dataset=hateful_memes run_type=train checkpoint.resume_zoo=unimodal_image.hateful_memes.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !MMF_SAVE_DIR=\"/home/jupyter/meme_hateful_detection/save/unimodal_text\" mmf_run config=configs/unimodal/bert_custom.yaml model=unimodal_text dataset=hateful_memes run_type=train checkpoint.resume_zoo=unimodal_text.hateful_memes.bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing user_dir from /home/jupyter/meme_hateful_detection\n",
      "Overriding option config to configs/late_fusion/defaults_custom.yaml\n",
      "Overriding option model to late_fusion\n",
      "Overriding option datasets to hateful_memes\n",
      "Overriding option run_type to train\n",
      "Overriding option checkpoint.resume_zoo to late_fusion.hateful_memes\n",
      "Using seed 29920586\n",
      "Logging to: /home/jupyter/meme_hateful_detection/logs/train_2020-06-08T21:50:29.log\n",
      "2020-06-08T21:50:29 INFO: =====  Training Parameters    =====\n",
      "2020-06-08T21:50:29 INFO: {\n",
      "    \"batch_size\": 32,\n",
      "    \"checkpoint_interval\": 1000,\n",
      "    \"clip_gradients\": false,\n",
      "    \"clip_norm_mode\": \"all\",\n",
      "    \"dataset_size_proportional_sampling\": true,\n",
      "    \"device\": \"cuda\",\n",
      "    \"early_stop\": {\n",
      "        \"criteria\": \"hateful_memes/roc_auc\",\n",
      "        \"enabled\": false,\n",
      "        \"minimize\": false,\n",
      "        \"patience\": 4000\n",
      "    },\n",
      "    \"evaluate_metrics\": true,\n",
      "    \"evaluation_interval\": 1000,\n",
      "    \"experiment_name\": \"run\",\n",
      "    \"fast_read\": false,\n",
      "    \"find_unused_parameters\": false,\n",
      "    \"local_rank\": null,\n",
      "    \"log_detailed_config\": true,\n",
      "    \"log_format\": \"json\",\n",
      "    \"log_interval\": 100,\n",
      "    \"logger_level\": \"info\",\n",
      "    \"lr_ratio\": 0.1,\n",
      "    \"lr_scheduler\": true,\n",
      "    \"lr_steps\": [],\n",
      "    \"max_epochs\": null,\n",
      "    \"max_updates\": 22000,\n",
      "    \"num_workers\": 4,\n",
      "    \"pin_memory\": false,\n",
      "    \"seed\": 29920586,\n",
      "    \"should_not_log\": false,\n",
      "    \"tensorboard\": true,\n",
      "    \"trainer\": \"base_trainer\",\n",
      "    \"use_warmup\": false,\n",
      "    \"verbose_dump\": true,\n",
      "    \"warmup_factor\": 0.2,\n",
      "    \"warmup_iterations\": 1000\n",
      "}\n",
      "2020-06-08T21:50:29 INFO: ======  Dataset Attributes  ======\n",
      "2020-06-08T21:50:29 INFO: ======== hateful_memes =======\n",
      "2020-06-08T21:50:29 INFO: {\n",
      "    \"annotations\": {\n",
      "        \"test\": [\n",
      "            \"hateful_memes/defaults/annotations/test.jsonl\"\n",
      "        ],\n",
      "        \"train\": [\n",
      "            \"hateful_memes/defaults/annotations/train.jsonl\"\n",
      "        ],\n",
      "        \"val\": [\n",
      "            \"hateful_memes/defaults/annotations/dev.jsonl\"\n",
      "        ]\n",
      "    },\n",
      "    \"data_dir\": \"/home/jupyter/meme_hateful_detection/data/raw/datasets\",\n",
      "    \"depth_first\": false,\n",
      "    \"fast_read\": false,\n",
      "    \"features\": {\n",
      "        \"test\": [\n",
      "            \"hateful_memes/defaults/features/detectron.lmdb\"\n",
      "        ],\n",
      "        \"train\": [\n",
      "            \"hateful_memes/defaults/features/detectron.lmdb\"\n",
      "        ],\n",
      "        \"val\": [\n",
      "            \"hateful_memes/defaults/features/detectron.lmdb\"\n",
      "        ]\n",
      "    },\n",
      "    \"images\": {\n",
      "        \"test\": [\n",
      "            \"hateful_memes/defaults/images/\"\n",
      "        ],\n",
      "        \"train\": [\n",
      "            \"hateful_memes/defaults/images/\"\n",
      "        ],\n",
      "        \"val\": [\n",
      "            \"hateful_memes/defaults/images/\"\n",
      "        ]\n",
      "    },\n",
      "    \"max_features\": 100,\n",
      "    \"processors\": {\n",
      "        \"bbox_processor\": {\n",
      "            \"params\": {\n",
      "                \"max_length\": 50\n",
      "            },\n",
      "            \"type\": \"bbox\"\n",
      "        },\n",
      "        \"image_processor\": {\n",
      "            \"params\": {\n",
      "                \"transforms\": [\n",
      "                    {\n",
      "                        \"params\": {\n",
      "                            \"size\": [\n",
      "                                256,\n",
      "                                256\n",
      "                            ]\n",
      "                        },\n",
      "                        \"type\": \"Resize\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"params\": {\n",
      "                            \"size\": [\n",
      "                                224,\n",
      "                                224\n",
      "                            ]\n",
      "                        },\n",
      "                        \"type\": \"CenterCrop\"\n",
      "                    },\n",
      "                    \"ToTensor\",\n",
      "                    \"GrayScaleTo3Channels\",\n",
      "                    {\n",
      "                        \"params\": {\n",
      "                            \"mean\": [\n",
      "                                0.46777044,\n",
      "                                0.44531429,\n",
      "                                0.40661017\n",
      "                            ],\n",
      "                            \"std\": [\n",
      "                                0.12221994,\n",
      "                                0.12145835,\n",
      "                                0.14380469\n",
      "                            ]\n",
      "                        },\n",
      "                        \"type\": \"Normalize\"\n",
      "                    }\n",
      "                ]\n",
      "            },\n",
      "            \"type\": \"torchvision_transforms\"\n",
      "        },\n",
      "        \"text_processor\": {\n",
      "            \"params\": {\n",
      "                \"mask_probability\": 0,\n",
      "                \"max_length\": 14,\n",
      "                \"max_seq_length\": 128,\n",
      "                \"preprocessor\": {\n",
      "                    \"params\": {},\n",
      "                    \"type\": \"simple_sentence\"\n",
      "                },\n",
      "                \"tokenizer_config\": {\n",
      "                    \"params\": {\n",
      "                        \"do_lower_case\": true\n",
      "                    },\n",
      "                    \"type\": \"bert-base-uncased\"\n",
      "                },\n",
      "                \"vocab\": {\n",
      "                    \"embedding_name\": \"glove.6B.300d\",\n",
      "                    \"type\": \"intersected\",\n",
      "                    \"vocab_file\": \"hateful_memes/defaults/extras/vocabs/vocabulary_100k.txt\"\n",
      "                }\n",
      "            },\n",
      "            \"type\": \"bert_tokenizer\"\n",
      "        }\n",
      "    },\n",
      "    \"return_features_info\": false,\n",
      "    \"use_features\": false,\n",
      "    \"use_images\": true\n",
      "}\n",
      "2020-06-08T21:50:29 INFO: ======  Optimizer Attributes  ======\n",
      "2020-06-08T21:50:29 INFO: {\n",
      "    \"params\": {\n",
      "        \"eps\": 1e-08,\n",
      "        \"lr\": 5e-05\n",
      "    },\n",
      "    \"type\": \"adam_w\"\n",
      "}\n",
      "2020-06-08T21:50:29 INFO: ======  Model (late_fusion) Attributes  ======\n",
      "2020-06-08T21:50:29 INFO: {\n",
      "    \"bert_model_name\": \"bert-base-uncased\",\n",
      "    \"direct_features_input\": false,\n",
      "    \"finetune_lr_multiplier\": 1,\n",
      "    \"freeze_complete_base\": false,\n",
      "    \"freeze_modal\": false,\n",
      "    \"freeze_text\": false,\n",
      "    \"losses\": [\n",
      "        {\n",
      "            \"type\": \"cross_entropy\"\n",
      "        }\n",
      "    ],\n",
      "    \"modal_classifier\": {\n",
      "        \"params\": {\n",
      "            \"hidden_dim\": 768,\n",
      "            \"in_dim\": 2048,\n",
      "            \"num_layers\": 2,\n",
      "            \"out_dim\": 2\n",
      "        },\n",
      "        \"type\": \"mlp\"\n",
      "    },\n",
      "    \"modal_encoder\": {\n",
      "        \"params\": {\n",
      "            \"num_output_features\": 1,\n",
      "            \"pool_type\": \"avg\",\n",
      "            \"pretrained\": true\n",
      "        },\n",
      "        \"type\": \"resnet152\"\n",
      "    },\n",
      "    \"modal_hidden_size\": 2048,\n",
      "    \"num_features\": 100,\n",
      "    \"num_labels\": 2,\n",
      "    \"text_classifier\": {\n",
      "        \"params\": {\n",
      "            \"hidden_dim\": 768,\n",
      "            \"in_dim\": 768,\n",
      "            \"num_layers\": 2,\n",
      "            \"out_dim\": 2\n",
      "        },\n",
      "        \"type\": \"mlp\"\n",
      "    },\n",
      "    \"text_encoder\": {\n",
      "        \"params\": {\n",
      "            \"bert_model_name\": \"bert-base-uncased\",\n",
      "            \"hidden_size\": 768,\n",
      "            \"num_attention_heads\": 12,\n",
      "            \"num_hidden_layers\": 12,\n",
      "            \"output_attentions\": false,\n",
      "            \"output_hidden_states\": false\n",
      "        },\n",
      "        \"type\": \"transformer\"\n",
      "    },\n",
      "    \"text_hidden_size\": 768\n",
      "}\n",
      "2020-06-08T21:50:29 INFO: Loading datasets\n",
      "2020-06-08T21:50:40 INFO: CUDA Device 0 is: Tesla T4\n",
      "2020-06-08T21:50:44 INFO: Torch version is: 1.5.0+cu101\n",
      "2020-06-08T21:50:44 INFO: Loading checkpoint\n",
      "2020-06-08T21:50:51 WARNING: /home/jupyter/mmf/mmf/utils/checkpoint.py:224: UserWarning: 'optimizer' key is not present in the checkpoint asked to be loaded. Skipping.\n",
      "  \"'optimizer' key is not present in the \"\n",
      "\n",
      "2020-06-08T21:50:51 INFO: Checkpoint loaded\n",
      "2020-06-08T21:50:51 INFO: ===== Model =====\n",
      "2020-06-08T21:50:51 INFO: LateFusion(\n",
      "  (base): FusionBase(\n",
      "    (text): BertModel(\n",
      "      (embeddings): BertEmbeddings(\n",
      "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "        (position_embeddings): Embedding(512, 768)\n",
      "        (token_type_embeddings): Embedding(2, 768)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (encoder): BertEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (2): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (3): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (4): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (5): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (6): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (7): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (8): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (9): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (10): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (11): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (pooler): BertPooler(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (activation): Tanh()\n",
      "      )\n",
      "    )\n",
      "    (modal): ResNet152ImageEncoder(\n",
      "      (model): Sequential(\n",
      "        (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "        (4): Sequential(\n",
      "          (0): Bottleneck(\n",
      "            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (downsample): Sequential(\n",
      "              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (1): Bottleneck(\n",
      "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (2): Bottleneck(\n",
      "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (5): Sequential(\n",
      "          (0): Bottleneck(\n",
      "            (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (downsample): Sequential(\n",
      "              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (1): Bottleneck(\n",
      "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (2): Bottleneck(\n",
      "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (3): Bottleneck(\n",
      "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (4): Bottleneck(\n",
      "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (5): Bottleneck(\n",
      "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (6): Bottleneck(\n",
      "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (7): Bottleneck(\n",
      "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (6): Sequential(\n",
      "          (0): Bottleneck(\n",
      "            (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (downsample): Sequential(\n",
      "              (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (1): Bottleneck(\n",
      "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (2): Bottleneck(\n",
      "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (3): Bottleneck(\n",
      "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (4): Bottleneck(\n",
      "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (5): Bottleneck(\n",
      "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (6): Bottleneck(\n",
      "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (7): Bottleneck(\n",
      "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (8): Bottleneck(\n",
      "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (9): Bottleneck(\n",
      "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (10): Bottleneck(\n",
      "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (11): Bottleneck(\n",
      "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (12): Bottleneck(\n",
      "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (13): Bottleneck(\n",
      "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (14): Bottleneck(\n",
      "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (15): Bottleneck(\n",
      "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (16): Bottleneck(\n",
      "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (17): Bottleneck(\n",
      "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (18): Bottleneck(\n",
      "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (19): Bottleneck(\n",
      "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (20): Bottleneck(\n",
      "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (21): Bottleneck(\n",
      "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (22): Bottleneck(\n",
      "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (23): Bottleneck(\n",
      "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (24): Bottleneck(\n",
      "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (25): Bottleneck(\n",
      "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (26): Bottleneck(\n",
      "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (27): Bottleneck(\n",
      "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (28): Bottleneck(\n",
      "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (29): Bottleneck(\n",
      "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (30): Bottleneck(\n",
      "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (31): Bottleneck(\n",
      "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (32): Bottleneck(\n",
      "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (33): Bottleneck(\n",
      "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (34): Bottleneck(\n",
      "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (35): Bottleneck(\n",
      "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (7): Sequential(\n",
      "          (0): Bottleneck(\n",
      "            (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (downsample): Sequential(\n",
      "              (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "              (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (1): Bottleneck(\n",
      "            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (2): Bottleneck(\n",
      "            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (modal_classifier): MLPClassifer(\n",
      "    (layers): ModuleList(\n",
      "      (0): Linear(in_features=2048, out_features=768, bias=True)\n",
      "      (1): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): Dropout(p=0.5, inplace=False)\n",
      "      (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (5): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (6): ReLU()\n",
      "      (7): Dropout(p=0.5, inplace=False)\n",
      "      (8): Linear(in_features=768, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (text_classifier): MLPClassifer(\n",
      "    (layers): ModuleList(\n",
      "      (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (1): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): Dropout(p=0.5, inplace=False)\n",
      "      (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (5): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (6): ReLU()\n",
      "      (7): Dropout(p=0.5, inplace=False)\n",
      "      (8): Linear(in_features=768, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (losses): Losses()\n",
      ")\n",
      "2020-06-08T21:50:51 INFO: Total Parameters: 170980676. Trained Parameters: 170980676\n",
      "2020-06-08T21:50:51 INFO: Starting training...\n",
      "2020-06-08T21:50:54 WARNING: /pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "\n",
      "2020-06-08T21:50:54 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-08T21:53:55 INFO: {\"progress\": \"100/22000\", \"train/total_loss\": \"0.0965\", \"train/total_loss/avg\": \"0.0965\", \"train/hateful_memes/cross_entropy\": \"0.0965\", \"train/hateful_memes/cross_entropy/avg\": \"0.0965\", \"train/hateful_memes/accuracy\": \"0.9688\", \"train/hateful_memes/accuracy/avg\": \"0.9688\", \"train/hateful_memes/binary_f1\": \"0.9677\", \"train/hateful_memes/binary_f1/avg\": \"0.9677\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"1.0000\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 1, \"num_updates\": 100, \"iterations\": 100, \"max_updates\": 22000, \"lr\": \"0.\", \"ups\": \"0.55\", \"time\": \"03m 03s 645ms\", \"time_since_start\": \"03m 25s 548ms\", \"eta\": \"11h 10m 18s 459ms\"}\n",
      "2020-06-08T21:53:57 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-08T21:57:01 INFO: {\"progress\": \"200/22000\", \"train/total_loss\": \"0.0504\", \"train/total_loss/avg\": \"0.0735\", \"train/hateful_memes/cross_entropy\": \"0.0504\", \"train/hateful_memes/cross_entropy/avg\": \"0.0735\", \"train/hateful_memes/accuracy\": \"0.9688\", \"train/hateful_memes/accuracy/avg\": \"0.9844\", \"train/hateful_memes/binary_f1\": \"0.9677\", \"train/hateful_memes/binary_f1/avg\": \"0.9839\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"1.0000\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 1, \"num_updates\": 200, \"iterations\": 200, \"max_updates\": 22000, \"lr\": \"0.\", \"ups\": \"0.54\", \"time\": \"03m 06s 086ms\", \"time_since_start\": \"06m 31s 634ms\", \"eta\": \"11h 16m 06s 874ms\"}\n",
      "2020-06-08T21:57:03 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-08T22:00:07 INFO: {\"progress\": \"300/22000\", \"train/total_loss\": \"0.0504\", \"train/total_loss/avg\": \"0.0567\", \"train/hateful_memes/cross_entropy\": \"0.0504\", \"train/hateful_memes/cross_entropy/avg\": \"0.0567\", \"train/hateful_memes/accuracy\": \"1.0000\", \"train/hateful_memes/accuracy/avg\": \"0.9896\", \"train/hateful_memes/binary_f1\": \"1.0000\", \"train/hateful_memes/binary_f1/avg\": \"0.9892\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"1.0000\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 2, \"num_updates\": 300, \"iterations\": 300, \"max_updates\": 22000, \"lr\": \"0.00001\", \"ups\": \"0.54\", \"time\": \"03m 06s 110ms\", \"time_since_start\": \"09m 37s 745ms\", \"eta\": \"11h 13m 06s 025ms\"}\n",
      "2020-06-08T22:00:09 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-08T22:03:13 INFO: {\"progress\": \"400/22000\", \"train/total_loss\": \"0.0504\", \"train/total_loss/avg\": \"0.0589\", \"train/hateful_memes/cross_entropy\": \"0.0504\", \"train/hateful_memes/cross_entropy/avg\": \"0.0589\", \"train/hateful_memes/accuracy\": \"0.9688\", \"train/hateful_memes/accuracy/avg\": \"0.9844\", \"train/hateful_memes/binary_f1\": \"0.9677\", \"train/hateful_memes/binary_f1/avg\": \"0.9788\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"1.0000\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 2, \"num_updates\": 400, \"iterations\": 400, \"max_updates\": 22000, \"lr\": \"0.00001\", \"ups\": \"0.54\", \"time\": \"03m 05s 959ms\", \"time_since_start\": \"12m 43s 704ms\", \"eta\": \"11h 09m 27s 153ms\"}\n",
      "2020-06-08T22:03:15 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-08T22:06:19 INFO: {\"progress\": \"500/22000\", \"train/total_loss\": \"0.0504\", \"train/total_loss/avg\": \"0.0550\", \"train/hateful_memes/cross_entropy\": \"0.0504\", \"train/hateful_memes/cross_entropy/avg\": \"0.0550\", \"train/hateful_memes/accuracy\": \"1.0000\", \"train/hateful_memes/accuracy/avg\": \"0.9875\", \"train/hateful_memes/binary_f1\": \"1.0000\", \"train/hateful_memes/binary_f1/avg\": \"0.9830\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"1.0000\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 2, \"num_updates\": 500, \"iterations\": 500, \"max_updates\": 22000, \"lr\": \"0.00001\", \"ups\": \"0.54\", \"time\": \"03m 05s 615ms\", \"time_since_start\": \"15m 49s 320ms\", \"eta\": \"11h 05m 07s 348ms\"}\n",
      "2020-06-08T22:06:21 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-08T22:09:25 INFO: {\"progress\": \"600/22000\", \"train/total_loss\": \"0.0392\", \"train/total_loss/avg\": \"0.0501\", \"train/hateful_memes/cross_entropy\": \"0.0392\", \"train/hateful_memes/cross_entropy/avg\": \"0.0501\", \"train/hateful_memes/accuracy\": \"1.0000\", \"train/hateful_memes/accuracy/avg\": \"0.9896\", \"train/hateful_memes/binary_f1\": \"1.0000\", \"train/hateful_memes/binary_f1/avg\": \"0.9859\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"1.0000\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 3, \"num_updates\": 600, \"iterations\": 600, \"max_updates\": 22000, \"lr\": \"0.00001\", \"ups\": \"0.54\", \"time\": \"03m 06s 131ms\", \"time_since_start\": \"18m 55s 451ms\", \"eta\": \"11h 03m 52s 112ms\"}\n",
      "2020-06-08T22:09:27 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-08T22:12:31 INFO: {\"progress\": \"700/22000\", \"train/total_loss\": \"0.0392\", \"train/total_loss/avg\": \"0.0459\", \"train/hateful_memes/cross_entropy\": \"0.0392\", \"train/hateful_memes/cross_entropy/avg\": \"0.0459\", \"train/hateful_memes/accuracy\": \"1.0000\", \"train/hateful_memes/accuracy/avg\": \"0.9911\", \"train/hateful_memes/binary_f1\": \"1.0000\", \"train/hateful_memes/binary_f1/avg\": \"0.9879\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"1.0000\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 3, \"num_updates\": 700, \"iterations\": 700, \"max_updates\": 22000, \"lr\": \"0.00002\", \"ups\": \"0.54\", \"time\": \"03m 05s 794ms\", \"time_since_start\": \"22m 01s 246ms\", \"eta\": \"10h 59m 34s 274ms\"}\n",
      "2020-06-08T22:12:32 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-08T22:15:36 INFO: {\"progress\": \"800/22000\", \"train/total_loss\": \"0.0279\", \"train/total_loss/avg\": \"0.0437\", \"train/hateful_memes/cross_entropy\": \"0.0279\", \"train/hateful_memes/cross_entropy/avg\": \"0.0437\", \"train/hateful_memes/accuracy\": \"1.0000\", \"train/hateful_memes/accuracy/avg\": \"0.9922\", \"train/hateful_memes/binary_f1\": \"1.0000\", \"train/hateful_memes/binary_f1/avg\": \"0.9894\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"1.0000\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 4, \"num_updates\": 800, \"iterations\": 800, \"max_updates\": 22000, \"lr\": \"0.00002\", \"ups\": \"0.54\", \"time\": \"03m 05s 854ms\", \"time_since_start\": \"25m 07s 100ms\", \"eta\": \"10h 56m 41s 132ms\"}\n",
      "2020-06-08T22:15:38 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-08T22:18:42 INFO: {\"progress\": \"900/22000\", \"train/total_loss\": \"0.0392\", \"train/total_loss/avg\": \"0.0440\", \"train/hateful_memes/cross_entropy\": \"0.0392\", \"train/hateful_memes/cross_entropy/avg\": \"0.0440\", \"train/hateful_memes/accuracy\": \"1.0000\", \"train/hateful_memes/accuracy/avg\": \"0.9896\", \"train/hateful_memes/binary_f1\": \"1.0000\", \"train/hateful_memes/binary_f1/avg\": \"0.9865\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"1.0000\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 4, \"num_updates\": 900, \"iterations\": 900, \"max_updates\": 22000, \"lr\": \"0.00002\", \"ups\": \"0.54\", \"time\": \"03m 05s 619ms\", \"time_since_start\": \"28m 12s 720ms\", \"eta\": \"10h 52m 45s 740ms\"}\n",
      "2020-06-08T22:18:44 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-08T22:21:48 INFO: {\"progress\": \"1000/22000\", \"train/total_loss\": \"0.0392\", \"train/total_loss/avg\": \"0.0460\", \"train/hateful_memes/cross_entropy\": \"0.0392\", \"train/hateful_memes/cross_entropy/avg\": \"0.0460\", \"train/hateful_memes/accuracy\": \"1.0000\", \"train/hateful_memes/accuracy/avg\": \"0.9875\", \"train/hateful_memes/binary_f1\": \"1.0000\", \"train/hateful_memes/binary_f1/avg\": \"0.9835\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"1.0000\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 4, \"num_updates\": 1000, \"iterations\": 1000, \"max_updates\": 22000, \"lr\": \"0.00002\", \"ups\": \"0.54\", \"time\": \"03m 05s 617ms\", \"time_since_start\": \"31m 18s 338ms\", \"eta\": \"10h 49m 39s 691ms\"}\n",
      "2020-06-08T22:21:48 INFO: Checkpoint time. Saving a checkpoint.\n",
      "2020-06-08T22:21:52 INFO: Evaluation time. Running on full validation set...\n",
      "2020-06-08T22:22:50 INFO: {\"progress\": \"1000/22000\", \"val/total_loss\": \"2.3707\", \"val/hateful_memes/cross_entropy\": \"2.3707\", \"val/hateful_memes/accuracy\": \"0.5720\", \"val/hateful_memes/binary_f1\": \"0.3743\", \"val/hateful_memes/roc_auc\": \"0.6221\", \"num_updates\": 1000, \"epoch\": 4, \"iterations\": 1000, \"max_updates\": 22000, \"val_time\": \"10s 966ms\", \"best_update\": 1000, \"best_iteration\": 1000, \"best_val/hateful_memes/roc_auc\": \"0.622120\"}\n",
      "2020-06-08T22:22:52 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-08T22:25:57 INFO: {\"progress\": \"1100/22000\", \"train/total_loss\": \"0.0392\", \"train/total_loss/avg\": \"0.0446\", \"train/hateful_memes/cross_entropy\": \"0.0392\", \"train/hateful_memes/cross_entropy/avg\": \"0.0446\", \"train/hateful_memes/accuracy\": \"1.0000\", \"train/hateful_memes/accuracy/avg\": \"0.9886\", \"train/hateful_memes/binary_f1\": \"1.0000\", \"train/hateful_memes/binary_f1/avg\": \"0.9850\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"1.0000\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 5, \"num_updates\": 1100, \"iterations\": 1100, \"max_updates\": 22000, \"lr\": \"0.00003\", \"ups\": \"0.54\", \"time\": \"03m 06s 499ms\", \"time_since_start\": \"35m 27s 538ms\", \"eta\": \"10h 49m 38s 364ms\"}\n",
      "2020-06-08T22:25:59 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-08T22:29:02 INFO: {\"progress\": \"1200/22000\", \"train/total_loss\": \"0.0392\", \"train/total_loss/avg\": \"0.0442\", \"train/hateful_memes/cross_entropy\": \"0.0392\", \"train/hateful_memes/cross_entropy/avg\": \"0.0442\", \"train/hateful_memes/accuracy\": \"1.0000\", \"train/hateful_memes/accuracy/avg\": \"0.9896\", \"train/hateful_memes/binary_f1\": \"1.0000\", \"train/hateful_memes/binary_f1/avg\": \"0.9862\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"1.0000\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 5, \"num_updates\": 1200, \"iterations\": 1200, \"max_updates\": 22000, \"lr\": \"0.00003\", \"ups\": \"0.54\", \"time\": \"03m 05s 581ms\", \"time_since_start\": \"38m 33s 119ms\", \"eta\": \"10h 43m 20s 918ms\"}\n",
      "2020-06-08T22:29:04 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-08T22:32:08 INFO: {\"progress\": \"1300/22000\", \"train/total_loss\": \"0.0400\", \"train/total_loss/avg\": \"0.0527\", \"train/hateful_memes/cross_entropy\": \"0.0400\", \"train/hateful_memes/cross_entropy/avg\": \"0.0527\", \"train/hateful_memes/accuracy\": \"1.0000\", \"train/hateful_memes/accuracy/avg\": \"0.9856\", \"train/hateful_memes/binary_f1\": \"1.0000\", \"train/hateful_memes/binary_f1/avg\": \"0.9803\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9990\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 5, \"num_updates\": 1300, \"iterations\": 1300, \"max_updates\": 22000, \"lr\": \"0.00003\", \"ups\": \"0.54\", \"time\": \"03m 05s 718ms\", \"time_since_start\": \"41m 38s 838ms\", \"eta\": \"10h 40m 43s 738ms\"}\n",
      "2020-06-08T22:32:10 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-08T22:35:14 INFO: {\"progress\": \"1400/22000\", \"train/total_loss\": \"0.0400\", \"train/total_loss/avg\": \"0.0585\", \"train/hateful_memes/cross_entropy\": \"0.0400\", \"train/hateful_memes/cross_entropy/avg\": \"0.0585\", \"train/hateful_memes/accuracy\": \"1.0000\", \"train/hateful_memes/accuracy/avg\": \"0.9821\", \"train/hateful_memes/binary_f1\": \"1.0000\", \"train/hateful_memes/binary_f1/avg\": \"0.9766\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9991\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 6, \"num_updates\": 1400, \"iterations\": 1400, \"max_updates\": 22000, \"lr\": \"0.00003\", \"ups\": \"0.54\", \"time\": \"03m 06s 091ms\", \"time_since_start\": \"44m 44s 930ms\", \"eta\": \"10h 38m 54s 901ms\"}\n",
      "2020-06-08T22:35:16 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-08T22:38:20 INFO: {\"progress\": \"1500/22000\", \"train/total_loss\": \"0.0462\", \"train/total_loss/avg\": \"0.0588\", \"train/hateful_memes/cross_entropy\": \"0.0462\", \"train/hateful_memes/cross_entropy/avg\": \"0.0588\", \"train/hateful_memes/accuracy\": \"1.0000\", \"train/hateful_memes/accuracy/avg\": \"0.9812\", \"train/hateful_memes/binary_f1\": \"1.0000\", \"train/hateful_memes/binary_f1/avg\": \"0.9746\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9991\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 6, \"num_updates\": 1500, \"iterations\": 1500, \"max_updates\": 22000, \"lr\": \"0.00004\", \"ups\": \"0.54\", \"time\": \"03m 05s 853ms\", \"time_since_start\": \"47m 50s 783ms\", \"eta\": \"10h 34m 59s 917ms\"}\n",
      "2020-06-08T22:38:22 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-08T22:41:26 INFO: {\"progress\": \"1600/22000\", \"train/total_loss\": \"0.0462\", \"train/total_loss/avg\": \"0.0697\", \"train/hateful_memes/cross_entropy\": \"0.0462\", \"train/hateful_memes/cross_entropy/avg\": \"0.0697\", \"train/hateful_memes/accuracy\": \"0.9688\", \"train/hateful_memes/accuracy/avg\": \"0.9746\", \"train/hateful_memes/binary_f1\": \"0.9677\", \"train/hateful_memes/binary_f1/avg\": \"0.9554\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9992\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 7, \"num_updates\": 1600, \"iterations\": 1600, \"max_updates\": 22000, \"lr\": \"0.00004\", \"ups\": \"0.54\", \"time\": \"03m 05s 957ms\", \"time_since_start\": \"50m 56s 741ms\", \"eta\": \"10h 32m 15s 413ms\"}\n",
      "2020-06-08T22:41:28 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-08T22:44:32 INFO: {\"progress\": \"1700/22000\", \"train/total_loss\": \"0.0504\", \"train/total_loss/avg\": \"0.0696\", \"train/hateful_memes/cross_entropy\": \"0.0504\", \"train/hateful_memes/cross_entropy/avg\": \"0.0696\", \"train/hateful_memes/accuracy\": \"0.9688\", \"train/hateful_memes/accuracy/avg\": \"0.9743\", \"train/hateful_memes/binary_f1\": \"0.9677\", \"train/hateful_memes/binary_f1/avg\": \"0.9549\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9992\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 7, \"num_updates\": 1700, \"iterations\": 1700, \"max_updates\": 22000, \"lr\": \"0.00004\", \"ups\": \"0.54\", \"time\": \"03m 05s 924ms\", \"time_since_start\": \"54m 02s 665ms\", \"eta\": \"10h 29m 02s 592ms\"}\n",
      "2020-06-08T22:44:34 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-08T22:47:38 INFO: {\"progress\": \"1800/22000\", \"train/total_loss\": \"0.0504\", \"train/total_loss/avg\": \"0.0700\", \"train/hateful_memes/cross_entropy\": \"0.0504\", \"train/hateful_memes/cross_entropy/avg\": \"0.0700\", \"train/hateful_memes/accuracy\": \"0.9688\", \"train/hateful_memes/accuracy/avg\": \"0.9740\", \"train/hateful_memes/binary_f1\": \"0.9630\", \"train/hateful_memes/binary_f1/avg\": \"0.9550\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9993\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 7, \"num_updates\": 1800, \"iterations\": 1800, \"max_updates\": 22000, \"lr\": \"0.00004\", \"ups\": \"0.54\", \"time\": \"03m 05s 620ms\", \"time_since_start\": \"57m 08s 285ms\", \"eta\": \"10h 24m 55s 339ms\"}\n",
      "2020-06-08T22:47:40 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-08T22:50:44 INFO: {\"progress\": \"1900/22000\", \"train/total_loss\": \"0.0504\", \"train/total_loss/avg\": \"0.0679\", \"train/hateful_memes/cross_entropy\": \"0.0504\", \"train/hateful_memes/cross_entropy/avg\": \"0.0679\", \"train/hateful_memes/accuracy\": \"0.9688\", \"train/hateful_memes/accuracy/avg\": \"0.9753\", \"train/hateful_memes/binary_f1\": \"0.9677\", \"train/hateful_memes/binary_f1/avg\": \"0.9574\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9993\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 8, \"num_updates\": 1900, \"iterations\": 1900, \"max_updates\": 22000, \"lr\": \"0.00005\", \"ups\": \"0.54\", \"time\": \"03m 05s 888ms\", \"time_since_start\": \"01h 14s 174ms\", \"eta\": \"10h 22m 43s 512ms\"}\n",
      "2020-06-08T22:50:45 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-08T22:53:49 INFO: {\"progress\": \"2000/22000\", \"train/total_loss\": \"0.0462\", \"train/total_loss/avg\": \"0.0662\", \"train/hateful_memes/cross_entropy\": \"0.0462\", \"train/hateful_memes/cross_entropy/avg\": \"0.0662\", \"train/hateful_memes/accuracy\": \"0.9688\", \"train/hateful_memes/accuracy/avg\": \"0.9766\", \"train/hateful_memes/binary_f1\": \"0.9677\", \"train/hateful_memes/binary_f1/avg\": \"0.9595\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9994\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 8, \"num_updates\": 2000, \"iterations\": 2000, \"max_updates\": 22000, \"lr\": \"0.00005\", \"ups\": \"0.54\", \"time\": \"03m 05s 741ms\", \"time_since_start\": \"01h 03m 19s 915ms\", \"eta\": \"10h 19m 08s 231ms\"}\n",
      "2020-06-08T22:53:49 INFO: Checkpoint time. Saving a checkpoint.\n",
      "2020-06-08T22:54:10 INFO: Evaluation time. Running on full validation set...\n",
      "2020-06-08T22:55:24 INFO: {\"progress\": \"2000/22000\", \"val/total_loss\": \"1.8659\", \"val/hateful_memes/cross_entropy\": \"1.8659\", \"val/hateful_memes/accuracy\": \"0.6000\", \"val/hateful_memes/binary_f1\": \"0.4949\", \"val/hateful_memes/roc_auc\": \"0.6397\", \"num_updates\": 2000, \"epoch\": 8, \"iterations\": 2000, \"max_updates\": 22000, \"val_time\": \"22s 786ms\", \"best_update\": 2000, \"best_iteration\": 2000, \"best_val/hateful_memes/roc_auc\": \"0.639708\"}\n",
      "2020-06-08T22:55:26 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-08T22:58:31 INFO: {\"progress\": \"2100/22000\", \"train/total_loss\": \"0.0405\", \"train/total_loss/avg\": \"0.0650\", \"train/hateful_memes/cross_entropy\": \"0.0405\", \"train/hateful_memes/cross_entropy/avg\": \"0.0650\", \"train/hateful_memes/accuracy\": \"1.0000\", \"train/hateful_memes/accuracy/avg\": \"0.9777\", \"train/hateful_memes/binary_f1\": \"1.0000\", \"train/hateful_memes/binary_f1/avg\": \"0.9614\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9994\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 8, \"num_updates\": 2100, \"iterations\": 2100, \"max_updates\": 22000, \"lr\": \"0.00005\", \"ups\": \"0.54\", \"time\": \"03m 06s 332ms\", \"time_since_start\": \"01h 08m 01s 547ms\", \"eta\": \"10h 18m 227ms\"}\n",
      "2020-06-08T22:58:33 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-08T23:01:37 INFO: {\"progress\": \"2200/22000\", \"train/total_loss\": \"0.0400\", \"train/total_loss/avg\": \"0.0633\", \"train/hateful_memes/cross_entropy\": \"0.0400\", \"train/hateful_memes/cross_entropy/avg\": \"0.0633\", \"train/hateful_memes/accuracy\": \"1.0000\", \"train/hateful_memes/accuracy/avg\": \"0.9787\", \"train/hateful_memes/binary_f1\": \"1.0000\", \"train/hateful_memes/binary_f1/avg\": \"0.9632\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9994\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 9, \"num_updates\": 2200, \"iterations\": 2200, \"max_updates\": 22000, \"lr\": \"0.00005\", \"ups\": \"0.54\", \"time\": \"03m 06s 008ms\", \"time_since_start\": \"01h 11m 07s 556ms\", \"eta\": \"10h 13m 49s 758ms\"}\n",
      "2020-06-08T23:01:39 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-08T23:04:43 INFO: {\"progress\": \"2300/22000\", \"train/total_loss\": \"0.0405\", \"train/total_loss/avg\": \"0.0651\", \"train/hateful_memes/cross_entropy\": \"0.0405\", \"train/hateful_memes/cross_entropy/avg\": \"0.0651\", \"train/hateful_memes/accuracy\": \"0.9688\", \"train/hateful_memes/accuracy/avg\": \"0.9783\", \"train/hateful_memes/binary_f1\": \"0.9630\", \"train/hateful_memes/binary_f1/avg\": \"0.9629\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9989\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 9, \"num_updates\": 2300, \"iterations\": 2300, \"max_updates\": 22000, \"lr\": \"0.00005\", \"ups\": \"0.54\", \"time\": \"03m 05s 767ms\", \"time_since_start\": \"01h 14m 13s 324ms\", \"eta\": \"10h 09m 56s 178ms\"}\n",
      "2020-06-08T23:04:45 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-08T23:07:49 INFO: {\"progress\": \"2400/22000\", \"train/total_loss\": \"0.0405\", \"train/total_loss/avg\": \"0.0646\", \"train/hateful_memes/cross_entropy\": \"0.0405\", \"train/hateful_memes/cross_entropy/avg\": \"0.0646\", \"train/hateful_memes/accuracy\": \"0.9688\", \"train/hateful_memes/accuracy/avg\": \"0.9779\", \"train/hateful_memes/binary_f1\": \"0.9677\", \"train/hateful_memes/binary_f1/avg\": \"0.9631\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9989\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 10, \"num_updates\": 2400, \"iterations\": 2400, \"max_updates\": 22000, \"lr\": \"0.00005\", \"ups\": \"0.54\", \"time\": \"03m 05s 918ms\", \"time_since_start\": \"01h 17m 19s 242ms\", \"eta\": \"10h 07m 20s 029ms\"}\n",
      "2020-06-08T23:07:50 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-08T23:10:55 INFO: {\"progress\": \"2500/22000\", \"train/total_loss\": \"0.0462\", \"train/total_loss/avg\": \"0.0659\", \"train/hateful_memes/cross_entropy\": \"0.0462\", \"train/hateful_memes/cross_entropy/avg\": \"0.0659\", \"train/hateful_memes/accuracy\": \"0.9688\", \"train/hateful_memes/accuracy/avg\": \"0.9775\", \"train/hateful_memes/binary_f1\": \"0.9630\", \"train/hateful_memes/binary_f1/avg\": \"0.9627\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9990\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 10, \"num_updates\": 2500, \"iterations\": 2500, \"max_updates\": 22000, \"lr\": \"0.00005\", \"ups\": \"0.54\", \"time\": \"03m 06s 144ms\", \"time_since_start\": \"01h 20m 25s 386ms\", \"eta\": \"10h 04m 58s 109ms\"}\n",
      "2020-06-08T23:10:57 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-08T23:14:01 INFO: {\"progress\": \"2600/22000\", \"train/total_loss\": \"0.0462\", \"train/total_loss/avg\": \"0.0648\", \"train/hateful_memes/cross_entropy\": \"0.0462\", \"train/hateful_memes/cross_entropy/avg\": \"0.0648\", \"train/hateful_memes/accuracy\": \"0.9688\", \"train/hateful_memes/accuracy/avg\": \"0.9772\", \"train/hateful_memes/binary_f1\": \"0.9565\", \"train/hateful_memes/binary_f1/avg\": \"0.9624\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9990\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 10, \"num_updates\": 2600, \"iterations\": 2600, \"max_updates\": 22000, \"lr\": \"0.00005\", \"ups\": \"0.54\", \"time\": \"03m 05s 887ms\", \"time_since_start\": \"01h 23m 31s 274ms\", \"eta\": \"10h 01m 02s 203ms\"}\n",
      "2020-06-08T23:14:03 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-08T23:17:07 INFO: {\"progress\": \"2700/22000\", \"train/total_loss\": \"0.0533\", \"train/total_loss/avg\": \"0.0665\", \"train/hateful_memes/cross_entropy\": \"0.0533\", \"train/hateful_memes/cross_entropy/avg\": \"0.0665\", \"train/hateful_memes/accuracy\": \"0.9688\", \"train/hateful_memes/accuracy/avg\": \"0.9769\", \"train/hateful_memes/binary_f1\": \"0.9565\", \"train/hateful_memes/binary_f1/avg\": \"0.9619\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9991\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 11, \"num_updates\": 2700, \"iterations\": 2700, \"max_updates\": 22000, \"lr\": \"0.00005\", \"ups\": \"0.54\", \"time\": \"03m 05s 967ms\", \"time_since_start\": \"01h 26m 37s 241ms\", \"eta\": \"09h 58m 11s 729ms\"}\n",
      "2020-06-08T23:17:08 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-08T23:20:13 INFO: {\"progress\": \"2800/22000\", \"train/total_loss\": \"0.0632\", \"train/total_loss/avg\": \"0.0752\", \"train/hateful_memes/cross_entropy\": \"0.0632\", \"train/hateful_memes/cross_entropy/avg\": \"0.0752\", \"train/hateful_memes/accuracy\": \"0.9688\", \"train/hateful_memes/accuracy/avg\": \"0.9732\", \"train/hateful_memes/binary_f1\": \"0.9565\", \"train/hateful_memes/binary_f1/avg\": \"0.9543\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9989\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 11, \"num_updates\": 2800, \"iterations\": 2800, \"max_updates\": 22000, \"lr\": \"0.00005\", \"ups\": \"0.54\", \"time\": \"03m 05s 951ms\", \"time_since_start\": \"01h 29m 43s 193ms\", \"eta\": \"09h 55m 02s 783ms\"}\n",
      "2020-06-08T23:20:14 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-08T23:23:18 INFO: {\"progress\": \"2900/22000\", \"train/total_loss\": \"0.0632\", \"train/total_loss/avg\": \"0.0734\", \"train/hateful_memes/cross_entropy\": \"0.0632\", \"train/hateful_memes/cross_entropy/avg\": \"0.0734\", \"train/hateful_memes/accuracy\": \"0.9688\", \"train/hateful_memes/accuracy/avg\": \"0.9741\", \"train/hateful_memes/binary_f1\": \"0.9565\", \"train/hateful_memes/binary_f1/avg\": \"0.9559\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9989\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 11, \"num_updates\": 2900, \"iterations\": 2900, \"max_updates\": 22000, \"lr\": \"0.00005\", \"ups\": \"0.54\", \"time\": \"03m 05s 860ms\", \"time_since_start\": \"01h 32m 49s 054ms\", \"eta\": \"09h 51m 39s 383ms\"}\n",
      "2020-06-08T23:23:20 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-08T23:26:24 INFO: {\"progress\": \"3000/22000\", \"train/total_loss\": \"0.0533\", \"train/total_loss/avg\": \"0.0716\", \"train/hateful_memes/cross_entropy\": \"0.0533\", \"train/hateful_memes/cross_entropy/avg\": \"0.0716\", \"train/hateful_memes/accuracy\": \"0.9688\", \"train/hateful_memes/accuracy/avg\": \"0.9750\", \"train/hateful_memes/binary_f1\": \"0.9565\", \"train/hateful_memes/binary_f1/avg\": \"0.9574\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9989\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 12, \"num_updates\": 3000, \"iterations\": 3000, \"max_updates\": 22000, \"lr\": \"0.00005\", \"ups\": \"0.54\", \"time\": \"03m 05s 762ms\", \"time_since_start\": \"01h 35m 54s 816ms\", \"eta\": \"09h 48m 14s 836ms\"}\n",
      "2020-06-08T23:26:24 INFO: Checkpoint time. Saving a checkpoint.\n",
      "2020-06-08T23:26:44 INFO: Evaluation time. Running on full validation set...\n",
      "2020-06-08T23:27:34 INFO: {\"progress\": \"3000/22000\", \"val/total_loss\": \"2.1830\", \"val/hateful_memes/cross_entropy\": \"2.1830\", \"val/hateful_memes/accuracy\": \"0.5800\", \"val/hateful_memes/binary_f1\": \"0.4776\", \"val/hateful_memes/roc_auc\": \"0.6189\", \"num_updates\": 3000, \"epoch\": 12, \"iterations\": 3000, \"max_updates\": 22000, \"val_time\": \"08s 859ms\", \"best_update\": 2000, \"best_iteration\": 2000, \"best_val/hateful_memes/roc_auc\": \"0.639708\"}\n",
      "2020-06-08T23:27:36 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-08T23:30:41 INFO: {\"progress\": \"3100/22000\", \"train/total_loss\": \"0.0533\", \"train/total_loss/avg\": \"0.0708\", \"train/hateful_memes/cross_entropy\": \"0.0533\", \"train/hateful_memes/cross_entropy/avg\": \"0.0708\", \"train/hateful_memes/accuracy\": \"0.9688\", \"train/hateful_memes/accuracy/avg\": \"0.9748\", \"train/hateful_memes/binary_f1\": \"0.9565\", \"train/hateful_memes/binary_f1/avg\": \"0.9572\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9990\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 12, \"num_updates\": 3100, \"iterations\": 3100, \"max_updates\": 22000, \"lr\": \"0.00005\", \"ups\": \"0.54\", \"time\": \"03m 06s 084ms\", \"time_since_start\": \"01h 40m 11s 150ms\", \"eta\": \"09h 46m 10s 058ms\"}\n",
      "2020-06-08T23:30:42 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-08T23:33:47 INFO: {\"progress\": \"3200/22000\", \"train/total_loss\": \"0.0533\", \"train/total_loss/avg\": \"0.0692\", \"train/hateful_memes/cross_entropy\": \"0.0533\", \"train/hateful_memes/cross_entropy/avg\": \"0.0692\", \"train/hateful_memes/accuracy\": \"0.9688\", \"train/hateful_memes/accuracy/avg\": \"0.9756\", \"train/hateful_memes/binary_f1\": \"0.9565\", \"train/hateful_memes/binary_f1/avg\": \"0.9585\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9990\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 13, \"num_updates\": 3200, \"iterations\": 3200, \"max_updates\": 22000, \"lr\": \"0.00005\", \"ups\": \"0.54\", \"time\": \"03m 06s 031ms\", \"time_since_start\": \"01h 43m 17s 182ms\", \"eta\": \"09h 42m 53s 970ms\"}\n",
      "2020-06-08T23:33:48 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-08T23:36:52 INFO: {\"progress\": \"3300/22000\", \"train/total_loss\": \"0.0481\", \"train/total_loss/avg\": \"0.0681\", \"train/hateful_memes/cross_entropy\": \"0.0481\", \"train/hateful_memes/cross_entropy/avg\": \"0.0681\", \"train/hateful_memes/accuracy\": \"0.9688\", \"train/hateful_memes/accuracy/avg\": \"0.9763\", \"train/hateful_memes/binary_f1\": \"0.9565\", \"train/hateful_memes/binary_f1/avg\": \"0.9598\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9990\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 13, \"num_updates\": 3300, \"iterations\": 3300, \"max_updates\": 22000, \"lr\": \"0.00005\", \"ups\": \"0.54\", \"time\": \"03m 05s 766ms\", \"time_since_start\": \"01h 46m 22s 949ms\", \"eta\": \"09h 38m 58s 365ms\"}\n",
      "2020-06-08T23:36:54 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-08T23:39:58 INFO: {\"progress\": \"3400/22000\", \"train/total_loss\": \"0.0405\", \"train/total_loss/avg\": \"0.0666\", \"train/hateful_memes/cross_entropy\": \"0.0405\", \"train/hateful_memes/cross_entropy/avg\": \"0.0666\", \"train/hateful_memes/accuracy\": \"0.9688\", \"train/hateful_memes/accuracy/avg\": \"0.9770\", \"train/hateful_memes/binary_f1\": \"0.9565\", \"train/hateful_memes/binary_f1/avg\": \"0.9610\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9991\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 13, \"num_updates\": 3400, \"iterations\": 3400, \"max_updates\": 22000, \"lr\": \"0.00005\", \"ups\": \"0.54\", \"time\": \"03m 05s 631ms\", \"time_since_start\": \"01h 49m 28s 580ms\", \"eta\": \"09h 35m 27s 429ms\"}\n",
      "2020-06-08T23:40:00 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-08T23:43:04 INFO: {\"progress\": \"3500/22000\", \"train/total_loss\": \"0.0378\", \"train/total_loss/avg\": \"0.0657\", \"train/hateful_memes/cross_entropy\": \"0.0378\", \"train/hateful_memes/cross_entropy/avg\": \"0.0657\", \"train/hateful_memes/accuracy\": \"0.9688\", \"train/hateful_memes/accuracy/avg\": \"0.9768\", \"train/hateful_memes/binary_f1\": \"0.9565\", \"train/hateful_memes/binary_f1/avg\": \"0.9608\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9991\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 14, \"num_updates\": 3500, \"iterations\": 3500, \"max_updates\": 22000, \"lr\": \"0.00005\", \"ups\": \"0.54\", \"time\": \"03m 05s 947ms\", \"time_since_start\": \"01h 52m 34s 528ms\", \"eta\": \"09h 33m 20s 333ms\"}\n",
      "2020-06-08T23:43:06 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-08T23:46:10 INFO: {\"progress\": \"3600/22000\", \"train/total_loss\": \"0.0378\", \"train/total_loss/avg\": \"0.0655\", \"train/hateful_memes/cross_entropy\": \"0.0378\", \"train/hateful_memes/cross_entropy/avg\": \"0.0655\", \"train/hateful_memes/accuracy\": \"0.9688\", \"train/hateful_memes/accuracy/avg\": \"0.9766\", \"train/hateful_memes/binary_f1\": \"0.9630\", \"train/hateful_memes/binary_f1/avg\": \"0.9609\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9991\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 14, \"num_updates\": 3600, \"iterations\": 3600, \"max_updates\": 22000, \"lr\": \"0.00005\", \"ups\": \"0.54\", \"time\": \"03m 05s 759ms\", \"time_since_start\": \"01h 55m 40s 287ms\", \"eta\": \"09h 29m 39s 733ms\"}\n",
      "2020-06-08T23:46:12 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-08T23:49:16 INFO: {\"progress\": \"3700/22000\", \"train/total_loss\": \"0.0378\", \"train/total_loss/avg\": \"0.0657\", \"train/hateful_memes/cross_entropy\": \"0.0378\", \"train/hateful_memes/cross_entropy/avg\": \"0.0657\", \"train/hateful_memes/accuracy\": \"0.9688\", \"train/hateful_memes/accuracy/avg\": \"0.9764\", \"train/hateful_memes/binary_f1\": \"0.9630\", \"train/hateful_memes/binary_f1/avg\": \"0.9609\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9990\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 14, \"num_updates\": 3700, \"iterations\": 3700, \"max_updates\": 22000, \"lr\": \"0.00005\", \"ups\": \"0.54\", \"time\": \"03m 05s 855ms\", \"time_since_start\": \"01h 58m 46s 143ms\", \"eta\": \"09h 26m 51s 581ms\"}\n",
      "2020-06-08T23:49:17 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-08T23:52:21 INFO: {\"progress\": \"3800/22000\", \"train/total_loss\": \"0.0358\", \"train/total_loss/avg\": \"0.0643\", \"train/hateful_memes/cross_entropy\": \"0.0358\", \"train/hateful_memes/cross_entropy/avg\": \"0.0643\", \"train/hateful_memes/accuracy\": \"0.9688\", \"train/hateful_memes/accuracy/avg\": \"0.9770\", \"train/hateful_memes/binary_f1\": \"0.9677\", \"train/hateful_memes/binary_f1/avg\": \"0.9619\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9991\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 15, \"num_updates\": 3800, \"iterations\": 3800, \"max_updates\": 22000, \"lr\": \"0.00005\", \"ups\": \"0.54\", \"time\": \"03m 05s 970ms\", \"time_since_start\": \"02h 01m 52s 113ms\", \"eta\": \"09h 24m 06s 614ms\"}\n",
      "2020-06-08T23:52:23 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-08T23:55:27 INFO: {\"progress\": \"3900/22000\", \"train/total_loss\": \"0.0358\", \"train/total_loss/avg\": \"0.0629\", \"train/hateful_memes/cross_entropy\": \"0.0358\", \"train/hateful_memes/cross_entropy/avg\": \"0.0629\", \"train/hateful_memes/accuracy\": \"0.9688\", \"train/hateful_memes/accuracy/avg\": \"0.9776\", \"train/hateful_memes/binary_f1\": \"0.9677\", \"train/hateful_memes/binary_f1/avg\": \"0.9629\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9991\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 15, \"num_updates\": 3900, \"iterations\": 3900, \"max_updates\": 22000, \"lr\": \"0.00005\", \"ups\": \"0.54\", \"time\": \"03m 05s 600ms\", \"time_since_start\": \"02h 04m 57s 714ms\", \"eta\": \"09h 19m 53s 778ms\"}\n",
      "2020-06-08T23:55:29 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-08T23:58:33 INFO: {\"progress\": \"4000/22000\", \"train/total_loss\": \"0.0358\", \"train/total_loss/avg\": \"0.0615\", \"train/hateful_memes/cross_entropy\": \"0.0358\", \"train/hateful_memes/cross_entropy/avg\": \"0.0615\", \"train/hateful_memes/accuracy\": \"0.9688\", \"train/hateful_memes/accuracy/avg\": \"0.9781\", \"train/hateful_memes/binary_f1\": \"0.9677\", \"train/hateful_memes/binary_f1/avg\": \"0.9638\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9991\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 16, \"num_updates\": 4000, \"iterations\": 4000, \"max_updates\": 22000, \"lr\": \"0.00005\", \"ups\": \"0.54\", \"time\": \"03m 06s 199ms\", \"time_since_start\": \"02h 08m 03s 913ms\", \"eta\": \"09h 18m 35s 829ms\"}\n",
      "2020-06-08T23:58:33 INFO: Checkpoint time. Saving a checkpoint.\n",
      "2020-06-08T23:58:53 INFO: Evaluation time. Running on full validation set...\n",
      "2020-06-09T00:00:02 INFO: {\"progress\": \"4000/22000\", \"val/total_loss\": \"2.4207\", \"val/hateful_memes/cross_entropy\": \"2.4207\", \"val/hateful_memes/accuracy\": \"0.5860\", \"val/hateful_memes/binary_f1\": \"0.4298\", \"val/hateful_memes/roc_auc\": \"0.6488\", \"num_updates\": 4000, \"epoch\": 16, \"iterations\": 4000, \"max_updates\": 22000, \"val_time\": \"08s 832ms\", \"best_update\": 4000, \"best_iteration\": 4000, \"best_val/hateful_memes/roc_auc\": \"0.648812\"}\n",
      "2020-06-09T00:00:05 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-09T00:03:09 INFO: {\"progress\": \"4100/22000\", \"train/total_loss\": \"0.0358\", \"train/total_loss/avg\": \"0.0637\", \"train/hateful_memes/cross_entropy\": \"0.0358\", \"train/hateful_memes/cross_entropy/avg\": \"0.0637\", \"train/hateful_memes/accuracy\": \"0.9688\", \"train/hateful_memes/accuracy/avg\": \"0.9771\", \"train/hateful_memes/binary_f1\": \"0.9630\", \"train/hateful_memes/binary_f1/avg\": \"0.9612\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9991\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 16, \"num_updates\": 4100, \"iterations\": 4100, \"max_updates\": 22000, \"lr\": \"0.00004\", \"ups\": \"0.54\", \"time\": \"03m 06s 216ms\", \"time_since_start\": \"02h 12m 39s 560ms\", \"eta\": \"09h 15m 32s 744ms\"}\n",
      "2020-06-09T00:03:11 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-09T00:06:15 INFO: {\"progress\": \"4200/22000\", \"train/total_loss\": \"0.0378\", \"train/total_loss/avg\": \"0.0632\", \"train/hateful_memes/cross_entropy\": \"0.0378\", \"train/hateful_memes/cross_entropy/avg\": \"0.0632\", \"train/hateful_memes/accuracy\": \"0.9688\", \"train/hateful_memes/accuracy/avg\": \"0.9777\", \"train/hateful_memes/binary_f1\": \"0.9630\", \"train/hateful_memes/binary_f1/avg\": \"0.9621\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9991\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 16, \"num_updates\": 4200, \"iterations\": 4200, \"max_updates\": 22000, \"lr\": \"0.00004\", \"ups\": \"0.54\", \"time\": \"03m 05s 976ms\", \"time_since_start\": \"02h 15m 45s 537ms\", \"eta\": \"09h 11m 43s 764ms\"}\n",
      "2020-06-09T00:06:17 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-09T00:09:21 INFO: {\"progress\": \"4300/22000\", \"train/total_loss\": \"0.0378\", \"train/total_loss/avg\": \"0.0637\", \"train/hateful_memes/cross_entropy\": \"0.0378\", \"train/hateful_memes/cross_entropy/avg\": \"0.0637\", \"train/hateful_memes/accuracy\": \"0.9688\", \"train/hateful_memes/accuracy/avg\": \"0.9775\", \"train/hateful_memes/binary_f1\": \"0.9630\", \"train/hateful_memes/binary_f1/avg\": \"0.9619\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9991\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 17, \"num_updates\": 4300, \"iterations\": 4300, \"max_updates\": 22000, \"lr\": \"0.00004\", \"ups\": \"0.54\", \"time\": \"03m 05s 921ms\", \"time_since_start\": \"02h 18m 51s 458ms\", \"eta\": \"09h 08m 28s 053ms\"}\n",
      "2020-06-09T00:09:23 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-09T00:12:27 INFO: {\"progress\": \"4400/22000\", \"train/total_loss\": \"0.0358\", \"train/total_loss/avg\": \"0.0624\", \"train/hateful_memes/cross_entropy\": \"0.0358\", \"train/hateful_memes/cross_entropy/avg\": \"0.0624\", \"train/hateful_memes/accuracy\": \"0.9688\", \"train/hateful_memes/accuracy/avg\": \"0.9780\", \"train/hateful_memes/binary_f1\": \"0.9630\", \"train/hateful_memes/binary_f1/avg\": \"0.9628\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9991\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 17, \"num_updates\": 4400, \"iterations\": 4400, \"max_updates\": 22000, \"lr\": \"0.00004\", \"ups\": \"0.54\", \"time\": \"03m 05s 819ms\", \"time_since_start\": \"02h 21m 57s 277ms\", \"eta\": \"09h 05m 04s 159ms\"}\n",
      "2020-06-09T00:12:29 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-09T00:15:32 INFO: {\"progress\": \"4500/22000\", \"train/total_loss\": \"0.0358\", \"train/total_loss/avg\": \"0.0619\", \"train/hateful_memes/cross_entropy\": \"0.0358\", \"train/hateful_memes/cross_entropy/avg\": \"0.0619\", \"train/hateful_memes/accuracy\": \"0.9688\", \"train/hateful_memes/accuracy/avg\": \"0.9778\", \"train/hateful_memes/binary_f1\": \"0.9630\", \"train/hateful_memes/binary_f1/avg\": \"0.9628\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9991\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 17, \"num_updates\": 4500, \"iterations\": 4500, \"max_updates\": 22000, \"lr\": \"0.00004\", \"ups\": \"0.54\", \"time\": \"03m 05s 658ms\", \"time_since_start\": \"02h 25m 02s 935ms\", \"eta\": \"09h 01m 30s 210ms\"}\n",
      "2020-06-09T00:15:34 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-09T00:18:38 INFO: {\"progress\": \"4600/22000\", \"train/total_loss\": \"0.0325\", \"train/total_loss/avg\": \"0.0606\", \"train/hateful_memes/cross_entropy\": \"0.0325\", \"train/hateful_memes/cross_entropy/avg\": \"0.0606\", \"train/hateful_memes/accuracy\": \"1.0000\", \"train/hateful_memes/accuracy/avg\": \"0.9783\", \"train/hateful_memes/binary_f1\": \"1.0000\", \"train/hateful_memes/binary_f1/avg\": \"0.9636\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9991\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 18, \"num_updates\": 4600, \"iterations\": 4600, \"max_updates\": 22000, \"lr\": \"0.00004\", \"ups\": \"0.54\", \"time\": \"03m 06s 028ms\", \"time_since_start\": \"02h 28m 08s 964ms\", \"eta\": \"08h 59m 28s 979ms\"}\n",
      "2020-06-09T00:18:40 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-09T00:21:44 INFO: {\"progress\": \"4700/22000\", \"train/total_loss\": \"0.0218\", \"train/total_loss/avg\": \"0.0594\", \"train/hateful_memes/cross_entropy\": \"0.0218\", \"train/hateful_memes/cross_entropy/avg\": \"0.0594\", \"train/hateful_memes/accuracy\": \"1.0000\", \"train/hateful_memes/accuracy/avg\": \"0.9787\", \"train/hateful_memes/binary_f1\": \"1.0000\", \"train/hateful_memes/binary_f1/avg\": \"0.9644\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9991\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 18, \"num_updates\": 4700, \"iterations\": 4700, \"max_updates\": 22000, \"lr\": \"0.00004\", \"ups\": \"0.54\", \"time\": \"03m 05s 898ms\", \"time_since_start\": \"02h 31m 14s 863ms\", \"eta\": \"08h 56m 494ms\"}\n",
      "2020-06-09T00:21:46 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-09T00:24:50 INFO: {\"progress\": \"4800/22000\", \"train/total_loss\": \"0.0218\", \"train/total_loss/avg\": \"0.0588\", \"train/hateful_memes/cross_entropy\": \"0.0218\", \"train/hateful_memes/cross_entropy/avg\": \"0.0588\", \"train/hateful_memes/accuracy\": \"1.0000\", \"train/hateful_memes/accuracy/avg\": \"0.9792\", \"train/hateful_memes/binary_f1\": \"1.0000\", \"train/hateful_memes/binary_f1/avg\": \"0.9651\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9992\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 19, \"num_updates\": 4800, \"iterations\": 4800, \"max_updates\": 22000, \"lr\": \"0.00004\", \"ups\": \"0.54\", \"time\": \"03m 05s 893ms\", \"time_since_start\": \"02h 34m 20s 756ms\", \"eta\": \"08h 52m 53s 659ms\"}\n",
      "2020-06-09T00:24:52 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-09T00:27:56 INFO: {\"progress\": \"4900/22000\", \"train/total_loss\": \"0.0195\", \"train/total_loss/avg\": \"0.0577\", \"train/hateful_memes/cross_entropy\": \"0.0195\", \"train/hateful_memes/cross_entropy/avg\": \"0.0577\", \"train/hateful_memes/accuracy\": \"1.0000\", \"train/hateful_memes/accuracy/avg\": \"0.9796\", \"train/hateful_memes/binary_f1\": \"1.0000\", \"train/hateful_memes/binary_f1/avg\": \"0.9658\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9992\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 19, \"num_updates\": 4900, \"iterations\": 4900, \"max_updates\": 22000, \"lr\": \"0.00004\", \"ups\": \"0.54\", \"time\": \"03m 06s 032ms\", \"time_since_start\": \"02h 37m 26s 789ms\", \"eta\": \"08h 50m 11s 610ms\"}\n",
      "2020-06-09T00:27:58 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-09T00:31:02 INFO: {\"progress\": \"5000/22000\", \"train/total_loss\": \"0.0277\", \"train/total_loss/avg\": \"0.0574\", \"train/hateful_memes/cross_entropy\": \"0.0277\", \"train/hateful_memes/cross_entropy/avg\": \"0.0574\", \"train/hateful_memes/accuracy\": \"1.0000\", \"train/hateful_memes/accuracy/avg\": \"0.9794\", \"train/hateful_memes/binary_f1\": \"1.0000\", \"train/hateful_memes/binary_f1/avg\": \"0.9657\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9992\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 19, \"num_updates\": 5000, \"iterations\": 5000, \"max_updates\": 22000, \"lr\": \"0.00004\", \"ups\": \"0.54\", \"time\": \"03m 05s 502ms\", \"time_since_start\": \"02h 40m 32s 291ms\", \"eta\": \"08h 45m 35s 373ms\"}\n",
      "2020-06-09T00:31:02 INFO: Checkpoint time. Saving a checkpoint.\n",
      "2020-06-09T00:31:22 INFO: Evaluation time. Running on full validation set...\n",
      "2020-06-09T00:32:08 INFO: {\"progress\": \"5000/22000\", \"val/total_loss\": \"3.0272\", \"val/hateful_memes/cross_entropy\": \"3.0272\", \"val/hateful_memes/accuracy\": \"0.5780\", \"val/hateful_memes/binary_f1\": \"0.3884\", \"val/hateful_memes/roc_auc\": \"0.6385\", \"num_updates\": 5000, \"epoch\": 19, \"iterations\": 5000, \"max_updates\": 22000, \"val_time\": \"10s 262ms\", \"best_update\": 4000, \"best_iteration\": 4000, \"best_val/hateful_memes/roc_auc\": \"0.648812\"}\n",
      "2020-06-09T00:32:11 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-09T00:35:15 INFO: {\"progress\": \"5100/22000\", \"train/total_loss\": \"0.0183\", \"train/total_loss/avg\": \"0.0564\", \"train/hateful_memes/cross_entropy\": \"0.0183\", \"train/hateful_memes/cross_entropy/avg\": \"0.0564\", \"train/hateful_memes/accuracy\": \"1.0000\", \"train/hateful_memes/accuracy/avg\": \"0.9798\", \"train/hateful_memes/binary_f1\": \"1.0000\", \"train/hateful_memes/binary_f1/avg\": \"0.9664\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9992\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 20, \"num_updates\": 5100, \"iterations\": 5100, \"max_updates\": 22000, \"lr\": \"0.00004\", \"ups\": \"0.54\", \"time\": \"03m 06s 400ms\", \"time_since_start\": \"02h 44m 45s 836ms\", \"eta\": \"08h 45m 01s 651ms\"}\n",
      "2020-06-09T00:35:17 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-09T00:38:21 INFO: {\"progress\": \"5200/22000\", \"train/total_loss\": \"0.0277\", \"train/total_loss/avg\": \"0.0570\", \"train/hateful_memes/cross_entropy\": \"0.0277\", \"train/hateful_memes/cross_entropy/avg\": \"0.0570\", \"train/hateful_memes/accuracy\": \"1.0000\", \"train/hateful_memes/accuracy/avg\": \"0.9796\", \"train/hateful_memes/binary_f1\": \"1.0000\", \"train/hateful_memes/binary_f1/avg\": \"0.9662\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9991\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 20, \"num_updates\": 5200, \"iterations\": 5200, \"max_updates\": 22000, \"lr\": \"0.00004\", \"ups\": \"0.54\", \"time\": \"03m 05s 583ms\", \"time_since_start\": \"02h 47m 51s 420ms\", \"eta\": \"08h 39m 38s 034ms\"}\n",
      "2020-06-09T00:38:23 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-09T00:41:27 INFO: {\"progress\": \"5300/22000\", \"train/total_loss\": \"0.0244\", \"train/total_loss/avg\": \"0.0564\", \"train/hateful_memes/cross_entropy\": \"0.0244\", \"train/hateful_memes/cross_entropy/avg\": \"0.0564\", \"train/hateful_memes/accuracy\": \"1.0000\", \"train/hateful_memes/accuracy/avg\": \"0.9800\", \"train/hateful_memes/binary_f1\": \"1.0000\", \"train/hateful_memes/binary_f1/avg\": \"0.9668\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9992\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 20, \"num_updates\": 5300, \"iterations\": 5300, \"max_updates\": 22000, \"lr\": \"0.00004\", \"ups\": \"0.54\", \"time\": \"03m 05s 750ms\", \"time_since_start\": \"02h 50m 57s 170ms\", \"eta\": \"08h 37m 390ms\"}\n",
      "2020-06-09T00:41:28 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-09T00:44:33 INFO: {\"progress\": \"5400/22000\", \"train/total_loss\": \"0.0277\", \"train/total_loss/avg\": \"0.0563\", \"train/hateful_memes/cross_entropy\": \"0.0277\", \"train/hateful_memes/cross_entropy/avg\": \"0.0563\", \"train/hateful_memes/accuracy\": \"1.0000\", \"train/hateful_memes/accuracy/avg\": \"0.9797\", \"train/hateful_memes/binary_f1\": \"1.0000\", \"train/hateful_memes/binary_f1/avg\": \"0.9662\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9992\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 21, \"num_updates\": 5400, \"iterations\": 5400, \"max_updates\": 22000, \"lr\": \"0.00004\", \"ups\": \"0.54\", \"time\": \"03m 06s 045ms\", \"time_since_start\": \"02h 54m 03s 216ms\", \"eta\": \"08h 34m 43s 524ms\"}\n",
      "2020-06-09T00:44:34 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-09T00:47:39 INFO: {\"progress\": \"5500/22000\", \"train/total_loss\": \"0.0277\", \"train/total_loss/avg\": \"0.0570\", \"train/hateful_memes/cross_entropy\": \"0.0277\", \"train/hateful_memes/cross_entropy/avg\": \"0.0570\", \"train/hateful_memes/accuracy\": \"1.0000\", \"train/hateful_memes/accuracy/avg\": \"0.9790\", \"train/hateful_memes/binary_f1\": \"1.0000\", \"train/hateful_memes/binary_f1/avg\": \"0.9642\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9991\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 21, \"num_updates\": 5500, \"iterations\": 5500, \"max_updates\": 22000, \"lr\": \"0.00004\", \"ups\": \"0.54\", \"time\": \"03m 05s 925ms\", \"time_since_start\": \"02h 57m 09s 141ms\", \"eta\": \"08h 31m 17s 639ms\"}\n",
      "2020-06-09T00:47:40 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-09T00:50:45 INFO: {\"progress\": \"5600/22000\", \"train/total_loss\": \"0.0277\", \"train/total_loss/avg\": \"0.0567\", \"train/hateful_memes/cross_entropy\": \"0.0277\", \"train/hateful_memes/cross_entropy/avg\": \"0.0567\", \"train/hateful_memes/accuracy\": \"1.0000\", \"train/hateful_memes/accuracy/avg\": \"0.9788\", \"train/hateful_memes/binary_f1\": \"1.0000\", \"train/hateful_memes/binary_f1/avg\": \"0.9643\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9991\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 22, \"num_updates\": 5600, \"iterations\": 5600, \"max_updates\": 22000, \"lr\": \"0.00004\", \"ups\": \"0.54\", \"time\": \"03m 06s 108ms\", \"time_since_start\": \"03h 15s 249ms\", \"eta\": \"08h 28m 41s 776ms\"}\n",
      "2020-06-09T00:50:46 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-09T00:53:50 INFO: {\"progress\": \"5700/22000\", \"train/total_loss\": \"0.0277\", \"train/total_loss/avg\": \"0.0564\", \"train/hateful_memes/cross_entropy\": \"0.0277\", \"train/hateful_memes/cross_entropy/avg\": \"0.0564\", \"train/hateful_memes/accuracy\": \"1.0000\", \"train/hateful_memes/accuracy/avg\": \"0.9792\", \"train/hateful_memes/binary_f1\": \"1.0000\", \"train/hateful_memes/binary_f1/avg\": \"0.9649\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9991\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 22, \"num_updates\": 5700, \"iterations\": 5700, \"max_updates\": 22000, \"lr\": \"0.00004\", \"ups\": \"0.54\", \"time\": \"03m 05s 470ms\", \"time_since_start\": \"03h 03m 20s 720ms\", \"eta\": \"08h 23m 51s 700ms\"}\n",
      "2020-06-09T00:53:52 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-09T00:56:56 INFO: {\"progress\": \"5800/22000\", \"train/total_loss\": \"0.0394\", \"train/total_loss/avg\": \"0.0571\", \"train/hateful_memes/cross_entropy\": \"0.0394\", \"train/hateful_memes/cross_entropy/avg\": \"0.0571\", \"train/hateful_memes/accuracy\": \"1.0000\", \"train/hateful_memes/accuracy/avg\": \"0.9790\", \"train/hateful_memes/binary_f1\": \"1.0000\", \"train/hateful_memes/binary_f1/avg\": \"0.9644\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9991\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 22, \"num_updates\": 5800, \"iterations\": 5800, \"max_updates\": 22000, \"lr\": \"0.00004\", \"ups\": \"0.54\", \"time\": \"03m 05s 757ms\", \"time_since_start\": \"03h 06m 26s 478ms\", \"eta\": \"08h 21m 32s 763ms\"}\n",
      "2020-06-09T00:56:58 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-09T01:00:02 INFO: {\"progress\": \"5900/22000\", \"train/total_loss\": \"0.0394\", \"train/total_loss/avg\": \"0.0563\", \"train/hateful_memes/cross_entropy\": \"0.0394\", \"train/hateful_memes/cross_entropy/avg\": \"0.0563\", \"train/hateful_memes/accuracy\": \"1.0000\", \"train/hateful_memes/accuracy/avg\": \"0.9793\", \"train/hateful_memes/binary_f1\": \"1.0000\", \"train/hateful_memes/binary_f1/avg\": \"0.9650\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9991\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 23, \"num_updates\": 5900, \"iterations\": 5900, \"max_updates\": 22000, \"lr\": \"0.00004\", \"ups\": \"0.54\", \"time\": \"03m 05s 672ms\", \"time_since_start\": \"03h 09m 32s 151ms\", \"eta\": \"08h 18m 13s 355ms\"}\n",
      "2020-06-09T01:00:03 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-09T01:03:07 INFO: {\"progress\": \"6000/22000\", \"train/total_loss\": \"0.0394\", \"train/total_loss/avg\": \"0.0554\", \"train/hateful_memes/cross_entropy\": \"0.0394\", \"train/hateful_memes/cross_entropy/avg\": \"0.0554\", \"train/hateful_memes/accuracy\": \"1.0000\", \"train/hateful_memes/accuracy/avg\": \"0.9797\", \"train/hateful_memes/binary_f1\": \"1.0000\", \"train/hateful_memes/binary_f1/avg\": \"0.9656\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9992\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 23, \"num_updates\": 6000, \"iterations\": 6000, \"max_updates\": 22000, \"lr\": \"0.00004\", \"ups\": \"0.54\", \"time\": \"03m 05s 951ms\", \"time_since_start\": \"03h 12m 38s 102ms\", \"eta\": \"08h 15m 52s 181ms\"}\n",
      "2020-06-09T01:03:07 INFO: Checkpoint time. Saving a checkpoint.\n",
      "2020-06-09T01:03:27 INFO: Evaluation time. Running on full validation set...\n",
      "2020-06-09T01:04:16 INFO: {\"progress\": \"6000/22000\", \"val/total_loss\": \"2.9979\", \"val/hateful_memes/cross_entropy\": \"2.9979\", \"val/hateful_memes/accuracy\": \"0.5780\", \"val/hateful_memes/binary_f1\": \"0.4548\", \"val/hateful_memes/roc_auc\": \"0.6205\", \"num_updates\": 6000, \"epoch\": 23, \"iterations\": 6000, \"max_updates\": 22000, \"val_time\": \"10s 224ms\", \"best_update\": 4000, \"best_iteration\": 4000, \"best_val/hateful_memes/roc_auc\": \"0.648812\"}\n",
      "2020-06-09T01:04:18 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-09T01:07:23 INFO: {\"progress\": \"6100/22000\", \"train/total_loss\": \"0.0383\", \"train/total_loss/avg\": \"0.0552\", \"train/hateful_memes/cross_entropy\": \"0.0383\", \"train/hateful_memes/cross_entropy/avg\": \"0.0552\", \"train/hateful_memes/accuracy\": \"1.0000\", \"train/hateful_memes/accuracy/avg\": \"0.9800\", \"train/hateful_memes/binary_f1\": \"1.0000\", \"train/hateful_memes/binary_f1/avg\": \"0.9661\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9992\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 23, \"num_updates\": 6100, \"iterations\": 6100, \"max_updates\": 22000, \"lr\": \"0.00004\", \"ups\": \"0.54\", \"time\": \"03m 06s 284ms\", \"time_since_start\": \"03h 16m 53s 128ms\", \"eta\": \"08h 13m 39s 231ms\"}\n",
      "2020-06-09T01:07:24 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-09T01:10:28 INFO: {\"progress\": \"6200/22000\", \"train/total_loss\": \"0.0277\", \"train/total_loss/avg\": \"0.0545\", \"train/hateful_memes/cross_entropy\": \"0.0277\", \"train/hateful_memes/cross_entropy/avg\": \"0.0545\", \"train/hateful_memes/accuracy\": \"1.0000\", \"train/hateful_memes/accuracy/avg\": \"0.9803\", \"train/hateful_memes/binary_f1\": \"1.0000\", \"train/hateful_memes/binary_f1/avg\": \"0.9667\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9992\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 24, \"num_updates\": 6200, \"iterations\": 6200, \"max_updates\": 22000, \"lr\": \"0.00004\", \"ups\": \"0.54\", \"time\": \"03m 05s 745ms\", \"time_since_start\": \"03h 19m 58s 874ms\", \"eta\": \"08h 09m 07s 723ms\"}\n",
      "2020-06-09T01:10:30 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-09T01:13:34 INFO: {\"progress\": \"6300/22000\", \"train/total_loss\": \"0.0244\", \"train/total_loss/avg\": \"0.0538\", \"train/hateful_memes/cross_entropy\": \"0.0244\", \"train/hateful_memes/cross_entropy/avg\": \"0.0538\", \"train/hateful_memes/accuracy\": \"1.0000\", \"train/hateful_memes/accuracy/avg\": \"0.9807\", \"train/hateful_memes/binary_f1\": \"1.0000\", \"train/hateful_memes/binary_f1/avg\": \"0.9672\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9992\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 24, \"num_updates\": 6300, \"iterations\": 6300, \"max_updates\": 22000, \"lr\": \"0.00004\", \"ups\": \"0.54\", \"time\": \"03m 05s 597ms\", \"time_since_start\": \"03h 23m 04s 471ms\", \"eta\": \"08h 05m 38s 770ms\"}\n",
      "2020-06-09T01:13:36 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-09T01:16:40 INFO: {\"progress\": \"6400/22000\", \"train/total_loss\": \"0.0244\", \"train/total_loss/avg\": \"0.0530\", \"train/hateful_memes/cross_entropy\": \"0.0244\", \"train/hateful_memes/cross_entropy/avg\": \"0.0530\", \"train/hateful_memes/accuracy\": \"1.0000\", \"train/hateful_memes/accuracy/avg\": \"0.9810\", \"train/hateful_memes/binary_f1\": \"1.0000\", \"train/hateful_memes/binary_f1/avg\": \"0.9677\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9992\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 25, \"num_updates\": 6400, \"iterations\": 6400, \"max_updates\": 22000, \"lr\": \"0.00004\", \"ups\": \"0.54\", \"time\": \"03m 05s 792ms\", \"time_since_start\": \"03h 26m 10s 263ms\", \"eta\": \"08h 03m 03s 597ms\"}\n",
      "2020-06-09T01:16:41 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-09T01:19:45 INFO: {\"progress\": \"6500/22000\", \"train/total_loss\": \"0.0158\", \"train/total_loss/avg\": \"0.0522\", \"train/hateful_memes/cross_entropy\": \"0.0158\", \"train/hateful_memes/cross_entropy/avg\": \"0.0522\", \"train/hateful_memes/accuracy\": \"1.0000\", \"train/hateful_memes/accuracy/avg\": \"0.9812\", \"train/hateful_memes/binary_f1\": \"1.0000\", \"train/hateful_memes/binary_f1/avg\": \"0.9682\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9992\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 25, \"num_updates\": 6500, \"iterations\": 6500, \"max_updates\": 22000, \"lr\": \"0.00004\", \"ups\": \"0.54\", \"time\": \"03m 05s 626ms\", \"time_since_start\": \"03h 29m 15s 890ms\", \"eta\": \"07h 59m 32s 092ms\"}\n",
      "2020-06-09T01:19:47 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-09T01:22:51 INFO: {\"progress\": \"6600/22000\", \"train/total_loss\": \"0.0212\", \"train/total_loss/avg\": \"0.0517\", \"train/hateful_memes/cross_entropy\": \"0.0212\", \"train/hateful_memes/cross_entropy/avg\": \"0.0517\", \"train/hateful_memes/accuracy\": \"1.0000\", \"train/hateful_memes/accuracy/avg\": \"0.9815\", \"train/hateful_memes/binary_f1\": \"1.0000\", \"train/hateful_memes/binary_f1/avg\": \"0.9687\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9992\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 25, \"num_updates\": 6600, \"iterations\": 6600, \"max_updates\": 22000, \"lr\": \"0.00004\", \"ups\": \"0.54\", \"time\": \"03m 05s 719ms\", \"time_since_start\": \"03h 32m 21s 610ms\", \"eta\": \"07h 56m 40s 870ms\"}\n",
      "2020-06-09T01:22:53 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-09T01:25:57 INFO: {\"progress\": \"6700/22000\", \"train/total_loss\": \"0.0212\", \"train/total_loss/avg\": \"0.0511\", \"train/hateful_memes/cross_entropy\": \"0.0212\", \"train/hateful_memes/cross_entropy/avg\": \"0.0511\", \"train/hateful_memes/accuracy\": \"1.0000\", \"train/hateful_memes/accuracy/avg\": \"0.9818\", \"train/hateful_memes/binary_f1\": \"1.0000\", \"train/hateful_memes/binary_f1/avg\": \"0.9692\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9992\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 26, \"num_updates\": 6700, \"iterations\": 6700, \"max_updates\": 22000, \"lr\": \"0.00004\", \"ups\": \"0.54\", \"time\": \"03m 05s 813ms\", \"time_since_start\": \"03h 35m 27s 423ms\", \"eta\": \"07h 53m 49s 487ms\"}\n",
      "2020-06-09T01:25:59 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-09T01:29:03 INFO: {\"progress\": \"6800/22000\", \"train/total_loss\": \"0.0212\", \"train/total_loss/avg\": \"0.0520\", \"train/hateful_memes/cross_entropy\": \"0.0212\", \"train/hateful_memes/cross_entropy/avg\": \"0.0520\", \"train/hateful_memes/accuracy\": \"1.0000\", \"train/hateful_memes/accuracy/avg\": \"0.9816\", \"train/hateful_memes/binary_f1\": \"1.0000\", \"train/hateful_memes/binary_f1/avg\": \"0.9680\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9993\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 26, \"num_updates\": 6800, \"iterations\": 6800, \"max_updates\": 22000, \"lr\": \"0.00004\", \"ups\": \"0.54\", \"time\": \"03m 06s 171ms\", \"time_since_start\": \"03h 38m 33s 595ms\", \"eta\": \"07h 51m 38s 038ms\"}\n",
      "2020-06-09T01:29:05 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-09T01:32:09 INFO: {\"progress\": \"6900/22000\", \"train/total_loss\": \"0.0212\", \"train/total_loss/avg\": \"0.0512\", \"train/hateful_memes/cross_entropy\": \"0.0212\", \"train/hateful_memes/cross_entropy/avg\": \"0.0512\", \"train/hateful_memes/accuracy\": \"1.0000\", \"train/hateful_memes/accuracy/avg\": \"0.9819\", \"train/hateful_memes/binary_f1\": \"1.0000\", \"train/hateful_memes/binary_f1/avg\": \"0.9684\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9993\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 26, \"num_updates\": 6900, \"iterations\": 6900, \"max_updates\": 22000, \"lr\": \"0.00004\", \"ups\": \"0.54\", \"time\": \"03m 05s 735ms\", \"time_since_start\": \"03h 41m 39s 330ms\", \"eta\": \"07h 47m 26s 119ms\"}\n",
      "2020-06-09T01:32:11 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-09T01:35:15 INFO: {\"progress\": \"7000/22000\", \"train/total_loss\": \"0.0158\", \"train/total_loss/avg\": \"0.0506\", \"train/hateful_memes/cross_entropy\": \"0.0158\", \"train/hateful_memes/cross_entropy/avg\": \"0.0506\", \"train/hateful_memes/accuracy\": \"1.0000\", \"train/hateful_memes/accuracy/avg\": \"0.9821\", \"train/hateful_memes/binary_f1\": \"1.0000\", \"train/hateful_memes/binary_f1/avg\": \"0.9689\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9993\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 27, \"num_updates\": 7000, \"iterations\": 7000, \"max_updates\": 22000, \"lr\": \"0.00004\", \"ups\": \"0.54\", \"time\": \"03m 05s 896ms\", \"time_since_start\": \"03h 44m 45s 227ms\", \"eta\": \"07h 44m 44s 434ms\"}\n",
      "2020-06-09T01:35:15 INFO: Checkpoint time. Saving a checkpoint.\n",
      "2020-06-09T01:35:36 INFO: Evaluation time. Running on full validation set...\n",
      "2020-06-09T01:36:23 INFO: {\"progress\": \"7000/22000\", \"val/total_loss\": \"3.4538\", \"val/hateful_memes/cross_entropy\": \"3.4538\", \"val/hateful_memes/accuracy\": \"0.5840\", \"val/hateful_memes/binary_f1\": \"0.3918\", \"val/hateful_memes/roc_auc\": \"0.6211\", \"num_updates\": 7000, \"epoch\": 27, \"iterations\": 7000, \"max_updates\": 22000, \"val_time\": \"10s 203ms\", \"best_update\": 4000, \"best_iteration\": 4000, \"best_val/hateful_memes/roc_auc\": \"0.648812\"}\n",
      "2020-06-09T01:36:25 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-09T01:39:30 INFO: {\"progress\": \"7100/22000\", \"train/total_loss\": \"0.0158\", \"train/total_loss/avg\": \"0.0499\", \"train/hateful_memes/cross_entropy\": \"0.0158\", \"train/hateful_memes/cross_entropy/avg\": \"0.0499\", \"train/hateful_memes/accuracy\": \"1.0000\", \"train/hateful_memes/accuracy/avg\": \"0.9824\", \"train/hateful_memes/binary_f1\": \"1.0000\", \"train/hateful_memes/binary_f1/avg\": \"0.9693\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9993\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 27, \"num_updates\": 7100, \"iterations\": 7100, \"max_updates\": 22000, \"lr\": \"0.00004\", \"ups\": \"0.54\", \"time\": \"03m 06s 433ms\", \"time_since_start\": \"03h 49m 138ms\", \"eta\": \"07h 42m 58s 654ms\"}\n",
      "2020-06-09T01:39:31 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-09T01:42:35 INFO: {\"progress\": \"7200/22000\", \"train/total_loss\": \"0.0128\", \"train/total_loss/avg\": \"0.0492\", \"train/hateful_memes/cross_entropy\": \"0.0128\", \"train/hateful_memes/cross_entropy/avg\": \"0.0492\", \"train/hateful_memes/accuracy\": \"1.0000\", \"train/hateful_memes/accuracy/avg\": \"0.9826\", \"train/hateful_memes/binary_f1\": \"1.0000\", \"train/hateful_memes/binary_f1/avg\": \"0.9698\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9993\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 28, \"num_updates\": 7200, \"iterations\": 7200, \"max_updates\": 22000, \"lr\": \"0.00004\", \"ups\": \"0.54\", \"time\": \"03m 05s 955ms\", \"time_since_start\": \"03h 52m 06s 094ms\", \"eta\": \"07h 38m 41s 487ms\"}\n",
      "2020-06-09T01:42:37 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-09T01:45:42 INFO: {\"progress\": \"7300/22000\", \"train/total_loss\": \"0.0128\", \"train/total_loss/avg\": \"0.0496\", \"train/hateful_memes/cross_entropy\": \"0.0128\", \"train/hateful_memes/cross_entropy/avg\": \"0.0496\", \"train/hateful_memes/accuracy\": \"1.0000\", \"train/hateful_memes/accuracy/avg\": \"0.9824\", \"train/hateful_memes/binary_f1\": \"1.0000\", \"train/hateful_memes/binary_f1/avg\": \"0.9697\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9993\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 28, \"num_updates\": 7300, \"iterations\": 7300, \"max_updates\": 22000, \"lr\": \"0.00004\", \"ups\": \"0.54\", \"time\": \"03m 06s 056ms\", \"time_since_start\": \"03h 55m 12s 150ms\", \"eta\": \"07h 35m 50s 313ms\"}\n",
      "2020-06-09T01:45:43 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-09T01:48:47 INFO: {\"progress\": \"7400/22000\", \"train/total_loss\": \"0.0118\", \"train/total_loss/avg\": \"0.0489\", \"train/hateful_memes/cross_entropy\": \"0.0118\", \"train/hateful_memes/cross_entropy/avg\": \"0.0489\", \"train/hateful_memes/accuracy\": \"1.0000\", \"train/hateful_memes/accuracy/avg\": \"0.9827\", \"train/hateful_memes/binary_f1\": \"1.0000\", \"train/hateful_memes/binary_f1/avg\": \"0.9701\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9993\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 28, \"num_updates\": 7400, \"iterations\": 7400, \"max_updates\": 22000, \"lr\": \"0.00004\", \"ups\": \"0.54\", \"time\": \"03m 05s 556ms\", \"time_since_start\": \"03h 58m 17s 706ms\", \"eta\": \"07h 31m 31s 195ms\"}\n",
      "2020-06-09T01:48:49 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-09T01:51:53 INFO: {\"progress\": \"7500/22000\", \"train/total_loss\": \"0.0093\", \"train/total_loss/avg\": \"0.0483\", \"train/hateful_memes/cross_entropy\": \"0.0093\", \"train/hateful_memes/cross_entropy/avg\": \"0.0483\", \"train/hateful_memes/accuracy\": \"1.0000\", \"train/hateful_memes/accuracy/avg\": \"0.9829\", \"train/hateful_memes/binary_f1\": \"1.0000\", \"train/hateful_memes/binary_f1/avg\": \"0.9705\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9993\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 29, \"num_updates\": 7500, \"iterations\": 7500, \"max_updates\": 22000, \"lr\": \"0.00004\", \"ups\": \"0.54\", \"time\": \"03m 05s 856ms\", \"time_since_start\": \"04h 01m 23s 563ms\", \"eta\": \"07h 29m 09s 257ms\"}\n",
      "2020-06-09T01:51:55 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-09T01:54:59 INFO: {\"progress\": \"7600/22000\", \"train/total_loss\": \"0.0093\", \"train/total_loss/avg\": \"0.0482\", \"train/hateful_memes/cross_entropy\": \"0.0093\", \"train/hateful_memes/cross_entropy/avg\": \"0.0482\", \"train/hateful_memes/accuracy\": \"1.0000\", \"train/hateful_memes/accuracy/avg\": \"0.9831\", \"train/hateful_memes/binary_f1\": \"1.0000\", \"train/hateful_memes/binary_f1/avg\": \"0.9709\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9993\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 29, \"num_updates\": 7600, \"iterations\": 7600, \"max_updates\": 22000, \"lr\": \"0.00004\", \"ups\": \"0.54\", \"time\": \"03m 05s 936ms\", \"time_since_start\": \"04h 04m 29s 500ms\", \"eta\": \"07h 26m 14s 809ms\"}\n",
      "2020-06-09T01:55:01 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-09T01:58:05 INFO: {\"progress\": \"7700/22000\", \"train/total_loss\": \"0.0093\", \"train/total_loss/avg\": \"0.0477\", \"train/hateful_memes/cross_entropy\": \"0.0093\", \"train/hateful_memes/cross_entropy/avg\": \"0.0477\", \"train/hateful_memes/accuracy\": \"1.0000\", \"train/hateful_memes/accuracy/avg\": \"0.9834\", \"train/hateful_memes/binary_f1\": \"1.0000\", \"train/hateful_memes/binary_f1/avg\": \"0.9712\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9993\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 29, \"num_updates\": 7700, \"iterations\": 7700, \"max_updates\": 22000, \"lr\": \"0.00004\", \"ups\": \"0.54\", \"time\": \"03m 05s 798ms\", \"time_since_start\": \"04h 07m 35s 298ms\", \"eta\": \"07h 22m 49s 117ms\"}\n",
      "2020-06-09T01:58:07 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-09T02:01:11 INFO: {\"progress\": \"7800/22000\", \"train/total_loss\": \"0.0093\", \"train/total_loss/avg\": \"0.0494\", \"train/hateful_memes/cross_entropy\": \"0.0093\", \"train/hateful_memes/cross_entropy/avg\": \"0.0494\", \"train/hateful_memes/accuracy\": \"1.0000\", \"train/hateful_memes/accuracy/avg\": \"0.9828\", \"train/hateful_memes/binary_f1\": \"1.0000\", \"train/hateful_memes/binary_f1/avg\": \"0.9703\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9993\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 30, \"num_updates\": 7800, \"iterations\": 7800, \"max_updates\": 22000, \"lr\": \"0.00004\", \"ups\": \"0.54\", \"time\": \"03m 05s 855ms\", \"time_since_start\": \"04h 10m 41s 153ms\", \"eta\": \"07h 19m 51s 473ms\"}\n",
      "2020-06-09T02:01:12 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-09T02:04:16 INFO: {\"progress\": \"7900/22000\", \"train/total_loss\": \"0.0043\", \"train/total_loss/avg\": \"0.0488\", \"train/hateful_memes/cross_entropy\": \"0.0043\", \"train/hateful_memes/cross_entropy/avg\": \"0.0488\", \"train/hateful_memes/accuracy\": \"1.0000\", \"train/hateful_memes/accuracy/avg\": \"0.9830\", \"train/hateful_memes/binary_f1\": \"1.0000\", \"train/hateful_memes/binary_f1/avg\": \"0.9707\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9993\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 30, \"num_updates\": 7900, \"iterations\": 7900, \"max_updates\": 22000, \"lr\": \"0.00004\", \"ups\": \"0.54\", \"time\": \"03m 05s 755ms\", \"time_since_start\": \"04h 13m 46s 908ms\", \"eta\": \"07h 16m 31s 465ms\"}\n",
      "2020-06-09T02:04:18 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-09T02:07:22 INFO: {\"progress\": \"8000/22000\", \"train/total_loss\": \"0.0093\", \"train/total_loss/avg\": \"0.0485\", \"train/hateful_memes/cross_entropy\": \"0.0093\", \"train/hateful_memes/cross_entropy/avg\": \"0.0485\", \"train/hateful_memes/accuracy\": \"1.0000\", \"train/hateful_memes/accuracy/avg\": \"0.9832\", \"train/hateful_memes/binary_f1\": \"1.0000\", \"train/hateful_memes/binary_f1/avg\": \"0.9711\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9993\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 31, \"num_updates\": 8000, \"iterations\": 8000, \"max_updates\": 22000, \"lr\": \"0.00004\", \"ups\": \"0.54\", \"time\": \"03m 05s 713ms\", \"time_since_start\": \"04h 16m 52s 622ms\", \"eta\": \"07h 13m 19s 899ms\"}\n",
      "2020-06-09T02:07:22 INFO: Checkpoint time. Saving a checkpoint.\n",
      "2020-06-09T02:07:42 INFO: Evaluation time. Running on full validation set...\n",
      "2020-06-09T02:08:28 INFO: {\"progress\": \"8000/22000\", \"val/total_loss\": \"2.9259\", \"val/hateful_memes/cross_entropy\": \"2.9259\", \"val/hateful_memes/accuracy\": \"0.6000\", \"val/hateful_memes/binary_f1\": \"0.4681\", \"val/hateful_memes/roc_auc\": \"0.6439\", \"num_updates\": 8000, \"epoch\": 31, \"iterations\": 8000, \"max_updates\": 22000, \"val_time\": \"10s 199ms\", \"best_update\": 4000, \"best_iteration\": 4000, \"best_val/hateful_memes/roc_auc\": \"0.648812\"}\n",
      "2020-06-09T02:08:31 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-09T02:11:35 INFO: {\"progress\": \"8100/22000\", \"train/total_loss\": \"0.0093\", \"train/total_loss/avg\": \"0.0487\", \"train/hateful_memes/cross_entropy\": \"0.0093\", \"train/hateful_memes/cross_entropy/avg\": \"0.0487\", \"train/hateful_memes/accuracy\": \"1.0000\", \"train/hateful_memes/accuracy/avg\": \"0.9830\", \"train/hateful_memes/binary_f1\": \"1.0000\", \"train/hateful_memes/binary_f1/avg\": \"0.9706\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9993\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 31, \"num_updates\": 8100, \"iterations\": 8100, \"max_updates\": 22000, \"lr\": \"0.00003\", \"ups\": \"0.54\", \"time\": \"03m 06s 058ms\", \"time_since_start\": \"04h 21m 05s 394ms\", \"eta\": \"07h 11m 02s 126ms\"}\n",
      "2020-06-09T02:11:37 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-09T02:14:41 INFO: {\"progress\": \"8200/22000\", \"train/total_loss\": \"0.0093\", \"train/total_loss/avg\": \"0.0489\", \"train/hateful_memes/cross_entropy\": \"0.0093\", \"train/hateful_memes/cross_entropy/avg\": \"0.0489\", \"train/hateful_memes/accuracy\": \"1.0000\", \"train/hateful_memes/accuracy/avg\": \"0.9829\", \"train/hateful_memes/binary_f1\": \"1.0000\", \"train/hateful_memes/binary_f1/avg\": \"0.9706\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9993\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 31, \"num_updates\": 8200, \"iterations\": 8200, \"max_updates\": 22000, \"lr\": \"0.00003\", \"ups\": \"0.54\", \"time\": \"03m 05s 855ms\", \"time_since_start\": \"04h 24m 11s 249ms\", \"eta\": \"07h 07m 28s 001ms\"}\n",
      "2020-06-09T02:14:42 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-09T02:17:46 INFO: {\"progress\": \"8300/22000\", \"train/total_loss\": \"0.0093\", \"train/total_loss/avg\": \"0.0492\", \"train/hateful_memes/cross_entropy\": \"0.0093\", \"train/hateful_memes/cross_entropy/avg\": \"0.0492\", \"train/hateful_memes/accuracy\": \"1.0000\", \"train/hateful_memes/accuracy/avg\": \"0.9827\", \"train/hateful_memes/binary_f1\": \"1.0000\", \"train/hateful_memes/binary_f1/avg\": \"0.9706\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9993\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 32, \"num_updates\": 8300, \"iterations\": 8300, \"max_updates\": 22000, \"lr\": \"0.00003\", \"ups\": \"0.54\", \"time\": \"03m 05s 628ms\", \"time_since_start\": \"04h 27m 16s 878ms\", \"eta\": \"07h 03m 51s 140ms\"}\n",
      "2020-06-09T02:17:48 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-09T02:20:52 INFO: {\"progress\": \"8400/22000\", \"train/total_loss\": \"0.0093\", \"train/total_loss/avg\": \"0.0487\", \"train/hateful_memes/cross_entropy\": \"0.0093\", \"train/hateful_memes/cross_entropy/avg\": \"0.0487\", \"train/hateful_memes/accuracy\": \"1.0000\", \"train/hateful_memes/accuracy/avg\": \"0.9829\", \"train/hateful_memes/binary_f1\": \"1.0000\", \"train/hateful_memes/binary_f1/avg\": \"0.9710\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9994\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 32, \"num_updates\": 8400, \"iterations\": 8400, \"max_updates\": 22000, \"lr\": \"0.00003\", \"ups\": \"0.54\", \"time\": \"03m 05s 608ms\", \"time_since_start\": \"04h 30m 22s 486ms\", \"eta\": \"07h 42s 691ms\"}\n",
      "2020-06-09T02:20:54 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-09T02:23:58 INFO: {\"progress\": \"8500/22000\", \"train/total_loss\": \"0.0102\", \"train/total_loss/avg\": \"0.0488\", \"train/hateful_memes/cross_entropy\": \"0.0102\", \"train/hateful_memes/cross_entropy/avg\": \"0.0488\", \"train/hateful_memes/accuracy\": \"1.0000\", \"train/hateful_memes/accuracy/avg\": \"0.9827\", \"train/hateful_memes/binary_f1\": \"1.0000\", \"train/hateful_memes/binary_f1/avg\": \"0.9709\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9994\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 32, \"num_updates\": 8500, \"iterations\": 8500, \"max_updates\": 22000, \"lr\": \"0.00003\", \"ups\": \"0.54\", \"time\": \"03m 05s 649ms\", \"time_since_start\": \"04h 33m 28s 136ms\", \"eta\": \"06h 57m 42s 719ms\"}\n",
      "2020-06-09T02:23:59 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-09T02:27:03 INFO: {\"progress\": \"8600/22000\", \"train/total_loss\": \"0.0102\", \"train/total_loss/avg\": \"0.0487\", \"train/hateful_memes/cross_entropy\": \"0.0102\", \"train/hateful_memes/cross_entropy/avg\": \"0.0487\", \"train/hateful_memes/accuracy\": \"1.0000\", \"train/hateful_memes/accuracy/avg\": \"0.9826\", \"train/hateful_memes/binary_f1\": \"1.0000\", \"train/hateful_memes/binary_f1/avg\": \"0.9702\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9994\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 33, \"num_updates\": 8600, \"iterations\": 8600, \"max_updates\": 22000, \"lr\": \"0.00003\", \"ups\": \"0.54\", \"time\": \"03m 05s 837ms\", \"time_since_start\": \"04h 36m 33s 973ms\", \"eta\": \"06h 55m 02s 281ms\"}\n",
      "2020-06-09T02:27:05 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-09T02:30:09 INFO: {\"progress\": \"8700/22000\", \"train/total_loss\": \"0.0210\", \"train/total_loss/avg\": \"0.0485\", \"train/hateful_memes/cross_entropy\": \"0.0210\", \"train/hateful_memes/cross_entropy/avg\": \"0.0485\", \"train/hateful_memes/accuracy\": \"1.0000\", \"train/hateful_memes/accuracy/avg\": \"0.9824\", \"train/hateful_memes/binary_f1\": \"1.0000\", \"train/hateful_memes/binary_f1/avg\": \"0.9700\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9994\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 33, \"num_updates\": 8700, \"iterations\": 8700, \"max_updates\": 22000, \"lr\": \"0.00003\", \"ups\": \"0.54\", \"time\": \"03m 05s 696ms\", \"time_since_start\": \"04h 39m 39s 670ms\", \"eta\": \"06h 51m 37s 581ms\"}\n",
      "2020-06-09T02:30:11 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-09T02:33:15 INFO: {\"progress\": \"8800/22000\", \"train/total_loss\": \"0.0102\", \"train/total_loss/avg\": \"0.0480\", \"train/hateful_memes/cross_entropy\": \"0.0102\", \"train/hateful_memes/cross_entropy/avg\": \"0.0480\", \"train/hateful_memes/accuracy\": \"1.0000\", \"train/hateful_memes/accuracy/avg\": \"0.9826\", \"train/hateful_memes/binary_f1\": \"1.0000\", \"train/hateful_memes/binary_f1/avg\": \"0.9703\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9994\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 34, \"num_updates\": 8800, \"iterations\": 8800, \"max_updates\": 22000, \"lr\": \"0.00003\", \"ups\": \"0.54\", \"time\": \"03m 05s 696ms\", \"time_since_start\": \"04h 42m 45s 366ms\", \"eta\": \"06h 48m 31s 946ms\"}\n",
      "2020-06-09T02:33:17 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-09T02:36:20 INFO: {\"progress\": \"8900/22000\", \"train/total_loss\": \"0.0102\", \"train/total_loss/avg\": \"0.0475\", \"train/hateful_memes/cross_entropy\": \"0.0102\", \"train/hateful_memes/cross_entropy/avg\": \"0.0475\", \"train/hateful_memes/accuracy\": \"1.0000\", \"train/hateful_memes/accuracy/avg\": \"0.9828\", \"train/hateful_memes/binary_f1\": \"1.0000\", \"train/hateful_memes/binary_f1/avg\": \"0.9707\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9994\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 34, \"num_updates\": 8900, \"iterations\": 8900, \"max_updates\": 22000, \"lr\": \"0.00003\", \"ups\": \"0.54\", \"time\": \"03m 05s 624ms\", \"time_since_start\": \"04h 45m 50s 991ms\", \"eta\": \"06h 45m 16s 807ms\"}\n",
      "2020-06-09T02:36:22 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-09T02:39:26 INFO: {\"progress\": \"9000/22000\", \"train/total_loss\": \"0.0102\", \"train/total_loss/avg\": \"0.0470\", \"train/hateful_memes/cross_entropy\": \"0.0102\", \"train/hateful_memes/cross_entropy/avg\": \"0.0470\", \"train/hateful_memes/accuracy\": \"1.0000\", \"train/hateful_memes/accuracy/avg\": \"0.9830\", \"train/hateful_memes/binary_f1\": \"1.0000\", \"train/hateful_memes/binary_f1/avg\": \"0.9710\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9994\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 34, \"num_updates\": 9000, \"iterations\": 9000, \"max_updates\": 22000, \"lr\": \"0.00003\", \"ups\": \"0.54\", \"time\": \"03m 05s 666ms\", \"time_since_start\": \"04h 48m 56s 657ms\", \"eta\": \"06h 42m 16s 597ms\"}\n",
      "2020-06-09T02:39:26 INFO: Checkpoint time. Saving a checkpoint.\n",
      "2020-06-09T02:39:47 INFO: Evaluation time. Running on full validation set...\n",
      "2020-06-09T02:39:58 INFO: {\"progress\": \"9000/22000\", \"val/total_loss\": \"3.6411\", \"val/hateful_memes/cross_entropy\": \"3.6411\", \"val/hateful_memes/accuracy\": \"0.5800\", \"val/hateful_memes/binary_f1\": \"0.4000\", \"val/hateful_memes/roc_auc\": \"0.6482\", \"num_updates\": 9000, \"epoch\": 34, \"iterations\": 9000, \"max_updates\": 22000, \"val_time\": \"10s 747ms\", \"best_update\": 4000, \"best_iteration\": 4000, \"best_val/hateful_memes/roc_auc\": \"0.648812\"}\n",
      "2020-06-09T02:40:00 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-09T02:43:05 INFO: {\"progress\": \"9100/22000\", \"train/total_loss\": \"0.0102\", \"train/total_loss/avg\": \"0.0465\", \"train/hateful_memes/cross_entropy\": \"0.0102\", \"train/hateful_memes/cross_entropy/avg\": \"0.0465\", \"train/hateful_memes/accuracy\": \"1.0000\", \"train/hateful_memes/accuracy/avg\": \"0.9832\", \"train/hateful_memes/binary_f1\": \"1.0000\", \"train/hateful_memes/binary_f1/avg\": \"0.9713\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9994\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 35, \"num_updates\": 9100, \"iterations\": 9100, \"max_updates\": 22000, \"lr\": \"0.00003\", \"ups\": \"0.54\", \"time\": \"03m 06s 441ms\", \"time_since_start\": \"04h 52m 35s 550ms\", \"eta\": \"06h 40m 51s 005ms\"}\n",
      "2020-06-09T02:43:07 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-09T02:46:11 INFO: {\"progress\": \"9200/22000\", \"train/total_loss\": \"0.0102\", \"train/total_loss/avg\": \"0.0460\", \"train/hateful_memes/cross_entropy\": \"0.0102\", \"train/hateful_memes/cross_entropy/avg\": \"0.0460\", \"train/hateful_memes/accuracy\": \"1.0000\", \"train/hateful_memes/accuracy/avg\": \"0.9834\", \"train/hateful_memes/binary_f1\": \"1.0000\", \"train/hateful_memes/binary_f1/avg\": \"0.9716\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9994\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 35, \"num_updates\": 9200, \"iterations\": 9200, \"max_updates\": 22000, \"lr\": \"0.00003\", \"ups\": \"0.54\", \"time\": \"03m 05s 783ms\", \"time_since_start\": \"04h 55m 41s 334ms\", \"eta\": \"06h 36m 20s 307ms\"}\n",
      "2020-06-09T02:46:13 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-09T02:49:16 INFO: {\"progress\": \"9300/22000\", \"train/total_loss\": \"0.0077\", \"train/total_loss/avg\": \"0.0455\", \"train/hateful_memes/cross_entropy\": \"0.0077\", \"train/hateful_memes/cross_entropy/avg\": \"0.0455\", \"train/hateful_memes/accuracy\": \"1.0000\", \"train/hateful_memes/accuracy/avg\": \"0.9835\", \"train/hateful_memes/binary_f1\": \"1.0000\", \"train/hateful_memes/binary_f1/avg\": \"0.9719\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9994\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 35, \"num_updates\": 9300, \"iterations\": 9300, \"max_updates\": 22000, \"lr\": \"0.00003\", \"ups\": \"0.54\", \"time\": \"03m 05s 759ms\", \"time_since_start\": \"04h 58m 47s 093ms\", \"eta\": \"06h 33m 11s 454ms\"}\n",
      "2020-06-09T02:49:18 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-09T02:52:22 INFO: {\"progress\": \"9400/22000\", \"train/total_loss\": \"0.0077\", \"train/total_loss/avg\": \"0.0451\", \"train/hateful_memes/cross_entropy\": \"0.0077\", \"train/hateful_memes/cross_entropy/avg\": \"0.0451\", \"train/hateful_memes/accuracy\": \"1.0000\", \"train/hateful_memes/accuracy/avg\": \"0.9837\", \"train/hateful_memes/binary_f1\": \"1.0000\", \"train/hateful_memes/binary_f1/avg\": \"0.9722\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9994\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 36, \"num_updates\": 9400, \"iterations\": 9400, \"max_updates\": 22000, \"lr\": \"0.00003\", \"ups\": \"0.54\", \"time\": \"03m 05s 982ms\", \"time_since_start\": \"05h 01m 53s 076ms\", \"eta\": \"06h 30m 33s 786ms\"}\n",
      "2020-06-09T02:52:24 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-09T02:55:28 INFO: {\"progress\": \"9500/22000\", \"train/total_loss\": \"0.0077\", \"train/total_loss/avg\": \"0.0446\", \"train/hateful_memes/cross_entropy\": \"0.0077\", \"train/hateful_memes/cross_entropy/avg\": \"0.0446\", \"train/hateful_memes/accuracy\": \"1.0000\", \"train/hateful_memes/accuracy/avg\": \"0.9839\", \"train/hateful_memes/binary_f1\": \"1.0000\", \"train/hateful_memes/binary_f1/avg\": \"0.9725\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9994\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 36, \"num_updates\": 9500, \"iterations\": 9500, \"max_updates\": 22000, \"lr\": \"0.00003\", \"ups\": \"0.54\", \"time\": \"03m 05s 550ms\", \"time_since_start\": \"05h 04m 58s 626ms\", \"eta\": \"06h 26m 33s 780ms\"}\n",
      "2020-06-09T02:55:30 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-09T02:58:34 INFO: {\"progress\": \"9600/22000\", \"train/total_loss\": \"0.0077\", \"train/total_loss/avg\": \"0.0442\", \"train/hateful_memes/cross_entropy\": \"0.0077\", \"train/hateful_memes/cross_entropy/avg\": \"0.0442\", \"train/hateful_memes/accuracy\": \"1.0000\", \"train/hateful_memes/accuracy/avg\": \"0.9840\", \"train/hateful_memes/binary_f1\": \"1.0000\", \"train/hateful_memes/binary_f1/avg\": \"0.9728\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9994\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 37, \"num_updates\": 9600, \"iterations\": 9600, \"max_updates\": 22000, \"lr\": \"0.00003\", \"ups\": \"0.54\", \"time\": \"03m 05s 927ms\", \"time_since_start\": \"05h 08m 04s 554ms\", \"eta\": \"06h 24m 15s 027ms\"}\n",
      "2020-06-09T02:58:36 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-09T03:01:40 INFO: {\"progress\": \"9700/22000\", \"train/total_loss\": \"0.0071\", \"train/total_loss/avg\": \"0.0438\", \"train/hateful_memes/cross_entropy\": \"0.0071\", \"train/hateful_memes/cross_entropy/avg\": \"0.0438\", \"train/hateful_memes/accuracy\": \"1.0000\", \"train/hateful_memes/accuracy/avg\": \"0.9842\", \"train/hateful_memes/binary_f1\": \"1.0000\", \"train/hateful_memes/binary_f1/avg\": \"0.9731\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9994\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 37, \"num_updates\": 9700, \"iterations\": 9700, \"max_updates\": 22000, \"lr\": \"0.00003\", \"ups\": \"0.54\", \"time\": \"03m 05s 911ms\", \"time_since_start\": \"05h 11m 10s 465ms\", \"eta\": \"06h 21m 07s 077ms\"}\n",
      "2020-06-09T03:01:42 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-09T03:04:46 INFO: {\"progress\": \"9800/22000\", \"train/total_loss\": \"0.0051\", \"train/total_loss/avg\": \"0.0434\", \"train/hateful_memes/cross_entropy\": \"0.0051\", \"train/hateful_memes/cross_entropy/avg\": \"0.0434\", \"train/hateful_memes/accuracy\": \"1.0000\", \"train/hateful_memes/accuracy/avg\": \"0.9844\", \"train/hateful_memes/binary_f1\": \"1.0000\", \"train/hateful_memes/binary_f1/avg\": \"0.9734\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9994\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 37, \"num_updates\": 9800, \"iterations\": 9800, \"max_updates\": 22000, \"lr\": \"0.00003\", \"ups\": \"0.54\", \"time\": \"03m 05s 729ms\", \"time_since_start\": \"05h 14m 16s 195ms\", \"eta\": \"06h 17m 39s 018ms\"}\n",
      "2020-06-09T03:04:47 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-09T03:07:52 INFO: {\"progress\": \"9900/22000\", \"train/total_loss\": \"0.0051\", \"train/total_loss/avg\": \"0.0430\", \"train/hateful_memes/cross_entropy\": \"0.0051\", \"train/hateful_memes/cross_entropy/avg\": \"0.0430\", \"train/hateful_memes/accuracy\": \"1.0000\", \"train/hateful_memes/accuracy/avg\": \"0.9845\", \"train/hateful_memes/binary_f1\": \"1.0000\", \"train/hateful_memes/binary_f1/avg\": \"0.9736\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9995\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 38, \"num_updates\": 9900, \"iterations\": 9900, \"max_updates\": 22000, \"lr\": \"0.00003\", \"ups\": \"0.54\", \"time\": \"03m 06s 027ms\", \"time_since_start\": \"05h 17m 22s 222ms\", \"eta\": \"06h 15m 09s 287ms\"}\n",
      "2020-06-09T03:07:53 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-09T03:10:57 INFO: {\"progress\": \"10000/22000\", \"train/total_loss\": \"0.0039\", \"train/total_loss/avg\": \"0.0426\", \"train/hateful_memes/cross_entropy\": \"0.0039\", \"train/hateful_memes/cross_entropy/avg\": \"0.0426\", \"train/hateful_memes/accuracy\": \"1.0000\", \"train/hateful_memes/accuracy/avg\": \"0.9847\", \"train/hateful_memes/binary_f1\": \"1.0000\", \"train/hateful_memes/binary_f1/avg\": \"0.9739\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9995\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 38, \"num_updates\": 10000, \"iterations\": 10000, \"max_updates\": 22000, \"lr\": \"0.00003\", \"ups\": \"0.54\", \"time\": \"03m 05s 615ms\", \"time_since_start\": \"05h 20m 27s 837ms\", \"eta\": \"06h 11m 13s 845ms\"}\n",
      "2020-06-09T03:10:57 INFO: Checkpoint time. Saving a checkpoint.\n",
      "2020-06-09T03:11:18 INFO: Evaluation time. Running on full validation set...\n",
      "2020-06-09T03:11:27 INFO: {\"progress\": \"10000/22000\", \"val/total_loss\": \"4.0005\", \"val/hateful_memes/cross_entropy\": \"4.0005\", \"val/hateful_memes/accuracy\": \"0.5760\", \"val/hateful_memes/binary_f1\": \"0.4011\", \"val/hateful_memes/roc_auc\": \"0.6255\", \"num_updates\": 10000, \"epoch\": 38, \"iterations\": 10000, \"max_updates\": 22000, \"val_time\": \"08s 922ms\", \"best_update\": 4000, \"best_iteration\": 4000, \"best_val/hateful_memes/roc_auc\": \"0.648812\"}\n",
      "2020-06-09T03:11:29 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-09T03:14:34 INFO: {\"progress\": \"10100/22000\", \"train/total_loss\": \"0.0027\", \"train/total_loss/avg\": \"0.0422\", \"train/hateful_memes/cross_entropy\": \"0.0027\", \"train/hateful_memes/cross_entropy/avg\": \"0.0422\", \"train/hateful_memes/accuracy\": \"1.0000\", \"train/hateful_memes/accuracy/avg\": \"0.9848\", \"train/hateful_memes/binary_f1\": \"1.0000\", \"train/hateful_memes/binary_f1/avg\": \"0.9742\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9995\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 38, \"num_updates\": 10100, \"iterations\": 10100, \"max_updates\": 22000, \"lr\": \"0.00003\", \"ups\": \"0.54\", \"time\": \"03m 06s 259ms\", \"time_since_start\": \"05h 24m 04s 182ms\", \"eta\": \"06h 09m 24s 903ms\"}\n",
      "2020-06-09T03:14:35 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-09T03:17:39 INFO: {\"progress\": \"10200/22000\", \"train/total_loss\": \"0.0023\", \"train/total_loss/avg\": \"0.0418\", \"train/hateful_memes/cross_entropy\": \"0.0023\", \"train/hateful_memes/cross_entropy/avg\": \"0.0418\", \"train/hateful_memes/accuracy\": \"1.0000\", \"train/hateful_memes/accuracy/avg\": \"0.9850\", \"train/hateful_memes/binary_f1\": \"1.0000\", \"train/hateful_memes/binary_f1/avg\": \"0.9744\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9995\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 39, \"num_updates\": 10200, \"iterations\": 10200, \"max_updates\": 22000, \"lr\": \"0.00003\", \"ups\": \"0.54\", \"time\": \"03m 05s 824ms\", \"time_since_start\": \"05h 27m 10s 006ms\", \"eta\": \"06h 05m 27s 245ms\"}\n",
      "2020-06-09T03:17:41 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-09T03:20:45 INFO: {\"progress\": \"10300/22000\", \"train/total_loss\": \"0.0020\", \"train/total_loss/avg\": \"0.0414\", \"train/hateful_memes/cross_entropy\": \"0.0020\", \"train/hateful_memes/cross_entropy/avg\": \"0.0414\", \"train/hateful_memes/accuracy\": \"1.0000\", \"train/hateful_memes/accuracy/avg\": \"0.9851\", \"train/hateful_memes/binary_f1\": \"1.0000\", \"train/hateful_memes/binary_f1/avg\": \"0.9747\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9995\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 39, \"num_updates\": 10300, \"iterations\": 10300, \"max_updates\": 22000, \"lr\": \"0.00003\", \"ups\": \"0.54\", \"time\": \"03m 05s 697ms\", \"time_since_start\": \"05h 30m 15s 704ms\", \"eta\": \"06h 02m 06s 639ms\"}\n",
      "2020-06-09T03:20:47 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-09T03:23:51 INFO: {\"progress\": \"10400/22000\", \"train/total_loss\": \"0.0017\", \"train/total_loss/avg\": \"0.0410\", \"train/hateful_memes/cross_entropy\": \"0.0017\", \"train/hateful_memes/cross_entropy/avg\": \"0.0410\", \"train/hateful_memes/accuracy\": \"1.0000\", \"train/hateful_memes/accuracy/avg\": \"0.9853\", \"train/hateful_memes/binary_f1\": \"1.0000\", \"train/hateful_memes/binary_f1/avg\": \"0.9749\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9995\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 40, \"num_updates\": 10400, \"iterations\": 10400, \"max_updates\": 22000, \"lr\": \"0.00003\", \"ups\": \"0.54\", \"time\": \"03m 05s 911ms\", \"time_since_start\": \"05h 33m 21s 615ms\", \"eta\": \"05h 59m 25s 694ms\"}\n",
      "2020-06-09T03:23:53 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-09T03:26:57 INFO: {\"progress\": \"10500/22000\", \"train/total_loss\": \"0.0017\", \"train/total_loss/avg\": \"0.0409\", \"train/hateful_memes/cross_entropy\": \"0.0017\", \"train/hateful_memes/cross_entropy/avg\": \"0.0409\", \"train/hateful_memes/accuracy\": \"1.0000\", \"train/hateful_memes/accuracy/avg\": \"0.9854\", \"train/hateful_memes/binary_f1\": \"1.0000\", \"train/hateful_memes/binary_f1/avg\": \"0.9751\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9995\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 40, \"num_updates\": 10500, \"iterations\": 10500, \"max_updates\": 22000, \"lr\": \"0.00003\", \"ups\": \"0.54\", \"time\": \"03m 05s 920ms\", \"time_since_start\": \"05h 36m 27s 536ms\", \"eta\": \"05h 56m 20s 901ms\"}\n",
      "2020-06-09T03:26:59 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-09T03:30:03 INFO: {\"progress\": \"10600/22000\", \"train/total_loss\": \"0.0017\", \"train/total_loss/avg\": \"0.0405\", \"train/hateful_memes/cross_entropy\": \"0.0017\", \"train/hateful_memes/cross_entropy/avg\": \"0.0405\", \"train/hateful_memes/accuracy\": \"1.0000\", \"train/hateful_memes/accuracy/avg\": \"0.9856\", \"train/hateful_memes/binary_f1\": \"1.0000\", \"train/hateful_memes/binary_f1/avg\": \"0.9754\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9995\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 40, \"num_updates\": 10600, \"iterations\": 10600, \"max_updates\": 22000, \"lr\": \"0.00003\", \"ups\": \"0.54\", \"time\": \"03m 05s 771ms\", \"time_since_start\": \"05h 39m 33s 308ms\", \"eta\": \"05h 52m 57s 984ms\"}\n",
      "2020-06-09T03:30:05 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-09T03:33:09 INFO: {\"progress\": \"10700/22000\", \"train/total_loss\": \"0.0017\", \"train/total_loss/avg\": \"0.0402\", \"train/hateful_memes/cross_entropy\": \"0.0017\", \"train/hateful_memes/cross_entropy/avg\": \"0.0402\", \"train/hateful_memes/accuracy\": \"1.0000\", \"train/hateful_memes/accuracy/avg\": \"0.9857\", \"train/hateful_memes/binary_f1\": \"1.0000\", \"train/hateful_memes/binary_f1/avg\": \"0.9756\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9995\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 41, \"num_updates\": 10700, \"iterations\": 10700, \"max_updates\": 22000, \"lr\": \"0.00003\", \"ups\": \"0.54\", \"time\": \"03m 06s 081ms\", \"time_since_start\": \"05h 42m 39s 389ms\", \"eta\": \"05h 50m 27s 171ms\"}\n",
      "2020-06-09T03:33:11 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-09T03:36:15 INFO: {\"progress\": \"10800/22000\", \"train/total_loss\": \"0.0017\", \"train/total_loss/avg\": \"0.0398\", \"train/hateful_memes/cross_entropy\": \"0.0017\", \"train/hateful_memes/cross_entropy/avg\": \"0.0398\", \"train/hateful_memes/accuracy\": \"1.0000\", \"train/hateful_memes/accuracy/avg\": \"0.9858\", \"train/hateful_memes/binary_f1\": \"1.0000\", \"train/hateful_memes/binary_f1/avg\": \"0.9758\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9995\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 41, \"num_updates\": 10800, \"iterations\": 10800, \"max_updates\": 22000, \"lr\": \"0.00003\", \"ups\": \"0.54\", \"time\": \"03m 05s 790ms\", \"time_since_start\": \"05h 45m 45s 180ms\", \"eta\": \"05h 46m 48s 555ms\"}\n",
      "2020-06-09T03:36:16 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-09T03:39:20 INFO: {\"progress\": \"10900/22000\", \"train/total_loss\": \"0.0020\", \"train/total_loss/avg\": \"0.0428\", \"train/hateful_memes/cross_entropy\": \"0.0020\", \"train/hateful_memes/cross_entropy/avg\": \"0.0428\", \"train/hateful_memes/accuracy\": \"1.0000\", \"train/hateful_memes/accuracy/avg\": \"0.9854\", \"train/hateful_memes/binary_f1\": \"1.0000\", \"train/hateful_memes/binary_f1/avg\": \"0.9752\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9993\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 41, \"num_updates\": 10900, \"iterations\": 10900, \"max_updates\": 22000, \"lr\": \"0.00003\", \"ups\": \"0.54\", \"time\": \"03m 05s 589ms\", \"time_since_start\": \"05h 48m 50s 769ms\", \"eta\": \"05h 43m 20s 392ms\"}\n",
      "2020-06-09T03:39:22 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-09T03:42:26 INFO: {\"progress\": \"11000/22000\", \"train/total_loss\": \"0.0017\", \"train/total_loss/avg\": \"0.0424\", \"train/hateful_memes/cross_entropy\": \"0.0017\", \"train/hateful_memes/cross_entropy/avg\": \"0.0424\", \"train/hateful_memes/accuracy\": \"1.0000\", \"train/hateful_memes/accuracy/avg\": \"0.9855\", \"train/hateful_memes/binary_f1\": \"1.0000\", \"train/hateful_memes/binary_f1/avg\": \"0.9754\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9993\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 42, \"num_updates\": 11000, \"iterations\": 11000, \"max_updates\": 22000, \"lr\": \"0.00003\", \"ups\": \"0.54\", \"time\": \"03m 06s 145ms\", \"time_since_start\": \"05h 51m 56s 915ms\", \"eta\": \"05h 41m 16s 037ms\"}\n",
      "2020-06-09T03:42:26 INFO: Checkpoint time. Saving a checkpoint.\n",
      "2020-06-09T03:42:47 INFO: Evaluation time. Running on full validation set...\n",
      "2020-06-09T03:42:56 INFO: {\"progress\": \"11000/22000\", \"val/total_loss\": \"3.8900\", \"val/hateful_memes/cross_entropy\": \"3.8900\", \"val/hateful_memes/accuracy\": \"0.5840\", \"val/hateful_memes/binary_f1\": \"0.4468\", \"val/hateful_memes/roc_auc\": \"0.6303\", \"num_updates\": 11000, \"epoch\": 42, \"iterations\": 11000, \"max_updates\": 22000, \"val_time\": \"08s 833ms\", \"best_update\": 4000, \"best_iteration\": 4000, \"best_val/hateful_memes/roc_auc\": \"0.648812\"}\n",
      "2020-06-09T03:42:58 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-09T03:46:03 INFO: {\"progress\": \"11100/22000\", \"train/total_loss\": \"0.0017\", \"train/total_loss/avg\": \"0.0420\", \"train/hateful_memes/cross_entropy\": \"0.0017\", \"train/hateful_memes/cross_entropy/avg\": \"0.0420\", \"train/hateful_memes/accuracy\": \"1.0000\", \"train/hateful_memes/accuracy/avg\": \"0.9856\", \"train/hateful_memes/binary_f1\": \"1.0000\", \"train/hateful_memes/binary_f1/avg\": \"0.9757\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9993\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 42, \"num_updates\": 11100, \"iterations\": 11100, \"max_updates\": 22000, \"lr\": \"0.00003\", \"ups\": \"0.54\", \"time\": \"03m 06s 405ms\", \"time_since_start\": \"05h 55m 33s 156ms\", \"eta\": \"05h 38m 38s 160ms\"}\n",
      "2020-06-09T03:46:04 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-09T03:49:09 INFO: {\"progress\": \"11200/22000\", \"train/total_loss\": \"0.0017\", \"train/total_loss/avg\": \"0.0417\", \"train/hateful_memes/cross_entropy\": \"0.0017\", \"train/hateful_memes/cross_entropy/avg\": \"0.0417\", \"train/hateful_memes/accuracy\": \"1.0000\", \"train/hateful_memes/accuracy/avg\": \"0.9858\", \"train/hateful_memes/binary_f1\": \"1.0000\", \"train/hateful_memes/binary_f1/avg\": \"0.9759\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9993\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 43, \"num_updates\": 11200, \"iterations\": 11200, \"max_updates\": 22000, \"lr\": \"0.00003\", \"ups\": \"0.54\", \"time\": \"03m 06s 207ms\", \"time_since_start\": \"05h 58m 39s 364ms\", \"eta\": \"05h 35m 10s 459ms\"}\n",
      "2020-06-09T03:49:11 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-09T03:52:14 INFO: {\"progress\": \"11300/22000\", \"train/total_loss\": \"0.0017\", \"train/total_loss/avg\": \"0.0413\", \"train/hateful_memes/cross_entropy\": \"0.0017\", \"train/hateful_memes/cross_entropy/avg\": \"0.0413\", \"train/hateful_memes/accuracy\": \"1.0000\", \"train/hateful_memes/accuracy/avg\": \"0.9859\", \"train/hateful_memes/binary_f1\": \"1.0000\", \"train/hateful_memes/binary_f1/avg\": \"0.9761\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9993\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 43, \"num_updates\": 11300, \"iterations\": 11300, \"max_updates\": 22000, \"lr\": \"0.00003\", \"ups\": \"0.54\", \"time\": \"03m 05s 697ms\", \"time_since_start\": \"06h 01m 45s 062ms\", \"eta\": \"05h 31m 09s 661ms\"}\n",
      "2020-06-09T03:52:16 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-09T03:55:20 INFO: {\"progress\": \"11400/22000\", \"train/total_loss\": \"0.0017\", \"train/total_loss/avg\": \"0.0412\", \"train/hateful_memes/cross_entropy\": \"0.0017\", \"train/hateful_memes/cross_entropy/avg\": \"0.0412\", \"train/hateful_memes/accuracy\": \"1.0000\", \"train/hateful_memes/accuracy/avg\": \"0.9857\", \"train/hateful_memes/binary_f1\": \"1.0000\", \"train/hateful_memes/binary_f1/avg\": \"0.9758\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9993\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 43, \"num_updates\": 11400, \"iterations\": 11400, \"max_updates\": 22000, \"lr\": \"0.00003\", \"ups\": \"0.54\", \"time\": \"03m 05s 623ms\", \"time_since_start\": \"06h 04m 50s 685ms\", \"eta\": \"05h 27m 56s 053ms\"}\n",
      "2020-06-09T03:55:22 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-09T03:58:26 INFO: {\"progress\": \"11500/22000\", \"train/total_loss\": \"0.0017\", \"train/total_loss/avg\": \"0.0409\", \"train/hateful_memes/cross_entropy\": \"0.0017\", \"train/hateful_memes/cross_entropy/avg\": \"0.0409\", \"train/hateful_memes/accuracy\": \"1.0000\", \"train/hateful_memes/accuracy/avg\": \"0.9859\", \"train/hateful_memes/binary_f1\": \"1.0000\", \"train/hateful_memes/binary_f1/avg\": \"0.9760\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9993\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 44, \"num_updates\": 11500, \"iterations\": 11500, \"max_updates\": 22000, \"lr\": \"0.00003\", \"ups\": \"0.54\", \"time\": \"03m 05s 857ms\", \"time_since_start\": \"06h 07m 56s 542ms\", \"eta\": \"05h 25m 15s 038ms\"}\n",
      "2020-06-09T03:58:28 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-09T04:01:31 INFO: {\"progress\": \"11600/22000\", \"train/total_loss\": \"0.0017\", \"train/total_loss/avg\": \"0.0406\", \"train/hateful_memes/cross_entropy\": \"0.0017\", \"train/hateful_memes/cross_entropy/avg\": \"0.0406\", \"train/hateful_memes/accuracy\": \"1.0000\", \"train/hateful_memes/accuracy/avg\": \"0.9860\", \"train/hateful_memes/binary_f1\": \"1.0000\", \"train/hateful_memes/binary_f1/avg\": \"0.9762\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9993\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 44, \"num_updates\": 11600, \"iterations\": 11600, \"max_updates\": 22000, \"lr\": \"0.00003\", \"ups\": \"0.54\", \"time\": \"03m 05s 467ms\", \"time_since_start\": \"06h 11m 02s 009ms\", \"eta\": \"05h 21m 28s 577ms\"}\n",
      "2020-06-09T04:01:33 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-09T04:04:37 INFO: {\"progress\": \"11700/22000\", \"train/total_loss\": \"0.0016\", \"train/total_loss/avg\": \"0.0403\", \"train/hateful_memes/cross_entropy\": \"0.0016\", \"train/hateful_memes/cross_entropy/avg\": \"0.0403\", \"train/hateful_memes/accuracy\": \"1.0000\", \"train/hateful_memes/accuracy/avg\": \"0.9861\", \"train/hateful_memes/binary_f1\": \"1.0000\", \"train/hateful_memes/binary_f1/avg\": \"0.9764\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9993\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 44, \"num_updates\": 11700, \"iterations\": 11700, \"max_updates\": 22000, \"lr\": \"0.00003\", \"ups\": \"0.54\", \"time\": \"03m 05s 466ms\", \"time_since_start\": \"06h 14m 07s 476ms\", \"eta\": \"05h 18m 23s 094ms\"}\n",
      "2020-06-09T04:04:39 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-09T04:07:43 INFO: {\"progress\": \"11800/22000\", \"train/total_loss\": \"0.0016\", \"train/total_loss/avg\": \"0.0400\", \"train/hateful_memes/cross_entropy\": \"0.0016\", \"train/hateful_memes/cross_entropy/avg\": \"0.0400\", \"train/hateful_memes/accuracy\": \"1.0000\", \"train/hateful_memes/accuracy/avg\": \"0.9862\", \"train/hateful_memes/binary_f1\": \"1.0000\", \"train/hateful_memes/binary_f1/avg\": \"0.9766\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9993\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 45, \"num_updates\": 11800, \"iterations\": 11800, \"max_updates\": 22000, \"lr\": \"0.00003\", \"ups\": \"0.54\", \"time\": \"03m 05s 955ms\", \"time_since_start\": \"06h 17m 13s 432ms\", \"eta\": \"05h 16m 07s 510ms\"}\n",
      "2020-06-09T04:07:45 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-09T04:10:48 INFO: {\"progress\": \"11900/22000\", \"train/total_loss\": \"0.0016\", \"train/total_loss/avg\": \"0.0397\", \"train/hateful_memes/cross_entropy\": \"0.0016\", \"train/hateful_memes/cross_entropy/avg\": \"0.0397\", \"train/hateful_memes/accuracy\": \"1.0000\", \"train/hateful_memes/accuracy/avg\": \"0.9863\", \"train/hateful_memes/binary_f1\": \"1.0000\", \"train/hateful_memes/binary_f1/avg\": \"0.9768\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9994\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 45, \"num_updates\": 11900, \"iterations\": 11900, \"max_updates\": 22000, \"lr\": \"0.00003\", \"ups\": \"0.54\", \"time\": \"03m 05s 571ms\", \"time_since_start\": \"06h 20m 19s 004ms\", \"eta\": \"05h 12m 22s 695ms\"}\n",
      "2020-06-09T04:10:50 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-09T04:13:54 INFO: {\"progress\": \"12000/22000\", \"train/total_loss\": \"0.0016\", \"train/total_loss/avg\": \"0.0393\", \"train/hateful_memes/cross_entropy\": \"0.0016\", \"train/hateful_memes/cross_entropy/avg\": \"0.0393\", \"train/hateful_memes/accuracy\": \"1.0000\", \"train/hateful_memes/accuracy/avg\": \"0.9865\", \"train/hateful_memes/binary_f1\": \"1.0000\", \"train/hateful_memes/binary_f1/avg\": \"0.9770\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9994\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 46, \"num_updates\": 12000, \"iterations\": 12000, \"max_updates\": 22000, \"lr\": \"0.00003\", \"ups\": \"0.54\", \"time\": \"03m 05s 999ms\", \"time_since_start\": \"06h 23m 25s 003ms\", \"eta\": \"05h 09m 59s 938ms\"}\n",
      "2020-06-09T04:13:54 INFO: Checkpoint time. Saving a checkpoint.\n",
      "2020-06-09T04:14:14 INFO: Evaluation time. Running on full validation set...\n",
      "2020-06-09T04:14:23 INFO: {\"progress\": \"12000/22000\", \"val/total_loss\": \"4.3616\", \"val/hateful_memes/cross_entropy\": \"4.3616\", \"val/hateful_memes/accuracy\": \"0.5580\", \"val/hateful_memes/binary_f1\": \"0.3775\", \"val/hateful_memes/roc_auc\": \"0.6209\", \"num_updates\": 12000, \"epoch\": 46, \"iterations\": 12000, \"max_updates\": 22000, \"val_time\": \"08s 893ms\", \"best_update\": 4000, \"best_iteration\": 4000, \"best_val/hateful_memes/roc_auc\": \"0.648812\"}\n",
      "2020-06-09T04:14:26 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "2020-06-09T04:17:30 INFO: {\"progress\": \"12100/22000\", \"train/total_loss\": \"0.0016\", \"train/total_loss/avg\": \"0.0391\", \"train/hateful_memes/cross_entropy\": \"0.0016\", \"train/hateful_memes/cross_entropy/avg\": \"0.0391\", \"train/hateful_memes/accuracy\": \"1.0000\", \"train/hateful_memes/accuracy/avg\": \"0.9866\", \"train/hateful_memes/binary_f1\": \"1.0000\", \"train/hateful_memes/binary_f1/avg\": \"0.9772\", \"train/hateful_memes/roc_auc\": \"1.0000\", \"train/hateful_memes/roc_auc/avg\": \"0.9994\", \"max mem\": 12643.0, \"experiment\": \"run\", \"epoch\": 46, \"num_updates\": 12100, \"iterations\": 12100, \"max_updates\": 22000, \"lr\": \"0.00002\", \"ups\": \"0.54\", \"time\": \"03m 06s 514ms\", \"time_since_start\": \"06h 27m 849ms\", \"eta\": \"05h 07m 44s 965ms\"}\n",
      "2020-06-09T04:17:32 WARNING: /opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!MMF_SAVE_DIR=\"/home/jupyter/meme_hateful_detection/save/late_fusion\" mmf_run config=configs/late_fusion/defaults_custom.yaml model=late_fusion dataset=hateful_memes run_type=train checkpoint.resume_zoo=late_fusion.hateful_memes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !MMF_SAVE_DIR=\"/home/jupyter/meme_hateful_detection/save/late_fusion\" mmf_run config=configs/late_fusion/defaults_custom.yaml model=late_fusion dataset=hateful_memes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !MMF_SAVE_DIR=\"/home/jupyter/meme_hateful_detection/save/concat_bert\" mmf_run config=configs/concat_bert/defaults_custom.yaml model=concat_bert dataset=hateful_memes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation\n",
    "for index, row in df_model_config.iterrows():\n",
    "    model_baseline = row['baseline']\n",
    "    model_key = row['model_key']\n",
    "    model_pretrained_key = row['pretrained_key']\n",
    "    baseline_config = row['baseline_config']\n",
    "    custom_config = row['custom_config']\n",
    "    str_run_eval  = f'mmf_run config={custom_config} model={model_key} dataset=hateful_memes run_type=val'\n",
    "#     !{str_run_eval}\n",
    "    print(str_run_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predictions val\n",
    "for index, row in df_model_config.iterrows():\n",
    "    model_baseline = row['baseline']\n",
    "    model_key = row['model_key']\n",
    "    model_pretrained_key = row['pretrained_key']\n",
    "    baseline_config = row['baseline_config']\n",
    "    custom_config = row['custom_config']\n",
    "    str_pred_eval = f'mmf_predict config={custom_config} model={model_key} dataset=hateful_memes run_type=train --evalai_inference=1 --resume_file={PATH_SAVE}/model_key.pth'\n",
    "#     !{str_pred_eval}\n",
    "    print(str_pred_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mmf_predict config=configs/unimodal/image_custom.yaml model=unimodal_image dataset=hateful_memes run_type=train evalai_inference=1 resume_file=/home/jupyter/meme_hateful_detection/save/unimodal_image_grid.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading pretrained model in your code\n",
    "model_baseline = 'Image-Grid'\n",
    "model_key = 'unimodal_image'\n",
    "model_pretrained_key = 'unimodal_image.hateful_memes.images'\n",
    "baseline_config = 'configs/unimodal/image.yaml'\n",
    "custom_config = row['custom_config']\n",
    "# Training\n",
    "str_run_train = f'mmf_run config={custom_config} model={model_key} dataset=hateful_memes'\n",
    "# Evaluation\n",
    "str_run_eval  = f'mmf_run config={custom_config} model={model_key} dataset=hateful_memes run_type=val'\n",
    "# Predictions val\n",
    "str_pred_eval = f'mmf_predict config={custom_config} model={model_key} dataset=hateful_memes run_type=train'\n",
    "# Predictions test\n",
    "str_pred_test = f'mmf_predict config={custom_config} model={model_key} dataset=hateful_memes run_type=test'\n",
    "# Evaluating Train dataset\n",
    "str_pret_eval = f'mmf_run config={custom_config} model={model_key} dataset=hateful_memes run_type=train checkpoint.resume_zoo={model_pretrained_key}'\n",
    "\n",
    "# Evaluating Pretrained Models\n",
    "str_pret_eval = f'mmf_run config={custom_config} model={model_key} dataset=hateful_memes run_type=val checkpoint.resume_zoo={model_pretrained_key}'\n",
    "# Predictions Pretrained Models\n",
    "str_pret_test = f'mmf_predict config={custom_config} model={model_key} dataset=hateful_memes run_type=test checkpoint.resume_zoo={model_pretrained_key}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "#Val\n",
    "for index, row in df_model_config.iterrows():\n",
    "    model_baseline = row['baseline']\n",
    "    model_key = row['model_key']\n",
    "    model_pretrained_key = row['pretrained_key']\n",
    "    baseline_config = row['baseline_config']\n",
    "    custom_config = row['custom_config']\n",
    "    str_exec = f'mmf_run config={custom_config} model={model_key} dataset=hateful_memes run_type=val checkpoint.resume_zoo={model_pretrained_key} evalai_inference=1 resume_file=data/[model].pth'\n",
    "    !{str_exec}\n",
    "#     print(str_exec)\n",
    "# python tools/run.py --datasets [dataset] --model [model] --config [config] \\\n",
    "# --run_type inference --evalai_inference 1 --resume_file data/[model].pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test\n",
    "for index, row in df_model_config.iterrows():\n",
    "    model_baseline = row['baseline']\n",
    "    model_key = row['model_key']\n",
    "    model_pretrained_key = row['pretrained_key']\n",
    "    baseline_config = row['baseline_config']\n",
    "    custom_config = row['custom_config']\n",
    "    str_exec = f'mmf_predict config={baseline_config} model={model_key} dataset=hateful_memes run_type=test checkpoint.resume_zoo={model_pretrained_key}'\n",
    "    !{str_exec}\n",
    "#     print(str_exec)\n",
    "#     MMF_USER_DIR=\".\" mmf_run config=\"configs/experiments/defaults.yaml\"  model=concat_vl dataset=hateful_memes training.num_workers=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmf.common.registry import registry\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "model_cls = registry.get_model_class(\"unimodal_image\")\n",
    "model = model_cls.from_pretrained(\"unimodal_image.hateful_memes.images\")\n",
    "model.summary()\n",
    "model_name.classifier[0]\n",
    "# default `log_dir` is \"runs\" - we'll be more specific here\n",
    "# writer = SummaryWriter('/home/jupyter/meme_hateful_detection/save/logs')\n",
    "# writer.add_graph(model)\n",
    "# writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "\n",
    "writer = SummaryWriter()\n",
    "writer = SummaryWriter('/home/jupyter/meme_hateful_detection/save/logs')\n",
    "for n_iter in range(100):\n",
    "    writer.add_scalar('Loss/train', np.random.random(), n_iter)\n",
    "    writer.add_scalar('Loss/test', np.random.random(), n_iter)\n",
    "    writer.add_scalar('Accuracy/train', np.random.random(), n_iter)\n",
    "    writer.add_scalar('Accuracy/test', np.random.random(), n_iter)\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-4.m46",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m46"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
