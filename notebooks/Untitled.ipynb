{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/jupyter/meme_hateful_detection/notebooks', '/opt/conda/lib/python37.zip', '/opt/conda/lib/python3.7', '/opt/conda/lib/python3.7/lib-dynload', '', '/opt/conda/lib/python3.7/site-packages', '/opt/conda/lib/python3.7/site-packages/IPython/extensions', '/home/jupyter/.ipython', '/home/jupyter/meme_hateful_detection', '/home/jupyter/meme_hateful_detection/src', '/home/jupyter/meme_hateful_detection/models', '/home/jupyter/meme_hateful_detection/data/raw/flickr8k_images_text', '/home/jupyter/meme_hateful_detection/data/raw/test_images', '/home/jupyter/meme_hateful_detection/src/cap_generator']\n"
     ]
    }
   ],
   "source": [
    "from pickle import load\n",
    "import numpy as np\n",
    "import argparse\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "import os\n",
    "PATH_CURRENT = '/home/jupyter/meme_hateful_detection'\n",
    "\n",
    "PATH_CODE = f'{PATH_CURRENT}/src'\n",
    "PATH_DATA = f'{PATH_CURRENT}/data'\n",
    "PATH_MODEL = f'{PATH_CURRENT}/models'\n",
    "PATH_NOTEBOOKS = f'{PATH_CURRENT}/notebooks'\n",
    "\n",
    "PATH_DEV_IMAGES = f'{PATH_CURRENT}/data/raw/flickr8k_images'\n",
    "PATH_TEST_IMAGES = f'{PATH_CURRENT}/data/raw/test_images'\n",
    "PATH_TRAIN_IMAGES = f'{PATH_CURRENT}/data/raw/flickr8k_images'\n",
    "PATH_TRAIN_IMAGES_TEXT = f'{PATH_CURRENT}/data/raw/flickr8k_images_text'\n",
    "PATH_TRAIN_MEMES = f'{PATH_CURRENT}/data/raw/facebook_memes'\n",
    "PATH_MEMES_DATASET = f'{PATH_CURRENT}/data/raw/meme_dataset'\n",
    "\n",
    "PATH_IMAGE_GENERATOR = f'{PATH_CODE}/cap_generator'\n",
    "\n",
    "# module_path = PATH_CURRENT\n",
    "if PATH_CURRENT not in sys.path:\n",
    "    sys.path.append(PATH_CURRENT)\n",
    "if PATH_CODE not in sys.path:\n",
    "    sys.path.append(PATH_CODE)\n",
    "if PATH_MODEL not in sys.path:\n",
    "    sys.path.append(PATH_MODEL)\n",
    "if PATH_TRAIN_IMAGES_TEXT not in sys.path:\n",
    "    sys.path.append(PATH_TRAIN_IMAGES_TEXT)\n",
    "if PATH_TEST_IMAGES not in sys.path:\n",
    "    sys.path.append(PATH_TEST_IMAGES)\n",
    "if PATH_IMAGE_GENERATOR not in sys.path:\n",
    "    sys.path.append(PATH_IMAGE_GENERATOR)\n",
    "    \n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cap_generator import load_data as ld\n",
    "from cap_generator import generate_model as gen\n",
    "from cap_generator import eval_model as em\n",
    "\n",
    "def generate_description(image_file):\n",
    "  tokenizer = load(open(f'{PATH_MODEL}/tokenizer.pkl', 'rb'))\n",
    "  index_word = load(open(f'{PATH_MODEL}/index_word.pkl', 'rb'))\n",
    "  # pre-define the max sequence length (from training)\n",
    "  max_length = 34\n",
    "\n",
    "  # load the model\n",
    "  filename = f'{PATH_MODEL}/model_weight.h5'\n",
    "  model = load_model(filename)\n",
    "\n",
    "  image=f'/home/jupyter/meme_hateful_detection/data/raw/facebook_memes/{image_file}'\n",
    "  photo = em.extract_features(image)\n",
    "  # generate description\n",
    "  captions = em.generate_desc(model, tokenizer, photo, index_word, max_length)\n",
    "  for cap in captions:\n",
    "    # remove start and end tokens\n",
    "    seq = cap[0].split()[1:-1]\n",
    "    desc = ' '.join(seq)\n",
    "    print('{} [log prob: {:1.2f}]'.format(desc,cap[1]))\n",
    "  else:\n",
    "    # load test set\n",
    "    test_features, test_descriptions = ld.prepare_dataset('test')[1]\n",
    "  return(desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group of people sit in the water [log prob: -10.94]\n",
      "group of people sit on the street [log prob: -11.03]\n",
      "group of people are sitting in the water [log prob: -12.22]\n",
      "group of people are sitting on the edge of the water [log prob: -16.51]\n",
      "group of people are sitting on the edge of the amusement street [log prob: -18.38]\n",
      "Dataset: 1000\n",
      "Descriptions: test=1000\n",
      "Photos: test=1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'group of people are sitting on the edge of the amusement street'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_description('08291.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-1.m46",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-1:m46"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
