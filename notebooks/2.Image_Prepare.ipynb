{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "PATH_CURRENT = '/home/jupyter/meme_hateful_detection'\n",
    "\n",
    "\n",
    "PATH_CODE = f'{PATH_CURRENT}/src'\n",
    "PATH_DATA = f'{PATH_CURRENT}/data'\n",
    "PATH_MODEL = f'{PATH_CURRENT}/models'\n",
    "PATH_NOTEBOOKS = f'{PATH_CURRENT}/notebooks'\n",
    "\n",
    "PATH_DEV_IMAGES = f'{PATH_CURRENT}/data/raw/flickr8k_images_dev'\n",
    "PATH_TEST_IMAGES = f'{PATH_CURRENT}/data/raw/flickr8k_images'\n",
    "PATH_TRAIN_IMAGES = f'{PATH_CURRENT}/data/raw/flickr8k_images'\n",
    "PATH_TRAIN_IMAGES_TEXT = f'{PATH_CURRENT}/data/raw/flickr8k_images_text'\n",
    "PATH_TRAIN_MEMES = f'{PATH_CURRENT}/data/raw/facebook_memes'\n",
    "PATH_MEMES_DATASET = f'{PATH_CURRENT}/data/raw/meme_dataset'\n",
    "\n",
    "PATH_IMAGE_GENERATOR = f'{PATH_CODE}/cap_generator'\n",
    "\n",
    "# module_path = PATH_CURRENT\n",
    "if PATH_CURRENT not in sys.path:\n",
    "    sys.path.append(PATH_CURRENT)\n",
    "if PATH_CODE not in sys.path:\n",
    "    sys.path.append(PATH_CODE)\n",
    "if PATH_MODEL not in sys.path:\n",
    "    sys.path.append(PATH_MODEL)\n",
    "if PATH_TRAIN_IMAGES_TEXT not in sys.path:\n",
    "    sys.path.append(PATH_TRAIN_IMAGES_TEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!export PYTHONPATH=/home/jupyter/meme_hateful_detection/src;/home/jupyter/meme_hateful_detection/data;/home/jupyter/meme_hateful_detection/models;/home/jupyter/meme_hateful_detection/data/raw/flickr8k_images_text;/home/jupyter/meme_hateful_detection/src/cap_generator\n"
     ]
    }
   ],
   "source": [
    "string = f'!export PYTHONPATH={PATH_CODE};{PATH_DATA};{PATH_MODEL};{PATH_TRAIN_IMAGES_TEXT};{PATH_IMAGE_GENERATOR}'\n",
    "print(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from cap_generator import load_data as ld\n",
    "from cap_generator import prepare_data as prd\n",
    "from cap_generator import train_model as tm\n",
    "from cap_generator import eval_model as em\n",
    "from pickle import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = PATH_DEV_IMAGES\n",
    "# prepare descriptions\n",
    "filename = f'{PATH_TRAIN_IMAGES_TEXT}/Flickr8k.token.txt'\n",
    "features_file = f'{PATH_MODEL}/features.pkl'\n",
    "descriptions_file = f'{PATH_MODEL}/descriptions.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract features from all images\n",
    "features = prd.extract_features(directory)\n",
    "print('Extracted Features: %d' % len(features))\n",
    "# # save to file\n",
    "dump(features, open(features_file, 'wb'))\n",
    "# load descriptions\n",
    "doc = prd.load_doc(filename)\n",
    "# # parse descriptions\n",
    "descriptions = prd.load_descriptions(doc)\n",
    "print('Loaded: %d ' % len(descriptions))\n",
    "# # clean descriptions\n",
    "prd.clean_descriptions(descriptions)\n",
    "# # summarize vocabulary\n",
    "vocabulary = prd.to_vocabulary(descriptions)\n",
    "print('Vocabulary Size: %d' % len(vocabulary))\n",
    "# # save to file\n",
    "prd.save_descriptions(descriptions, descriptions_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: 13\n",
      "Descriptions: train=13, test=13\n",
      "Photos: train=13, test=13\n",
      "Vocabulary Size: 209\n",
      "Description Length: 21\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 4096)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 4096)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          1048832     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 21)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_1 (RepeatVector)  (None, 21, 256)      0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 21, 256)      53504       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 21, 512)      0           repeat_vector_1[0][0]            \n",
      "                                                                 embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 500)          2026000     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 209)          104709      lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 3,233,045\n",
      "Trainable params: 3,233,045\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "13/13 [==============================] - 16s 1s/step - loss: 5.0771 - accuracy: 0.0626 - val_loss: 5.0425 - val_accuracy: 0.0939\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 5.04254, saving model to /home/jupyter/meme_hateful_detection/models/model-ep001-loss5.078-val_loss5.043.h5\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 13s 983ms/step - loss: 4.5205 - accuracy: 0.0912 - val_loss: 4.7128 - val_accuracy: 0.1143\n",
      "\n",
      "Epoch 00002: val_loss improved from 5.04254 to 4.71280, saving model to /home/jupyter/meme_hateful_detection/models/model-ep002-loss4.536-val_loss4.713.h5\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 13s 1s/step - loss: 4.1620 - accuracy: 0.1156 - val_loss: 4.4113 - val_accuracy: 0.1116\n",
      "\n",
      "Epoch 00003: val_loss improved from 4.71280 to 4.41128, saving model to /home/jupyter/meme_hateful_detection/models/model-ep003-loss4.193-val_loss4.411.h5\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 13s 1s/step - loss: 3.9183 - accuracy: 0.1197 - val_loss: 4.0884 - val_accuracy: 0.1224\n",
      "\n",
      "Epoch 00004: val_loss improved from 4.41128 to 4.08840, saving model to /home/jupyter/meme_hateful_detection/models/model-ep004-loss3.955-val_loss4.088.h5\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 13s 988ms/step - loss: 3.7544 - accuracy: 0.1116 - val_loss: 3.9650 - val_accuracy: 0.1129\n",
      "\n",
      "Epoch 00005: val_loss improved from 4.08840 to 3.96500, saving model to /home/jupyter/meme_hateful_detection/models/model-ep005-loss3.799-val_loss3.965.h5\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 13s 989ms/step - loss: 3.6218 - accuracy: 0.1061 - val_loss: 3.7416 - val_accuracy: 0.1320\n",
      "\n",
      "Epoch 00006: val_loss improved from 3.96500 to 3.74157, saving model to /home/jupyter/meme_hateful_detection/models/model-ep006-loss3.664-val_loss3.742.h5\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 13s 991ms/step - loss: 3.4429 - accuracy: 0.1238 - val_loss: 3.5961 - val_accuracy: 0.1429\n",
      "\n",
      "Epoch 00007: val_loss improved from 3.74157 to 3.59613, saving model to /home/jupyter/meme_hateful_detection/models/model-ep007-loss3.482-val_loss3.596.h5\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 13s 985ms/step - loss: 3.2806 - accuracy: 0.1347 - val_loss: 3.4081 - val_accuracy: 0.1755\n",
      "\n",
      "Epoch 00008: val_loss improved from 3.59613 to 3.40809, saving model to /home/jupyter/meme_hateful_detection/models/model-ep008-loss3.317-val_loss3.408.h5\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 13s 1s/step - loss: 3.1998 - accuracy: 0.1592 - val_loss: 3.3991 - val_accuracy: 0.1741\n",
      "\n",
      "Epoch 00009: val_loss improved from 3.40809 to 3.39906, saving model to /home/jupyter/meme_hateful_detection/models/model-ep009-loss3.234-val_loss3.399.h5\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 13s 990ms/step - loss: 3.1278 - accuracy: 0.1442 - val_loss: 3.3094 - val_accuracy: 0.1633\n",
      "\n",
      "Epoch 00010: val_loss improved from 3.39906 to 3.30939, saving model to /home/jupyter/meme_hateful_detection/models/model-ep010-loss3.160-val_loss3.309.h5\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 13s 998ms/step - loss: 3.0987 - accuracy: 0.1483 - val_loss: 3.1876 - val_accuracy: 0.1850\n",
      "\n",
      "Epoch 00011: val_loss improved from 3.30939 to 3.18759, saving model to /home/jupyter/meme_hateful_detection/models/model-ep011-loss3.129-val_loss3.188.h5\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 13s 1s/step - loss: 3.0255 - accuracy: 0.1755 - val_loss: 3.1231 - val_accuracy: 0.2027\n",
      "\n",
      "Epoch 00012: val_loss improved from 3.18759 to 3.12308, saving model to /home/jupyter/meme_hateful_detection/models/model-ep012-loss3.055-val_loss3.123.h5\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 13s 1s/step - loss: 2.9615 - accuracy: 0.1878 - val_loss: 3.0327 - val_accuracy: 0.2340\n",
      "\n",
      "Epoch 00013: val_loss improved from 3.12308 to 3.03272, saving model to /home/jupyter/meme_hateful_detection/models/model-ep013-loss2.991-val_loss3.033.h5\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 13s 998ms/step - loss: 2.8997 - accuracy: 0.2218 - val_loss: 3.1056 - val_accuracy: 0.2626\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 3.03272\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 13s 981ms/step - loss: 2.8282 - accuracy: 0.2367 - val_loss: 2.9841 - val_accuracy: 0.2667\n",
      "\n",
      "Epoch 00015: val_loss improved from 3.03272 to 2.98414, saving model to /home/jupyter/meme_hateful_detection/models/model-ep015-loss2.859-val_loss2.984.h5\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 13s 993ms/step - loss: 2.7171 - accuracy: 0.2449 - val_loss: 2.8338 - val_accuracy: 0.2898\n",
      "\n",
      "Epoch 00016: val_loss improved from 2.98414 to 2.83378, saving model to /home/jupyter/meme_hateful_detection/models/model-ep016-loss2.749-val_loss2.834.h5\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 13s 1000ms/step - loss: 2.6378 - accuracy: 0.2762 - val_loss: 2.6880 - val_accuracy: 0.3170\n",
      "\n",
      "Epoch 00017: val_loss improved from 2.83378 to 2.68797, saving model to /home/jupyter/meme_hateful_detection/models/model-ep017-loss2.669-val_loss2.688.h5\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 13s 973ms/step - loss: 2.5476 - accuracy: 0.2816 - val_loss: 2.6179 - val_accuracy: 0.3687\n",
      "\n",
      "Epoch 00018: val_loss improved from 2.68797 to 2.61794, saving model to /home/jupyter/meme_hateful_detection/models/model-ep018-loss2.578-val_loss2.618.h5\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 13s 981ms/step - loss: 2.4262 - accuracy: 0.3293 - val_loss: 2.4907 - val_accuracy: 0.3973\n",
      "\n",
      "Epoch 00019: val_loss improved from 2.61794 to 2.49071, saving model to /home/jupyter/meme_hateful_detection/models/model-ep019-loss2.452-val_loss2.491.h5\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 13s 1s/step - loss: 2.2975 - accuracy: 0.3660 - val_loss: 2.4305 - val_accuracy: 0.4231\n",
      "\n",
      "Epoch 00020: val_loss improved from 2.49071 to 2.43048, saving model to /home/jupyter/meme_hateful_detection/models/model-ep020-loss2.331-val_loss2.430.h5\n",
      "Training complete...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tm.train_model(epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python: can't open file 'eval_model.py': [Errno 2] No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!python eval_model.py -i ~/meme_hateful_detection/data/raw/test_images/dog.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-1.m46",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-1:m46"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
